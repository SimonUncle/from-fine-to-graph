{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ Day 1 ì‹¤ìŠµ 4: ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- **í•µì‹¬ ëª©í‘œ**: íŒŒì¸íŠœë‹ ì „ (ë² ì´ìŠ¤ë¼ì¸) vs í›„ (íŒŒì¸íŠœë‹) ëª¨ë¸ ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµ\n",
    "- ROUGE, BLEU, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë“± ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •\n",
    "- RAG ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì‹¤ì œ ì„±ëŠ¥ ê°œì„  í™•ì¸\n",
    "- ì‹œê°í™”ë¥¼ í†µí•œ ì„±ëŠ¥ ì°¨ì´ ë¶„ì„\n",
    "- íŒŒì¸íŠœë‹ íš¨ê³¼ì— ëŒ€í•œ ì¢…í•©ì  í‰ê°€\n",
    "\n",
    "### ğŸ’¡ Day 1 ì‹¤ìŠµì˜ í•µì‹¬\n",
    "**ë² ì´ìŠ¤ë¼ì¸(ì›ë³¸ ëª¨ë¸) vs íŒŒì¸íŠœë‹ ëª¨ë¸** ì„±ëŠ¥ ë¹„êµë¥¼ í†µí•´ \n",
    "**RAFT íŒŒì¸íŠœë‹ì´ ì‹¤ì œë¡œ RAG ì„±ëŠ¥ì„ ê°œì„ í–ˆëŠ”ì§€ ê²€ì¦**í•˜ëŠ” ê²ƒì´ ì´ ì‹¤ìŠµì˜ ê°€ì¥ ì¤‘ìš”í•œ ëª©í‘œì…ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸ ë° ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš° ìŠ¤í‚µ)\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def check_and_install_package(package_name, import_name=None, version=None):\n",
    "    \"\"\"\n",
    "    íŒ¨í‚¤ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ í•„ìš”ì‹œì—ë§Œ ì„¤ì¹˜\n",
    "    \n",
    "    Args:\n",
    "        package_name: pipë¡œ ì„¤ì¹˜í•  íŒ¨í‚¤ì§€ëª…\n",
    "        import_name: importí•  ëª¨ë“ˆëª… (Noneì´ë©´ package_name ì‚¬ìš©)\n",
    "        version: íŠ¹ì • ë²„ì „ ì§€ì • (Noneì´ë©´ ë²„ì „ ì²´í¬ ì•ˆí•¨)\n",
    "    \"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name.replace('-', '_')\n",
    "    \n",
    "    try:\n",
    "        # íŒ¨í‚¤ì§€ê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "        module = importlib.import_module(import_name)\n",
    "        \n",
    "        if version is not None and hasattr(module, '__version__'):\n",
    "            current_version = module.__version__\n",
    "            print(f\"âœ… {package_name} ì´ë¯¸ ì„¤ì¹˜ë¨ (ë²„ì „: {current_version})\")\n",
    "        else:\n",
    "            print(f\"âœ… {package_name} ì´ë¯¸ ì„¤ì¹˜ë¨\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ {package_name} ì„¤ì¹˜ ì¤‘...\")\n",
    "        try:\n",
    "            if version:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", f\"{package_name}=={version}\"], \n",
    "                             check=True, capture_output=True)\n",
    "            else:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name], \n",
    "                             check=True, capture_output=True)\n",
    "            print(f\"âœ… {package_name} ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "            return True\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ {package_name} ì„¤ì¹˜ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "\n",
    "print(\"ğŸ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± í™•ì¸ ì¤‘...\")\n",
    "\n",
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ í™•ì¸ ë° ì„¤ì¹˜\n",
    "packages_to_check = [\n",
    "    # ì½”ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì€ ì´ë¯¸ 03ë²ˆì—ì„œ ì„¤ì¹˜í–ˆìœ¼ë¯€ë¡œ ì²´í¬ë§Œ\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"peft\", \"peft\"),\n",
    "    \n",
    "    # í‰ê°€ ì „ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ë§Œ í•„ìš”ì‹œ ì„¤ì¹˜\n",
    "    (\"rouge-score\", \"rouge_score\"),\n",
    "    (\"nltk\", \"nltk\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    \n",
    "    # ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"seaborn\", \"seaborn\"),\n",
    "    \n",
    "    # ë°ì´í„° ì²˜ë¦¬\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"tqdm\", \"tqdm\")\n",
    "]\n",
    "\n",
    "print(\"ğŸ“‹ íŒ¨í‚¤ì§€ í™•ì¸ ê²°ê³¼:\")\n",
    "for package_name, import_name in packages_to_check:\n",
    "    check_and_install_package(package_name, import_name)\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ì˜ì¡´ì„± í™•ì¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ ì´ë¯¸ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ë“¤ì€ ì¬ì„¤ì¹˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    pipeline, BitsAndBytesConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "from rouge_score import rouge_scorer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (matplotlib) - ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì„¤ì •\n",
    "print(\"ğŸ”§ í•œê¸€ í°íŠ¸ ì„¤ì • ì¤‘...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install fonts-nanum -qq > /dev/null\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ë‚˜ëˆ”ë°”ë¥¸ê³ ë”• í°íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "fm.fontManager.addfont(fontpath)\n",
    "\n",
    "# matplotlib ì„¤ì • ì—…ë°ì´íŠ¸ - ëª¨ë“  í‰ê°€ ê²°ê³¼ ì°¨íŠ¸ì—ì„œ í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ í‘œì‹œë¨\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'NanumBarunGothic',  # ê¸°ë³¸ í°íŠ¸ë¥¼ ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•ìœ¼ë¡œ ì„¤ì •\n",
    "    'axes.unicode_minus': False         # ìŒìˆ˜ ê¸°í˜¸ í‘œì‹œ ë¬¸ì œ í•´ê²° (ì„±ëŠ¥ ì°¨ì´ í‘œì‹œì—ì„œ ì¤‘ìš”)\n",
    "})\n",
    "\n",
    "# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì • - ë” ì „ë¬¸ì ì´ê³  ê¹”ë”í•œ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ë¥¼ ìœ„í•œ ì„¤ì •\n",
    "plt.style.use('default')              # ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©\n",
    "sns.set_palette(\"Set2\")               # êµ¬ë³„í•˜ê¸° ì‰¬ìš´ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì„¤ì •\n",
    "\n",
    "print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ - ì„±ëŠ¥ í‰ê°€ ì°¨íŠ¸ì—ì„œ í•œê¸€ì´ ì •ìƒ í‘œì‹œë©ë‹ˆë‹¤\")\n",
    "print(\"ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë° í‰ê°€ í™˜ê²½ ì„¤ì •\n",
    "MODEL_NAME = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ê²½ë¡œ ìë™ íƒì§€ - ê°œì„ ëœ ë²„ì „\n",
    "def find_fine_tuned_model_path():\n",
    "    \"\"\"íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ íƒì§€ ì•Œê³ ë¦¬ì¦˜\"\"\"\n",
    "    print(\"ğŸ” íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ê²€ìƒ‰ ì¤‘...\")\n",
    "    \n",
    "    # 1. ë‹¤ì–‘í•œ ê²½ë¡œ íŒ¨í„´ìœ¼ë¡œ ê²€ìƒ‰\n",
    "    possible_patterns = [\n",
    "        \"./fine_tuned_model*\",     # ê¸°ë³¸ íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨í„´\n",
    "        \"./exaone_raft_lora_*\",    # 03ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ìƒì„±í•˜ëŠ” ìƒˆ íŒ¨í„´\n",
    "        \"./outputs/*\",             # ëŒ€ì²´ ê²½ë¡œ\n",
    "        \"./*lora*\",               # LoRAê°€ í¬í•¨ëœ ëª¨ë“  ë””ë ‰í† ë¦¬\n",
    "        \"./*fine*\",               # fineì´ í¬í•¨ëœ ëª¨ë“  ë””ë ‰í† ë¦¬\n",
    "        \"./*exaone*\",             # exaoneì´ í¬í•¨ëœ ëª¨ë“  ë””ë ‰í† ë¦¬\n",
    "    ]\n",
    "    \n",
    "    found_models = []\n",
    "    \n",
    "    for pattern in possible_patterns:\n",
    "        matches = glob.glob(pattern)\n",
    "        for match in matches:\n",
    "            if os.path.isdir(match):  # ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸\n",
    "                # í•„ìˆ˜ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "                adapter_config = os.path.join(match, \"adapter_config.json\")\n",
    "                adapter_model = os.path.join(match, \"adapter_model.safetensors\")\n",
    "                \n",
    "                if os.path.exists(adapter_config) and os.path.exists(adapter_model):\n",
    "                    # íŒŒì¼ í¬ê¸° í™•ì¸ (ë¹ˆ íŒŒì¼ì´ ì•„ë‹Œì§€)\n",
    "                    if os.path.getsize(adapter_config) > 0 and os.path.getsize(adapter_model) > 0:\n",
    "                        modification_time = os.path.getctime(match)\n",
    "                        found_models.append({\n",
    "                            \"path\": match,\n",
    "                            \"mtime\": modification_time,\n",
    "                            \"config_size\": os.path.getsize(adapter_config),\n",
    "                            \"model_size\": os.path.getsize(adapter_model)\n",
    "                        })\n",
    "                        print(f\"  âœ… ë°œê²¬: {match}\")\n",
    "                        print(f\"      Config: {os.path.getsize(adapter_config):,} bytes\")\n",
    "                        print(f\"      Model:  {os.path.getsize(adapter_model):,} bytes\")\n",
    "    \n",
    "    if not found_models:\n",
    "        print(\"  âŒ ìœ íš¨í•œ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "        return None\n",
    "    \n",
    "    # 2. ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì„ íƒ\n",
    "    latest_model = max(found_models, key=lambda x: x[\"mtime\"])\n",
    "    selected_path = latest_model[\"path\"]\n",
    "    \n",
    "    print(f\"\\nğŸ¯ ì„ íƒëœ ëª¨ë¸: {selected_path}\")\n",
    "    print(f\"   ìƒì„± ì‹œê°„: {datetime.fromtimestamp(latest_model['mtime'])}\")\n",
    "    print(f\"   ëª¨ë¸ í¬ê¸°: {latest_model['model_size']:,} bytes\")\n",
    "    \n",
    "    # 3. ì¶”ê°€ ìœ íš¨ì„± ê²€ì‚¬\n",
    "    try:\n",
    "        # adapter_config.json íŒŒì¼ì„ ì½ì–´ì„œ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸\n",
    "        with open(os.path.join(selected_path, \"adapter_config.json\"), 'r') as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        if \"peft_type\" in config and config.get(\"peft_type\") == \"LORA\":\n",
    "            print(f\"   âœ… LoRA ì„¤ì • í™•ì¸ë¨\")\n",
    "            return selected_path\n",
    "        else:\n",
    "            print(f\"   âš ï¸ LoRA ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ ì„¤ì • íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_03_notebook_completion():\n",
    "    \"\"\"\n",
    "    03ë²ˆ ë…¸íŠ¸ë¶ì˜ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“‹ 03ë²ˆ ë…¸íŠ¸ë¶ ì‹¤í–‰ ìƒíƒœ í™•ì¸:\")\n",
    "    \n",
    "    # 1. ì „ì²˜ë¦¬ëœ ë°ì´í„° í™•ì¸\n",
    "    data_files = [\n",
    "        \"processed_data/train_raft_ko.jsonl\",\n",
    "        \"processed_data/valid_raft_ko.jsonl\",\n",
    "        \"processed_data/metadata.json\"\n",
    "    ]\n",
    "    \n",
    "    data_ready = True\n",
    "    for file_path in data_files:\n",
    "        if os.path.exists(file_path):\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  âœ… {file_path}: {file_size:,} bytes\")\n",
    "        else:\n",
    "            print(f\"  âŒ {file_path}: íŒŒì¼ ì—†ìŒ\")\n",
    "            data_ready = False\n",
    "    \n",
    "    # 2. íŒŒì¸íŠœë‹ ëª¨ë¸ í™•ì¸\n",
    "    model_path = find_fine_tuned_model_path()\n",
    "    \n",
    "    # 3. ê²°ê³¼ ìš”ì•½\n",
    "    if not data_ready:\n",
    "        print(f\"\\nâš ï¸ ì „ì²˜ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"   ğŸ‘‰ 01_data_preprocessing_and_validation.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    if not model_path:\n",
    "        print(f\"\\nâš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"   ğŸ‘‰ 03_fine_tuning_with_lora.ipynbë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        print(f\"\\nğŸ’¡ 03ë²ˆ ë…¸íŠ¸ë¶ ì‹¤í–‰ ìˆœì„œ:\")\n",
    "        print(f\"   1. ëª¨ë“  ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\")\n",
    "        print(f\"   2. 19ë²ˆ ì…€(í•™ìŠµ ì‹¤í–‰)ì—ì„œ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°\")\n",
    "        print(f\"   3. 23ë²ˆ ì…€(ëª¨ë¸ ì €ì¥)ì—ì„œ ì €ì¥ ì™„ë£Œ í™•ì¸\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"\\nâœ… 03ë²ˆ ë…¸íŠ¸ë¶ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    return True\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°\n",
    "ADAPTER_PATH = find_fine_tuned_model_path()\n",
    "\n",
    "print(f\"ğŸ”§ í‰ê°€ í™˜ê²½ ì„¤ì •:\")\n",
    "print(f\"  ë””ë°”ì´ìŠ¤: {device}\")\n",
    "print(f\"  ë² ì´ìŠ¤ ëª¨ë¸: {MODEL_NAME}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"  GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB\")\n",
    "else:\n",
    "    print(\"  âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤í–‰ ìƒíƒœ ì¢…í•© í™•ì¸\n",
    "notebook_ready = check_03_notebook_completion()\n",
    "\n",
    "if ADAPTER_PATH and notebook_ready:\n",
    "    print(f\"\\nğŸ‰ ì™„ì „í•œ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    print(f\"  íŒŒì¸íŠœë‹ ëª¨ë¸: {ADAPTER_PATH}\")\n",
    "elif ADAPTER_PATH:\n",
    "    print(f\"\\nâœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë°œê²¬: {ADAPTER_PATH}\")\n",
    "    print(f\"ğŸ”¥ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ ê°€ëŠ¥!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"ğŸ”„ í˜„ì¬ëŠ” ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë§Œ í‰ê°€ë©ë‹ˆë‹¤.\")\n",
    "    print(f\"\\nğŸ’¡ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ìƒì„±í•˜ë ¤ë©´:\")\n",
    "    print(f\"   1. 03_fine_tuning_with_lora.ipynb ì—´ê¸°\")\n",
    "    print(f\"   2. ëª¨ë“  ì…€ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì‹¤í–‰\")\n",
    "    print(f\"   3. í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥ í™•ì¸\")\n",
    "    print(f\"   4. ì´ ë…¸íŠ¸ë¶ì„ ë‹¤ì‹œ ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í‰ê°€ í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"ë‹¤ì–‘í•œ í‰ê°€ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(\n",
    "            ['rouge1', 'rouge2', 'rougeL'], use_stemmer=True\n",
    "        )\n",
    "        self.smoothing = SmoothingFunction().method4\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "    \n",
    "    def compute_rouge(self, predictions, references):\n",
    "        \"\"\"ROUGE ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "        \n",
    "        for pred, ref in zip(predictions, references):\n",
    "            scores = self.rouge_scorer.score(ref, pred)\n",
    "            for key in rouge_scores:\n",
    "                rouge_scores[key].append(scores[key].fmeasure)\n",
    "        \n",
    "        return {key: np.mean(values) for key, values in rouge_scores.items()}\n",
    "    \n",
    "    def compute_bleu(self, predictions, references):\n",
    "        \"\"\"BLEU ì ìˆ˜ ê³„ì‚°\"\"\"\n",
    "        bleu_scores = []\n",
    "        \n",
    "        for pred, ref in zip(predictions, references):\n",
    "            pred_tokens = pred.split()\n",
    "            ref_tokens = [ref.split()]  # BLEUëŠ” referenceë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ìš”êµ¬\n",
    "            \n",
    "            try:\n",
    "                score = sentence_bleu(ref_tokens, pred_tokens, smoothing_function=self.smoothing)\n",
    "                bleu_scores.append(score)\n",
    "            except:\n",
    "                bleu_scores.append(0.0)\n",
    "        \n",
    "        return np.mean(bleu_scores)\n",
    "    \n",
    "    def compute_cosine_similarity(self, predictions, references):\n",
    "        \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
    "        try:\n",
    "            all_texts = predictions + references\n",
    "            tfidf_matrix = self.tfidf.fit_transform(all_texts)\n",
    "            \n",
    "            pred_vectors = tfidf_matrix[:len(predictions)]\n",
    "            ref_vectors = tfidf_matrix[len(predictions):]\n",
    "            \n",
    "            similarities = []\n",
    "            for i in range(len(predictions)):\n",
    "                sim = cosine_similarity(\n",
    "                    pred_vectors[i:i+1], ref_vectors[i:i+1]\n",
    "                )[0][0]\n",
    "                similarities.append(sim)\n",
    "            \n",
    "            return np.mean(similarities)\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "evaluator = EvaluationMetrics()\n",
    "print(\"âœ… í‰ê°€ ë©”íŠ¸ë¦­ í´ë˜ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í‰ê°€ ë°ì´í„°ì…‹ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_dataset():\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ í•¨ìˆ˜ - RAG ì„±ëŠ¥ í‰ê°€ì— ì í•©í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ í‰ê°€ ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    try:\n",
    "        # ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸\n",
    "        if os.path.exists(\"processed_data/valid_raft_ko.jsonl\"):\n",
    "            print(\"ğŸ“ ì „ì²˜ë¦¬ëœ ê²€ì¦ ë°ì´í„° ì‚¬ìš©\")\n",
    "            import jsonlines\n",
    "            \n",
    "            valid_data = []\n",
    "            with jsonlines.open(\"processed_data/valid_raft_ko.jsonl\", \"r\") as reader:\n",
    "                valid_data = list(reader)\n",
    "            \n",
    "            # RAFT í˜•ì‹ì—ì„œ í‰ê°€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "            eval_samples = []\n",
    "            for item in valid_data[:50]:  # í‰ê°€ ì‹œê°„ ê³ ë ¤í•˜ì—¬ 50ê°œ ì œí•œ\n",
    "                if \"original_question\" in item and \"original_answer\" in item:\n",
    "                    # Context ì¶”ì¶œ (User ë©”ì‹œì§€ì—ì„œ)\n",
    "                    user_content = item[\"messages\"][1][\"content\"] if \"messages\" in item else \"\"\n",
    "                    context_match = user_content.split(\"=== ì§ˆë¬¸ ===\")[0] if \"=== ì§ˆë¬¸ ===\" in user_content else \"\"\n",
    "                    context = context_match.replace(\"=== ì»¨í…ìŠ¤íŠ¸ ===\", \"\").strip()\n",
    "                    \n",
    "                    eval_samples.append({\n",
    "                        \"context\": context,\n",
    "                        \"question\": item[\"original_question\"],\n",
    "                        \"answer\": item[\"original_answer\"]\n",
    "                    })\n",
    "            \n",
    "            print(f\"âœ… ì „ì²˜ë¦¬ëœ ê²€ì¦ ë°ì´í„°ì—ì„œ {len(eval_samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ\")\n",
    "            return eval_samples\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "    # ëŒ€ì•ˆ: ì›ë³¸ ë°ì´í„°ì…‹ ì‚¬ìš©\n",
    "    try:\n",
    "        print(\"ğŸ“‚ ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ\")\n",
    "        dataset = load_dataset(\"neural-bridge/rag-dataset-12000\")\n",
    "        \n",
    "        eval_size = min(50, len(dataset[\"train\"]))  # í‰ê°€ ì‹œê°„ ë‹¨ì¶•\n",
    "        eval_data = dataset[\"train\"].select(range(eval_size))\n",
    "        \n",
    "        eval_samples = []\n",
    "        for item in eval_data:\n",
    "            eval_samples.append({\n",
    "                \"context\": item.get(\"context\", \"\"),\n",
    "                \"question\": item.get(\"question\", \"\"),\n",
    "                \"answer\": item.get(\"answer\", \"\")\n",
    "            })\n",
    "        \n",
    "        print(f\"âœ… ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ {len(eval_samples)}ê°œ ìƒ˜í”Œ ë¡œë“œ\")\n",
    "        return eval_samples\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # ìµœì¢… ëŒ€ì•ˆ: ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "        print(\"ğŸ”„ ìƒ˜í”Œ í‰ê°€ ë°ì´í„° ìƒì„±\")\n",
    "        sample_data = [\n",
    "            {\n",
    "                \"context\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì€ í•œê°•ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë°œë‹¬í–ˆìœ¼ë©°, ì•½ ì²œë§Œ ëª…ì˜ ì¸êµ¬ê°€ ê±°ì£¼í•©ë‹ˆë‹¤.\",\n",
    "                \"question\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
    "                \"answer\": \"í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"ê¹€ì¹˜ëŠ” í•œêµ­ì˜ ì „í†µ ë°œíš¨ ì‹í’ˆì…ë‹ˆë‹¤. ë°°ì¶”ì™€ ë‹¤ì–‘í•œ ì–‘ë…ì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“¤ë©°, ê±´ê°•ì— ì¢‹ì€ ìœ ì‚°ê· ì´ í’ë¶€í•©ë‹ˆë‹¤.\",\n",
    "                \"question\": \"ê¹€ì¹˜ëŠ” ì–´ë–¤ ìŒì‹ì¸ê°€ìš”?\",\n",
    "                \"answer\": \"ê¹€ì¹˜ëŠ” í•œêµ­ì˜ ì „í†µ ë°œíš¨ ì‹í’ˆìœ¼ë¡œ, ë°°ì¶”ì™€ ì–‘ë…ìœ¼ë¡œ ë§Œë“¤ì–´ì§€ë©° ìœ ì‚°ê· ì´ í’ë¶€í•©ë‹ˆë‹¤.\"\n",
    "            },\n",
    "            {\n",
    "                \"context\": \"ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ì˜ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ ëª¨ë°©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì´ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "                \"question\": \"ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "                \"answer\": \"ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì§€ëŠ¥ì  í–‰ë™ì„ ëª¨ë°©í•˜ëŠ” ê¸°ìˆ ë¡œ, ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì´ í•µì‹¬ì…ë‹ˆë‹¤.\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        print(f\"ğŸ“ {len(sample_data)}ê°œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ\")\n",
    "        return sample_data\n",
    "\n",
    "# í‰ê°€ ë°ì´í„° ë¡œë“œ\n",
    "eval_samples = load_evaluation_dataset()\n",
    "print(f\"\\nğŸ“Š í‰ê°€ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(eval_samples)}ê°œ ìƒ˜í”Œ\")\n",
    "if eval_samples:\n",
    "    print(f\"\\nğŸ“‹ ì²« ë²ˆì§¸ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(f\"  Context: {eval_samples[0]['context'][:100]}...\")\n",
    "    print(f\"  Question: {eval_samples[0]['question']}\")\n",
    "    print(f\"  Answer: {eval_samples[0]['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"\n",
    "    ë² ì´ìŠ¤ë¼ì¸ê³¼ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ëª¨ë‘ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "    \n",
    "    # 4-bit ì–‘ìí™” ì„¤ì • (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,  # ì•ˆì •ì„±ì„ ìœ„í•´ bfloat16 ì‚¬ìš©\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    print(\"ğŸ“ í† í¬ë‚˜ì´ì € ë¡œë“œ...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(f\"âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ (vocab size: {tokenizer.vocab_size:,})\")\n",
    "    \n",
    "    # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¡œë“œ\n",
    "    print(\"ğŸ¤– ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¡œë“œ...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"âœ… ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì‹œë„ - ê°œì„ ëœ ì˜¤ë¥˜ ì²˜ë¦¬\n",
    "    fine_tuned_model = None\n",
    "    if ADAPTER_PATH and os.path.exists(ADAPTER_PATH):\n",
    "        try:\n",
    "            print(\"ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ...\")\n",
    "            print(f\"   ëª¨ë¸ ê²½ë¡œ: {ADAPTER_PATH}\")\n",
    "            \n",
    "            # í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "            required_files = [\n",
    "                \"adapter_config.json\",\n",
    "                \"adapter_model.safetensors\"\n",
    "            ]\n",
    "            \n",
    "            missing_files = []\n",
    "            for file_name in required_files:\n",
    "                file_path = os.path.join(ADAPTER_PATH, file_name)\n",
    "                if not os.path.exists(file_path):\n",
    "                    missing_files.append(file_name)\n",
    "                else:\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    print(f\"   âœ… {file_name}: {file_size:,} bytes\")\n",
    "            \n",
    "            if missing_files:\n",
    "                print(f\"   âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_files)}\")\n",
    "                raise FileNotFoundError(f\"Missing required files: {missing_files}\")\n",
    "            \n",
    "            # PEFT ì–´ëŒ‘í„° ì ìš©\n",
    "            fine_tuned_model = PeftModel.from_pretrained(\n",
    "                base_model, \n",
    "                ADAPTER_PATH,\n",
    "                torch_dtype=torch.bfloat16\n",
    "            )\n",
    "            print(\"âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"âŒ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {error_msg}\")\n",
    "            \n",
    "            # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë¶„ì„ ë° í•´ê²° ë°©ì•ˆ ì œì‹œ\n",
    "            if \"adapter_config.json\" in error_msg:\n",
    "                print(f\"\\nğŸ” ë¬¸ì œ ë¶„ì„: LoRA ì–´ëŒ‘í„° ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                print(f\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "                print(f\"   1. 03ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ íŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "                print(f\"   2. 23ë²ˆ ì…€(ëª¨ë¸ ì €ì¥)ì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "                print(f\"   3. ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œì— ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸:\")\n",
    "                for file_name in required_files:\n",
    "                    file_path = os.path.join(ADAPTER_PATH, file_name)\n",
    "                    if os.path.exists(file_path):\n",
    "                        print(f\"      âœ… {file_name}\")\n",
    "                    else:\n",
    "                        print(f\"      âŒ {file_name} (ì—†ìŒ)\")\n",
    "                        \n",
    "            elif \"safetensors\" in error_msg or \"model\" in error_msg:\n",
    "                print(f\"\\nğŸ” ë¬¸ì œ ë¶„ì„: LoRA ì–´ëŒ‘í„° ëª¨ë¸ íŒŒì¼ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "                print(f\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "                print(f\"   1. 03ë²ˆ ë…¸íŠ¸ë¶ì˜ í•™ìŠµì´ ì¤‘ë‹¨ ì—†ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸\")\n",
    "                print(f\"   2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì €ì¥ì´ ì‹¤íŒ¨í–ˆì„ ê°€ëŠ¥ì„± í™•ì¸\")\n",
    "                print(f\"   3. 03ë²ˆ ë…¸íŠ¸ë¶ì„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"\\nğŸ” ë¬¸ì œ ë¶„ì„: ì¼ë°˜ì ì¸ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜\")\n",
    "                print(f\"ğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "                print(f\"   1. 03ë²ˆ ë…¸íŠ¸ë¶ ì „ì²´ë¥¼ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "                print(f\"   2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ì¬ì‹¤í–‰\")\n",
    "                print(f\"   3. íŒŒì¸íŠœë‹ ì„¤ì •ì„ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •\")\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ í˜„ì¬ ìƒíƒœ:\")\n",
    "            print(f\"   ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸: âœ… ë¡œë“œë¨\")\n",
    "            print(f\"   íŒŒì¸íŠœë‹ ëª¨ë¸: âŒ ë¡œë“œ ì‹¤íŒ¨\")\n",
    "            print(f\"   í‰ê°€ ê°€ëŠ¥ ì—¬ë¶€: ë² ì´ìŠ¤ë¼ì¸ë§Œ í‰ê°€ ê°€ëŠ¥\")\n",
    "            print(f\"ğŸ’¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë§Œìœ¼ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "            fine_tuned_model = None\n",
    "            \n",
    "    else:\n",
    "        print(\"âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ\")\n",
    "        print(f\"\\nğŸ“‹ íŒŒì¸íŠœë‹ ëª¨ë¸ ìƒì„± ê°€ì´ë“œ:\")\n",
    "        print(f\"   1. 03_fine_tuning_with_lora.ipynb ë…¸íŠ¸ë¶ ì—´ê¸°\")\n",
    "        print(f\"   2. ì…€ 1-2: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\")\n",
    "        print(f\"   3. ì…€ 3-11: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\")\n",
    "        print(f\"   4. ì…€ 12-19: ëª¨ë¸ ì„¤ì • ë° í•™ìŠµ ì‹¤í–‰ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)\")\n",
    "        print(f\"   5. ì…€ 20-23: ê²°ê³¼ ë¶„ì„ ë° ëª¨ë¸ ì €ì¥\")\n",
    "        print(f\"   6. ì´ ë…¸íŠ¸ë¶ìœ¼ë¡œ ëŒì•„ì™€ì„œ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "    \n",
    "    return tokenizer, base_model, fine_tuned_model\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ëª¨ë¸ ìƒíƒœ ì§„ë‹¨ í•¨ìˆ˜\n",
    "def diagnose_fine_tuning_status():\n",
    "    \"\"\"\n",
    "    íŒŒì¸íŠœë‹ ìƒíƒœë¥¼ ì§„ë‹¨í•˜ê³  ì‚¬ìš©ìì—ê²Œ êµ¬ì²´ì ì¸ ê°€ì´ë“œ ì œê³µ\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” íŒŒì¸íŠœë‹ ìƒíƒœ ì§„ë‹¨:\")\n",
    "    \n",
    "    # 1. ë°ì´í„° ì¤€ë¹„ ìƒíƒœ í™•ì¸\n",
    "    data_status = \"âœ…\"\n",
    "    if not os.path.exists(\"processed_data\"):\n",
    "        data_status = \"âŒ\"\n",
    "        print(\"   ë°ì´í„° ì „ì²˜ë¦¬: âŒ (01ë²ˆ ë…¸íŠ¸ë¶ ë¯¸ì‹¤í–‰)\")\n",
    "    elif not os.path.exists(\"processed_data/train_raft_ko.jsonl\"):\n",
    "        data_status = \"âš ï¸\"\n",
    "        print(\"   ë°ì´í„° ì „ì²˜ë¦¬: âš ï¸ (ì¼ë¶€ íŒŒì¼ ëˆ„ë½)\")\n",
    "    else:\n",
    "        print(\"   ë°ì´í„° ì „ì²˜ë¦¬: âœ…\")\n",
    "    \n",
    "    # 2. íŒŒì¸íŠœë‹ ëª¨ë¸ ìƒíƒœ í™•ì¸\n",
    "    if ADAPTER_PATH:\n",
    "        print(f\"   íŒŒì¸íŠœë‹ ëª¨ë¸: âœ… ê²½ë¡œ ë°œê²¬ ({ADAPTER_PATH})\")\n",
    "        \n",
    "        # íŒŒì¼ ìƒì„¸ í™•ì¸\n",
    "        config_path = os.path.join(ADAPTER_PATH, \"adapter_config.json\")\n",
    "        model_path = os.path.join(ADAPTER_PATH, \"adapter_model.safetensors\")\n",
    "        \n",
    "        if os.path.exists(config_path) and os.path.exists(model_path):\n",
    "            config_size = os.path.getsize(config_path)\n",
    "            model_size = os.path.getsize(model_path)\n",
    "            print(f\"      Config íŒŒì¼: {config_size:,} bytes\")\n",
    "            print(f\"      Model íŒŒì¼: {model_size:,} bytes\")\n",
    "            \n",
    "            if model_size < 1000000:  # 1MBë³´ë‹¤ ì‘ìœ¼ë©´ ë¬¸ì œ\n",
    "                print(\"      âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. í•™ìŠµì´ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"      âœ… íŒŒì¼ í¬ê¸°ê°€ ì •ìƒì ì…ë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(\"   íŒŒì¸íŠœë‹ ëª¨ë¸: âŒ í•„ìˆ˜ íŒŒì¼ ëˆ„ë½\")\n",
    "    else:\n",
    "        print(\"   íŒŒì¸íŠœë‹ ëª¨ë¸: âŒ ëª¨ë¸ ì—†ìŒ\")\n",
    "    \n",
    "    # 3. ê¶Œì¥ ì‚¬í•­ ì œì‹œ\n",
    "    print(f\"\\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "    if data_status == \"âŒ\":\n",
    "        print(\"   ğŸ‘‰ 01_data_preprocessing_and_validation.ipynb ë¨¼ì € ì‹¤í–‰\")\n",
    "    elif not ADAPTER_PATH:\n",
    "        print(\"   ğŸ‘‰ 03_fine_tuning_with_lora.ipynb ì‹¤í–‰í•˜ì—¬ íŒŒì¸íŠœë‹ ìˆ˜í–‰\")\n",
    "        print(\"      - ì˜ˆìƒ ì†Œìš” ì‹œê°„: 30-60ë¶„ (GPU ì„±ëŠ¥ì— ë”°ë¼)\")\n",
    "        print(\"      - ì™„ë£Œ í›„ ì´ ë…¸íŠ¸ë¶ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "    else:\n",
    "        print(\"   ğŸ‘‰ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ í‰ê°€ ì§„í–‰ ê°€ëŠ¥!\")\n",
    "\n",
    "# ëª¨ë¸ë“¤ ë¡œë“œ\n",
    "tokenizer, base_model, fine_tuned_model = load_models()\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ìƒíƒœ ì§„ë‹¨ (íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°)\n",
    "if fine_tuned_model is None:\n",
    "    diagnose_fine_tuning_status()\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nğŸ’¾ í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        total = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "        print(f\"  GPU {i}: {allocated:.1f}GB / {total:.1f}GB ({allocated/total:.1%})\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ë¡œë“œ ì™„ë£Œëœ ëª¨ë¸:\")\n",
    "print(f\"  âœ… ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸: {MODEL_NAME}\")\n",
    "if fine_tuned_model is not None:\n",
    "    print(f\"  âœ… íŒŒì¸íŠœë‹ ëª¨ë¸: {ADAPTER_PATH}\")\n",
    "    print(f\"  ğŸ”¥ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ë¹„êµ ê°€ëŠ¥!\")\n",
    "else:\n",
    "    print(f\"  âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸: ë¡œë“œ ì‹¤íŒ¨\")\n",
    "    print(f\"  ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë§Œ í‰ê°€\")\n",
    "    print(f\"\\nğŸ¯ ì™„ì „í•œ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ”:\")\n",
    "    print(f\"     03_fine_tuning_with_lora.ipynb ì™„ë£Œ â†’ ì´ ë…¸íŠ¸ë¶ ì¬ì‹¤í–‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ ì¶”ë¡  ë° í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, context, question, max_new_tokens=150):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ë¡œë¶€í„° ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ - EXAONE ì±„íŒ… í…œí”Œë¦¿ ì‚¬ìš©\n",
    "    \n",
    "    Args:\n",
    "        model: ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸\n",
    "        tokenizer: í† í¬ë‚˜ì´ì €\n",
    "        context: ì°¸ì¡°í•  ì»¨í…ìŠ¤íŠ¸\n",
    "        question: ì§ˆë¬¸\n",
    "        max_new_tokens: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜\n",
    "        \n",
    "    Returns:\n",
    "        ìƒì„±ëœ ì‘ë‹µ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    \n",
    "    # EXAONE ëª¨ë¸ì— ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ í˜•ì‹\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³ , ì£¼ì–´ì§„ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "=== ì»¨í…ìŠ¤íŠ¸ ===\n",
    "{context}\n",
    "\n",
    "=== ì§ˆë¬¸ ===\n",
    "{question}\n",
    "\n",
    "ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # ì±„íŒ… í…œí”Œë¦¿ ì ìš©\n",
    "    try:\n",
    "        formatted_input = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    except Exception:\n",
    "        # ì±„íŒ… í…œí”Œë¦¿ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš° ëŒ€ì•ˆ í˜•ì‹\n",
    "        formatted_input = f\"\"\"ì‹œìŠ¤í…œ: ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš©ì: ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ì–´ì‹œìŠ¤í„´íŠ¸:\"\"\"\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì§•\n",
    "    inputs = tokenizer(\n",
    "        formatted_input,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=2048  # ì»¨í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¶©ë¶„í•œ ê¸¸ì´ í™•ë³´\n",
    "    )\n",
    "    \n",
    "    # GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ GPUë¡œ ì´ë™\n",
    "    if torch.cuda.is_available() and hasattr(model, 'device'):\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # ì‘ë‹µ ìƒì„±\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,                    # ì ë‹¹í•œ ì°½ì˜ì„±\n",
    "            do_sample=True,                     # ìƒ˜í”Œë§ í™œì„±í™”\n",
    "            top_p=0.9,                         # Nucleus sampling\n",
    "            repetition_penalty=1.1,            # ë°˜ë³µ ë°©ì§€\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # ìƒì„±ëœ ë¶€ë¶„ë§Œ ë””ì½”ë”© (ì…ë ¥ ì œì™¸)\n",
    "    generated_tokens = outputs[0][inputs['input_ids'].shape[-1]:]\n",
    "    response = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "    \n",
    "    # ë¶ˆí•„ìš”í•œ ì ‘ë‘ì–´ ì œê±°\n",
    "    if response.startswith(\"ì–´ì‹œìŠ¤í„´íŠ¸:\"):\n",
    "        response = response[5:].strip()\n",
    "    elif response.startswith(\"ë‹µë³€:\"):\n",
    "        response = response[3:].strip()\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"âœ… ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ (EXAONE ìµœì í™”)\")\n",
    "print(\"  - EXAONE ì±„íŒ… í…œí”Œë¦¿ ì‚¬ìš©\")\n",
    "print(\"  - ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±\")\n",
    "print(\"  - ë°˜ë³µ ë°©ì§€ ë° í’ˆì§ˆ ìµœì í™”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, eval_samples):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ - RAG ì„±ëŠ¥ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€\n",
    "    \n",
    "    Args:\n",
    "        model: í‰ê°€í•  ëª¨ë¸\n",
    "        model_name: ëª¨ë¸ ì´ë¦„ (ê²°ê³¼ í‘œì‹œìš©)\n",
    "        eval_samples: í‰ê°€ ë°ì´í„° (context, question, answer í¬í•¨)\n",
    "        \n",
    "    Returns:\n",
    "        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ” {model_name} í‰ê°€ ì‹œì‘...\")\n",
    "    print(f\"  í‰ê°€ ìƒ˜í”Œ ìˆ˜: {len(eval_samples)}ê°œ\")\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    generation_times = []  # ì‘ë‹µ ìƒì„± ì‹œê°„ë„ ì¸¡ì •\n",
    "    \n",
    "    # ì¶”ë¡  ì‹¤í–‰\n",
    "    for i, sample in enumerate(tqdm(eval_samples, desc=f\"{model_name} ì¶”ë¡ \", ncols=80)):\n",
    "        context = sample.get('context', '')\n",
    "        question = sample.get('question', '')\n",
    "        answer = sample.get('answer', '')\n",
    "        \n",
    "        if not context or not question or not answer:\n",
    "            print(f\"  âš ï¸ ìƒ˜í”Œ {i}: ë¶ˆì™„ì „í•œ ë°ì´í„° ê±´ë„ˆë›°ê¸°\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ì‘ë‹µ ìƒì„± ì‹œê°„ ì¸¡ì •\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            prediction = generate_response(model, tokenizer, context, question)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            generation_time = end_time - start_time\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            if prediction and prediction.strip():  # ë¹ˆ ì‘ë‹µ í•„í„°ë§\n",
    "                predictions.append(prediction.strip())\n",
    "                references.append(answer.strip())\n",
    "                contexts.append(context)\n",
    "                questions.append(question)\n",
    "                generation_times.append(generation_time)\n",
    "            else:\n",
    "                print(f\"  âš ï¸ ìƒ˜í”Œ {i}: ë¹ˆ ì‘ë‹µ ìƒì„±\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ ìƒ˜í”Œ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nğŸ“Š {model_name} ë©”íŠ¸ë¦­ ê³„ì‚° ì¤‘... (ìœ íš¨ ìƒ˜í”Œ: {len(predictions)}ê°œ)\")\n",
    "    \n",
    "    if not predictions:\n",
    "        print(f\"âŒ {model_name}: í‰ê°€í•  ìˆ˜ ìˆëŠ” ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    # ë©”íŠ¸ë¦­ ê³„ì‚°\n",
    "    try:\n",
    "        rouge_scores = evaluator.compute_rouge(predictions, references)\n",
    "        bleu_score = evaluator.compute_bleu(predictions, references)\n",
    "        cosine_sim = evaluator.compute_cosine_similarity(predictions, references)\n",
    "        \n",
    "        # ì¶”ê°€ ë©”íŠ¸ë¦­: í‰ê·  ì‘ë‹µ ê¸¸ì´, ì‘ë‹µ ì‹œê°„\n",
    "        avg_prediction_length = np.mean([len(pred.split()) for pred in predictions])\n",
    "        avg_reference_length = np.mean([len(ref.split()) for ref in references])\n",
    "        avg_generation_time = np.mean(generation_times) if generation_times else 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "    \n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'sample_count': len(predictions),\n",
    "        'rouge1': rouge_scores['rouge1'],\n",
    "        'rouge2': rouge_scores['rouge2'],\n",
    "        'rougeL': rouge_scores['rougeL'],\n",
    "        'bleu': bleu_score,\n",
    "        'cosine_similarity': cosine_sim,\n",
    "        'avg_prediction_length': avg_prediction_length,\n",
    "        'avg_reference_length': avg_reference_length,\n",
    "        'avg_generation_time': avg_generation_time,\n",
    "        'predictions': predictions,\n",
    "        'references': references,\n",
    "        'contexts': contexts,\n",
    "        'questions': questions\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… {model_name} í‰ê°€ ì™„ë£Œ\")\n",
    "    print(f\"  ROUGE-1: {rouge_scores['rouge1']:.3f}\")\n",
    "    print(f\"  ROUGE-L: {rouge_scores['rougeL']:.3f}\")\n",
    "    print(f\"  BLEU: {bleu_score:.3f}\")\n",
    "    print(f\"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {cosine_sim:.3f}\")\n",
    "    print(f\"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_generation_time:.2f}ì´ˆ\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€ ì‹¤í–‰\n",
    "if eval_samples:\n",
    "    print(\"ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í‰ê°€\n",
    "    baseline_results = evaluate_model(base_model, \"ğŸ¤– ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\", eval_samples)\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ ëª¨ë¸ í‰ê°€ (ìˆëŠ” ê²½ìš°)\n",
    "    finetuned_results = None\n",
    "    if fine_tuned_model is not None:\n",
    "        finetuned_results = evaluate_model(fine_tuned_model, \"ğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸\", eval_samples)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ!\")\n",
    "    \n",
    "    if baseline_results and finetuned_results:\n",
    "        print(\"ğŸ”¥ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ë¹„êµ ê°€ëŠ¥!\")\n",
    "    elif baseline_results:\n",
    "        print(\"ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ê²°ê³¼ë§Œ ì‚¬ìš© ê°€ëŠ¥\")\n",
    "    else:\n",
    "        print(\"âŒ í‰ê°€í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ í‰ê°€ ë°ì´í„°ê°€ ì—†ì–´ ëª¨ë¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    baseline_results = None\n",
    "    finetuned_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. í‰ê°€ ê²°ê³¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_table(baseline_results, finetuned_results=None):\n",
    "    \"\"\"\n",
    "    ë² ì´ìŠ¤ë¼ì¸ê³¼ íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ìƒì„±\n",
    "    \n",
    "    Args:\n",
    "        baseline_results: ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í‰ê°€ ê²°ê³¼\n",
    "        finetuned_results: íŒŒì¸íŠœë‹ ëª¨ë¸ í‰ê°€ ê²°ê³¼ (ì„ íƒì‚¬í•­)\n",
    "        \n",
    "    Returns:\n",
    "        ë¹„êµ ê²°ê³¼ DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = ['rouge1', 'rouge2', 'rougeL', 'bleu', 'cosine_similarity', 'avg_generation_time']\n",
    "    metric_names = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BLEU', 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„', 'ì‘ë‹µì‹œê°„(ì´ˆ)']\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    if baseline_results:\n",
    "        baseline_row = [baseline_results['model_name']] + [baseline_results[metric] for metric in metrics]\n",
    "        data.append(baseline_row)\n",
    "    \n",
    "    if finetuned_results:\n",
    "        finetuned_row = [finetuned_results['model_name']] + [finetuned_results[metric] for metric in metrics]\n",
    "        data.append(finetuned_row)\n",
    "    \n",
    "    columns = ['ëª¨ë¸'] + metric_names\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_improvement(baseline_results, finetuned_results):\n",
    "    \"\"\"\n",
    "    íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ê°œì„  ê³„ì‚°\n",
    "    \n",
    "    Returns:\n",
    "        ê°œì„ ìœ¨ ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    if not baseline_results or not finetuned_results:\n",
    "        return None\n",
    "    \n",
    "    metrics = ['rouge1', 'rouge2', 'rougeL', 'bleu', 'cosine_similarity']\n",
    "    improvements = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        baseline_score = baseline_results[metric]\n",
    "        finetuned_score = finetuned_results[metric]\n",
    "        \n",
    "        if baseline_score > 0:\n",
    "            improvement = ((finetuned_score - baseline_score) / baseline_score) * 100\n",
    "            improvements[metric] = improvement\n",
    "        else:\n",
    "            improvements[metric] = 0\n",
    "    \n",
    "    return improvements\n",
    "\n",
    "# ê²°ê³¼ ë¶„ì„ ë° í‘œì‹œ\n",
    "if baseline_results:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ë¹„êµ í…Œì´ë¸” ìƒì„±\n",
    "    comparison_df = create_comparison_table(baseline_results, finetuned_results)\n",
    "    \n",
    "    # ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥\n",
    "    print(\"\\nğŸ“‹ ì „ì²´ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "    print(comparison_df.round(4).to_string(index=False))\n",
    "    \n",
    "    # ê°œì„ ìœ¨ ê³„ì‚° ë° ì¶œë ¥\n",
    "    if finetuned_results:\n",
    "        improvements = calculate_improvement(baseline_results, finetuned_results)\n",
    "        \n",
    "        if improvements:\n",
    "            print(\"\\nğŸš€ íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ê°œì„ :\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            improvement_data = []\n",
    "            for metric, improvement in improvements.items():\n",
    "                metric_name = {\n",
    "                    'rouge1': 'ROUGE-1',\n",
    "                    'rouge2': 'ROUGE-2', \n",
    "                    'rougeL': 'ROUGE-L',\n",
    "                    'bleu': 'BLEU',\n",
    "                    'cosine_similarity': 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„'\n",
    "                }[metric]\n",
    "                \n",
    "                if improvement > 0:\n",
    "                    status = \"ğŸ“ˆ ê°œì„ \"\n",
    "                elif improvement < 0:\n",
    "                    status = \"ğŸ“‰ ì•…í™”\"\n",
    "                else:\n",
    "                    status = \"â– ë™ì¼\"\n",
    "                \n",
    "                improvement_data.append([metric_name, f\"{improvement:+.2f}%\", status])\n",
    "                print(f\"  {metric_name}: {improvement:+.2f}% {status}\")\n",
    "            \n",
    "            # ì¢…í•© ê°œì„  í‰ê°€\n",
    "            avg_improvement = np.mean(list(improvements.values()))\n",
    "            print(f\"\\nğŸ¯ ì¢…í•© í‰ê·  ê°œì„ ìœ¨: {avg_improvement:+.2f}%\")\n",
    "            \n",
    "            if avg_improvement > 5:\n",
    "                print(\"ğŸŒŸ íŒŒì¸íŠœë‹ì´ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!\")\n",
    "            elif avg_improvement > 1:\n",
    "                print(\"âœ… íŒŒì¸íŠœë‹ì´ ì„±ëŠ¥ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            elif avg_improvement > -1:\n",
    "                print(\"â– íŒŒì¸íŠœë‹ íš¨ê³¼ê°€ ë¯¸ë¯¸í•©ë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"âš ï¸ íŒŒì¸íŠœë‹ í›„ ì„±ëŠ¥ì´ ë‹¤ì†Œ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nâš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ì–´ ì„±ëŠ¥ ë¹„êµë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"ğŸ’¡ ë¨¼ì € 03_fine_tuning_with_lora.ipynbë¥¼ ì™„ë£Œí•˜ì„¸ìš”.\")\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ì–´ ì„±ëŠ¥ ë¹„êµë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\n",
    "\n",
    "### ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ ì°¨ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„\n",
    "- **ë§‰ëŒ€ ì°¨íŠ¸**: ê° ë©”íŠ¸ë¦­ë³„ ì§ì ‘ì ì¸ ì„±ëŠ¥ ë¹„êµ  \n",
    "- **ë°©ì‚¬í˜• ì°¨íŠ¸**: ì¢…í•©ì ì¸ ì„±ëŠ¥ í”„ë¡œí•„ ë¹„êµ\n",
    "- **ê°œì„ ìœ¨ ì°¨íŠ¸**: íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ ê°œì„  ì •ë„ ì‹œê°í™”\n",
    "- **ì‘ë‹µ ì˜ˆì‹œ ë¹„êµ**: ì‹¤ì œ ìƒì„± ê²°ê³¼ ì§ˆì  ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_visualization(baseline_results, finetuned_results=None):\n",
    "    \"\"\"\n",
    "    ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ìƒì„±\n",
    "    \n",
    "    ì´ í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ ê´€ì ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ ì‹œê°ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤:\n",
    "    1. ğŸ“Š ë©”íŠ¸ë¦­ë³„ ë§‰ëŒ€ ì°¨íŠ¸: ê° ì„±ëŠ¥ ì§€í‘œì˜ ì§ì ‘ì ì¸ ë¹„êµ\n",
    "    2. ğŸ¯ ë°©ì‚¬í˜• ì°¨íŠ¸: ì „ì²´ì ì¸ ì„±ëŠ¥ í”„ë¡œí•„ ë¹„êµ  \n",
    "    3. ğŸ“ˆ ê°œì„ ìœ¨ ì°¨íŠ¸: íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ ê°œì„  ì •ë„\n",
    "    4. â±ï¸ ì‘ë‹µ ì‹œê°„ ë¹„êµ: ì‹¤ìš©ì„± ì¸¡ë©´ì˜ ì„±ëŠ¥ ë¶„ì„\n",
    "    \"\"\"\n",
    "    \n",
    "    if not baseline_results:\n",
    "        print(\"âŒ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"ğŸ¨ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # ì‹œê°í™” ì„¤ì •\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì¢…í•© ì„±ëŠ¥ ë¹„êµ', \n",
    "                 fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # 1. ë©”íŠ¸ë¦­ë³„ ë§‰ëŒ€ ì°¨íŠ¸ (ì¢Œìƒë‹¨)\n",
    "    # ğŸ“Š ì˜ë¯¸: ê° í‰ê°€ ì§€í‘œì—ì„œ ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì§ì ‘ì ìœ¼ë¡œ ë¹„êµ\n",
    "    # - ROUGE: í…ìŠ¤íŠ¸ ì¤‘ë³µë„ ê¸°ë°˜ ìœ ì‚¬ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    # - BLEU: ë²ˆì—­ í’ˆì§ˆ ì¸¡ì • ì§€í‘œ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) \n",
    "    # - ì½”ì‚¬ì¸ ìœ ì‚¬ë„: ì˜ë¯¸ì  ìœ ì‚¬ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    metrics = ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'BLEU', 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„']\n",
    "    baseline_scores = [\n",
    "        baseline_results['rouge1'], baseline_results['rouge2'], \n",
    "        baseline_results['rougeL'], baseline_results['bleu'], \n",
    "        baseline_results['cosine_similarity']\n",
    "    ]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[0, 0].bar(x - width/2, baseline_scores, width, \n",
    "                          label='ğŸ¤– ë² ì´ìŠ¤ë¼ì¸', color='lightblue', alpha=0.8)\n",
    "    \n",
    "    if finetuned_results:\n",
    "        finetuned_scores = [\n",
    "            finetuned_results['rouge1'], finetuned_results['rouge2'],\n",
    "            finetuned_results['rougeL'], finetuned_results['bleu'],\n",
    "            finetuned_results['cosine_similarity']\n",
    "        ]\n",
    "        bars2 = axes[0, 0].bar(x + width/2, finetuned_scores, width,\n",
    "                              label='ğŸ¯ íŒŒì¸íŠœë‹', color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        # ê°œì„ ëœ ë©”íŠ¸ë¦­ì— ë³„í‘œ í‘œì‹œ\n",
    "        for i, (baseline, finetuned) in enumerate(zip(baseline_scores, finetuned_scores)):\n",
    "            if finetuned > baseline:\n",
    "                axes[0, 0].text(i, max(baseline, finetuned) + 0.01, 'â­', \n",
    "                               ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    axes[0, 0].set_xlabel('í‰ê°€ ë©”íŠ¸ë¦­')\n",
    "    axes[0, 0].set_ylabel('ì ìˆ˜')\n",
    "    axes[0, 0].set_title('ğŸ“Š ë©”íŠ¸ë¦­ë³„ ì„±ëŠ¥ ë¹„êµ\\n(â­: íŒŒì¸íŠœë‹ì´ ë” ìš°ìˆ˜)')\n",
    "    axes[0, 0].set_xticks(x)\n",
    "    axes[0, 0].set_xticklabels(metrics, rotation=45, ha='right')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. ë°©ì‚¬í˜• ì°¨íŠ¸ (ìš°ìƒë‹¨) - ì¢…í•©ì ì¸ ì„±ëŠ¥ í”„ë¡œí•„ ë¹„êµ\n",
    "    # ğŸ“Š ì˜ë¯¸: ë‹¤ê°í˜• ëª¨ì–‘ìœ¼ë¡œ ëª¨ë¸ì˜ ì „ì²´ì ì¸ ê°•ì•½ì ì„ í•œëˆˆì— íŒŒì•…\n",
    "    # - ë©´ì ì´ í´ìˆ˜ë¡ ì „ë°˜ì ì¸ ì„±ëŠ¥ì´ ìš°ìˆ˜\n",
    "    # - ê° ê¼­ì§“ì ì€ íŠ¹ì • ì„±ëŠ¥ ì§€í‘œë¥¼ ë‚˜íƒ€ëƒ„\n",
    "    if finetuned_results:\n",
    "        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # ë‹«íŒ ë‹¤ê°í˜•ì„ ìœ„í•´\n",
    "        \n",
    "        baseline_scores_radar = baseline_scores + baseline_scores[:1]\n",
    "        finetuned_scores_radar = finetuned_scores + finetuned_scores[:1]\n",
    "        \n",
    "        ax_radar = plt.subplot(2, 2, 2, projection='polar')\n",
    "        ax_radar.plot(angles, baseline_scores_radar, 'o-', linewidth=2, \n",
    "                     label='ğŸ¤– ë² ì´ìŠ¤ë¼ì¸', color='blue', alpha=0.7)\n",
    "        ax_radar.fill(angles, baseline_scores_radar, alpha=0.25, color='blue')\n",
    "        \n",
    "        ax_radar.plot(angles, finetuned_scores_radar, 'o-', linewidth=2,\n",
    "                     label='ğŸ¯ íŒŒì¸íŠœë‹', color='red', alpha=0.7)\n",
    "        ax_radar.fill(angles, finetuned_scores_radar, alpha=0.25, color='red')\n",
    "        \n",
    "        ax_radar.set_xticks(angles[:-1])\n",
    "        ax_radar.set_xticklabels(metrics)\n",
    "        ax_radar.set_ylim(0, 1)\n",
    "        ax_radar.set_title('ğŸ¯ ì¢…í•© ì„±ëŠ¥ í”„ë¡œí•„ ë¹„êµ\\n(ë©´ì ì´ í´ìˆ˜ë¡ ìš°ìˆ˜)')\n",
    "        ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "        ax_radar.grid(True)\n",
    "    else:\n",
    "        axes[0, 1].text(0.5, 0.5, 'âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ì–´\\në°©ì‚¬í˜• ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\n\\nğŸ’¡ 03ë²ˆ ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì™„ë£Œí•˜ì„¸ìš”.',\n",
    "                       ha='center', va='center', fontsize=12, \n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "        axes[0, 1].set_title('ğŸ¯ ì¢…í•© ì„±ëŠ¥ í”„ë¡œí•„ ë¹„êµ')\n",
    "        axes[0, 1].axis('off')\n",
    "    \n",
    "    # 3. ê°œì„ ìœ¨ ì°¨íŠ¸ (ì¢Œí•˜ë‹¨)\n",
    "    # ğŸ“Š ì˜ë¯¸: íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ë³€í™”ë¥¼ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ\n",
    "    # - ì–‘ìˆ˜: ì„±ëŠ¥ í–¥ìƒ, ìŒìˆ˜: ì„±ëŠ¥ ì €í•˜\n",
    "    # - ë§‰ëŒ€ì˜ ìƒ‰ê¹”ë¡œ ê°œì„ /ì €í•˜ë¥¼ ì§ê´€ì ìœ¼ë¡œ í‘œì‹œ\n",
    "    if finetuned_results:\n",
    "        improvements = []\n",
    "        for baseline, finetuned in zip(baseline_scores, finetuned_scores):\n",
    "            if baseline > 0:\n",
    "                improvement = ((finetuned - baseline) / baseline) * 100\n",
    "                improvements.append(improvement)\n",
    "            else:\n",
    "                improvements.append(0)\n",
    "        \n",
    "        colors = ['green' if imp > 0 else 'red' if imp < 0 else 'gray' for imp in improvements]\n",
    "        bars = axes[1, 0].bar(metrics, improvements, color=colors, alpha=0.7)\n",
    "        \n",
    "        # ê°œì„ ìœ¨ ìˆ˜ì¹˜ í‘œì‹œ\n",
    "        for bar, improvement in zip(bars, improvements):\n",
    "            height = bar.get_height()\n",
    "            axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -3),\n",
    "                           f'{improvement:+.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                           fontweight='bold')\n",
    "        \n",
    "        axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        axes[1, 0].set_xlabel('í‰ê°€ ë©”íŠ¸ë¦­')\n",
    "        axes[1, 0].set_ylabel('ê°œì„ ìœ¨ (%)')\n",
    "        axes[1, 0].set_title('ğŸ“ˆ íŒŒì¸íŠœë‹ ê°œì„ ìœ¨\\n(ì´ˆë¡: ê°œì„ , ë¹¨ê°•: ì €í•˜)')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # í‰ê·  ê°œì„ ìœ¨ í‘œì‹œ\n",
    "        avg_improvement = np.mean(improvements)\n",
    "        axes[1, 0].text(0.02, 0.98, f'í‰ê·  ê°œì„ ìœ¨: {avg_improvement:+.1f}%', \n",
    "                       transform=axes[1, 0].transAxes, fontsize=12, fontweight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\" if avg_improvement > 0 else \"lightcoral\"))\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ì–´\\nê°œì„ ìœ¨ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\\n\\nğŸ’¡ 03ë²ˆ ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì™„ë£Œí•˜ì„¸ìš”.',\n",
    "                       ha='center', va='center', fontsize=12,\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightyellow\"))\n",
    "        axes[1, 0].set_title('ğŸ“ˆ íŒŒì¸íŠœë‹ ê°œì„ ìœ¨')\n",
    "        axes[1, 0].axis('off')\n",
    "    \n",
    "    # 4. ì‘ë‹µ ì‹œê°„ ë° ê¸¸ì´ ë¹„êµ (ìš°í•˜ë‹¨)  \n",
    "    # ğŸ“Š ì˜ë¯¸: ëª¨ë¸ì˜ ì‹¤ìš©ì„± ì¸¡ë©´ ë¹„êµ\n",
    "    # - ì‘ë‹µ ì‹œê°„: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œì˜ ì‚¬ìš©ì„± (ì§§ì„ìˆ˜ë¡ ì¢‹ìŒ)\n",
    "    # - ì‘ë‹µ ê¸¸ì´: ë‹µë³€ì˜ ìƒì„¸í•¨ ì •ë„\n",
    "    response_metrics = ['í‰ê·  ì‘ë‹µ ì‹œê°„(ì´ˆ)', 'í‰ê·  ì‘ë‹µ ê¸¸ì´(ë‹¨ì–´)']\n",
    "    baseline_practical = [baseline_results['avg_generation_time'], baseline_results['avg_prediction_length']]\n",
    "    \n",
    "    if finetuned_results:\n",
    "        finetuned_practical = [finetuned_results['avg_generation_time'], finetuned_results['avg_prediction_length']]\n",
    "        \n",
    "        x = np.arange(len(response_metrics))\n",
    "        bars1 = axes[1, 1].bar(x - width/2, baseline_practical, width,\n",
    "                              label='ğŸ¤– ë² ì´ìŠ¤ë¼ì¸', color='lightblue', alpha=0.8)\n",
    "        bars2 = axes[1, 1].bar(x + width/2, finetuned_practical, width,\n",
    "                              label='ğŸ¯ íŒŒì¸íŠœë‹', color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        # ìˆ˜ì¹˜ í‘œì‹œ\n",
    "        for bars in [bars1, bars2]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                               f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        axes[1, 1].legend()\n",
    "    else:\n",
    "        bars = axes[1, 1].bar(response_metrics, baseline_practical, \n",
    "                             color='lightblue', alpha=0.8, label='ğŸ¤– ë² ì´ìŠ¤ë¼ì¸')\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                           f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    axes[1, 1].set_xlabel('ì‹¤ìš©ì„± ì§€í‘œ')\n",
    "    axes[1, 1].set_ylabel('ê°’')\n",
    "    axes[1, 1].set_title('â±ï¸ ì‹¤ìš©ì„± ë¹„êµ\\n(ì‘ë‹µ ì†ë„ ë° ê¸¸ì´)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)  # ì œëª© ì—¬ë°± ì¡°ì •\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì €ì¥\n",
    "    plt.savefig('model_performance_comparison.png', dpi=300, bbox_inches='tight', \n",
    "                facecolor='white', edgecolor='none')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ì™„ë£Œ\")\n",
    "    print(\"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: model_performance_comparison.png\")\n",
    "    \n",
    "    # ì‹œê°í™” í•´ì„ ê°€ì´ë“œ ì¶œë ¥\n",
    "    print(\"\\nğŸ“– ì‹œê°í™” í•´ì„ ê°€ì´ë“œ:\")\n",
    "    print(\"  ğŸ“Š ë©”íŠ¸ë¦­ë³„ ë¹„êµ: ê° ì§€í‘œì—ì„œ ì–´ëŠ ëª¨ë¸ì´ ìš°ìˆ˜í•œì§€ ì§ì ‘ ë¹„êµ\")\n",
    "    print(\"  ğŸ¯ ë°©ì‚¬í˜• ì°¨íŠ¸: ëª¨ë¸ì˜ ì „ì²´ì ì¸ ì„±ëŠ¥ ë°¸ëŸ°ìŠ¤ë¥¼ ë©´ì ìœ¼ë¡œ ë¹„êµ\")  \n",
    "    print(\"  ğŸ“ˆ ê°œì„ ìœ¨ ì°¨íŠ¸: íŒŒì¸íŠœë‹ìœ¼ë¡œ ì¸í•œ êµ¬ì²´ì ì¸ ê°œì„  ì •ë„ (% ë‹¨ìœ„)\")\n",
    "    print(\"  â±ï¸ ì‹¤ìš©ì„± ë¹„êµ: ì‹¤ì œ ì‚¬ìš© ì‹œ ê³ ë ¤í•´ì•¼ í•  ì†ë„ì™€ ì‘ë‹µ í’ˆì§ˆ\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ì„±ëŠ¥ ë¹„êµ ì‹œê°í™” ì‹¤í–‰\n",
    "if baseline_results:\n",
    "    comparison_fig = create_performance_visualization(baseline_results, finetuned_results)\n",
    "else:\n",
    "    print(\"âŒ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_response_examples(baseline_results, finetuned_results=None, num_examples=3):\n",
    "    \"\"\"\n",
    "    ë² ì´ìŠ¤ë¼ì¸ê³¼ íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì‹¤ì œ ì‘ë‹µ ì˜ˆì‹œë¥¼ ë¹„êµí•˜ì—¬ ì¶œë ¥\n",
    "    \n",
    "    ì´ í•¨ìˆ˜ëŠ” ì •ëŸ‰ì  ë©”íŠ¸ë¦­ìœ¼ë¡œëŠ” íŒŒì•…í•˜ê¸° ì–´ë ¤ìš´ ì§ˆì  ì°¨ì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:\n",
    "    - ë‹µë³€ì˜ ì •í™•ì„±: ì»¨í…ìŠ¤íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•íˆ í™œìš©í–ˆëŠ”ê°€\n",
    "    - ë‹µë³€ì˜ ì™„ì„±ë„: ì§ˆë¬¸ì— ëŒ€í•œ ì¶©ë¶„í•œ ë‹µë³€ì„ ì œê³µí–ˆëŠ”ê°€  \n",
    "    - ë‹µë³€ì˜ ì¼ê´€ì„±: ì£¼ì–´ì§„ ì •ë³´ì— ê¸°ë°˜í•œ ë…¼ë¦¬ì  ë‹µë³€ì¸ê°€\n",
    "    - ì–¸ì–´ í’ˆì§ˆ: ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ í•œêµ­ì–´ì¸ê°€\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"ğŸ” ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µ ì˜ˆì‹œ ë¹„êµ\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"ğŸ“‹ ì´ ë¹„êµë¥¼ í†µí•´ ì •ëŸ‰ì  ë©”íŠ¸ë¦­ìœ¼ë¡œëŠ” ë³´ê¸° ì–´ë ¤ìš´ ì§ˆì  ì°¨ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   - ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„\")\n",
    "    print(\"   - ì»¨í…ìŠ¤íŠ¸ í™œìš© ëŠ¥ë ¥\") \n",
    "    print(\"   - í•œêµ­ì–´ ë‹µë³€ì˜ ìì—°ìŠ¤ëŸ¬ì›€\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    if not baseline_results:\n",
    "        print(\"âŒ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ê°€ ì—†ì–´ ì˜ˆì‹œë¥¼ ì¶œë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    \n",
    "    # ë¹„êµí•  ì˜ˆì‹œ ê°œìˆ˜ ê²°ì •\n",
    "    max_examples = min(num_examples, len(baseline_results['predictions']))\n",
    "    \n",
    "    for i in range(max_examples):\n",
    "        print(f\"\\nã€ì˜ˆì‹œ {i+1}ã€‘\")\n",
    "        print(\"â”€\" * 80)\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ ë° ì§ˆë¬¸ ì¶œë ¥\n",
    "        context = baseline_results['contexts'][i]\n",
    "        question = baseline_results['questions'][i]\n",
    "        reference = baseline_results['references'][i]\n",
    "        \n",
    "        print(f\"ğŸŒ ì»¨í…ìŠ¤íŠ¸:\")\n",
    "        print(f\"   {context[:200]}{'...' if len(context) > 200 else ''}\")\n",
    "        print(f\"\\nâ“ ì§ˆë¬¸:\")\n",
    "        print(f\"   {question}\")\n",
    "        print(f\"\\nğŸ¯ ì •ë‹µ:\")\n",
    "        print(f\"   {reference}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¬ ëª¨ë¸ ì‘ë‹µ ë¹„êµ:\")\n",
    "        print(\"â”€\" * 50)\n",
    "        \n",
    "        # ë² ì´ìŠ¤ë¼ì¸ ì‘ë‹µ\n",
    "        baseline_pred = baseline_results['predictions'][i]\n",
    "        print(f\"ğŸ¤– ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸:\")\n",
    "        print(f\"   {baseline_pred}\")\n",
    "        \n",
    "        # íŒŒì¸íŠœë‹ ì‘ë‹µ (ìˆëŠ” ê²½ìš°)\n",
    "        if finetuned_results and i < len(finetuned_results['predictions']):\n",
    "            finetuned_pred = finetuned_results['predictions'][i]\n",
    "            print(f\"\\nğŸ¯ íŒŒì¸íŠœë‹ ëª¨ë¸:\")\n",
    "            print(f\"   {finetuned_pred}\")\n",
    "            \n",
    "            # ê°„ë‹¨í•œ ì§ˆì  ë¹„êµ ë¶„ì„\n",
    "            print(f\"\\nğŸ“Š ê°„ë‹¨ ë¶„ì„:\")\n",
    "            \n",
    "            # ê¸¸ì´ ë¹„êµ\n",
    "            baseline_len = len(baseline_pred.split())\n",
    "            finetuned_len = len(finetuned_pred.split())\n",
    "            print(f\"   ê¸¸ì´: ë² ì´ìŠ¤ë¼ì¸ {baseline_len}ë‹¨ì–´ vs íŒŒì¸íŠœë‹ {finetuned_len}ë‹¨ì–´\")\n",
    "            \n",
    "            # ì •ë‹µê³¼ì˜ ìœ ì‚¬ì„± (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)\n",
    "            ref_keywords = set(reference.lower().split())\n",
    "            baseline_keywords = set(baseline_pred.lower().split())\n",
    "            finetuned_keywords = set(finetuned_pred.lower().split())\n",
    "            \n",
    "            baseline_overlap = len(ref_keywords & baseline_keywords) / len(ref_keywords) if ref_keywords else 0\n",
    "            finetuned_overlap = len(ref_keywords & finetuned_keywords) / len(ref_keywords) if ref_keywords else 0\n",
    "            \n",
    "            print(f\"   ì •ë‹µ í‚¤ì›Œë“œ ë§¤ì¹­: ë² ì´ìŠ¤ë¼ì¸ {baseline_overlap:.1%} vs íŒŒì¸íŠœë‹ {finetuned_overlap:.1%}\")\n",
    "            \n",
    "            # ì–´ëŠ ëª¨ë¸ì´ ë” ë‚˜ì€ì§€ ê°„ë‹¨í•œ íŒë‹¨\n",
    "            if finetuned_overlap > baseline_overlap + 0.1:  # 10% ì´ìƒ ì°¨ì´\n",
    "                print(f\"   ğŸŒŸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            elif baseline_overlap > finetuned_overlap + 0.1:\n",
    "                print(f\"   ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì´ ë” ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(f\"   â– ë‘ ëª¨ë¸ì˜ ë‹µë³€ í’ˆì§ˆì´ ë¹„ìŠ·í•©ë‹ˆë‹¤.\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        print(\"\\n\" + \"â”€\" * 80)\n",
    "        \n",
    "        # ì˜ˆì‹œ ê°„ êµ¬ë¶„ì„ \n",
    "        if i < max_examples - 1:\n",
    "            print(\"\\n\")\n",
    "    \n",
    "    # ì „ì²´ì ì¸ ì§ˆì  í‰ê°€ ìš”ì•½\n",
    "    if finetuned_results:\n",
    "        print(f\"\\nğŸ“‹ ì „ì²´ ì‘ë‹µ í’ˆì§ˆ ë¹„êµ ìš”ì•½:\")\n",
    "        print(\"â”€\" * 50)\n",
    "        \n",
    "        # ì „ì²´ ì‘ë‹µì— ëŒ€í•œ ê°„ë‹¨í•œ í†µê³„\n",
    "        total_baseline_length = np.mean([len(pred.split()) for pred in baseline_results['predictions']])\n",
    "        total_finetuned_length = np.mean([len(pred.split()) for pred in finetuned_results['predictions']])\n",
    "        \n",
    "        print(f\"í‰ê·  ì‘ë‹µ ê¸¸ì´: ë² ì´ìŠ¤ë¼ì¸ {total_baseline_length:.1f}ë‹¨ì–´ vs íŒŒì¸íŠœë‹ {total_finetuned_length:.1f}ë‹¨ì–´\")\n",
    "        \n",
    "        # ì „ë°˜ì ì¸ í’ˆì§ˆ í‰ê°€ (ROUGE-L ê¸°ì¤€)\n",
    "        baseline_quality = baseline_results['rougeL']\n",
    "        finetuned_quality = finetuned_results['rougeL']\n",
    "        \n",
    "        quality_improvement = ((finetuned_quality - baseline_quality) / baseline_quality) * 100 if baseline_quality > 0 else 0\n",
    "        \n",
    "        if quality_improvement > 5:\n",
    "            overall_assessment = \"ğŸŒŸ íŒŒì¸íŠœë‹ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤!\"\n",
    "        elif quality_improvement > 1:\n",
    "            overall_assessment = \"âœ… íŒŒì¸íŠœë‹ìœ¼ë¡œ ë‹µë³€ í’ˆì§ˆì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.\"\n",
    "        elif quality_improvement > -1:\n",
    "            overall_assessment = \"â– ë‘ ëª¨ë¸ì˜ ë‹µë³€ í’ˆì§ˆì´ ë¹„ìŠ·í•©ë‹ˆë‹¤.\"\n",
    "        else:\n",
    "            overall_assessment = \"ğŸ”„ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì˜ ë‹µë³€ì´ ë” ë‚˜ì€ ê²½ìš°ë„ ìˆìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        print(f\"\\nì „ë°˜ì  í‰ê°€: {overall_assessment}\")\n",
    "        print(f\"í’ˆì§ˆ ê°œì„ ìœ¨: {quality_improvement:+.1f}% (ROUGE-L ê¸°ì¤€)\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ì—†ì–´ ì§ˆì  ë¹„êµë¥¼ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"ğŸ’¡ ë¨¼ì € 03_fine_tuning_with_lora.ipynbë¥¼ ì™„ë£Œí•˜ì—¬ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”.\")\n",
    "\n",
    "# ì‘ë‹µ ì˜ˆì‹œ ë¹„êµ ì‹¤í–‰\n",
    "if baseline_results:\n",
    "    show_response_examples(baseline_results, finetuned_results, num_examples=3)\n",
    "else:\n",
    "    print(\"âŒ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ê°€ ì—†ì–´ ì‘ë‹µ ì˜ˆì‹œë¥¼ ì¶œë ¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‰ê°€ ê²°ê³¼ ì €ì¥ ë° ìš”ì•½\n",
    "def save_evaluation_results(baseline_results, finetuned_results=None):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ìµœì¢… ìš”ì•½ì„ ìƒì„±\n",
    "    \"\"\"\n",
    "    print(\"ğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "    evaluation_summary = {\n",
    "        'evaluation_date': pd.Timestamp.now().isoformat(),\n",
    "        'baseline_model': {\n",
    "            'name': baseline_results['model_name'],\n",
    "            'sample_count': baseline_results['sample_count'],\n",
    "            'rouge1': float(baseline_results['rouge1']),\n",
    "            'rouge2': float(baseline_results['rouge2']),\n",
    "            'rougeL': float(baseline_results['rougeL']),\n",
    "            'bleu': float(baseline_results['bleu']),\n",
    "            'cosine_similarity': float(baseline_results['cosine_similarity']),\n",
    "            'avg_generation_time': float(baseline_results['avg_generation_time']),\n",
    "            'avg_prediction_length': float(baseline_results['avg_prediction_length'])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # íŒŒì¸íŠœë‹ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€\n",
    "    if finetuned_results:\n",
    "        evaluation_summary['finetuned_model'] = {\n",
    "            'name': finetuned_results['model_name'],\n",
    "            'sample_count': finetuned_results['sample_count'],\n",
    "            'rouge1': float(finetuned_results['rouge1']),\n",
    "            'rouge2': float(finetuned_results['rouge2']),\n",
    "            'rougeL': float(finetuned_results['rougeL']),\n",
    "            'bleu': float(finetuned_results['bleu']),\n",
    "            'cosine_similarity': float(finetuned_results['cosine_similarity']),\n",
    "            'avg_generation_time': float(finetuned_results['avg_generation_time']),\n",
    "            'avg_prediction_length': float(finetuned_results['avg_prediction_length'])\n",
    "        }\n",
    "        \n",
    "        # ê°œì„ ìœ¨ ê³„ì‚° ë° ì €ì¥\n",
    "        improvements = calculate_improvement(baseline_results, finetuned_results)\n",
    "        if improvements:\n",
    "            evaluation_summary['improvement_analysis'] = {\n",
    "                'rouge1_improvement': float(improvements['rouge1']),\n",
    "                'rouge2_improvement': float(improvements['rouge2']),\n",
    "                'rougeL_improvement': float(improvements['rougeL']),\n",
    "                'bleu_improvement': float(improvements['bleu']),\n",
    "                'cosine_similarity_improvement': float(improvements['cosine_similarity']),\n",
    "                'average_improvement': float(np.mean(list(improvements.values())))\n",
    "            }\n",
    "    \n",
    "    # JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "    with open('baseline_vs_finetuned_evaluation.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(evaluation_summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ\")\n",
    "    print(\"ğŸ“ ì €ì¥ëœ íŒŒì¼:\")\n",
    "    print(\"  - baseline_vs_finetuned_evaluation.json: ì¢…í•© í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"  - model_performance_comparison.png: ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”\")\n",
    "    \n",
    "    return evaluation_summary\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤í–‰\n",
    "if baseline_results:\n",
    "    evaluation_summary = save_evaluation_results(baseline_results, finetuned_results)\n",
    "else:\n",
    "    print(\"âŒ ì €ì¥í•  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ğŸ“‹ Day 1 ì‹¤ìŠµ ìµœì¢… ìš”ì•½ ë° ê²°ë¡ \n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "1. **ë°ì´í„° ì „ì²˜ë¦¬ (01ë²ˆ)**: RAFT ë°©ë²•ë¡ ì„ í™œìš©í•œ í•œêµ­ì–´ RAG ë°ì´í„°ì…‹ ìƒì„±\n",
    "2. **ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (02ë²ˆ)**: í† í° ë¶„í¬, ì¤‘ë³µì„±, RAFT êµ¬ì¡° ê²€ì¦\n",
    "3. **QLoRA íŒŒì¸íŠœë‹ (03ë²ˆ)**: 4-bit ì–‘ìí™”ë¥¼ í™œìš©í•œ íš¨ìœ¨ì  EXAONE ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "4. **ì„±ëŠ¥ í‰ê°€ ë° ë¹„êµ (04ë²ˆ)**: ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì •ëŸ‰ì /ì •ì„±ì  ë¹„êµ\n",
    "\n",
    "### ğŸ¯ í•µì‹¬ ì„±ê³¼\n",
    "- **RAFT ê¸°ë°˜ íŒŒì¸íŠœë‹**: RAG ì„±ëŠ¥ í–¥ìƒì— íŠ¹í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ ë° í•™ìŠµ\n",
    "- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í•™ìŠµ**: QLoRAë¥¼ í†µí•œ Colab ë¬´ë£Œ í™˜ê²½ì—ì„œì˜ ëŒ€ê·œëª¨ ëª¨ë¸ íŒŒì¸íŠœë‹\n",
    "- **ì¢…í•©ì  í‰ê°€**: ROUGE, BLEU, ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë“± ë‹¤ê°ë„ ì„±ëŠ¥ ì¸¡ì •\n",
    "- **ì‹¤ìš©ì  ê²€ì¦**: ì‹¤ì œ RAG ì‹œë‚˜ë¦¬ì˜¤ì—ì„œì˜ ì„±ëŠ¥ ê°œì„  í™•ì¸\n",
    "\n",
    "### ğŸ“Š ê¸°ëŒ€ íš¨ê³¼\n",
    "íŒŒì¸íŠœë‹ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ê°œì„ ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "- **ì •í™•ì„± í–¥ìƒ**: ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë” ì •í™•íˆ í™œìš©í•œ ë‹µë³€ ìƒì„±\n",
    "- **ì¼ê´€ì„± ê°œì„ **: RAFT í›ˆë ¨ì„ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ë¡  ëŠ¥ë ¥ ê°•í™”\n",
    "- **í•œêµ­ì–´ í’ˆì§ˆ**: í•œêµ­ì–´ íŠ¹í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ì¸í•œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ ìƒì„±\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ í™œìš© ë°©ì•ˆ\n",
    "1. **ê¸°ì—… ë‚´ RAG ì‹œìŠ¤í…œ**: ì‚¬ë‚´ ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "2. **ê³ ê° ì„œë¹„ìŠ¤ ë´‡**: FAQ ê¸°ë°˜ ìë™ ì‘ë‹µ ì‹œìŠ¤í…œì˜ ì •í™•ë„ í–¥ìƒ\n",
    "3. **êµìœ¡ í”Œë«í¼**: êµì¬ ë‚´ìš© ê¸°ë°˜ í•™ìŠµ ë„ìš°ë¯¸ ê°œë°œ\n",
    "4. **ì—°êµ¬ ì§€ì› ë„êµ¬**: ë…¼ë¬¸/ìë£Œ ê¸°ë°˜ ì—°êµ¬ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\n",
    "\n",
    "### ğŸ”„ ì¶”ê°€ ê°œì„  ë°©í–¥\n",
    "1. **ë” ë§ì€ ë°ì´í„°**: ë„ë©”ì¸ë³„ íŠ¹í™” ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ\n",
    "2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: Learning rate, LoRA rank ë“± ìµœì í™”\n",
    "3. **ì•™ìƒë¸” ê¸°ë²•**: ì—¬ëŸ¬ íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ê²°í•©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ\n",
    "4. **ì§€ì†ì  í•™ìŠµ**: ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í†µí•œ ëª¨ë¸ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Day 1 ì‹¤ìŠµ 4 ìµœì¢… ì™„ë£Œ!\n",
    "print(\"ğŸ‰ Day 1 ì‹¤ìŠµ 4: ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "if baseline_results:\n",
    "    print(\"ğŸ“Š í‰ê°€ ì™„ë£Œëœ ëª¨ë¸:\")\n",
    "    print(f\"  âœ… ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸: {baseline_results['model_name']}\")\n",
    "    if finetuned_results:\n",
    "        print(f\"  âœ… íŒŒì¸íŠœë‹ ëª¨ë¸: {finetuned_results['model_name']}\")\n",
    "        print(\"\\nğŸ”¥ ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ì™„ì „ ë¹„êµ ì„±ê³µ!\")\n",
    "    else:\n",
    "        print(\"  âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸: ë¹„êµ ë¶ˆê°€\")\n",
    "        print(\"\\nğŸ’¡ íŒŒì¸íŠœë‹ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì€ ì´ìœ :\")\n",
    "        print(\"   1. 03ë²ˆ ë…¸íŠ¸ë¶ì˜ íŒŒì¸íŠœë‹ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŒ\")\n",
    "        print(\"   2. ëª¨ë¸ ì €ì¥ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ\")\n",
    "        print(\"   3. íŒŒì¼ ê²½ë¡œë‚˜ ê¶Œí•œ ë¬¸ì œ\")\n",
    "        print(\"\\nğŸ”§ í•´ê²° ë°©ë²•:\")\n",
    "        print(\"   ğŸ‘‰ 03_fine_tuning_with_lora.ipynbë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì™„ë£Œ\")\n",
    "        print(\"   ğŸ‘‰ íŠ¹íˆ 23ë²ˆ ì…€(ëª¨ë¸ ì €ì¥)ì—ì„œ 'âœ… ëª¨ë¸ ì €ì¥ ì„±ê³µ!' ë©”ì‹œì§€ í™•ì¸\")\n",
    "        print(\"   ğŸ‘‰ ì´ ë…¸íŠ¸ë¶ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì™„ì „í•œ ë¹„êµ ìˆ˜í–‰\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ í‰ê°€ ìƒ˜í”Œ ìˆ˜: {baseline_results['sample_count']}ê°œ\")\n",
    "    \n",
    "    # í•µì‹¬ ë©”íŠ¸ë¦­ ìš”ì•½\n",
    "    if finetuned_results:\n",
    "        print(\"\\nğŸ¯ í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ:\")\n",
    "        metrics = ['rouge1', 'rougeL', 'bleu', 'cosine_similarity']\n",
    "        metric_names = ['ROUGE-1', 'ROUGE-L', 'BLEU', 'ì½”ì‚¬ì¸ ìœ ì‚¬ë„']\n",
    "        \n",
    "        for metric, name in zip(metrics, metric_names):\n",
    "            baseline_score = baseline_results[metric]\n",
    "            finetuned_score = finetuned_results[metric]\n",
    "            improvement = ((finetuned_score - baseline_score) / baseline_score * 100) if baseline_score > 0 else 0\n",
    "            \n",
    "            if improvement > 1:\n",
    "                status = \"ğŸ“ˆ\"\n",
    "            elif improvement < -1:\n",
    "                status = \"ğŸ“‰\"\n",
    "            else:\n",
    "                status = \"â–\"\n",
    "            \n",
    "            print(f\"  {name}: {baseline_score:.3f} â†’ {finetuned_score:.3f} ({improvement:+.1f}%) {status}\")\n",
    "        \n",
    "        # ì „ì²´ ê°œì„ ìœ¨\n",
    "        improvements = calculate_improvement(baseline_results, finetuned_results)\n",
    "        if improvements:\n",
    "            avg_improvement = np.mean(list(improvements.values()))\n",
    "            print(f\"\\nğŸŒŸ í‰ê·  ì„±ëŠ¥ ê°œì„ : {avg_improvement:+.1f}%\")\n",
    "            \n",
    "            if avg_improvement > 5:\n",
    "                print(\"ğŸš€ íŒŒì¸íŠœë‹ì´ ìƒë‹¹í•œ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!\")\n",
    "            elif avg_improvement > 1:\n",
    "                print(\"âœ… íŒŒì¸íŠœë‹ìœ¼ë¡œ ì„±ëŠ¥ì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"ğŸ’¡ íŒŒì¸íŠœë‹ íš¨ê³¼ë¥¼ ë” ë†’ì´ê¸° ìœ„í•œ ì¶”ê°€ ìµœì í™”ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ (ë‹¨ë… í‰ê°€):\")\n",
    "        print(f\"  ROUGE-1: {baseline_results['rouge1']:.3f}\")\n",
    "        print(f\"  ROUGE-L: {baseline_results['rougeL']:.3f}\")\n",
    "        print(f\"  BLEU: {baseline_results['bleu']:.3f}\")\n",
    "        print(f\"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {baseline_results['cosine_similarity']:.3f}\")\n",
    "        print(f\"\\nğŸ“ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ í•´ì„:\")\n",
    "        print(f\"  - ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ì˜ RAG ì„±ëŠ¥ì„ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤\")\n",
    "        print(f\"  - íŒŒì¸íŠœë‹ ëª¨ë¸ê³¼ ë¹„êµí•˜ë©´ ê°œì„  íš¨ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "        print(f\"  - í˜„ì¬ ê²°ê³¼ëŠ” í–¥í›„ íŒŒì¸íŠœë‹ íš¨ê³¼ ì¸¡ì •ì˜ ê¸°ì¤€ì ì´ ë©ë‹ˆë‹¤\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼:\")\n",
    "    print(f\"  - baseline_vs_finetuned_evaluation.json (í‰ê°€ ê²°ê³¼)\")\n",
    "    print(f\"  - model_performance_comparison.png (ì‹œê°í™”)\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë„ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´:\")\n",
    "    print(\"   1. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ â†’ ëŸ°íƒ€ì„ ì¬ì‹œì‘\")\n",
    "    print(\"   2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ â†’ 1-2ë²ˆ ì…€ ì¬ì‹¤í–‰\") \n",
    "    print(\"   3. í‰ê°€ ë°ì´í„°ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ â†’ 01ë²ˆ ë…¸íŠ¸ë¶ ë¨¼ì € ì‹¤í–‰\")\n",
    "\n",
    "print(f\"\\nğŸ“ Day 1 ì‹¤ìŠµ ì‹œë¦¬ì¦ˆ ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"âœ… 01ë²ˆ: RAFT ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦\")\n",
    "print(\"âœ… 02ë²ˆ: ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ë° ì‹œê°í™”\") \n",
    "print(\"âœ… 03ë²ˆ: QLoRA íŒŒì¸íŠœë‹ ì‹¤í–‰\")\n",
    "print(\"âœ… 04ë²ˆ: ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ì„±ëŠ¥ ë¹„êµ\")\n",
    "print(\"\")\n",
    "\n",
    "# ì‹¤ìŠµ ì™„ë£Œ ìˆ˜ì¤€ í™•ì¸\n",
    "if 'finetuned_results' in locals() and finetuned_results:\n",
    "    completion_level = \"ğŸŒŸ ì™„ì „ ì™„ë£Œ\"\n",
    "    print(f\"{completion_level}: ëª¨ë“  ì‹¤ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ğŸ† ë² ì´ìŠ¤ë¼ì¸ vs íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ ë¹„êµê¹Œì§€ ëª¨ë“  ë‹¨ê³„ë¥¼ ë§ˆì³¤ìŠµë‹ˆë‹¤!\")\n",
    "elif 'baseline_results' in locals() and baseline_results:\n",
    "    completion_level = \"âš ï¸ ë¶€ë¶„ ì™„ë£Œ\"\n",
    "    print(f\"{completion_level}: ë² ì´ìŠ¤ë¼ì¸ í‰ê°€ê¹Œì§€ëŠ” ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ¯ ì™„ì „í•œ ì‹¤ìŠµ ì™„ë£Œë¥¼ ìœ„í•´ì„œëŠ”:\")\n",
    "    print(\"   1. 03_fine_tuning_with_lora.ipynb ì™„ë£Œ\")\n",
    "    print(\"   2. ì´ ë…¸íŠ¸ë¶ ì¬ì‹¤í–‰ìœ¼ë¡œ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¹„êµ\")\n",
    "else:\n",
    "    completion_level = \"ğŸ”„ ì¬ì‹¤í–‰ í•„ìš”\"\n",
    "    print(f\"{completion_level}: ì‹¤ìŠµ í™˜ê²½ì— ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ğŸ’¡ í•´ê²°ì±…:\")\n",
    "    print(\"   1. ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ì²˜ìŒë¶€í„° ì¬ì‹¤í–‰\")\n",
    "    print(\"   2. 01ë²ˆ â†’ 02ë²ˆ â†’ 03ë²ˆ â†’ 04ë²ˆ ìˆœì„œë¡œ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"ğŸš€ ì´ì œ ì—¬ëŸ¬ë¶„ì€ ë‹¤ìŒ ëŠ¥ë ¥ì„ ê°–ì¶”ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "print(\"   â€¢ RAG ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ RAFT ë°ì´í„° ì „ì²˜ë¦¬\")\n",
    "print(\"   â€¢ QLoRAë¥¼ í™œìš©í•œ íš¨ìœ¨ì  ëŒ€ê·œëª¨ ëª¨ë¸ íŒŒì¸íŠœë‹\")\n",
    "print(\"   â€¢ ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ í™œìš©í•œ ì¢…í•©ì  ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\")\n",
    "print(\"   â€¢ ë² ì´ìŠ¤ë¼ì¸ê³¼ íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ì •ëŸ‰ì /ì •ì„±ì  ë¹„êµ\")\n",
    "print(\"\")\n",
    "print(\"ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:\")\n",
    "if 'finetuned_results' in locals() and finetuned_results:\n",
    "    print(\"   ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! ëª¨ë“  ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   â€¢ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì— ëª¨ë¸ ì ìš© ê³ ë ¤\")\n",
    "    print(\"   â€¢ ë„ë©”ì¸ë³„ íŠ¹í™” ë°ì´í„°ë¡œ ì¶”ê°€ íŒŒì¸íŠœë‹ ì‹œë„\")\n",
    "    print(\"   â€¢ ë” í° ëª¨ë¸ì´ë‚˜ ë‹¤ë¥¸ íŒŒì¸íŠœë‹ ê¸°ë²• ì‹¤í—˜\")\n",
    "    print(\"   â€¢ í—ˆê¹…í˜ì´ìŠ¤ Hubì— ëª¨ë¸ ì—…ë¡œë“œ ë° ê³µìœ \")\n",
    "else:\n",
    "    print(\"   ğŸ”„ 03ë²ˆ ë…¸íŠ¸ë¶ì„ ì™„ë£Œí•˜ì—¬ íŒŒì¸íŠœë‹ ëª¨ë¸ ìƒì„±\")\n",
    "    print(\"   ğŸ” ì´ ë…¸íŠ¸ë¶ì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì—¬ ì™„ì „í•œ ì„±ëŠ¥ ë¹„êµ\")\n",
    "    print(\"   ğŸ“ˆ íŒŒì¸íŠœë‹ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •\")\n",
    "    print(\"   ğŸ¯ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„  í™•ì¸\")\n",
    "\n",
    "print(f\"\\nğŸŒŸ RAFT ë°©ë²•ë¡ ì„ í™œìš©í•œ í•œêµ­ì–´ RAG ëª¨ë¸ íŒŒì¸íŠœë‹ ì‹¤ìŠµ\")\n",
    "print(f\"   ì™„ë£Œ ìˆ˜ì¤€: {completion_level}\")\n",
    "print(\"ğŸ“ í•œêµ­ì–´ RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì—­ëŸ‰ì„ íšë“í•˜ì…¨ìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
