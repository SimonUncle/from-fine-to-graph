{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Day 1 실습 2: 데이터 품질 검증 및 점검\n",
    "\n",
    "## 학습 목표\n",
    "- 전처리된 데이터의 품질 검증\n",
    "- 토큰 길이 사전 점검\n",
    "- RAFT 데이터 구조 검증\n",
    "- 중복 및 이상치 탐지\n",
    "- 데이터 분포 분석 및 시각화\n",
    "\n",
    "## 시간: 14:00–14:40 (40분)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 필요한 라이브러리 확인 (01번에서 이미 설치되었으므로 확인만)\nimport importlib\n\ndef check_package(package_name, import_name=None):\n    \"\"\"패키지 설치 여부만 확인\"\"\"\n    if import_name is None:\n        import_name = package_name.replace('-', '_')\n    \n    try:\n        importlib.import_module(import_name)\n        print(f\"✅ {package_name} 사용 가능\")\n        return True\n    except ImportError:\n        print(f\"❌ {package_name} 설치 필요 - 01번 노트북을 먼저 실행하세요\")\n        return False\n\nprint(\"🚀 Day 1 실습 2: 데이터 품질 검증\")\nprint(\"🔍 필요한 라이브러리 확인 중...\")\n\n# 02번에서 사용할 라이브러리들 확인\npackages = [\n    (\"transformers\", \"transformers\"),\n    (\"torch\", \"torch\"), \n    (\"datasets\", \"datasets\"),\n    (\"jsonlines\", \"jsonlines\"),\n    (\"pandas\", \"pandas\"),\n    (\"numpy\", \"numpy\"),\n    (\"matplotlib\", \"matplotlib\"),\n    (\"seaborn\", \"seaborn\"),\n    (\"tqdm\", \"tqdm\"),\n    (\"scikit-learn\", \"sklearn\")\n]\n\nall_available = True\nprint(\"📋 라이브러리 상태:\")\nfor package_name, import_name in packages:\n    if not check_package(package_name, import_name):\n        all_available = False\n\nif all_available:\n    print(\"\\n🎉 모든 라이브러리 준비 완료!\")\n    print(\"💡 데이터 품질 검증을 시작합니다.\")\nelse:\n    print(\"\\n⚠️ 일부 라이브러리가 설치되지 않았습니다.\")\n    print(\"💡 먼저 01_data_preprocessing_and_validation.ipynb를 실행하세요.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport jsonlines\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom tqdm import tqdm\nimport warnings\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, TrainerCallback\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport torch\n\nwarnings.filterwarnings('ignore')\n\n# 한글 폰트 설정 (matplotlib) - 데이터 품질 검증 차트에서 한글이 깨지지 않도록 설정\nprint(\"🔧 한글 폰트 설정 중...\")\n!apt-get update -qq\n!apt-get install fonts-nanum -qq > /dev/null\n\nimport matplotlib.font_manager as fm\n\n# 나눔바른고딕 폰트 경로 설정\nfontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n# 폰트 매니저에 폰트 추가 - 품질 분석 그래프에서 한글 표시를 위해 필요\nfm.fontManager.addfont(fontpath)\n\n# matplotlib 설정 업데이트 - 모든 품질 분석 차트에서 한글이 정상적으로 표시됨\nplt.rcParams.update({\n    'font.family': 'NanumBarunGothic',  # 기본 폰트를 나눔바른고딕으로 설정\n    'axes.unicode_minus': False         # 음수 기호 표시 문제 해결 (통계 차트에서 중요)\n})\n\n# 시각화 스타일 설정 - 더 깔끔하고 전문적인 차트를 위한 설정\nplt.style.use('default')  # 기본 스타일 사용\nsns.set_palette(\"husl\")   # 색상 팔레트 설정 - 구별하기 쉬운 색상 사용\n\nprint(\"✅ 한글 폰트 설정 완료 - 데이터 품질 분석 차트에서 한글이 정상 표시됩니다\")\nprint(\"📦 라이브러리 import 완료!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 추가 라이브러리 import (품질 분석에 필요한 특수 라이브러리들)\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom collections import Counter, defaultdict\nimport re\nfrom sentence_transformers import SentenceTransformer\nfrom wordcloud import WordCloud\n\nprint(\"📦 추가 분석 라이브러리 import 완료!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 전처리된 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_data():\n",
    "    \"\"\"\n",
    "    전처리된 데이터와 메타데이터를 로드하는 함수\n",
    "    \n",
    "    Returns:\n",
    "        train_data, valid_data, metadata\n",
    "    \"\"\"\n",
    "    print(\"🔄 전처리된 데이터 로드 중...\")\n",
    "    \n",
    "    \n",
    "    # Train 데이터 로드\n",
    "    train_data = []\n",
    "    with jsonlines.open(\"processed_data/train_raft_ko.jsonl\", \"r\") as reader:\n",
    "        train_data = list(reader)\n",
    "    \n",
    "    # Valid 데이터 로드\n",
    "    valid_data = []\n",
    "    with jsonlines.open(\"processed_data/valid_raft_ko.jsonl\", \"r\") as reader:\n",
    "        valid_data = list(reader)\n",
    "    \n",
    "    # 메타데이터 로드\n",
    "    with open(\"processed_data/metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"✅ 데이터 로드 완료:\")\n",
    "    print(f\"  - Train: {len(train_data)}개 샘플\")\n",
    "    print(f\"  - Valid: {len(valid_data)}개 샘플\")\n",
    "    \n",
    "    return train_data, valid_data, metadata\n",
    "        \n",
    "    \n",
    "# 데이터 로드\n",
    "train_data, valid_data, metadata = load_processed_data()\n",
    "\n",
    "if train_data is not None:\n",
    "    print(f\"\\n📋 메타데이터 정보:\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 기본 데이터 품질 검증\n",
    "\n",
    "### 📋 검증 항목\n",
    "1. 데이터 무결성 확인\n",
    "2. 필수 필드 존재 여부\n",
    "3. 데이터 타입 검증\n",
    "4. 빈 값 및 결측치 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_integrity(data: List[Dict], data_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    데이터 무결성 검증 함수\n",
    "    \n",
    "    Args:\n",
    "        data: 검증할 데이터 리스트\n",
    "        data_name: 데이터셋 이름\n",
    "        \n",
    "    Returns:\n",
    "        검증 결과 딕셔너리\n",
    "    \"\"\"\n",
    "    print(f\"🔍 {data_name} 데이터 무결성 검증 중...\")\n",
    "    \n",
    "    integrity_report = {\n",
    "        \"total_samples\": len(data),\n",
    "        \"required_fields\": [\"messages\", \"type\", \"original_question\", \"original_answer\"],\n",
    "        \"missing_fields\": defaultdict(int),\n",
    "        \"empty_values\": defaultdict(int),\n",
    "        \"invalid_types\": defaultdict(int),\n",
    "        \"message_structure_errors\": 0,\n",
    "        \"type_distribution\": defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    for i, item in enumerate(data):\n",
    "        # 1. 필수 필드 존재 확인\n",
    "        for field in integrity_report[\"required_fields\"]:\n",
    "            if field not in item:\n",
    "                integrity_report[\"missing_fields\"][field] += 1\n",
    "        \n",
    "        # 2. 빈 값 확인\n",
    "        for field in [\"original_question\", \"original_answer\"]:\n",
    "            if field in item and (not item[field] or item[field].strip() == \"\"):\n",
    "                integrity_report[\"empty_values\"][field] += 1\n",
    "        \n",
    "        # 3. messages 구조 검증\n",
    "        if \"messages\" in item:\n",
    "            if not isinstance(item[\"messages\"], list) or len(item[\"messages\"]) != 3:\n",
    "                integrity_report[\"message_structure_errors\"] += 1\n",
    "            else:\n",
    "                # 메시지 역할 확인\n",
    "                expected_roles = [\"system\", \"user\", \"assistant\"]\n",
    "                actual_roles = [msg.get(\"role\", \"\") for msg in item[\"messages\"]]\n",
    "                if actual_roles != expected_roles:\n",
    "                    integrity_report[\"message_structure_errors\"] += 1\n",
    "        \n",
    "        # 4. type 분포 확인\n",
    "        if \"type\" in item:\n",
    "            integrity_report[\"type_distribution\"][item[\"type\"]] += 1\n",
    "    \n",
    "    return integrity_report\n",
    "\n",
    "def print_integrity_report(report: Dict[str, Any], data_name: str):\n",
    "    \"\"\"\n",
    "    무결성 검증 결과 출력 함수\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 {data_name} 무결성 검증 결과:\")\n",
    "    print(f\"  총 샘플 수: {report['total_samples']}개\")\n",
    "    \n",
    "    # 결측 필드\n",
    "    if report['missing_fields']:\n",
    "        print(f\"  ❌ 결측 필드:\")\n",
    "        for field, count in report['missing_fields'].items():\n",
    "            print(f\"    {field}: {count}개 ({count/report['total_samples']:.1%})\")\n",
    "    else:\n",
    "        print(f\"  ✅ 필수 필드 모두 존재\")\n",
    "    \n",
    "    # 빈 값\n",
    "    if report['empty_values']:\n",
    "        print(f\"  ⚠️ 빈 값:\")\n",
    "        for field, count in report['empty_values'].items():\n",
    "            print(f\"    {field}: {count}개 ({count/report['total_samples']:.1%})\")\n",
    "    else:\n",
    "        print(f\"  ✅ 빈 값 없음\")\n",
    "    \n",
    "    # 메시지 구조 오류\n",
    "    if report['message_structure_errors'] > 0:\n",
    "        error_rate = report['message_structure_errors'] / report['total_samples']\n",
    "        print(f\"  ❌ 메시지 구조 오류: {report['message_structure_errors']}개 ({error_rate:.1%})\")\n",
    "    else:\n",
    "        print(f\"  ✅ 메시지 구조 정상\")\n",
    "    \n",
    "    # 타입 분포\n",
    "    print(f\"  📈 타입 분포:\")\n",
    "    for type_name, count in report['type_distribution'].items():\n",
    "        print(f\"    {type_name}: {count}개 ({count/report['total_samples']:.1%})\")\n",
    "\n",
    "# Train/Valid 데이터 무결성 검증\n",
    "if train_data is not None:\n",
    "    train_report = validate_data_integrity(train_data, \"Train\")\n",
    "    valid_report = validate_data_integrity(valid_data, \"Valid\")\n",
    "    \n",
    "    print_integrity_report(train_report, \"Train\")\n",
    "    print_integrity_report(valid_report, \"Valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 토큰 길이 분석\n",
    "\n",
    "### 🔍 분석 내용\n",
    "1. 전체 대화 토큰 길이 분포\n",
    "2. 메시지별 토큰 길이 분석\n",
    "3. 4096 토큰 제한 준수 확인\n",
    "4. Outlier 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAONE 토크나이저 로드\n",
    "print(\"🔄 토크나이저 로드 중...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\")\n",
    "print(\"✅ 토크나이저 로드 완료\")\n",
    "\n",
    "def analyze_token_distribution(data: List[Dict], data_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    토큰 길이 분포 분석 함수\n",
    "    \n",
    "    Args:\n",
    "        data: 분석할 데이터\n",
    "        data_name: 데이터셋 이름\n",
    "        \n",
    "    Returns:\n",
    "        토큰 분석 결과\n",
    "    \"\"\"\n",
    "    print(f\"📊 {data_name} 토큰 길이 분석 중...\")\n",
    "    \n",
    "    token_analysis = {\n",
    "        \"total_tokens\": [],\n",
    "        \"system_tokens\": [],\n",
    "        \"user_tokens\": [],\n",
    "        \"assistant_tokens\": [],\n",
    "        \"overflow_samples\": [],\n",
    "        \"type_wise_tokens\": {\"positive\": [], \"negative\": []}\n",
    "    }\n",
    "    \n",
    "    for i, item in enumerate(tqdm(data, desc=f\"{data_name} 토큰 분석\")):\n",
    "        if \"messages\" not in item or len(item[\"messages\"]) != 3:\n",
    "            continue\n",
    "        \n",
    "        messages = item[\"messages\"]\n",
    "        \n",
    "        # 전체 대화 토큰 수\n",
    "        full_conversation = tokenizer.apply_chat_template(\n",
    "            messages, tokenize=False, add_generation_prompt=False\n",
    "        )\n",
    "        total_tokens = len(tokenizer.encode(full_conversation))\n",
    "        token_analysis[\"total_tokens\"].append(total_tokens)\n",
    "        \n",
    "        # 메시지별 토큰 수\n",
    "        for j, (msg, token_list) in enumerate(zip(messages, \n",
    "                                                 [\"system_tokens\", \"user_tokens\", \"assistant_tokens\"])):\n",
    "            msg_tokens = len(tokenizer.encode(msg[\"content\"]))\n",
    "            token_analysis[token_list].append(msg_tokens)\n",
    "        \n",
    "        # 4096 토큰 초과 샘플 기록\n",
    "        if total_tokens > 4096:\n",
    "            token_analysis[\"overflow_samples\"].append({\n",
    "                \"index\": i,\n",
    "                \"total_tokens\": total_tokens,\n",
    "                \"type\": item.get(\"type\", \"unknown\")\n",
    "            })\n",
    "        \n",
    "        # Type별 토큰 분포\n",
    "        sample_type = item.get(\"type\", \"unknown\")\n",
    "        if sample_type in token_analysis[\"type_wise_tokens\"]:\n",
    "            token_analysis[\"type_wise_tokens\"][sample_type].append(total_tokens)\n",
    "    \n",
    "    return token_analysis\n",
    "\n",
    "# 토큰 분석 실행\n",
    "if train_data is not None:\n",
    "    train_tokens = analyze_token_distribution(train_data, \"Train\")\n",
    "    valid_tokens = analyze_token_distribution(valid_data, \"Valid\")\n",
    "    \n",
    "    # 결과 요약 출력\n",
    "    def print_token_summary(token_analysis: Dict, data_name: str):\n",
    "        total_tokens = token_analysis[\"total_tokens\"]\n",
    "        if not total_tokens:\n",
    "            return\n",
    "            \n",
    "        print(f\"\\n📊 {data_name} 토큰 분석 결과:\")\n",
    "        print(f\"  평균 토큰 수: {np.mean(total_tokens):.1f}\")\n",
    "        print(f\"  중간값: {np.median(total_tokens):.1f}\")\n",
    "        print(f\"  표준편차: {np.std(total_tokens):.1f}\")\n",
    "        print(f\"  최소/최대: {min(total_tokens)} / {max(total_tokens)}\")\n",
    "        print(f\"  4096 초과: {len(token_analysis['overflow_samples'])}개 ({len(token_analysis['overflow_samples'])/len(total_tokens):.1%})\")\n",
    "        \n",
    "        # Type별 평균\n",
    "        for type_name, tokens in token_analysis[\"type_wise_tokens\"].items():\n",
    "            if tokens:\n",
    "                print(f\"  {type_name} 평균: {np.mean(tokens):.1f} 토큰\")\n",
    "    \n",
    "    print_token_summary(train_tokens, \"Train\")\n",
    "    print_token_summary(valid_tokens, \"Valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 분포 시각화\n",
    "\n",
    "### 📈 시각화 차트\n",
    "1. 토큰 길이 분포 히스토그램\n",
    "2. Type별 토큰 길이 비교\n",
    "3. 메시지 역할별 토큰 분포\n",
    "4. Train/Valid 분포 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_comprehensive_visualization(train_tokens: Dict, valid_tokens: Dict):\n    \"\"\"\n    종합적인 데이터 품질 시각화 함수\n    이 함수는 6개의 다른 관점에서 데이터를 분석하고 시각화합니다.\n    각 차트는 데이터의 특정 측면을 보여주며, 전체적인 품질을 평가할 수 있게 해줍니다.\n    \"\"\"\n    print(\"📊 종합 데이터 품질 대시보드 생성 중...\")\n    \n    # 대시보드 스타일 서브플롯 생성 (3행 2열 구성)\n    # 📊 의미: 6개의 차트로 데이터의 다양한 측면을 한번에 분석\n    fig = make_subplots(\n        rows=3, cols=2,\n        subplot_titles=[\n            \"📏 토큰 길이 분포 비교 (Train vs Valid)\",\n            \"🎯 Type별 토큰 길이 특성\", \n            \"💬 메시지 역할별 토큰 분포\",\n            \"⚠️ 4096 토큰 초과 샘플 분석\",\n            \"📦 토큰 길이 통계 (박스플롯)\",\n            \"📈 누적 분포 함수 (CDF) 비교\"\n        ],\n        specs=[\n            [{\"secondary_y\": False}, {\"secondary_y\": False}],\n            [{\"secondary_y\": False}, {\"secondary_y\": False}],\n            [{\"secondary_y\": False}, {\"secondary_y\": False}]\n        ]\n    )\n    \n    # 1. 토큰 길이 분포 히스토그램 (Train vs Valid)\n    # 📊 의미: Train과 Valid 데이터의 토큰 길이 분포가 유사한지 확인\n    # - 두 분포가 비슷하면 데이터 분할이 잘 되었음을 의미\n    # - 큰 차이가 있다면 분할 전략을 재검토해야 함\n    fig.add_trace(\n        go.Histogram(x=train_tokens[\"total_tokens\"], name=\"Train 데이터\", \n                    opacity=0.7, nbinsx=50, marker_color='lightblue'),\n        row=1, col=1\n    )\n    fig.add_trace(\n        go.Histogram(x=valid_tokens[\"total_tokens\"], name=\"Valid 데이터\", \n                    opacity=0.7, nbinsx=50, marker_color='lightcoral'),\n        row=1, col=1\n    )\n    \n    # 2. Type별 토큰 길이 분포\n    # 📊 의미: RAFT의 Positive/Negative 샘플이 토큰 길이 측면에서 균형잡혀 있는지 확인\n    # - Positive 샘플: 정답 context가 포함되어 보통 더 길 수 있음\n    # - Negative 샘플: 정답 없는 distractor만 있어 비교적 짧을 수 있음\n    colors = ['lightgreen', 'lightsalmon']\n    for i, (type_name, tokens) in enumerate(train_tokens[\"type_wise_tokens\"].items()):\n        if tokens:\n            fig.add_trace(\n                go.Histogram(x=tokens, name=f\"Train-{type_name.capitalize()}\", \n                           opacity=0.7, nbinsx=30, marker_color=colors[i % len(colors)]),\n                row=1, col=2\n            )\n    \n    # 3. 메시지 역할별 토큰 분포\n    # 📊 의미: System, User, Assistant 메시지의 길이 분포를 비교\n    # - System: 보통 고정된 길이 (역할 설명)\n    # - User: Context와 질문 포함으로 가장 길 수 있음  \n    # - Assistant: 답변 길이로 적절한 범위에 있어야 함\n    roles = [\"system_tokens\", \"user_tokens\", \"assistant_tokens\"] \n    role_names = [\"System (역할 설명)\", \"User (질문+Context)\", \"Assistant (답변)\"]\n    role_colors = ['lightsteelblue', 'lightpink', 'lightgreen']\n    \n    for role, name, color in zip(roles, role_names, role_colors):\n        if train_tokens[role]:\n            fig.add_trace(\n                go.Box(y=train_tokens[role], name=name, \n                      marker_color=color, boxmean=True),\n                row=2, col=1\n            )\n    \n    # 4. 4096 토큰 초과 분석\n    # 📊 의미: 모델의 최대 입력 길이를 초과하는 샘플들의 Type별 분포\n    # - 초과 샘플이 많으면 데이터 전처리나 Context 길이 조정 필요\n    # - Type별로 초과 비율이 다르면 해당 Type의 구조적 문제 가능성\n    overflow_types = defaultdict(int)\n    for sample in train_tokens[\"overflow_samples\"]:\n        overflow_types[sample[\"type\"]] += 1\n    \n    if overflow_types:\n        fig.add_trace(\n            go.Bar(x=list(overflow_types.keys()), y=list(overflow_types.values()),\n                   name=\"토큰 초과 샘플\", marker_color='red', opacity=0.7),\n            row=2, col=2\n        )\n        # 초과율 표시를 위한 텍스트 추가\n        total_samples = len(train_tokens[\"total_tokens\"])\n        for type_name, count in overflow_types.items():\n            fig.add_annotation(\n                x=type_name, y=count + 0.1,\n                text=f\"{count/total_samples:.1%}\",\n                showarrow=False, row=2, col=2\n            )\n    \n    # 5. 토큰 길이 박스플롯 (Train vs Valid)\n    # 📊 의미: 사분위수와 이상값을 통한 상세 분포 비교\n    # - 중앙값, 사분위수로 분포의 중심과 퍼짐 정도 파악\n    # - 이상값(outlier)으로 비정상적으로 긴 샘플 식별\n    fig.add_trace(\n        go.Box(y=train_tokens[\"total_tokens\"], name=\"Train 분포\",\n               marker_color='lightblue', boxmean=True),\n        row=3, col=1\n    )\n    fig.add_trace(\n        go.Box(y=valid_tokens[\"total_tokens\"], name=\"Valid 분포\", \n               marker_color='lightcoral', boxmean=True),\n        row=3, col=1\n    )\n    \n    # 6. 누적 분포 함수 (CDF)\n    # 📊 의미: 특정 토큰 길이 이하의 샘플 비율을 보여줌\n    # - 예: 2000 토큰 이하 샘플이 전체의 몇 %인지 확인\n    # - 데이터의 분포 특성과 길이 제한 설정에 도움\n    train_sorted = np.sort(train_tokens[\"total_tokens\"])\n    train_cdf = np.arange(1, len(train_sorted) + 1) / len(train_sorted)\n    \n    valid_sorted = np.sort(valid_tokens[\"total_tokens\"])  \n    valid_cdf = np.arange(1, len(valid_sorted) + 1) / len(valid_sorted)\n    \n    fig.add_trace(\n        go.Scatter(x=train_sorted, y=train_cdf, mode='lines', \n                   name=\"Train CDF\", line=dict(color='blue', width=2)),\n        row=3, col=2\n    )\n    fig.add_trace(\n        go.Scatter(x=valid_sorted, y=valid_cdf, mode='lines',\n                   name=\"Valid CDF\", line=dict(color='red', width=2)),\n        row=3, col=2\n    )\n    \n    # 4096 토큰 제한선 추가 (중요한 기준선)\n    # 📊 의미: 모델의 최대 입력 길이 표시로 데이터 적합성 판단\n    fig.add_vline(x=4096, line_dash=\"dash\", line_color=\"orange\", \n                  annotation_text=\"🚨 모델 최대 길이: 4096 토큰\", \n                  annotation_position=\"top\", row=3, col=2)\n    \n    # 평균선도 추가 (참고용)\n    train_mean = np.mean(train_tokens[\"total_tokens\"])\n    fig.add_vline(x=train_mean, line_dash=\"dot\", line_color=\"green\",\n                  annotation_text=f\"📊 Train 평균: {train_mean:.0f}토큰\",\n                  annotation_position=\"bottom\", row=3, col=2)\n    \n    # 전체 레이아웃 업데이트\n    fig.update_layout(\n        height=1200,  # 충분한 높이로 각 차트가 잘 보이도록\n        title_text=\"📊 데이터 품질 종합 분석 대시보드<br><sub>파인튜닝 전 필수 점검 사항</sub>\",\n        showlegend=True,\n        title_x=0.5,\n        title_font_size=18\n    )\n    \n    # 각 서브플롯별 축 제목 설정\n    fig.update_xaxes(title_text=\"토큰 길이\", row=1, col=1)\n    fig.update_yaxes(title_text=\"샘플 수\", row=1, col=1)\n    \n    fig.update_xaxes(title_text=\"토큰 길이\", row=1, col=2)\n    fig.update_yaxes(title_text=\"샘플 수\", row=1, col=2)\n    \n    fig.update_yaxes(title_text=\"토큰 길이\", row=2, col=1)\n    \n    fig.update_xaxes(title_text=\"샘플 Type\", row=2, col=2)\n    fig.update_yaxes(title_text=\"초과 샘플 수\", row=2, col=2)\n    \n    fig.update_yaxes(title_text=\"토큰 길이\", row=3, col=1)\n    \n    fig.update_xaxes(title_text=\"토큰 길이\", row=3, col=2)\n    fig.update_yaxes(title_text=\"누적 확률\", row=3, col=2)\n    \n    return fig\n\n# 시각화 생성 및 표시\nif train_data is not None and train_tokens[\"total_tokens\"]:\n    print(\"🎨 데이터 품질 대시보드 생성 중...\")\n    dashboard_fig = create_comprehensive_visualization(train_tokens, valid_tokens)\n    dashboard_fig.show()\n    \n    # HTML로도 저장하여 상호작용 가능하게 함\n    dashboard_fig.write_html(\"processed_data/interactive_dashboard.html\")\n    print(\"✅ 상호작용 대시보드 저장: processed_data/interactive_dashboard.html\")\n    print(\"\\n🔍 대시보드 해석 가이드:\")\n    print(\"  📏 토큰 길이 분포: Train/Valid 분포가 유사해야 분할이 적절함\")\n    print(\"  🎯 Type별 분포: Positive/Negative 샘플의 토큰 길이 균형 확인\")\n    print(\"  💬 메시지 역할별: System < Assistant < User 순으로 길이가 일반적\")\n    print(\"  ⚠️ 토큰 초과: 4096을 초과하는 샘플은 잘리거나 제거 필요\")  \n    print(\"  📦 박스플롯: 이상값(점들)이 많으면 데이터 정제 필요\")\n    print(\"  📈 CDF: 90% 샘플이 4096 이하에 있어야 이상적\")\n    print(\"\\n💡 이 대시보드를 통해 파인튜닝 전 데이터 적합성을 종합 판단할 수 있습니다!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 중복 및 유사도 분석\n",
    "\n",
    "### 🔍 분석 내용\n",
    "1. 정확한 텍스트 중복 탐지\n",
    "2. 의미적 유사도 분석\n",
    "3. Question 다양성 검증\n",
    "4. Answer 품질 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_duplicates_and_similarity(data: List[Dict], sample_size: int = 100) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    중복 및 유사도 분석 함수\n",
    "    \n",
    "    Args:\n",
    "        data: 분석할 데이터\n",
    "        sample_size: 유사도 분석을 위한 샘플 크기\n",
    "        \n",
    "    Returns:\n",
    "        중복/유사도 분석 결과\n",
    "    \"\"\"\n",
    "    print(\"🔍 중복 및 유사도 분석 중...\")\n",
    "    \n",
    "    analysis_result = {\n",
    "        \"exact_duplicates\": {\n",
    "            \"questions\": 0,\n",
    "            \"answers\": 0,\n",
    "            \"full_conversations\": 0\n",
    "        },\n",
    "        \"question_diversity\": {},\n",
    "        \"answer_diversity\": {},\n",
    "        \"semantic_similarity\": {}\n",
    "    }\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    questions = [item.get(\"original_question\", \"\") for item in data]\n",
    "    answers = [item.get(\"original_answer\", \"\") for item in data]\n",
    "    \n",
    "    # 1. 정확한 중복 탐지\n",
    "    unique_questions = set(questions)\n",
    "    unique_answers = set(answers)\n",
    "    \n",
    "    analysis_result[\"exact_duplicates\"][\"questions\"] = len(questions) - len(unique_questions)\n",
    "    analysis_result[\"exact_duplicates\"][\"answers\"] = len(answers) - len(unique_answers)\n",
    "    \n",
    "    # 2. Question/Answer 다양성 분석\n",
    "    analysis_result[\"question_diversity\"] = {\n",
    "        \"total_questions\": len(questions),\n",
    "        \"unique_questions\": len(unique_questions),\n",
    "        \"diversity_ratio\": len(unique_questions) / len(questions) if questions else 0,\n",
    "        \"avg_length\": np.mean([len(q) for q in questions if q]),\n",
    "        \"length_std\": np.std([len(q) for q in questions if q])\n",
    "    }\n",
    "    \n",
    "    analysis_result[\"answer_diversity\"] = {\n",
    "        \"total_answers\": len(answers),\n",
    "        \"unique_answers\": len(unique_answers),\n",
    "        \"diversity_ratio\": len(unique_answers) / len(answers) if answers else 0,\n",
    "        \"avg_length\": np.mean([len(a) for a in answers if a]),\n",
    "        \"length_std\": np.std([len(a) for a in answers if a])\n",
    "    }\n",
    "    \n",
    "    # 3. 의미적 유사도 분석 (샘플링)\n",
    "    if len(data) > sample_size:\n",
    "        sampled_indices = np.random.choice(len(data), sample_size, replace=False)\n",
    "        sampled_questions = [questions[i] for i in sampled_indices if questions[i]]\n",
    "        sampled_answers = [answers[i] for i in sampled_indices if answers[i]]\n",
    "    else:\n",
    "        sampled_questions = [q for q in questions if q]\n",
    "        sampled_answers = [a for a in answers if a]\n",
    "    \n",
    "    try:\n",
    "        print(\"🔄 의미적 유사도 계산 중... (시간이 걸릴 수 있습니다)\")\n",
    "        model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        \n",
    "        if sampled_questions:\n",
    "            question_embeddings = model.encode(sampled_questions[:50])  # 계산 시간 단축\n",
    "            q_similarity_matrix = cosine_similarity(question_embeddings)\n",
    "            \n",
    "            # 대각선 제외한 유사도 점수\n",
    "            q_similarities = q_similarity_matrix[np.triu_indices_from(q_similarity_matrix, k=1)]\n",
    "            \n",
    "            analysis_result[\"semantic_similarity\"][\"questions\"] = {\n",
    "                \"mean_similarity\": np.mean(q_similarities),\n",
    "                \"max_similarity\": np.max(q_similarities),\n",
    "                \"high_similarity_pairs\": np.sum(q_similarities > 0.8)\n",
    "            }\n",
    "        \n",
    "        if sampled_answers:\n",
    "            answer_embeddings = model.encode(sampled_answers[:50])\n",
    "            a_similarity_matrix = cosine_similarity(answer_embeddings)\n",
    "            \n",
    "            a_similarities = a_similarity_matrix[np.triu_indices_from(a_similarity_matrix, k=1)]\n",
    "            \n",
    "            analysis_result[\"semantic_similarity\"][\"answers\"] = {\n",
    "                \"mean_similarity\": np.mean(a_similarities),\n",
    "                \"max_similarity\": np.max(a_similarities),\n",
    "                \"high_similarity_pairs\": np.sum(a_similarities > 0.8)\n",
    "            }\n",
    "            \n",
    "        print(\"✅ 의미적 유사도 계산 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ 의미적 유사도 계산 실패: {e}\")\n",
    "        analysis_result[\"semantic_similarity\"] = {\"error\": str(e)}\n",
    "    \n",
    "    return analysis_result\n",
    "\n",
    "# 중복/유사도 분석 실행\n",
    "if train_data is not None:\n",
    "    similarity_analysis = analyze_duplicates_and_similarity(train_data)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n📊 중복 및 유사도 분석 결과:\")\n",
    "    print(f\"\\n🔍 정확한 중복:\")\n",
    "    for key, value in similarity_analysis[\"exact_duplicates\"].items():\n",
    "        print(f\"  {key}: {value}개\")\n",
    "    \n",
    "    print(f\"\\n📝 Question 다양성:\")\n",
    "    q_div = similarity_analysis[\"question_diversity\"]\n",
    "    print(f\"  전체/고유: {q_div['total_questions']}/{q_div['unique_questions']}\")\n",
    "    print(f\"  다양성 비율: {q_div['diversity_ratio']:.1%}\")\n",
    "    print(f\"  평균 길이: {q_div['avg_length']:.1f}자\")\n",
    "    \n",
    "    print(f\"\\n💬 Answer 다양성:\")\n",
    "    a_div = similarity_analysis[\"answer_diversity\"]\n",
    "    print(f\"  전체/고유: {a_div['total_answers']}/{a_div['unique_answers']}\")\n",
    "    print(f\"  다양성 비율: {a_div['diversity_ratio']:.1%}\")\n",
    "    print(f\"  평균 길이: {a_div['avg_length']:.1f}자\")\n",
    "    \n",
    "    if \"error\" not in similarity_analysis[\"semantic_similarity\"]:\n",
    "        print(f\"\\n🧠 의미적 유사도:\")\n",
    "        if \"questions\" in similarity_analysis[\"semantic_similarity\"]:\n",
    "            q_sim = similarity_analysis[\"semantic_similarity\"][\"questions\"]\n",
    "            print(f\"  Question 평균 유사도: {q_sim['mean_similarity']:.3f}\")\n",
    "            print(f\"  Question 최대 유사도: {q_sim['max_similarity']:.3f}\")\n",
    "            print(f\"  고유사도(>0.8) 쌍: {q_sim['high_similarity_pairs']}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. RAFT 구조 검증\n",
    "\n",
    "### 🎯 RAFT 특화 검증\n",
    "1. Positive/Negative 샘플 균형\n",
    "2. Context 개수 분포\n",
    "3. Context 관련성 분석\n",
    "4. Distractor 품질 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_raft_structure(data: List[Dict]) -> Dict[str, Any]:\n    \"\"\"\n    RAFT 데이터 구조 분석 함수\n    \n    Args:\n        data: RAFT 구조 데이터\n        \n    Returns:\n        RAFT 구조 분석 결과\n    \"\"\"\n    print(\"🎯 RAFT 구조 분석 중...\")\n    \n    raft_analysis = {\n        \"type_distribution\": defaultdict(int),\n        \"context_analysis\": {\n            \"context_counts\": [],\n            \"context_lengths\": []\n        },\n        \"message_analysis\": {\n            \"user_message_lengths\": [],\n            \"system_message_lengths\": [],\n            \"assistant_message_lengths\": []\n        },\n        \"structure_issues\": []\n    }\n    \n    for i, item in enumerate(data):\n        # 1. Type 분포\n        item_type = item.get(\"type\", \"unknown\")\n        raft_analysis[\"type_distribution\"][item_type] += 1\n        \n        # 2. Message 구조 분석\n        if \"messages\" in item and len(item[\"messages\"]) == 3:\n            messages = item[\"messages\"]\n            \n            # 각 메시지 길이 수집\n            raft_analysis[\"message_analysis\"][\"system_message_lengths\"].append(\n                len(messages[0].get(\"content\", \"\"))\n            )\n            raft_analysis[\"message_analysis\"][\"user_message_lengths\"].append(\n                len(messages[1].get(\"content\", \"\"))\n            )\n            raft_analysis[\"message_analysis\"][\"assistant_message_lengths\"].append(\n                len(messages[2].get(\"content\", \"\"))\n            )\n            \n            # 3. User 메시지에서 context 정보 추출\n            user_content = messages[1].get(\"content\", \"\")\n            \n            # Context 개수 추정 (간단한 휴리스틱)\n            context_matches = re.findall(r'컨텍스트 \\d+:', user_content)\n            context_count = len(context_matches)\n            \n            if context_count > 0:\n                raft_analysis[\"context_analysis\"][\"context_counts\"].append(context_count)\n            \n            # Context 섹션 길이\n            context_section_match = re.search(r'=== 컨텍스트 ===\\n(.*?)\\n=== 질문 ===', \n                                             user_content, re.DOTALL)\n            if context_section_match:\n                context_length = len(context_section_match.group(1).strip())\n                raft_analysis[\"context_analysis\"][\"context_lengths\"].append(context_length)\n        else:\n            raft_analysis[\"structure_issues\"].append(f\"Sample {i}: Invalid message structure\")\n    \n    return raft_analysis\n\ndef visualize_raft_analysis(raft_analysis: Dict[str, Any]):\n    \"\"\"\n    RAFT 분석 결과 시각화\n    \"\"\"\n    # 한글 폰트 설정 재확인 - RAFT 차트에서 한글이 깨지지 않도록 보장\n    plt.rcParams.update({\n        'font.family': 'NanumBarunGothic',\n        'axes.unicode_minus': False\n    })\n    \n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n    \n    # 1. Type 분포 파이차트\n    type_counts = list(raft_analysis[\"type_distribution\"].values())\n    type_labels = list(raft_analysis[\"type_distribution\"].keys())\n    \n    ax1.pie(type_counts, labels=type_labels, autopct='%1.1f%%', startangle=90)\n    ax1.set_title('RAFT Type 분포', fontsize=14, fontweight='bold')\n    \n    # 2. Context 개수 분포\n    context_counts = raft_analysis[\"context_analysis\"][\"context_counts\"]\n    if context_counts:\n        ax2.hist(context_counts, bins=range(1, max(context_counts)+2), \n                alpha=0.7, edgecolor='black')\n        ax2.set_xlabel('Context 개수')\n        ax2.set_ylabel('샘플 수')\n        ax2.set_title('Context 개수별 분포', fontsize=14, fontweight='bold')\n        ax2.grid(True, alpha=0.3)\n    \n    # 3. 메시지 길이 분포\n    msg_analysis = raft_analysis[\"message_analysis\"]\n    roles = ['system_message_lengths', 'user_message_lengths', 'assistant_message_lengths']\n    role_names = ['System', 'User', 'Assistant']\n    \n    box_data = [msg_analysis[role] for role in roles if msg_analysis[role]]\n    box_labels = [name for role, name in zip(roles, role_names) if msg_analysis[role]]\n    \n    if box_data:\n        ax3.boxplot(box_data, labels=box_labels)\n        ax3.set_ylabel('메시지 길이 (문자)')\n        ax3.set_title('메시지 역할별 길이 분포', fontsize=14, fontweight='bold')\n        ax3.grid(True, alpha=0.3)\n    \n    # 4. Context 길이 분포\n    context_lengths = raft_analysis[\"context_analysis\"][\"context_lengths\"]\n    if context_lengths:\n        ax4.hist(context_lengths, bins=30, alpha=0.7, color='lightblue', edgecolor='black')\n        ax4.set_xlabel('Context 섹션 길이 (문자)')\n        ax4.set_ylabel('빈도')\n        ax4.set_title('Context 길이 분포', fontsize=14, fontweight='bold')\n        ax4.axvline(np.mean(context_lengths), color='red', linestyle='--', \n                   label=f'평균: {np.mean(context_lengths):.0f}')\n        ax4.legend()\n        ax4.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('processed_data/raft_analysis.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    return fig\n\n# RAFT 구조 분석 실행\nif train_data is not None:\n    raft_analysis = analyze_raft_structure(train_data)\n    \n    # 분석 결과 출력\n    print(\"\\n🎯 RAFT 구조 분석 결과:\")\n    print(f\"\\n📊 Type 분포:\")\n    total_samples = sum(raft_analysis[\"type_distribution\"].values())\n    for type_name, count in raft_analysis[\"type_distribution\"].items():\n        percentage = (count / total_samples) * 100 if total_samples > 0 else 0\n        print(f\"  {type_name}: {count}개 ({percentage:.1f}%)\")\n    \n    # Context 분석\n    context_counts = raft_analysis[\"context_analysis\"][\"context_counts\"]\n    context_lengths = raft_analysis[\"context_analysis\"][\"context_lengths\"]\n    \n    if context_counts:\n        print(f\"\\n📋 Context 분석:\")\n        print(f\"  평균 Context 개수: {np.mean(context_counts):.1f}개\")\n        print(f\"  Context 개수 범위: {min(context_counts)} ~ {max(context_counts)}개\")\n        \n        # Context 개수별 빈도\n        context_freq = Counter(context_counts)\n        print(f\"  Context 개수별 분포:\")\n        for count, freq in sorted(context_freq.items()):\n            print(f\"    {count}개: {freq}회 ({freq/len(context_counts):.1%})\")\n    \n    if context_lengths:\n        print(f\"\\n📏 Context 길이 통계:\")\n        print(f\"  평균 길이: {np.mean(context_lengths):.0f}자\")\n        print(f\"  중간값: {np.median(context_lengths):.0f}자\")\n        print(f\"  길이 범위: {min(context_lengths)} ~ {max(context_lengths)}자\")\n    \n    # 구조 문제 확인\n    if raft_analysis[\"structure_issues\"]:\n        print(f\"\\n⚠️ 구조 문제 발견:\")\n        for issue in raft_analysis[\"structure_issues\"][:5]:  # 처음 5개만 표시\n            print(f\"  {issue}\")\n        if len(raft_analysis[\"structure_issues\"]) > 5:\n            print(f\"  ... 총 {len(raft_analysis['structure_issues'])}개 문제\")\n    else:\n        print(f\"\\n✅ 구조 문제 없음\")\n    \n    # 시각화\n    raft_viz = visualize_raft_analysis(raft_analysis)\n    print(\"\\n✅ RAFT 분석 차트 저장: processed_data/raft_analysis.png\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 최종 품질 점수 및 권장사항\n",
    "\n",
    "### 📋 데이터 품질 스코어카드\n",
    "1. 무결성 점수 (0-100)\n",
    "2. 다양성 점수 (0-100) \n",
    "3. 구조 적합성 점수 (0-100)\n",
    "4. 토큰 효율성 점수 (0-100)\n",
    "5. 종합 품질 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality_score(train_report: Dict, valid_report: Dict, \n",
    "                          train_tokens: Dict, similarity_analysis: Dict,\n",
    "                          raft_analysis: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    데이터 품질 종합 점수 계산\n",
    "    \n",
    "    Returns:\n",
    "        품질 점수 딕셔너리\n",
    "    \"\"\"\n",
    "    print(\"📊 데이터 품질 종합 점수 계산 중...\")\n",
    "    \n",
    "    quality_scores = {}\n",
    "    \n",
    "    # 1. 무결성 점수 (0-100)\n",
    "    integrity_issues = (\n",
    "        sum(train_report.get(\"missing_fields\", {}).values()) +\n",
    "        sum(train_report.get(\"empty_values\", {}).values()) +\n",
    "        train_report.get(\"message_structure_errors\", 0)\n",
    "    )\n",
    "    total_train_samples = train_report.get(\"total_samples\", 1)\n",
    "    integrity_score = max(0, 100 - (integrity_issues / total_train_samples) * 100)\n",
    "    quality_scores[\"integrity_score\"] = integrity_score\n",
    "    \n",
    "    # 2. 다양성 점수 (0-100)\n",
    "    q_diversity = similarity_analysis.get(\"question_diversity\", {}).get(\"diversity_ratio\", 0)\n",
    "    a_diversity = similarity_analysis.get(\"answer_diversity\", {}).get(\"diversity_ratio\", 0)\n",
    "    diversity_score = ((q_diversity + a_diversity) / 2) * 100\n",
    "    quality_scores[\"diversity_score\"] = diversity_score\n",
    "    \n",
    "    # 3. 구조 적합성 점수 (0-100)\n",
    "    structure_issues = len(raft_analysis.get(\"structure_issues\", []))\n",
    "    structure_score = max(0, 100 - (structure_issues / total_train_samples) * 100)\n",
    "    quality_scores[\"structure_score\"] = structure_score\n",
    "    \n",
    "    # 4. 토큰 효율성 점수 (0-100)\n",
    "    overflow_rate = len(train_tokens.get(\"overflow_samples\", [])) / len(train_tokens.get(\"total_tokens\", [1]))\n",
    "    token_efficiency_score = max(0, 100 - (overflow_rate * 100))\n",
    "    quality_scores[\"token_efficiency_score\"] = token_efficiency_score\n",
    "    \n",
    "    # 5. RAFT 균형 점수 (0-100)\n",
    "    type_dist = raft_analysis.get(\"type_distribution\", {})\n",
    "    positive_ratio = type_dist.get(\"positive\", 0) / sum(type_dist.values()) if type_dist else 0\n",
    "    # 이상적인 비율(0.6)에서 얼마나 벗어났는지 계산\n",
    "    balance_deviation = abs(positive_ratio - 0.6)\n",
    "    raft_balance_score = max(0, 100 - (balance_deviation * 200))  # 편차를 점수로 변환\n",
    "    quality_scores[\"raft_balance_score\"] = raft_balance_score\n",
    "    \n",
    "    # 6. 종합 품질 점수 (가중평균)\n",
    "    weights = {\n",
    "        \"integrity_score\": 0.3,\n",
    "        \"diversity_score\": 0.25,\n",
    "        \"structure_score\": 0.2,\n",
    "        \"token_efficiency_score\": 0.15,\n",
    "        \"raft_balance_score\": 0.1\n",
    "    }\n",
    "    \n",
    "    overall_score = sum(quality_scores[key] * weight for key, weight in weights.items())\n",
    "    quality_scores[\"overall_score\"] = overall_score\n",
    "    \n",
    "    return quality_scores\n",
    "\n",
    "def generate_recommendations(quality_scores: Dict[str, float], \n",
    "                           train_tokens: Dict, \n",
    "                           similarity_analysis: Dict) -> List[str]:\n",
    "    \"\"\"\n",
    "    품질 점수 기반 권장사항 생성\n",
    "    \"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # 무결성 관련\n",
    "    if quality_scores[\"integrity_score\"] < 90:\n",
    "        recommendations.append(\n",
    "            \"⚠️ 데이터 무결성 개선 필요: 결측값이나 구조적 문제가 있는 샘플을 수정하세요.\"\n",
    "        )\n",
    "    \n",
    "    # 다양성 관련\n",
    "    if quality_scores[\"diversity_score\"] < 80:\n",
    "        recommendations.append(\n",
    "            \"📝 데이터 다양성 개선 필요: 중복된 질문이나 답변을 제거하고 더 다양한 샘플을 추가하세요.\"\n",
    "        )\n",
    "    \n",
    "    # 토큰 효율성 관련\n",
    "    if quality_scores[\"token_efficiency_score\"] < 90:\n",
    "        overflow_count = len(train_tokens.get(\"overflow_samples\", []))\n",
    "        recommendations.append(\n",
    "            f\"📏 토큰 길이 최적화 필요: {overflow_count}개 샘플이 4096 토큰을 초과합니다. \"\n",
    "            \"긴 context를 줄이거나 분할을 고려하세요.\"\n",
    "        )\n",
    "    \n",
    "    # RAFT 균형 관련\n",
    "    if quality_scores[\"raft_balance_score\"] < 85:\n",
    "        recommendations.append(\n",
    "            \"⚖️ RAFT 샘플 균형 조정 필요: Positive와 Negative 샘플 비율을 6:4로 맞추세요.\"\n",
    "        )\n",
    "    \n",
    "    # 의미적 유사도 관련\n",
    "    if \"semantic_similarity\" in similarity_analysis:\n",
    "        q_sim = similarity_analysis[\"semantic_similarity\"].get(\"questions\", {})\n",
    "        if q_sim.get(\"high_similarity_pairs\", 0) > 5:\n",
    "            recommendations.append(\n",
    "                \"🧠 의미적 중복 제거 필요: 유사한 질문들이 많이 발견되었습니다. \"\n",
    "                \"의미적으로 중복되는 샘플을 제거하세요.\"\n",
    "            )\n",
    "    \n",
    "    # 전체 점수가 낮은 경우\n",
    "    if quality_scores[\"overall_score\"] < 75:\n",
    "        recommendations.append(\n",
    "            \"🔄 전면적인 데이터 개선 필요: 전체 품질 점수가 낮습니다. \"\n",
    "            \"데이터 수집부터 전처리까지 전 과정을 재검토하세요.\"\n",
    "        )\n",
    "    elif quality_scores[\"overall_score\"] >= 90:\n",
    "        recommendations.append(\n",
    "            \"✅ 우수한 데이터 품질: 현재 데이터는 파인튜닝에 적합한 품질을 가지고 있습니다.\"\n",
    "        )\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\n",
    "            \"✅ 전반적으로 양호한 데이터 품질입니다. 파인튜닝을 진행해도 좋습니다.\"\n",
    "        )\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def create_quality_scorecard_viz(quality_scores: Dict[str, float]):\n",
    "    \"\"\"\n",
    "    품질 스코어카드 시각화\n",
    "    \"\"\"\n",
    "    # 점수 데이터 준비\n",
    "    score_names = [\n",
    "        \"무결성\", \"다양성\", \"구조 적합성\", \n",
    "        \"토큰 효율성\", \"RAFT 균형\", \"종합 점수\"\n",
    "    ]\n",
    "    score_keys = [\n",
    "        \"integrity_score\", \"diversity_score\", \"structure_score\",\n",
    "        \"token_efficiency_score\", \"raft_balance_score\", \"overall_score\"\n",
    "    ]\n",
    "    scores = [quality_scores[key] for key in score_keys]\n",
    "    \n",
    "    # 색상 매핑 (점수에 따라)\n",
    "    def get_color(score):\n",
    "        if score >= 90:\n",
    "            return 'green'\n",
    "        elif score >= 75:\n",
    "            return 'orange'\n",
    "        else:\n",
    "            return 'red'\n",
    "    \n",
    "    colors = [get_color(score) for score in scores]\n",
    "    \n",
    "    # 바 차트 생성\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    bars = ax.barh(score_names, scores, color=colors, alpha=0.7)\n",
    "    \n",
    "    # 점수 표시\n",
    "    for i, (bar, score) in enumerate(zip(bars, scores)):\n",
    "        ax.text(score + 1, i, f'{score:.1f}', va='center', fontweight='bold')\n",
    "    \n",
    "    # 차트 설정\n",
    "    ax.set_xlim(0, 105)\n",
    "    ax.set_xlabel('점수', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('📊 데이터 품질 스코어카드', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # 점수 구간 표시\n",
    "    ax.axvline(x=75, color='orange', linestyle='--', alpha=0.5, label='양호 기준 (75점)')\n",
    "    ax.axvline(x=90, color='green', linestyle='--', alpha=0.5, label='우수 기준 (90점)')\n",
    "    ax.legend()\n",
    "    \n",
    "    # 그리드\n",
    "    ax.grid(True, axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('processed_data/quality_scorecard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 품질 점수 계산 및 권장사항 생성\n",
    "if train_data is not None:\n",
    "    quality_scores = calculate_quality_score(\n",
    "        train_report, valid_report, train_tokens, similarity_analysis, raft_analysis\n",
    "    )\n",
    "    \n",
    "    recommendations = generate_recommendations(\n",
    "        quality_scores, train_tokens, similarity_analysis\n",
    "    )\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n🏆 데이터 품질 종합 평가 결과:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    score_names = {\n",
    "        \"integrity_score\": \"무결성 점수\",\n",
    "        \"diversity_score\": \"다양성 점수\", \n",
    "        \"structure_score\": \"구조 적합성 점수\",\n",
    "        \"token_efficiency_score\": \"토큰 효율성 점수\",\n",
    "        \"raft_balance_score\": \"RAFT 균형 점수\",\n",
    "        \"overall_score\": \"📊 종합 품질 점수\"\n",
    "    }\n",
    "    \n",
    "    for key, name in score_names.items():\n",
    "        score = quality_scores[key]\n",
    "        if score >= 90:\n",
    "            status = \"🟢 우수\"\n",
    "        elif score >= 75:\n",
    "            status = \"🟡 양호\"\n",
    "        else:\n",
    "            status = \"🔴 개선 필요\"\n",
    "        \n",
    "        print(f\"{name}: {score:.1f}점 {status}\")\n",
    "    \n",
    "    print(f\"\\n💡 권장사항:\")\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    \n",
    "    # 스코어카드 시각화\n",
    "    scorecard_fig = create_quality_scorecard_viz(quality_scores)\n",
    "    print(\"\\n✅ 품질 스코어카드 저장: processed_data/quality_scorecard.png\")\n",
    "    \n",
    "    # 품질 리포트 JSON 저장\n",
    "    quality_report = {\n",
    "        \"quality_scores\": quality_scores,\n",
    "        \"recommendations\": recommendations,\n",
    "        \"analysis_timestamp\": pd.Timestamp.now().isoformat(),\n",
    "        \"data_summary\": {\n",
    "            \"train_samples\": len(train_data),\n",
    "            \"valid_samples\": len(valid_data),\n",
    "            \"avg_token_length\": np.mean(train_tokens[\"total_tokens\"]) if train_tokens[\"total_tokens\"] else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(\"processed_data/quality_report.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(quality_report, f, ensure_ascii=False, indent=2, default=str)\n",
    "    \n",
    "    print(\"✅ 품질 리포트 저장: processed_data/quality_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 최종 요약 및 다음 단계\n",
    "\n",
    "### ✅ 완료된 검증 항목\n",
    "1. **데이터 무결성 검증**: 필수 필드, 빈 값, 구조 오류 확인\n",
    "2. **토큰 길이 분석**: 분포, 초과 샘플, 효율성 평가\n",
    "3. **중복 및 유사도 분석**: 정확한 중복, 의미적 유사도 측정\n",
    "4. **RAFT 구조 검증**: Type 균형, Context 품질, 구조 적합성\n",
    "5. **종합 품질 평가**: 5개 영역 점수 + 전체 점수\n",
    "6. **시각화 및 리포트**: 대시보드, 차트, JSON 리포트\n",
    "\n",
    "### 📁 생성된 파일들\n",
    "- `processed_data/token_analysis_dashboard.png`: 토큰 분석 대시보드\n",
    "- `processed_data/raft_analysis.png`: RAFT 구조 분석 차트\n",
    "- `processed_data/quality_scorecard.png`: 품질 스코어카드\n",
    "- `processed_data/quality_report.json`: 종합 품질 리포트\n",
    "\n",
    "### 🔄 다음 단계\n",
    "**03_fine_tuning_with_lora.ipynb**에서 실제 파인튜닝을 진행합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 Day 1 실습 2 완료!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if train_data is not None:\n",
    "    final_summary = {\n",
    "        \"데이터 현황\": {\n",
    "            \"Train 샘플\": len(train_data),\n",
    "            \"Valid 샘플\": len(valid_data),\n",
    "            \"평균 토큰 길이\": f\"{np.mean(train_tokens['total_tokens']):.1f}\" if train_tokens['total_tokens'] else \"N/A\",\n",
    "            \"4096 토큰 초과율\": f\"{len(train_tokens.get('overflow_samples', [])) / len(train_tokens.get('total_tokens', [1])):.1%}\" if train_tokens.get('total_tokens') else \"N/A\"\n",
    "        },\n",
    "        \"RAFT 구조\": {\n",
    "            \"Positive 샘플\": raft_analysis.get(\"type_distribution\", {}).get(\"positive\", 0),\n",
    "            \"Negative 샘플\": raft_analysis.get(\"type_distribution\", {}).get(\"negative\", 0),\n",
    "            \"평균 Context 개수\": f\"{np.mean(raft_analysis.get('context_analysis', {}).get('context_counts', [4])):.1f}개\" if raft_analysis.get('context_analysis', {}).get('context_counts') else \"4개\"\n",
    "        },\n",
    "        \"품질 점수\": {\n",
    "            \"종합 점수\": f\"{quality_scores['overall_score']:.1f}점\",\n",
    "            \"무결성\": f\"{quality_scores['integrity_score']:.1f}점\",\n",
    "            \"다양성\": f\"{quality_scores['diversity_score']:.1f}점\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"📊 최종 요약:\")\n",
    "    for category, items in final_summary.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for key, value in items.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\n📁 생성된 파일:\")\n",
    "    files = [\n",
    "        \"token_analysis_dashboard.png\",\n",
    "        \"raft_analysis.png\", \n",
    "        \"quality_scorecard.png\",\n",
    "        \"quality_report.json\"\n",
    "    ]\n",
    "    for file in files:\n",
    "        print(f\"  - processed_data/{file}\")\n",
    "    \n",
    "    print(f\"\\n🚀 다음 단계: 03_fine_tuning_with_lora.ipynb에서 파인튜닝을 시작하세요!\")\n",
    "    \n",
    "    # 종합 품질 등급 판정\n",
    "    overall_score = quality_scores['overall_score']\n",
    "    if overall_score >= 90:\n",
    "        grade = \"A (우수)\"\n",
    "        message = \"데이터 품질이 우수합니다. 파인튜닝을 진행하세요! 🌟\"\n",
    "    elif overall_score >= 75:\n",
    "        grade = \"B (양호)\"\n",
    "        message = \"데이터 품질이 양호합니다. 파인튜닝을 진행해도 좋습니다. ✅\"\n",
    "    elif overall_score >= 60:\n",
    "        grade = \"C (보통)\"\n",
    "        message = \"데이터 품질이 보통입니다. 권장사항을 검토 후 진행하세요. ⚠️\"\n",
    "    else:\n",
    "        grade = \"D (개선 필요)\"\n",
    "        message = \"데이터 품질 개선이 필요합니다. 권장사항을 적용하세요. 🔄\"\n",
    "    \n",
    "    print(f\"\\n🏆 최종 품질 등급: {grade}\")\n",
    "    print(f\"💬 {message}\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 데이터를 불러올 수 없어 분석을 완료하지 못했습니다.\")\n",
    "    print(\"💡 먼저 01_data_preprocessing_and_validation.ipynb를 실행하세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}