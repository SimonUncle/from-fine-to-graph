{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 실습 6: 2개 태스크로 빠른 LoRA 파인튜닝\n",
    "\n",
    "## 🎯 이 노트북의 목적\n",
    "\n",
    "**동일한 모델(EXAONE-3.5)**을 **2가지 다른 태스크**로 파인튜닝하여 비교합니다.\n",
    "\n",
    "| 태스크 | 데이터셋 | 목표 | 샘플 수 |\n",
    "|--------|----------|------|---------|\n",
    "| **감정 분류** | IMDB | 영화 리뷰 → 긍정/부정 | 100 |\n",
    "| **영어 QA** | SQuAD | 지문 + 질문 → 답변 | 100 |\n",
    "\n",
    "**한국어 요약**은 03번에서 이미 학습했으므로 제외합니다.\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "- ✅ **Task별 LoRA 학습**: 같은 모델도 데이터가 다르면 다르게 학습됨\n",
    "- ✅ **빠른 실험**: 각 200개씩만 사용해 빠르게 비교\n",
    "- ✅ **성능 비교**: 어떤 태스크가 쉽고 어려운지 확인\n",
    "\n",
    "### 실습 흐름\n",
    "\n",
    "1. 2개 태스크 데이터 준비\n",
    "2. 각 태스크별로 LoRA 학습 (동일 설정: r=8)\n",
    "3. Baseline vs LoRA 비교 평가\n",
    "4. 결과 비교 및 인사이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 패키지 설치\n",
    "\n",
    "Colab이라면 아래를 실행하고 **런타임 재시작**하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade bitsandbytes accelerate peft datasets transformers evaluate\n",
    "\n",
    "# 설치 후 런타임 재시작 필요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import evaluate\n",
    "\n",
    "print(\"✅ 라이브러리 로드 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 태스크 설정\n",
    "\n",
    "각 태스크의 데이터셋과 프롬프트 템플릿을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태스크 설정 (2개만)\n",
    "TASKS = {\n",
    "    \"sentiment\": {\n",
    "        \"name\": \"감정 분류\",\n",
    "        \"dataset\": \"imdb\",\n",
    "        \"split\": \"train[:100]\",\n",
    "        \"eval_split\": \"test[:10]\",\n",
    "        \"input_col\": \"text\",\n",
    "        \"output_col\": \"label\",\n",
    "        \"prompt_template\": \"다음 영화 리뷰의 감정을 분류하세요.\\n\\n리뷰: {input}\\n\\n감정:\",\n",
    "        \"label_map\": {0: \"부정\", 1: \"긍정\"},\n",
    "        \"description\": \"영화 리뷰 감정을 긍정/부정으로 분류\"\n",
    "    },\n",
    "    \"qa\": {\n",
    "        \"name\": \"영어 QA\",\n",
    "        \"dataset\": \"squad\",\n",
    "        \"split\": \"train[:100]\",\n",
    "        \"eval_split\": \"validation[:10]\",\n",
    "        \"input_col\": [\"question\", \"context\"],\n",
    "        \"output_col\": \"answers\",\n",
    "        \"prompt_template\": \"Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:\",\n",
    "        \"description\": \"영어 지문과 질문을 받아 답변 생성\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# 공통 모델 설정\n",
    "BASE_MODEL = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "# LoRA 설정 (모든 태스크 동일)\n",
    "LORA_CONFIG = {\n",
    "    \"r\": 8,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"],\n",
    "}\n",
    "\n",
    "# 학습 설정 (모든 태스크 동일)\n",
    "TRAINING_CONFIG = {\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"max_steps\": 50,  # 빠른 테스트용\n",
    "}\n",
    "\n",
    "print(\"✅ 태스크 설정 완료\\n\")\n",
    "for task_id, task in TASKS.items():\n",
    "    print(f\"📌 {task['name']}: {task['description']}\")\n",
    "\n",
    "# 토크나이저 미리 로드 (전역에서 한 번만)\n",
    "print(\"📥 토크나이저 로드 중...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    trust_remote_code=True,\n",
    "    padding_side=\"right\",\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"✅ 토크나이저 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 로드 및 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_data(task_id):\n",
    "    \"\"\"태스크별 데이터 로드 및 프롬프트 생성\"\"\"\n",
    "    task = TASKS[task_id]\n",
    "    \n",
    "    print(f\"\\n📥 {task['name']} 데이터 로드 중...\")\n",
    "    \n",
    "    # 데이터셋 로드\n",
    "    dataset = load_dataset(task[\"dataset\"], split=task[\"split\"])\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    processed_data = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        # Input 처리\n",
    "        if isinstance(task[\"input_col\"], list):\n",
    "            # 여러 컬럼 (QA)\n",
    "            inputs = {col: str(item[col]) for col in task[\"input_col\"]}\n",
    "            prompt = task[\"prompt_template\"].format(**inputs)\n",
    "        else:\n",
    "            # 단일 컬럼\n",
    "            input_text = str(item[task[\"input_col\"]])\n",
    "            prompt = task[\"prompt_template\"].format(input=input_text)\n",
    "        \n",
    "        # Output 처리\n",
    "        output_col = task[\"output_col\"]\n",
    "        if output_col == \"label\":\n",
    "            # 감정 분류\n",
    "            label = item[output_col]\n",
    "            output = task[\"label_map\"][label]\n",
    "        elif output_col == \"answers\":\n",
    "            # SQuAD\n",
    "            answers = item[output_col][\"text\"]\n",
    "            output = answers[0] if answers else \"\"\n",
    "        else:\n",
    "            # 일반 텍스트\n",
    "            output = str(item[output_col])\n",
    "        \n",
    "        processed_data.append({\n",
    "            \"text\": prompt,\n",
    "            \"answer\": output\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(processed_data)\n",
    "    print(f\"   ✅ {len(df)}개 샘플 준비\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"✅ 데이터 로드 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 공통 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lora_for_task(task_id, output_dir):\n",
    "    \"\"\"태스크별 LoRA 학습 실행\"\"\"\n",
    "    task = TASKS[task_id]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🚀 {task['name']} 학습 시작\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # 1. 데이터 로드\n",
    "    train_df = load_task_data(task_id)\n",
    "    \n",
    "    # 2. 모델 로드 (4-bit quantization)\n",
    "    print(\"\\n📥 모델 로드 중...\")\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quant_config,\n",
    "    )\n",
    "    \n",
    "    # 3. LoRA 설정\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        r=LORA_CONFIG[\"r\"],\n",
    "        lora_alpha=LORA_CONFIG[\"lora_alpha\"],\n",
    "        lora_dropout=LORA_CONFIG[\"lora_dropout\"],\n",
    "        target_modules=LORA_CONFIG[\"target_modules\"],\n",
    "        bias=\"none\",\n",
    "    )\n",
    "    \n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    print(f\"   ✅ LoRA 적용 완료 (r={LORA_CONFIG['r']})\")\n",
    "    \n",
    "    # 4. 데이터 전처리\n",
    "    def prepare_example(row):\n",
    "        prompt = row[\"text\"]\n",
    "        answer = row[\"answer\"]\n",
    "        full_text = prompt + \" \" + answer + tokenizer.eos_token\n",
    "        \n",
    "        # 프롬프트만 토큰화 (라벨 마스크용)\n",
    "        prompt_tokens = tokenizer(\n",
    "            prompt,\n",
    "            add_special_tokens=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "        \n",
    "        # 전체 토큰화\n",
    "        full_tokens = tokenizer(\n",
    "            full_text,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "        \n",
    "        input_ids = full_tokens[\"input_ids\"]\n",
    "        attention_mask = full_tokens[\"attention_mask\"]\n",
    "        labels = input_ids.copy()\n",
    "        \n",
    "        # 프롬프트 부분 마스킹\n",
    "        prompt_len = len(prompt_tokens[\"input_ids\"])\n",
    "        labels[:prompt_len] = [-100] * prompt_len\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    from datasets import Dataset\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    train_dataset = train_dataset.map(lambda x: prepare_example(x))\n",
    "    \n",
    "    # 5. 학습 실행\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=TRAINING_CONFIG[\"num_train_epochs\"],\n",
    "        per_device_train_batch_size=TRAINING_CONFIG[\"per_device_train_batch_size\"],\n",
    "        gradient_accumulation_steps=TRAINING_CONFIG[\"gradient_accumulation_steps\"],\n",
    "        learning_rate=TRAINING_CONFIG[\"learning_rate\"],\n",
    "        max_steps=TRAINING_CONFIG[\"max_steps\"],\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        report_to=[],\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n🏋️ 학습 중...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    # 6. 저장\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    print(f\"\\n✅ 학습 완료! 저장 경로: {output_dir}\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "print(\"✅ 학습 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task 1: 감정 분류 학습\n",
    "\n",
    "영화 리뷰를 긍정/부정으로 분류하는 태스크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: 감정 분류\n",
    "task1_dir = \"./lora_sentiment\"\n",
    "\n",
    "model_sent, tokenizer_sent = train_lora_for_task(\"sentiment\", task1_dir)\n",
    "\n",
    "print(\"\\n📊 Task 1 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Task 2: 영어 QA 학습\n",
    "\n",
    "영어 지문과 질문을 받아 답변을 생성하는 태스크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: 영어 QA\n",
    "task2_dir = \"./lora_qa\"\n",
    "\n",
    "model_qa, tokenizer_qa = train_lora_for_task(\"qa\", task2_dir)\n",
    "\n",
    "print(\"\\n📊 Task 2 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 학습 결과 요약\n",
    "\n",
    "2개 태스크 모두 학습이 완료되었습니다!\n",
    "\n",
    "각 태스크별로 LoRA 어댑터가 저장되었습니다:\n",
    "- `./lora_sentiment` - 감정 분류\n",
    "- `./lora_qa` - 영어 QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Task\": \"감정 분류\",\n",
    "        \"Dataset\": \"IMDB\",\n",
    "        \"Samples\": 100,\n",
    "        \"LoRA Path\": \"./lora_sentiment\",\n",
    "        \"Description\": \"리뷰 → 긍정/부정\"\n",
    "    },\n",
    "    {\n",
    "        \"Task\": \"영어 QA\",\n",
    "        \"Dataset\": \"SQuAD\",\n",
    "        \"Samples\": 100,\n",
    "        \"LoRA Path\": \"./lora_qa\",\n",
    "        \"Description\": \"지문 + 질문 → 답변\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 학습 결과 요약\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "display(results_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 평가 도구 로드\n",
    "\n",
    "ROUGE-1과 임베딩 유사도 평가를 위한 도구를 준비합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Baseline vs LoRA 평가\n",
    "\n",
    "각 태스크별로 **파인튜닝 전(Baseline)**과 **파인튜닝 후(LoRA)**를 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "print(\"📥 평가 도구 로드 중...\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-m3\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def compute_rouge1(reference, candidate):\n",
    "    try:\n",
    "        return rouge.compute(predictions=[candidate], references=[reference])[\"rouge1\"]\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def compute_embedding_similarity(reference, candidate):\n",
    "    try:\n",
    "        if not reference.strip() or not candidate.strip():\n",
    "            return 0.0\n",
    "        embeddings = embed_model.encode([reference, candidate], convert_to_numpy=True, normalize_embeddings=True)\n",
    "        return float(np.dot(embeddings[0], embeddings[1]))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "print(\"✅ 평가 도구 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_task(task_id, lora_model, tokenizer, num_samples=3):\n",
    "    \"\"\"태스크별 Baseline vs LoRA 평가\"\"\"\n",
    "    task = TASKS[task_id]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🔍 {task['name']} 평가 중...\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # 1. 평가 데이터 로드\n",
    "    eval_dataset = load_dataset(task[\"dataset\"], split=task[\"eval_split\"])\n",
    "    eval_samples = eval_dataset.select(range(min(num_samples, len(eval_dataset))))\n",
    "    \n",
    "    # 2. Baseline 모델 로드\n",
    "    print(\"📥 Baseline 모델 로드 중...\")\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "    )\n",
    "    \n",
    "    baseline_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quant_config,\n",
    "    )\n",
    "    \n",
    "    # 3. 각 샘플 평가\n",
    "    results = []\n",
    "    \n",
    "    for idx, item in enumerate(eval_samples):\n",
    "        # Input 처리\n",
    "        if isinstance(task[\"input_col\"], list):\n",
    "            inputs = {col: str(item[col]) for col in task[\"input_col\"]}\n",
    "            prompt = task[\"prompt_template\"].format(**inputs)\n",
    "            input_display = inputs[\"question\"][:50] + \"...\"\n",
    "        else:\n",
    "            input_text = str(item[task[\"input_col\"]])\n",
    "            prompt = task[\"prompt_template\"].format(input=input_text)\n",
    "            input_display = input_text[:50] + \"...\"\n",
    "        \n",
    "        # Reference 처리\n",
    "        output_col = task[\"output_col\"]\n",
    "        if output_col == \"label\":\n",
    "            label = item[output_col]\n",
    "            reference = task[\"label_map\"][label]\n",
    "        elif output_col == \"answers\":\n",
    "            answers = item[output_col][\"text\"]\n",
    "            reference = answers[0] if answers else \"\"\n",
    "        else:\n",
    "            reference = str(item[output_col])\n",
    "        \n",
    "        # Baseline 생성\n",
    "        inputs_tokens = tokenizer(prompt, return_tensors=\"pt\").to(baseline_model.device)\n",
    "        with torch.no_grad():\n",
    "            baseline_outputs = baseline_model.generate(\n",
    "                **inputs_tokens,\n",
    "                max_new_tokens=60 if task_id == \"qa\" else 10,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        baseline_result = tokenizer.decode(baseline_outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 프롬프트 제거\n",
    "        if \"감정:\" in baseline_result:\n",
    "            baseline_output = baseline_result.split(\"감정:\")[-1].strip()\n",
    "        elif \"Answer:\" in baseline_result:\n",
    "            baseline_output = baseline_result.split(\"Answer:\")[-1].strip()\n",
    "        else:\n",
    "            baseline_output = baseline_result[len(prompt):].strip()\n",
    "        \n",
    "        # LoRA 생성\n",
    "        inputs_tokens = tokenizer(prompt, return_tensors=\"pt\").to(lora_model.device)\n",
    "        with torch.no_grad():\n",
    "            lora_outputs = lora_model.generate(\n",
    "                **inputs_tokens,\n",
    "                max_new_tokens=60 if task_id == \"qa\" else 10,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        lora_result = tokenizer.decode(lora_outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 프롬프트 제거\n",
    "        if \"감정:\" in lora_result:\n",
    "            lora_output = lora_result.split(\"감정:\")[-1].strip()\n",
    "        elif \"Answer:\" in lora_result:\n",
    "            lora_output = lora_result.split(\"Answer:\")[-1].strip()\n",
    "        else:\n",
    "            lora_output = lora_result[len(prompt):].strip()\n",
    "        \n",
    "        # 점수 계산\n",
    "        baseline_rouge = compute_rouge1(reference, baseline_output)\n",
    "        lora_rouge = compute_rouge1(reference, lora_output)\n",
    "        baseline_emb = compute_embedding_similarity(reference, baseline_output)\n",
    "        lora_emb = compute_embedding_similarity(reference, lora_output)\n",
    "        \n",
    "        results.append({\n",
    "            \"input\": input_display,\n",
    "            \"reference\": reference[:100],\n",
    "            \"baseline\": baseline_output[:100],\n",
    "            \"lora\": lora_output[:100],\n",
    "            \"baseline_rouge1\": baseline_rouge,\n",
    "            \"lora_rouge1\": lora_rouge,\n",
    "            \"baseline_emb\": baseline_emb,\n",
    "            \"lora_emb\": lora_emb,\n",
    "        })\n",
    "        \n",
    "        print(f\"   {idx + 1}/{num_samples} 완료\")\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    results_df = pd.DataFrame(results).round(3)\n",
    "    \n",
    "    # 평균 계산\n",
    "    avg_results = {\n",
    "        \"task\": task[\"name\"],\n",
    "        \"baseline_rouge1\": results_df[\"baseline_rouge1\"].mean(),\n",
    "        \"lora_rouge1\": results_df[\"lora_rouge1\"].mean(),\n",
    "        \"baseline_emb\": results_df[\"baseline_emb\"].mean(),\n",
    "        \"lora_emb\": results_df[\"lora_emb\"].mean(),\n",
    "        \"rouge_improvement\": results_df[\"lora_rouge1\"].mean() - results_df[\"baseline_rouge1\"].mean(),\n",
    "        \"emb_improvement\": results_df[\"lora_emb\"].mean() - results_df[\"baseline_emb\"].mean(),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✅ {task['name']} 평가 완료!\")\n",
    "    \n",
    "    return results_df, avg_results\n",
    "\n",
    "print(\"✅ 평가 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Task 1 평가: 감정 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: 감정 분류 평가\n",
    "results_df_sent, avg_sent = evaluate_task(\"sentiment\", model_sent, tokenizer_sent, num_samples=3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 감정 분류 - 상세 결과\")\n",
    "print(\"=\"*80)\n",
    "display(results_df_sent)\n",
    "\n",
    "print(f\"\\n평균 ROUGE-1: Baseline {avg_sent['baseline_rouge1']:.3f} → LoRA {avg_sent['lora_rouge1']:.3f} (개선: {avg_sent['rouge_improvement']:+.3f})\")\n",
    "print(f\"평균 임베딩:  Baseline {avg_sent['baseline_emb']:.3f} → LoRA {avg_sent['lora_emb']:.3f} (개선: {avg_sent['emb_improvement']:+.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Task 2 평가: 영어 QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: 영어 QA 평가\n",
    "results_df_qa, avg_qa = evaluate_task(\"qa\", model_qa, tokenizer_qa, num_samples=3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 영어 QA - 상세 결과\")\n",
    "print(\"=\"*80)\n",
    "display(results_df_qa)\n",
    "\n",
    "print(f\"\\n평균 ROUGE-1: Baseline {avg_qa['baseline_rouge1']:.3f} → LoRA {avg_qa['lora_rouge1']:.3f} (개선: {avg_qa['rouge_improvement']:+.3f})\")\n",
    "print(f\"평균 임베딩:  Baseline {avg_qa['baseline_emb']:.3f} → LoRA {avg_qa['lora_emb']:.3f} (개선: {avg_qa['emb_improvement']:+.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 전체 비교 요약\n",
    "\n",
    "2개 태스크의 성능을 한눈에 비교합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 비교표\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Task\": avg_sent[\"task\"],\n",
    "        \"Baseline ROUGE\": avg_sent[\"baseline_rouge1\"],\n",
    "        \"LoRA ROUGE\": avg_sent[\"lora_rouge1\"],\n",
    "        \"ROUGE 개선\": avg_sent[\"rouge_improvement\"],\n",
    "        \"Baseline 임베딩\": avg_sent[\"baseline_emb\"],\n",
    "        \"LoRA 임베딩\": avg_sent[\"lora_emb\"],\n",
    "        \"임베딩 개선\": avg_sent[\"emb_improvement\"],\n",
    "    },\n",
    "    {\n",
    "        \"Task\": avg_qa[\"task\"],\n",
    "        \"Baseline ROUGE\": avg_qa[\"baseline_rouge1\"],\n",
    "        \"LoRA ROUGE\": avg_qa[\"lora_rouge1\"],\n",
    "        \"ROUGE 개선\": avg_qa[\"rouge_improvement\"],\n",
    "        \"Baseline 임베딩\": avg_qa[\"baseline_emb\"],\n",
    "        \"LoRA 임베딩\": avg_qa[\"lora_emb\"],\n",
    "        \"임베딩 개선\": avg_qa[\"emb_improvement\"],\n",
    "    }\n",
    "]).round(3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 2개 태스크 종합 비교\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "display(comparison_df)\n",
    "\n",
    "# 시각화\n",
    "print(\"\\n개선도 요약:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    rouge_arrow = \"🔼\" if row[\"ROUGE 개선\"] > 0 else (\"🔽\" if row[\"ROUGE 개선\"] < 0 else \"➖\")\n",
    "    emb_arrow = \"🔼\" if row[\"임베딩 개선\"] > 0 else (\"🔽\" if row[\"임베딩 개선\"] < 0 else \"➖\")\n",
    "    print(f\"{row['Task']:12s} | ROUGE {rouge_arrow} {row['ROUGE 개선']:+.3f} | 임베딩 {emb_arrow} {row['임베딩 개선']:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 허깅페이스에 업로드하기 (선택)\n",
    "\n",
    "학습한 LoRA 어댑터를 허깅페이스에 업로드하여 공유하거나 7번 노트북에서 사용할 수 있습니다.\n",
    "\n",
    "### 📋 준비 사항\n",
    "\n",
    "1. **허깅페이스 계정**: https://huggingface.co 회원가입\n",
    "2. **Access Token 발급**:\n",
    "   - https://huggingface.co/settings/tokens\n",
    "   - `New token` → `Write` 권한 선택\n",
    "   - 토큰 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face 로그인\n",
    "from huggingface_hub import login\n",
    "\n",
    "# HF 토큰 입력 (https://huggingface.co/settings/tokens)\n",
    "login(token=\"YOUR_HF_TOKEN_HERE\")\n",
    "\n",
    "# 감정 분류 모델 업로드\n",
    "repo_name_sentiment = \"your-username/lora-sentiment\"  # 원하는 이름으로 변경\n",
    "model_sent.push_to_hub(repo_name_sentiment)\n",
    "tokenizer_sent.push_to_hub(repo_name_sentiment)\n",
    "print(f\"✅ 감정 분류 업로드 완료: https://huggingface.co/{repo_name_sentiment}\")\n",
    "\n",
    "# 영어 QA 모델 업로드\n",
    "repo_name_qa = \"your-username/lora-qa\"  # 원하는 이름으로 변경\n",
    "model_qa.push_to_hub(repo_name_qa)\n",
    "tokenizer_qa.push_to_hub(repo_name_qa)\n",
    "print(f\"✅ 영어 QA 업로드 완료: https://huggingface.co/{repo_name_qa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 인사이트 및 결론\n",
    "\n",
    "### 🔍 태스크별 분석\n",
    "\n",
    "#### 1. 감정 분류\n",
    "- **난이도**: 낮음 (단순 분류)\n",
    "- **기대 개선**: 높음\n",
    "- **특징**: \"긍정\" 또는 \"부정\" 단어만 출력하면 됨\n",
    "- **실전 활용**: 고객 리뷰 분석, 소셜 미디어 모니터링\n",
    "\n",
    "#### 2. 영어 QA\n",
    "- **난이도**: 중간 (정보 추출)\n",
    "- **기대 개선**: 중간\n",
    "- **특징**: 컨텍스트에서 정확한 정보를 찾아야 함\n",
    "- **실전 활용**: 문서 검색, FAQ 자동 응답\n",
    "\n",
    "### 📊 성능 패턴\n",
    "\n",
    "| 현상 | 설명 | 대응 방법 |\n",
    "|------|------|-----------|\n",
    "| **분류 태스크가 쉬움** | 출력이 단순함 (긍정/부정) | 적은 데이터로도 학습 가능 |\n",
    "| **QA 태스크는 중간** | 정보 추출 능력 필요 | 더 많은 컨텍스트 예제 필요 |\n",
    "| **태스크별 차이** | 데이터 형식이 다름 | 프롬프트 최적화 중요 |\n",
    "\n",
    "### ✅ 성공 기준\n",
    "\n",
    "- **ROUGE 개선 > 0.05**: 의미 있는 향상\n",
    "- **임베딩 개선 > 0.03**: 의미적 유사도 향상\n",
    "- **모든 태스크 개선**: LoRA가 일반적으로 효과적\n",
    "\n",
    "### 🚀 다음 단계\n",
    "\n",
    "1. **실습 7**: Gradio로 배포하여 실제 사용자 테스트\n",
    "2. **하이퍼파라미터 튜닝**: \n",
    "   - 데이터 증가 (200 → 1000)\n",
    "   - Epoch 증가 (3 → 10)\n",
    "   - LoRA rank 증가 (r=8 → r=16)\n",
    "3. **프롬프트 최적화**: 각 태스크에 맞는 최적 프롬프트 찾기\n",
    "4. **한국어 요약 추가**: 03번에서 학습한 모델과 함께 3개 모델 비교\n",
    "\n",
    "### 💡 핵심 인사이트\n",
    "\n",
    "1. **동일 모델, 다른 데이터 = 다른 결과**\n",
    "   - LoRA는 태스크별로 독립적으로 학습됨\n",
    "   - 각 어댑터는 특정 태스크에만 특화\n",
    "\n",
    "2. **작은 데이터로도 효과 확인 가능**\n",
    "   - 200개 샘플로도 개선 확인\n",
    "   - 실전에서는 1000개 이상 권장\n",
    "\n",
    "3. **태스크 난이도가 다름**\n",
    "   - 단순 분류: 빠르게 학습\n",
    "   - 복잡한 생성: 더 많은 데이터 필요\n",
    "\n",
    "축하합니다! Day 1의 실습 6을 완료했습니다! 🎉\n",
    "\n",
    "**다음**: 실습 7에서 이 모델들을 Gradio로 배포해봅시다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
