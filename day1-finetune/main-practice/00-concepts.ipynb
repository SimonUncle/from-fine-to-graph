{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1-0: 파인튜닝 핵심 개념 이해\n",
    "\n",
    "## 🎯 학습 목표\n",
    "- **파인튜닝(Fine-tuning)**의 기본 개념과 원리 이해\n",
    "- **LoRA(Low-Rank Adaptation)**의 작동 방식과 장점\n",
    "- **PEFT(Parameter Efficient Fine-Tuning)** 기법들 비교\n",
    "- **파인튜닝 vs 프롬프트 엔지니어링** 차이점과 선택 기준\n",
    "- **실제 프로덕션 환경**에서의 파인튜닝 적용 사례\n",
    "\n",
    "## 📚 핵심 개념 소개\n",
    "\n",
    "### 💡 파인튜닝이란?\n",
    "**파인튜닝(Fine-tuning)**은 이미 사전 훈련된 대규모 언어 모델을 특정 태스크나 도메인에 맞게 추가로 학습시키는 기법입니다.\n",
    "\n",
    "마치 이미 기본기가 갖춰진 선수를 특정 종목에 맞게 전문 훈련시키는 것과 같습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치 및 임포트\n",
    "!pip install -q transformers datasets torch peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 🧠 파인튜닝의 기본 원리\n",
    "\n",
    "### 📊 사전 훈련 vs 파인튜닝 비교\n",
    "파인튜닝과 사전 훈련의 차이점을 시각화로 이해해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_concept_visualization():\n",
    "    \"\"\"\n",
    "    파인튜닝 개념을 시각화하는 함수\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Fine-tuning Core Concepts Visualization', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. 사전 훈련 vs 파인튜닝 데이터 크기 비교\n",
    "    categories = ['Pre-training\\nData', 'Fine-tuning\\nData']\n",
    "    data_sizes = [1000000, 1000]  # 상대적 크기 (1M vs 1K)\n",
    "    colors = ['lightblue', 'orange']\n",
    "    \n",
    "    bars = axes[0, 0].bar(categories, data_sizes, color=colors, alpha=0.7)\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].set_ylabel('Data Size (examples)')\n",
    "    axes[0, 0].set_title('📊 Pre-training vs Fine-tuning Data Size')\n",
    "    \n",
    "    # 막대 위에 수치 표시\n",
    "    for bar, size in zip(bars, data_sizes):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{size:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. 파인튜닝 방법별 학습 파라미터 수 비교\n",
    "    methods = ['Full\\nFine-tuning', 'LoRA', 'Adapter', 'Prompt\\nTuning']\n",
    "    param_percentages = [100, 0.1, 2, 0.01]  # 전체 파라미터 대비 학습 파라미터 비율\n",
    "    method_colors = ['red', 'green', 'blue', 'purple']\n",
    "    \n",
    "    bars2 = axes[0, 1].bar(methods, param_percentages, color=method_colors, alpha=0.7)\n",
    "    axes[0, 1].set_ylabel('Trainable Parameters (%)')\n",
    "    axes[0, 1].set_title('🔧 Parameter Efficiency Comparison')\n",
    "    axes[0, 1].set_yscale('log')\n",
    "    \n",
    "    for bar, pct in zip(bars2, param_percentages):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{pct}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. LoRA의 작동 원리 시각화\n",
    "    # 원래 가중치 행렬을 시각화\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(8, 8)  # 원래 가중치 행렬\n",
    "    \n",
    "    im1 = axes[1, 0].imshow(W, cmap='RdBu', aspect='auto')\n",
    "    axes[1, 0].set_title('🎯 Original Weight Matrix W')\n",
    "    axes[1, 0].set_xlabel('Input Dimension')\n",
    "    axes[1, 0].set_ylabel('Output Dimension')\n",
    "    \n",
    "    # LoRA 분해 시각화\n",
    "    rank = 2\n",
    "    A = np.random.randn(8, rank) * 0.1  # Low-rank matrix A\n",
    "    B = np.random.randn(rank, 8) * 0.1  # Low-rank matrix B\n",
    "    \n",
    "    # A와 B를 나란히 표시\n",
    "    combined = np.hstack([A, np.zeros((8, 2)), B.T])\n",
    "    im2 = axes[1, 1].imshow(combined, cmap='RdBu', aspect='auto')\n",
    "    axes[1, 1].set_title('🔄 LoRA Decomposition: A + B^T')\n",
    "    axes[1, 1].set_xlabel('A Matrix | Gap | B^T Matrix')\n",
    "    axes[1, 1].set_ylabel('Dimensions')\n",
    "    \n",
    "    # 컬러바 추가\n",
    "    plt.colorbar(im1, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "    plt.colorbar(im2, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('finetuning_concepts.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# 시각화 생성\n",
    "concept_fig = create_finetuning_concept_visualization()\n",
    "print(\"✅ 파인튜닝 개념 시각화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 🎯 LoRA (Low-Rank Adaptation) 깊이 이해\n",
    "\n",
    "### 💡 LoRA의 핵심 아이디어\n",
    "\n",
    "LoRA는 \"**큰 행렬을 작은 두 행렬의 곱으로 근사**\"하는 아이디어에 기반합니다.\n",
    "\n",
    "**수학적 표현:**\n",
    "- 원래: `h = W₀x + ΔWx` (전체 가중치 업데이트)\n",
    "- LoRA: `h = W₀x + BAx` (저차원 분해)\n",
    "\n",
    "여기서 `B ∈ ℝᵈˣʳ`, `A ∈ ℝʳˣᵏ`, `r << min(d,k)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_lora_math():\n",
    "    \"\"\"\n",
    "    LoRA의 수학적 원리를 실제 코드로 시연\n",
    "    \"\"\"\n",
    "    print(\"🔍 LoRA 수학적 원리 시연\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 가상의 가중치 행렬 (예: GPT의 어텐션 레이어)\n",
    "    d_model = 768  # 모델 차원\n",
    "    seq_length = 512  # 시퀀스 길이\n",
    "    \n",
    "    print(f\"📏 모델 설정:\")\n",
    "    print(f\"   - 모델 차원 (d_model): {d_model}\")\n",
    "    print(f\"   - 시퀀스 길이: {seq_length}\")\n",
    "    \n",
    "    # 원래 가중치 행렬 W₀ (freeze됨)\n",
    "    W0 = torch.randn(d_model, d_model) * 0.02\n",
    "    \n",
    "    # Full Fine-tuning의 경우\n",
    "    delta_W_full = torch.randn(d_model, d_model) * 0.001  # 업데이트할 가중치\n",
    "    full_params = delta_W_full.numel()\n",
    "    \n",
    "    print(f\"\\n🔴 Full Fine-tuning:\")\n",
    "    print(f\"   - 업데이트할 파라미터 수: {full_params:,}\")\n",
    "    print(f\"   - 메모리 사용량: ~{full_params * 4 / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # LoRA의 경우\n",
    "    ranks = [1, 2, 4, 8, 16, 32]\n",
    "    \n",
    "    print(f\"\\n🟢 LoRA 방식:\")\n",
    "    print(f\"{'Rank':<6} {'Parameters':<12} {'Reduction':<12} {'Memory (MB)':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for rank in ranks:\n",
    "        # LoRA 행렬들\n",
    "        A = torch.randn(rank, d_model) * 0.001  # A ∈ ℝʳˣᵈ\n",
    "        B = torch.randn(d_model, rank) * 0.001  # B ∈ ℝᵈˣʳ\n",
    "        \n",
    "        lora_params = A.numel() + B.numel()\n",
    "        reduction_ratio = full_params / lora_params\n",
    "        memory_mb = lora_params * 4 / 1024**2\n",
    "        \n",
    "        print(f\"{rank:<6} {lora_params:<12,} {reduction_ratio:<12.1f}x {memory_mb:<12.2f}\")\n",
    "    \n",
    "    # 실제 계산 시연\n",
    "    print(f\"\\n🧮 계산 과정 시연 (rank=4):\")\n",
    "    rank = 4\n",
    "    A = torch.randn(rank, d_model) * 0.001\n",
    "    B = torch.randn(d_model, rank) * 0.001\n",
    "    \n",
    "    # 입력 벡터\n",
    "    x = torch.randn(d_model, 1)\n",
    "    \n",
    "    # 원래 계산\n",
    "    h_original = W0 @ x\n",
    "    \n",
    "    # LoRA 계산\n",
    "    h_lora = W0 @ x + B @ (A @ x)\n",
    "    \n",
    "    print(f\"   - A 행렬 크기: {A.shape}\")\n",
    "    print(f\"   - B 행렬 크기: {B.shape}\")\n",
    "    print(f\"   - 입력 x 크기: {x.shape}\")\n",
    "    print(f\"   - 원래 출력 h 크기: {h_original.shape}\")\n",
    "    print(f\"   - LoRA 출력 h 크기: {h_lora.shape}\")\n",
    "    print(f\"   - 출력 차이 (norm): {torch.norm(h_lora - h_original).item():.6f}\")\n",
    "    \n",
    "    return {\"full_params\": full_params, \"lora_params\": A.numel() + B.numel()}\n",
    "\n",
    "# LoRA 수학 시연\n",
    "lora_demo = demonstrate_lora_math()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 📋 PEFT 기법들 비교 분석\n",
    "\n",
    "### 🔍 Parameter Efficient Fine-Tuning 기법들\n",
    "\n",
    "다양한 PEFT 기법들의 특징과 적용 상황을 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_peft_comparison_table():\n",
    "    \"\"\"\n",
    "    PEFT 기법들을 종합 비교하는 표\n",
    "    \"\"\"\n",
    "    peft_methods = {\n",
    "        \"방법\": [\"Full Fine-tuning\", \"LoRA\", \"AdaLoRA\", \"Adapter\", \"Prefix Tuning\", \"P-Tuning v2\", \"Prompt Tuning\"],\n",
    "        \"학습 파라미터 비율\": [\"100%\", \"0.1-1%\", \"0.1-1%\", \"2-4%\", \"0.01-0.1%\", \"0.1-3%\", \"0.01%\"],\n",
    "        \"메모리 효율성\": [\"낮음\", \"매우 높음\", \"매우 높음\", \"높음\", \"매우 높음\", \"높음\", \"매우 높음\"],\n",
    "        \"성능 유지도\": [\"최고\", \"높음\", \"높음\", \"중간\", \"중간\", \"높음\", \"낮음\"],\n",
    "        \"구현 복잡도\": [\"낮음\", \"중간\", \"높음\", \"중간\", \"높음\", \"높음\", \"낮음\"],\n",
    "        \"적합한 태스크\": [\n",
    "            \"모든 태스크\",\n",
    "            \"언어 생성, QA\", \n",
    "            \"동적 중요도 태스크\",\n",
    "            \"분류, 감정분석\",\n",
    "            \"생성 태스크\",\n",
    "            \"이해/생성 태스크\",\n",
    "            \"간단한 태스크\"\n",
    "        ],\n",
    "        \"주요 장점\": [\n",
    "            \"최고 성능\",\n",
    "            \"효율성과 성능 균형\",\n",
    "            \"동적 rank 조정\",\n",
    "            \"안정적 성능\",\n",
    "            \"생성 품질 향상\",\n",
    "            \"범용적 적용\",\n",
    "            \"초고효율\"\n",
    "        ],\n",
    "        \"주요 단점\": [\n",
    "            \"메모리/비용 과다\",\n",
    "            \"하이퍼파라미터 민감\",\n",
    "            \"구현 복잡\",\n",
    "            \"추가 레이어 필요\",\n",
    "            \"시퀀스 길이 제한\",\n",
    "            \"토큰별 최적화 필요\",\n",
    "            \"복잡 태스크 한계\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.DataFrame(peft_methods)\n",
    "    \n",
    "    print(\"🔍 PEFT 기법 종합 비교\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # 표 출력 (가독성을 위해 분할 출력)\n",
    "    print(\"\\n📊 기본 정보:\")\n",
    "    basic_info = df[['방법', '학습 파라미터 비율', '메모리 효율성', '성능 유지도', '구현 복잡도']]\n",
    "    print(basic_info.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n🎯 적용 정보:\")\n",
    "    application_info = df[['방법', '적합한 태스크', '주요 장점', '주요 단점']]\n",
    "    for idx, row in application_info.iterrows():\n",
    "        print(f\"\\n{row['방법']}:\")\n",
    "        print(f\"  적합한 태스크: {row['적합한 태스크']}\")\n",
    "        print(f\"  주요 장점: {row['주요 장점']}\")\n",
    "        print(f\"  주요 단점: {row['주요 단점']}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# PEFT 비교표 생성\n",
    "peft_comparison = create_peft_comparison_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ⚖️ 파인튜닝 vs 프롬프트 엔지니어링\n",
    "\n",
    "### 🤔 언제 파인튜닝을 선택해야 할까?\n",
    "\n",
    "파인튜닝과 프롬프트 엔지니어링의 적절한 선택 기준을 알아봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_vs_prompting_guide():\n",
    "    \"\"\"\n",
    "    파인튜닝 vs 프롬프트 엔지니어링 선택 가이드\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🎯 파인튜닝 vs 프롬프트 엔지니어링 선택 가이드\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 선택 기준표\n",
    "    criteria = {\n",
    "        \"기준\": [\n",
    "            \"데이터 양\",\n",
    "            \"도메인 특수성\", \n",
    "            \"성능 요구사항\",\n",
    "            \"지연시간 요구사항\",\n",
    "            \"개발 리소스\",\n",
    "            \"유지보수성\",\n",
    "            \"비용 제약\",\n",
    "            \"개인정보 보호\"\n",
    "        ],\n",
    "        \"프롬프트 엔지니어링\": [\n",
    "            \"< 100 예제\",\n",
    "            \"일반적 도메인\",\n",
    "            \"중간 수준 충분\",\n",
    "            \"실시간 필요\",\n",
    "            \"제한적\",\n",
    "            \"높음 (쉬운 수정)\",\n",
    "            \"낮은 비용\",\n",
    "            \"외부 API 사용\"\n",
    "        ],\n",
    "        \"파인튜닝\": [\n",
    "            \"> 1,000 예제\",\n",
    "            \"고도로 전문화\",\n",
    "            \"높은 성능 필요\",\n",
    "            \"배치 처리 가능\",\n",
    "            \"충분한 리소스\",\n",
    "            \"중간 (모델 재훈련)\",\n",
    "            \"중간-높은 비용\",\n",
    "            \"온프레미스 가능\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    criteria_df = pd.DataFrame(criteria)\n",
    "    print(criteria_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # 실제 사용 사례\n",
    "    use_cases = {\n",
    "        \"프롬프트 엔지니어링 추천\": [\n",
    "            \"💬 일반적인 챗봇 서비스\",\n",
    "            \"📝 간단한 텍스트 분류\", \n",
    "            \"🔄 프로토타입 빠른 개발\",\n",
    "            \"📊 다양한 태스크 실험\",\n",
    "            \"⚡ 실시간 응답 필요\",\n",
    "            \"💰 예산 제약이 큰 경우\"\n",
    "        ],\n",
    "        \"파인튜닝 추천\": [\n",
    "            \"🏥 의료진 전문 상담 AI\",\n",
    "            \"⚖️ 법률 문서 분석 AI\",\n",
    "            \"💼 기업 특화 업무 자동화\",\n",
    "            \"🎯 높은 정확도가 중요한 태스크\",\n",
    "            \"🔒 데이터 보안이 중요한 경우\",\n",
    "            \"📈 장기적 서비스 운영\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n🎯 실제 사용 사례:\")\n",
    "    \n",
    "    print(\"\\n🟦 프롬프트 엔지니어링이 적합한 경우:\")\n",
    "    for case in use_cases[\"프롬프트 엔지니어링 추천\"]:\n",
    "        print(f\"  {case}\")\n",
    "    \n",
    "    print(\"\\n🟩 파인튜닝이 적합한 경우:\")\n",
    "    for case in use_cases[\"파인튜닝 추천\"]:\n",
    "        print(f\"  {case}\")\n",
    "    \n",
    "    # 하이브리드 접근법\n",
    "    print(\"\\n🔄 하이브리드 접근법:\")\n",
    "    print(\"  1️⃣ 프롬프트 엔지니어링으로 빠른 프로토타입\")\n",
    "    print(\"  2️⃣ 성능 한계 도달 시 파인튜닝 적용\")\n",
    "    print(\"  3️⃣ 파인튜닝된 모델에 프롬프트 엔지니어링 추가 적용\")\n",
    "    print(\"  4️⃣ RAG + 파인튜닝으로 최적 성능 달성\")\n",
    "    \n",
    "    return criteria_df, use_cases\n",
    "\n",
    "# 선택 가이드 생성\n",
    "selection_guide, use_case_examples = create_finetuning_vs_prompting_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 🏗️ 파인튜닝 파이프라인 전체 구조\n",
    "\n",
    "### 📋 실제 프로덕션에서의 파인튜닝 워크플로우\n",
    "\n",
    "전체 파인튜닝 과정을 단계별로 이해해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_pipeline_overview():\n",
    "    \"\"\"\n",
    "    파인튜닝 파이프라인 전체 구조 설명\n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline_stages = {\n",
    "        \"1. 데이터 준비\": {\n",
    "            \"설명\": \"고품질 학습 데이터 수집 및 전처리\",\n",
    "            \"주요 작업\": [\n",
    "                \"📊 데이터 수집 및 검증\",\n",
    "                \"🧹 데이터 클리닝 및 필터링\",\n",
    "                \"📝 프롬프트 템플릿 설계\",\n",
    "                \"✂️ 데이터 분할 (train/val/test)\",\n",
    "                \"🔍 데이터 품질 검증\"\n",
    "            ],\n",
    "            \"체크포인트\": \"데이터 품질과 양이 충분한가?\",\n",
    "            \"일반적 문제\": \"편향된 데이터, 품질 불량, 양 부족\"\n",
    "        },\n",
    "        \"2. 모델 선택\": {\n",
    "            \"설명\": \"태스크에 적합한 베이스 모델 선택\",\n",
    "            \"주요 작업\": [\n",
    "                \"🎯 태스크 유형 분석\",\n",
    "                \"📏 모델 크기 vs 성능 트레이드오프\",\n",
    "                \"💻 하드웨어 제약사항 고려\",\n",
    "                \"🌐 언어 및 도메인 적합성 평가\",\n",
    "                \"📜 라이선스 확인\"\n",
    "            ],\n",
    "            \"체크포인트\": \"선택한 모델이 태스크와 환경에 적합한가?\",\n",
    "            \"일반적 문제\": \"오버스펙, 언더스펙, 라이선스 이슈\"\n",
    "        },\n",
    "        \"3. PEFT 기법 선택\": {\n",
    "            \"설명\": \"효율적 파인튜닝 방법 결정\",\n",
    "            \"주요 작업\": [\n",
    "                \"⚖️ Full vs PEFT 방식 선택\",\n",
    "                \"🔧 LoRA rank 설정\",\n",
    "                \"📊 학습 파라미터 수 계산\",\n",
    "                \"💾 메모리 요구량 추정\",\n",
    "                \"🎛️ 하이퍼파라미터 설계\"\n",
    "            ],\n",
    "            \"체크포인트\": \"메모리와 성능 요구사항을 만족하는가?\",\n",
    "            \"일반적 문제\": \"부적절한 rank, 메모리 부족\"\n",
    "        },\n",
    "        \"4. 학습 실행\": {\n",
    "            \"설명\": \"실제 파인튜닝 학습 과정\",\n",
    "            \"주요 작업\": [\n",
    "                \"🏃‍♂️ 학습률 스케줄링\",\n",
    "                \"📈 손실 함수 모니터링\",\n",
    "                \"💾 체크포인트 저장\",\n",
    "                \"📊 검증 데이터 평가\",\n",
    "                \"⏰ 조기 종료 조건 확인\"\n",
    "            ],\n",
    "            \"체크포인트\": \"학습이 안정적으로 수렴하고 있는가?\",\n",
    "            \"일반적 문제\": \"과적합, 발산, 메모리 부족\"\n",
    "        },\n",
    "        \"5. 평가 및 검증\": {\n",
    "            \"설명\": \"모델 성능 종합 평가\",\n",
    "            \"주요 작업\": [\n",
    "                \"📊 정량적 지표 측정\",\n",
    "                \"👀 정성적 결과 분석\",\n",
    "                \"⚖️ 베이스라인 대비 성능 비교\",\n",
    "                \"🔍 실패 케이스 분석\",\n",
    "                \"🧪 A/B 테스트 준비\"\n",
    "            ],\n",
    "            \"체크포인트\": \"목표 성능을 달성했는가?\",\n",
    "            \"일반적 문제\": \"과적합, 일반화 부족, 편향\"\n",
    "        },\n",
    "        \"6. 배포 및 모니터링\": {\n",
    "            \"설명\": \"프로덕션 환경 배포 및 운영\",\n",
    "            \"주요 작업\": [\n",
    "                \"🚀 모델 배포 파이프라인\",\n",
    "                \"📊 실시간 성능 모니터링\",\n",
    "                \"🔄 모델 버전 관리\",\n",
    "                \"📈 사용자 피드백 수집\",\n",
    "                \"🔄 지속적 개선 계획\"\n",
    "            ],\n",
    "            \"체크포인트\": \"실제 환경에서 안정적으로 동작하는가?\",\n",
    "            \"일반적 문제\": \"성능 저하, 드리프트, 확장성 이슈\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"🏗️ 파인튜닝 파이프라인 전체 구조\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for stage_name, stage_info in pipeline_stages.items():\n",
    "        print(f\"\\n{stage_name}\")\n",
    "        print(f\"📋 {stage_info['설명']}\")\n",
    "        print(f\"\\n주요 작업:\")\n",
    "        for task in stage_info['주요 작업']:\n",
    "            print(f\"  {task}\")\n",
    "        print(f\"\\n✅ 체크포인트: {stage_info['체크포인트']}\")\n",
    "        print(f\"⚠️ 일반적 문제: {stage_info['일반적 문제']}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # 성공을 위한 핵심 팁\n",
    "    success_tips = {\n",
    "        \"데이터 품질\": \"양보다 질! 고품질 데이터 1000개가 저품질 10000개보다 낫다\",\n",
    "        \"점진적 접근\": \"작은 모델로 시작해서 점진적으로 확장\",\n",
    "        \"체계적 실험\": \"모든 실험을 기록하고 재현 가능하게 관리\",\n",
    "        \"지속적 모니터링\": \"배포 후에도 성능과 편향성을 지속적으로 관찰\",\n",
    "        \"도메인 전문가 협업\": \"기술적 구현뿐만 아니라 도메인 지식 활용\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\n🎯 성공을 위한 핵심 팁:\")\n",
    "    for tip_name, tip_content in success_tips.items():\n",
    "        print(f\"  💡 {tip_name}: {tip_content}\")\n",
    "    \n",
    "    return pipeline_stages, success_tips\n",
    "\n",
    "# 파이프라인 구조 설명\n",
    "pipeline_overview, success_guidelines = create_finetuning_pipeline_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 📚 실제 프로덕션 사례 연구\n",
    "\n",
    "### 🏢 기업에서의 파인튜닝 활용 사례\n",
    "\n",
    "실제 기업 환경에서 파인튜닝이 어떻게 활용되는지 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showcase_production_cases():\n",
    "    \"\"\"\n",
    "    실제 프로덕션 파인튜닝 사례들\n",
    "    \"\"\"\n",
    "    \n",
    "    production_cases = {\n",
    "        \"🏥 의료 AI 어시스턴트\": {\n",
    "            \"배경\": \"대형 병원의 의료진 업무 지원 AI 개발\",\n",
    "            \"데이터\": \"의료 문헌 10만건 + 진료 기록 5만건 (개인정보 제거)\",\n",
    "            \"베이스 모델\": \"Llama 2 7B (의료 도메인 사전 학습 모델)\",\n",
    "            \"PEFT 방법\": \"LoRA (rank=16, α=32)\",\n",
    "            \"학습 시간\": \"Tesla V100 4장으로 48시간\",\n",
    "            \"성과\": {\n",
    "                \"정확도\": \"의료 질의응답 85% → 94% 향상\",\n",
    "                \"효율성\": \"의료진 문서 작업 시간 40% 단축\",\n",
    "                \"안전성\": \"잘못된 의학 정보 제공률 90% 감소\"\n",
    "            },\n",
    "            \"주요 도전과제\": [\n",
    "                \"개인정보 보호 규정 준수\",\n",
    "                \"의학적 정확성 보장\",\n",
    "                \"전문 용어 정확한 이해\"\n",
    "            ]\n",
    "        },\n",
    "        \"💼 금융 문서 분석 AI\": {\n",
    "            \"배경\": \"투자은행의 리서치 보고서 자동 생성 시스템\",\n",
    "            \"데이터\": \"금융 리포트 50만건 + 시장 데이터 연동\",\n",
    "            \"베이스 모델\": \"GPT-3.5 Turbo (OpenAI API)\",\n",
    "            \"PEFT 방법\": \"Few-shot learning + Function calling\",\n",
    "            \"학습 시간\": \"API 파인튜닝 서비스 이용 (24시간)\",\n",
    "            \"성과\": {\n",
    "                \"품질\": \"리포트 품질 점수 7.2/10 → 8.8/10\",\n",
    "                \"속도\": \"리포트 작성 시간 5일 → 2시간 단축\",\n",
    "                \"비용\": \"리서치 인력 비용 60% 절감\"\n",
    "            },\n",
    "            \"주요 도전과제\": [\n",
    "                \"실시간 시장 데이터 반영\",\n",
    "                \"규제 요구사항 준수\",\n",
    "                \"시장 변동성에 대한 적응\"\n",
    "            ]\n",
    "        },\n",
    "        \"🛒 E-commerce 상품 추천 AI\": {\n",
    "            \"배경\": \"대형 쇼핑몰의 개인화 상품 설명 생성\",\n",
    "            \"데이터\": \"상품 정보 100만건 + 사용자 리뷰 500만건\",\n",
    "            \"베이스 모델\": \"KoAlpaca 13B (한국어 특화)\",\n",
    "            \"PEFT 방법\": \"LoRA (rank=8) + Adapter (상품 카테고리별)\",\n",
    "            \"학습 시간\": \"RTX 4090 8장으로 72시간\",\n",
    "            \"성과\": {\n",
    "                \"전환율\": \"상품 구매 전환율 2.3% → 3.8% 상승\",\n",
    "                \"만족도\": \"고객 만족도 4.2/5 → 4.7/5 향상\",\n",
    "                \"매출\": \"월 매출 15% 증가\"\n",
    "            },\n",
    "            \"주요 도전과제\": [\n",
    "                \"다양한 상품 카테고리 대응\",\n",
    "                \"계절성 및 트렌드 반영\",\n",
    "                \"실시간 추천 시스템 통합\"\n",
    "            ]\n",
    "        },\n",
    "        \"🎓 교육 콘텐츠 AI\": {\n",
    "            \"배경\": \"온라인 교육 플랫폼의 맞춤형 학습 도우미\",\n",
    "            \"데이터\": \"교육 콘텐츠 20만건 + 학습자 상호작용 데이터\",\n",
    "            \"베이스 모델\": \"EXAONE 7.8B (한국어 교육 도메인)\",\n",
    "            \"PEFT 방법\": \"AdaLoRA (동적 rank 조정)\",\n",
    "            \"학습 시간\": \"A100 2장으로 36시간\",\n",
    "            \"성과\": {\n",
    "                \"학습 효과\": \"학습자 이해도 평가 점수 20% 향상\",\n",
    "                \"참여도\": \"수업 완주율 65% → 82% 증가\",\n",
    "                \"개인화\": \"개별 학습자 맞춤 콘텐츠 제공률 95%\"\n",
    "            },\n",
    "            \"주요 도전과제\": [\n",
    "                \"연령별 학습 수준 차이 대응\",\n",
    "                \"교육학적 효과성 검증\",\n",
    "                \"다국어 지원 확장\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"🏢 실제 프로덕션 파인튜닝 사례 연구\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for case_name, case_info in production_cases.items():\n",
    "        print(f\"\\n{case_name}\")\n",
    "        print(f\"📋 배경: {case_info['배경']}\")\n",
    "        print(f\"📊 데이터: {case_info['데이터']}\")\n",
    "        print(f\"🤖 베이스 모델: {case_info['베이스 모델']}\")\n",
    "        print(f\"⚙️ PEFT 방법: {case_info['PEFT 방법']}\")\n",
    "        print(f\"⏰ 학습 시간: {case_info['학습 시간']}\")\n",
    "        \n",
    "        print(f\"\\n📈 주요 성과:\")\n",
    "        for metric, value in case_info['성과'].items():\n",
    "            print(f\"  • {metric}: {value}\")\n",
    "        \n",
    "        print(f\"\\n🚧 주요 도전과제:\")\n",
    "        for challenge in case_info['주요 도전과제']:\n",
    "            print(f\"  • {challenge}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # 공통 성공 요인\n",
    "    success_factors = [\n",
    "        \"🎯 명확한 비즈니스 목표 설정\",\n",
    "        \"📊 고품질 도메인 데이터 확보\",\n",
    "        \"🤝 도메인 전문가와의 밀접한 협업\",\n",
    "        \"📈 체계적인 성능 측정 및 모니터링\",\n",
    "        \"🔄 지속적인 모델 개선 및 업데이트\",\n",
    "        \"⚖️ 윤리적 AI 사용 가이드라인 준수\",\n",
    "        \"🛡️ 강력한 보안 및 개인정보 보호 체계\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🎯 공통 성공 요인:\")\n",
    "    for factor in success_factors:\n",
    "        print(f\"  {factor}\")\n",
    "    \n",
    "    return production_cases, success_factors\n",
    "\n",
    "# 프로덕션 사례 소개\n",
    "cases, success_keys = showcase_production_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 🚀 Day 1 실습 미리보기\n",
    "\n",
    "### 📋 오늘 진행할 실습 내용\n",
    "\n",
    "이론을 바탕으로 실제로 진행할 파인튜닝 실습을 미리 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_day1_practicals():\n",
    "    \"\"\"\n",
    "    Day 1 실습 내용 미리보기\n",
    "    \"\"\"\n",
    "    \n",
    "    practicals = {\n",
    "        \"01_dataset_preparation.ipynb\": {\n",
    "            \"제목\": \"📊 고품질 학습 데이터셋 준비\",\n",
    "            \"목표\": \"RAFT 형식의 한국어 QA 데이터셋 구축\",\n",
    "            \"주요 내용\": [\n",
    "                \"🔍 다양한 도메인의 한국어 데이터 수집\",\n",
    "                \"🧹 데이터 품질 검증 및 클리닝\",\n",
    "                \"📝 RAFT 프롬프트 템플릿 적용\",\n",
    "                \"✂️ 적절한 길이로 데이터 분할\",\n",
    "                \"📊 데이터 분포 분석 및 시각화\"\n",
    "            ],\n",
    "            \"실습 시간\": \"45분\",\n",
    "            \"난이도\": \"초급\"\n",
    "        },\n",
    "        \"02_model_setup.ipynb\": {\n",
    "            \"제목\": \"🤖 EXAONE 모델 설정 및 준비\",\n",
    "            \"목표\": \"파인튜닝을 위한 모델 환경 구축\",\n",
    "            \"주요 내용\": [\n",
    "                \"🏗️ EXAONE-3.0-7.8B-Instruct 모델 로드\",\n",
    "                \"🔧 토크나이저 설정 및 특수 토큰 추가\",\n",
    "                \"💾 모델 메모리 사용량 최적화\",\n",
    "                \"⚙️ PEFT 설정 (LoRA) 구성\",\n",
    "                \"🧪 모델 기본 동작 테스트\"\n",
    "            ],\n",
    "            \"실습 시간\": \"30분\",\n",
    "            \"난이도\": \"초급-중급\"\n",
    "        },\n",
    "        \"03_fine_tuning_with_lora.ipynb\": {\n",
    "            \"제목\": \"🎯 LoRA 기반 효율적 파인튜닝\",\n",
    "            \"목표\": \"실제 파인튜닝 학습 과정 완주\",\n",
    "            \"주요 내용\": [\n",
    "                \"⚙️ LoRA 하이퍼파라미터 설정 (rank, alpha)\",\n",
    "                \"🏃‍♂️ 학습률 스케줄링 및 옵티마이저 설정\",\n",
    "                \"📈 학습 진행 상황 실시간 모니터링\",\n",
    "                \"💾 체크포인트 저장 및 관리\",\n",
    "                \"🔍 학습 곡선 분석 및 해석\"\n",
    "            ],\n",
    "            \"실습 시간\": \"60분\",\n",
    "            \"난이도\": \"중급\"\n",
    "        },\n",
    "        \"04_evaluation_and_comparison.ipynb\": {\n",
    "            \"제목\": \"📊 모델 성능 평가 및 비교\",\n",
    "            \"목표\": \"파인튜닝 전후 성능 차이 정량적 분석\",\n",
    "            \"주요 내용\": [\n",
    "                \"📋 다양한 평가 메트릭 적용\",\n",
    "                \"📊 베이스라인 vs 파인튜닝 모델 비교\",\n",
    "                \"🎯 도메인별 성능 분석\",\n",
    "                \"📈 성능 향상 요인 분석\",\n",
    "                \"🔍 실패 케이스 분석 및 개선 방향 도출\"\n",
    "            ],\n",
    "            \"실습 시간\": \"45분\",\n",
    "            \"난이도\": \"중급\"\n",
    "        },\n",
    "        \"05_deployment_and_serving.ipynb\": {\n",
    "            \"제목\": \"🚀 모델 배포 및 서빙\",\n",
    "            \"목표\": \"파인튜닝된 모델의 실제 배포\",\n",
    "            \"주요 내용\": [\n",
    "                \"🔗 Hugging Face Hub 업로드\",\n",
    "                \"⚡ 추론 최적화 (양자화, 캐싱)\",\n",
    "                \"🌐 FastAPI 기반 서비스 API 구축\",\n",
    "                \"📊 실시간 성능 모니터링 설정\",\n",
    "                \"🔄 모델 버전 관리 및 롤백 전략\"\n",
    "            ],\n",
    "            \"실습 시간\": \"50분\",\n",
    "            \"난이도\": \"중급-고급\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"🚀 Day 1 실습 과정 미리보기\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_time = 0\n",
    "    \n",
    "    for notebook, info in practicals.items():\n",
    "        time_minutes = int(info['실습 시간'].replace('분', ''))\n",
    "        total_time += time_minutes\n",
    "        \n",
    "        print(f\"\\n📖 {notebook}\")\n",
    "        print(f\"🎯 {info['제목']}\")\n",
    "        print(f\"📋 목표: {info['목표']}\")\n",
    "        print(f\"⏰ 소요시간: {info['실습 시간']}\")\n",
    "        print(f\"🎚️ 난이도: {info['난이도']}\")\n",
    "        \n",
    "        print(f\"\\n주요 실습 내용:\")\n",
    "        for content in info['주요 내용']:\n",
    "            print(f\"  {content}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"\\n⏰ 총 예상 실습 시간: {total_time}분 ({total_time//60}시간 {total_time%60}분)\")\n",
    "    \n",
    "    # 실습 준비사항\n",
    "    requirements = {\n",
    "        \"하드웨어\": [\n",
    "            \"🖥️ GPU 메모리 16GB 이상 권장 (RTX 4090, A100 등)\",\n",
    "            \"💻 RAM 32GB 이상\",\n",
    "            \"💽 저장공간 50GB 이상\"\n",
    "        ],\n",
    "        \"소프트웨어\": [\n",
    "            \"🐍 Python 3.8+\",\n",
    "            \"🔥 PyTorch 2.0+\",\n",
    "            \"🤗 Transformers 4.35+\",\n",
    "            \"📊 Dataset, PEFT, Accelerate 라이브러리\"\n",
    "        ],\n",
    "        \"계정\": [\n",
    "            \"🤗 Hugging Face 계정 (모델 다운로드/업로드)\",\n",
    "            \"📊 Weights & Biases 계정 (선택사항, 실험 추적)\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\n🛠️ 실습 준비사항:\")\n",
    "    for category, items in requirements.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  {item}\")\n",
    "    \n",
    "    # 학습 목표 달성 체크리스트\n",
    "    objectives = [\n",
    "        \"✅ 파인튜닝의 기본 개념과 원리를 이해한다\",\n",
    "        \"✅ LoRA를 이용한 효율적 파인튜닝을 실습한다\",\n",
    "        \"✅ 한국어 도메인 데이터로 실제 모델을 학습시킨다\",\n",
    "        \"✅ 파인튜닝 전후의 성능 차이를 정량적으로 분석한다\",\n",
    "        \"✅ 파인튜닝된 모델을 실제 서비스 가능한 형태로 배포한다\",\n",
    "        \"✅ 프로덕션 환경에서의 고려사항들을 이해한다\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🎯 Day 1 종료 후 달성 목표:\")\n",
    "    for objective in objectives:\n",
    "        print(f\"  {objective}\")\n",
    "    \n",
    "    return practicals, requirements, objectives\n",
    "\n",
    "# Day 1 실습 미리보기\n",
    "day1_preview, prep_requirements, learning_objectives = preview_day1_practicals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 🎓 개념 학습 정리\n",
    "\n",
    "### ✅ 핵심 개념 체크리스트\n",
    "\n",
    "지금까지 학습한 파인튜닝 핵심 개념들을 정리해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concept_summary_quiz():\n",
    "    \"\"\"\n",
    "    학습한 개념들에 대한 간단한 퀴즈와 정리\n",
    "    \"\"\"\n",
    "    \n",
    "    # 핵심 개념 체크리스트\n",
    "    concept_checklist = {\n",
    "        \"파인튜닝 기본 개념\": [\n",
    "            \"사전 훈련 vs 파인튜닝의 차이점을 설명할 수 있다\",\n",
    "            \"파인튜닝이 필요한 상황과 적합한 태스크를 구분할 수 있다\",\n",
    "            \"Full Fine-tuning의 장단점을 이해한다\"\n",
    "        ],\n",
    "        \"PEFT 이해\": [\n",
    "            \"Parameter Efficient Fine-Tuning의 필요성을 설명할 수 있다\",\n",
    "            \"LoRA의 수학적 원리 (저차원 분해)를 이해한다\",\n",
    "            \"다양한 PEFT 기법들의 특징과 적용 상황을 구분할 수 있다\"\n",
    "        ],\n",
    "        \"실무 적용\": [\n",
    "            \"파인튜닝 vs 프롬프트 엔지니어링 선택 기준을 안다\",\n",
    "            \"파인튜닝 파이프라인의 전체 과정을 이해한다\",\n",
    "            \"프로덕션 환경에서의 주요 고려사항을 파악한다\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"📋 파인튜닝 핵심 개념 체크리스트\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for category, items in concept_checklist.items():\n",
    "        print(f\"\\n🎯 {category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  ☐ {item}\")\n",
    "    \n",
    "    # 간단한 개념 확인 문제\n",
    "    quiz_questions = [\n",
    "        {\n",
    "            \"질문\": \"LoRA에서 rank 값을 높이면 어떤 변화가 일어날까요?\",\n",
    "            \"선택지\": [\n",
    "                \"A) 학습 파라미터 수가 줄어든다\",\n",
    "                \"B) 학습 파라미터 수가 늘어나고 표현력이 증가한다\",\n",
    "                \"C) 학습 속도가 빨라진다\",\n",
    "                \"D) 메모리 사용량이 줄어든다\"\n",
    "            ],\n",
    "            \"정답\": \"B\",\n",
    "            \"해설\": \"rank가 높아지면 A와 B 행렬의 크기가 커져서 학습 파라미터가 늘어나고, 더 복잡한 변화를 표현할 수 있습니다.\"\n",
    "        },\n",
    "        {\n",
    "            \"질문\": \"다음 중 파인튜닝이 프롬프트 엔지니어링보다 적합한 경우는?\",\n",
    "            \"선택지\": [\n",
    "                \"A) 100개 미만의 예제 데이터\",\n",
    "                \"B) 실시간 응답이 중요한 서비스\",\n",
    "                \"C) 의료 도메인의 고도로 전문화된 태스크\",\n",
    "                \"D) 빠른 프로토타입 개발\"\n",
    "            ],\n",
    "            \"정답\": \"C\",\n",
    "            \"해설\": \"의료처럼 고도로 전문화되고 정확성이 중요한 도메인에서는 충분한 데이터로 파인튜닝하는 것이 효과적입니다.\"\n",
    "        },\n",
    "        {\n",
    "            \"질문\": \"PEFT 기법의 주요 장점이 아닌 것은?\",\n",
    "            \"선택지\": [\n",
    "                \"A) 메모리 효율성\",\n",
    "                \"B) 학습 속도 향상\",\n",
    "                \"C) 재앙적 망각 방지\",\n",
    "                \"D) 항상 Full Fine-tuning보다 높은 성능\"\n",
    "            ],\n",
    "            \"정답\": \"D\",\n",
    "            \"해설\": \"PEFT는 효율성 면에서 장점이 있지만, 성능은 태스크와 데이터에 따라 Full Fine-tuning보다 낮을 수 있습니다.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\\n🧠 개념 확인 퀴즈\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, q in enumerate(quiz_questions, 1):\n",
    "        print(f\"\\n❓ 문제 {i}: {q['질문']}\")\n",
    "        for choice in q['선택지']:\n",
    "            print(f\"   {choice}\")\n",
    "        print(f\"\\n💡 정답: {q['정답']}\")\n",
    "        print(f\"📝 해설: {q['해설']}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # 다음 단계 준비\n",
    "    next_steps = [\n",
    "        \"🛠️ 개발 환경 설정 (GPU, Python, 라이브러리)\",\n",
    "        \"🤗 Hugging Face 계정 생성 및 토큰 설정\",\n",
    "        \"📊 실습용 데이터셋 다운로드 준비\",\n",
    "        \"🔍 EXAONE 모델 문서 및 사용법 숙지\",\n",
    "        \"⚙️ LoRA 하이퍼파라미터 실험 계획 수립\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n🚀 실습 전 준비할 것들:\")\n",
    "    for step in next_steps:\n",
    "        print(f\"  {step}\")\n",
    "    \n",
    "    return concept_checklist, quiz_questions, next_steps\n",
    "\n",
    "# 개념 정리 및 퀴즈\n",
    "checklist, quiz, preparation_steps = create_concept_summary_quiz()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎯 파인튜닝 개념 학습 완료!\")\n",
    "print(\"이제 실제 실습으로 넘어가서 이론을 코드로 구현해보겠습니다.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 개념 학습 완료!\n",
    "\n",
    "### 🎓 축하합니다!\n",
    "\n",
    "파인튜닝의 핵심 개념들을 성공적으로 학습하셨습니다:\n",
    "\n",
    "✅ **파인튜닝 기본 원리** - 사전 훈련 모델을 특정 태스크에 맞게 조정하는 방법  \n",
    "✅ **LoRA 이해** - 효율적인 저차원 분해 기반 파라미터 업데이트  \n",
    "✅ **PEFT 기법 비교** - 다양한 효율적 파인튜닝 방법들의 특징  \n",
    "✅ **실무 적용** - 프로덕션 환경에서의 고려사항과 선택 기준  \n",
    "\n",
    "### 🚀 다음 단계: 실습\n",
    "\n",
    "이제 배운 개념들을 실제 코드로 구현해보겠습니다!\n",
    "\n",
    "**📚 다음 실습 노트북:**\n",
    "- `01_dataset_preparation.ipynb` - 고품질 한국어 데이터셋 준비\n",
    "- `02_model_setup.ipynb` - EXAONE 모델 설정\n",
    "- `03_fine_tuning_with_lora.ipynb` - 실제 파인튜닝 실행\n",
    "- `04_evaluation_and_comparison.ipynb` - 성능 평가\n",
    "- `05_deployment_and_serving.ipynb` - 모델 배포\n",
    "\n",
    "**💪 여러분이 만들 결과물:**\n",
    "- 한국어 도메인에 특화된 고성능 언어 모델\n",
    "- Hugging Face에 업로드된 나만의 파인튜닝 모델\n",
    "- 실제 서비스 가능한 API 엔드포인트\n",
    "\n",
    "**🎯 최종 목표:**\n",
    "여러분의 파인튜닝 모델은 Day 2-3의 RAG와 Advanced RAG 실습에서도 계속 활용됩니다!\n",
    "\n",
    "---\n",
    "\n",
    "*\"이론은 시작에 불과하다. 실습에서 진정한 배움이 일어난다.\"* 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}