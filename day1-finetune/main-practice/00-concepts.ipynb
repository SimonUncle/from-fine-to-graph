{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1-0: νμΈνλ‹ ν•µμ‹¬ κ°λ… μ΄ν•΄\n",
    "\n",
    "## π― ν•™μµ λ©ν‘\n",
    "- **νμΈνλ‹(Fine-tuning)**μ κΈ°λ³Έ κ°λ…κ³Ό μ›λ¦¬ μ΄ν•΄\n",
    "- **LoRA(Low-Rank Adaptation)**μ μ‘λ™ λ°©μ‹κ³Ό μ¥μ \n",
    "- **PEFT(Parameter Efficient Fine-Tuning)** κΈ°λ²•λ“¤ λΉ„κµ\n",
    "- **νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§** μ°¨μ΄μ κ³Ό μ„ νƒ κΈ°μ¤€\n",
    "- **μ‹¤μ  ν”„λ΅λ•μ… ν™κ²½**μ—μ„μ νμΈνλ‹ μ μ© μ‚¬λ΅€\n",
    "\n",
    "## π“ ν•µμ‹¬ κ°λ… μ†κ°\n",
    "\n",
    "### π’΅ νμΈνλ‹μ΄λ€?\n",
    "**νμΈνλ‹(Fine-tuning)**μ€ μ΄λ―Έ μ‚¬μ „ ν›λ ¨λ λ€κ·λ¨ μ–Έμ–΄ λ¨λΈμ„ νΉμ • νƒμ¤ν¬λ‚ λ„λ©”μΈμ— λ§κ² μ¶”κ°€λ΅ ν•™μµμ‹ν‚¤λ” κΈ°λ²•μ…λ‹λ‹¤.\n",
    "\n",
    "λ§μΉ μ΄λ―Έ κΈ°λ³ΈκΈ°κ°€ κ°–μ¶°μ§„ μ„ μλ¥Ό νΉμ • μΆ…λ©μ— λ§κ² μ „λ¬Έ ν›λ ¨μ‹ν‚¤λ” κ²ƒκ³Ό κ°™μµλ‹λ‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ν•„μ”ν• λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ λ° μ„ν¬νΈ\n",
    "!pip install -q transformers datasets torch peft accelerate bitsandbytes\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# ν•κΈ€ ν°νΈ μ„¤μ •\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "print(\"β… λΌμ΄λΈλ¬λ¦¬ μ„ν¬νΈ μ™„λ£!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. π§  νμΈνλ‹μ κΈ°λ³Έ μ›λ¦¬\n",
    "\n",
    "### π“ μ‚¬μ „ ν›λ ¨ vs νμΈνλ‹ λΉ„κµ\n",
    "νμΈνλ‹κ³Ό μ‚¬μ „ ν›λ ¨μ μ°¨μ΄μ μ„ μ‹κ°ν™”λ΅ μ΄ν•΄ν•΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_concept_visualization():\n",
    "    \"\"\"\n",
    "    νμΈνλ‹ κ°λ…μ„ μ‹κ°ν™”ν•λ” ν•¨μ\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Fine-tuning Core Concepts Visualization', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. μ‚¬μ „ ν›λ ¨ vs νμΈνλ‹ λ°μ΄ν„° ν¬κΈ° λΉ„κµ\n",
    "    categories = ['Pre-training\\nData', 'Fine-tuning\\nData']\n",
    "    data_sizes = [1000000, 1000]  # μƒλ€μ  ν¬κΈ° (1M vs 1K)\n",
    "    colors = ['lightblue', 'orange']\n",
    "    \n",
    "    bars = axes[0, 0].bar(categories, data_sizes, color=colors, alpha=0.7)\n",
    "    axes[0, 0].set_yscale('log')\n",
    "    axes[0, 0].set_ylabel('Data Size (examples)')\n",
    "    axes[0, 0].set_title('π“ Pre-training vs Fine-tuning Data Size')\n",
    "    \n",
    "    # λ§‰λ€ μ„μ— μμΉ ν‘μ‹\n",
    "    for bar, size in zip(bars, data_sizes):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{size:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 2. νμΈνλ‹ λ°©λ²•λ³„ ν•™μµ νλΌλ―Έν„° μ λΉ„κµ\n",
    "    methods = ['Full\\nFine-tuning', 'LoRA', 'Adapter', 'Prompt\\nTuning']\n",
    "    param_percentages = [100, 0.1, 2, 0.01]  # μ „μ²΄ νλΌλ―Έν„° λ€λΉ„ ν•™μµ νλΌλ―Έν„° λΉ„μ¨\n",
    "    method_colors = ['red', 'green', 'blue', 'purple']\n",
    "    \n",
    "    bars2 = axes[0, 1].bar(methods, param_percentages, color=method_colors, alpha=0.7)\n",
    "    axes[0, 1].set_ylabel('Trainable Parameters (%)')\n",
    "    axes[0, 1].set_title('π”§ Parameter Efficiency Comparison')\n",
    "    axes[0, 1].set_yscale('log')\n",
    "    \n",
    "    for bar, pct in zip(bars2, param_percentages):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{pct}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. LoRAμ μ‘λ™ μ›λ¦¬ μ‹κ°ν™”\n",
    "    # μ›λ κ°€μ¤‘μΉ ν–‰λ ¬μ„ μ‹κ°ν™”\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(8, 8)  # μ›λ κ°€μ¤‘μΉ ν–‰λ ¬\n",
    "    \n",
    "    im1 = axes[1, 0].imshow(W, cmap='RdBu', aspect='auto')\n",
    "    axes[1, 0].set_title('π― Original Weight Matrix W')\n",
    "    axes[1, 0].set_xlabel('Input Dimension')\n",
    "    axes[1, 0].set_ylabel('Output Dimension')\n",
    "    \n",
    "    # LoRA λ¶„ν•΄ μ‹κ°ν™”\n",
    "    rank = 2\n",
    "    A = np.random.randn(8, rank) * 0.1  # Low-rank matrix A\n",
    "    B = np.random.randn(rank, 8) * 0.1  # Low-rank matrix B\n",
    "    \n",
    "    # Aμ™€ Bλ¥Ό λ‚λ€ν ν‘μ‹\n",
    "    combined = np.hstack([A, np.zeros((8, 2)), B.T])\n",
    "    im2 = axes[1, 1].imshow(combined, cmap='RdBu', aspect='auto')\n",
    "    axes[1, 1].set_title('π”„ LoRA Decomposition: A + B^T')\n",
    "    axes[1, 1].set_xlabel('A Matrix | Gap | B^T Matrix')\n",
    "    axes[1, 1].set_ylabel('Dimensions')\n",
    "    \n",
    "    # μ»¬λ¬λ°” μ¶”κ°€\n",
    "    plt.colorbar(im1, ax=axes[1, 0], fraction=0.046, pad=0.04)\n",
    "    plt.colorbar(im2, ax=axes[1, 1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('finetuning_concepts.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# μ‹κ°ν™” μƒμ„±\n",
    "concept_fig = create_finetuning_concept_visualization()\n",
    "print(\"β… νμΈνλ‹ κ°λ… μ‹κ°ν™” μ™„λ£!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. π― LoRA (Low-Rank Adaptation) κΉμ΄ μ΄ν•΄\n",
    "\n",
    "### π’΅ LoRAμ ν•µμ‹¬ μ•„μ΄λ””μ–΄\n",
    "\n",
    "LoRAλ” \"**ν° ν–‰λ ¬μ„ μ‘μ€ λ‘ ν–‰λ ¬μ κ³±μΌλ΅ κ·Όμ‚¬**\"ν•λ” μ•„μ΄λ””μ–΄μ— κΈ°λ°ν•©λ‹λ‹¤.\n",
    "\n",
    "**μν•™μ  ν‘ν„:**\n",
    "- μ›λ: `h = Wβ‚€x + Ξ”Wx` (μ „μ²΄ κ°€μ¤‘μΉ μ—…λ°μ΄νΈ)\n",
    "- LoRA: `h = Wβ‚€x + BAx` (μ €μ°¨μ› λ¶„ν•΄)\n",
    "\n",
    "μ—¬κΈ°μ„ `B β β„αµΛ£Κ³`, `A β β„Κ³Λ£αµ`, `r << min(d,k)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_lora_math():\n",
    "    \"\"\"\n",
    "    LoRAμ μν•™μ  μ›λ¦¬λ¥Ό μ‹¤μ  μ½”λ“λ΅ μ‹μ—°\n",
    "    \"\"\"\n",
    "    print(\"π” LoRA μν•™μ  μ›λ¦¬ μ‹μ—°\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # κ°€μƒμ κ°€μ¤‘μΉ ν–‰λ ¬ (μ: GPTμ μ–΄ν…μ… λ μ΄μ–΄)\n",
    "    d_model = 768  # λ¨λΈ μ°¨μ›\n",
    "    seq_length = 512  # μ‹ν€€μ¤ κΈΈμ΄\n",
    "    \n",
    "    print(f\"π“ λ¨λΈ μ„¤μ •:\")\n",
    "    print(f\"   - λ¨λΈ μ°¨μ› (d_model): {d_model}\")\n",
    "    print(f\"   - μ‹ν€€μ¤ κΈΈμ΄: {seq_length}\")\n",
    "    \n",
    "    # μ›λ κ°€μ¤‘μΉ ν–‰λ ¬ Wβ‚€ (freezeλ¨)\n",
    "    W0 = torch.randn(d_model, d_model) * 0.02\n",
    "    \n",
    "    # Full Fine-tuningμ κ²½μ°\n",
    "    delta_W_full = torch.randn(d_model, d_model) * 0.001  # μ—…λ°μ΄νΈν•  κ°€μ¤‘μΉ\n",
    "    full_params = delta_W_full.numel()\n",
    "    \n",
    "    print(f\"\\nπ”΄ Full Fine-tuning:\")\n",
    "    print(f\"   - μ—…λ°μ΄νΈν•  νλΌλ―Έν„° μ: {full_params:,}\")\n",
    "    print(f\"   - λ©”λ¨λ¦¬ μ‚¬μ©λ‰: ~{full_params * 4 / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # LoRAμ κ²½μ°\n",
    "    ranks = [1, 2, 4, 8, 16, 32]\n",
    "    \n",
    "    print(f\"\\nπΆ LoRA λ°©μ‹:\")\n",
    "    print(f\"{'Rank':<6} {'Parameters':<12} {'Reduction':<12} {'Memory (MB)':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for rank in ranks:\n",
    "        # LoRA ν–‰λ ¬λ“¤\n",
    "        A = torch.randn(rank, d_model) * 0.001  # A β β„Κ³Λ£αµ\n",
    "        B = torch.randn(d_model, rank) * 0.001  # B β β„αµΛ£Κ³\n",
    "        \n",
    "        lora_params = A.numel() + B.numel()\n",
    "        reduction_ratio = full_params / lora_params\n",
    "        memory_mb = lora_params * 4 / 1024**2\n",
    "        \n",
    "        print(f\"{rank:<6} {lora_params:<12,} {reduction_ratio:<12.1f}x {memory_mb:<12.2f}\")\n",
    "    \n",
    "    # μ‹¤μ  κ³„μ‚° μ‹μ—°\n",
    "    print(f\"\\nπ§® κ³„μ‚° κ³Όμ • μ‹μ—° (rank=4):\")\n",
    "    rank = 4\n",
    "    A = torch.randn(rank, d_model) * 0.001\n",
    "    B = torch.randn(d_model, rank) * 0.001\n",
    "    \n",
    "    # μ…λ ¥ λ²΅ν„°\n",
    "    x = torch.randn(d_model, 1)\n",
    "    \n",
    "    # μ›λ κ³„μ‚°\n",
    "    h_original = W0 @ x\n",
    "    \n",
    "    # LoRA κ³„μ‚°\n",
    "    h_lora = W0 @ x + B @ (A @ x)\n",
    "    \n",
    "    print(f\"   - A ν–‰λ ¬ ν¬κΈ°: {A.shape}\")\n",
    "    print(f\"   - B ν–‰λ ¬ ν¬κΈ°: {B.shape}\")\n",
    "    print(f\"   - μ…λ ¥ x ν¬κΈ°: {x.shape}\")\n",
    "    print(f\"   - μ›λ μ¶λ ¥ h ν¬κΈ°: {h_original.shape}\")\n",
    "    print(f\"   - LoRA μ¶λ ¥ h ν¬κΈ°: {h_lora.shape}\")\n",
    "    print(f\"   - μ¶λ ¥ μ°¨μ΄ (norm): {torch.norm(h_lora - h_original).item():.6f}\")\n",
    "    \n",
    "    return {\"full_params\": full_params, \"lora_params\": A.numel() + B.numel()}\n",
    "\n",
    "# LoRA μν•™ μ‹μ—°\n",
    "lora_demo = demonstrate_lora_math()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. π“‹ PEFT κΈ°λ²•λ“¤ λΉ„κµ λ¶„μ„\n",
    "\n",
    "### π” Parameter Efficient Fine-Tuning κΈ°λ²•λ“¤\n",
    "\n",
    "λ‹¤μ–‘ν• PEFT κΈ°λ²•λ“¤μ νΉμ§•κ³Ό μ μ© μƒν™©μ„ λΉ„κµν•΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_peft_comparison_table():\n",
    "    \"\"\"\n",
    "    PEFT κΈ°λ²•λ“¤μ„ μΆ…ν•© λΉ„κµν•λ” ν‘\n",
    "    \"\"\"\n",
    "    peft_methods = {\n",
    "        \"λ°©λ²•\": [\"Full Fine-tuning\", \"LoRA\", \"AdaLoRA\", \"Adapter\", \"Prefix Tuning\", \"P-Tuning v2\", \"Prompt Tuning\"],\n",
    "        \"ν•™μµ νλΌλ―Έν„° λΉ„μ¨\": [\"100%\", \"0.1-1%\", \"0.1-1%\", \"2-4%\", \"0.01-0.1%\", \"0.1-3%\", \"0.01%\"],\n",
    "        \"λ©”λ¨λ¦¬ ν¨μ¨μ„±\": [\"λ‚®μ\", \"λ§¤μ° λ†’μ\", \"λ§¤μ° λ†’μ\", \"λ†’μ\", \"λ§¤μ° λ†’μ\", \"λ†’μ\", \"λ§¤μ° λ†’μ\"],\n",
    "        \"μ„±λ¥ μ μ§€λ„\": [\"μµκ³ \", \"λ†’μ\", \"λ†’μ\", \"μ¤‘κ°„\", \"μ¤‘κ°„\", \"λ†’μ\", \"λ‚®μ\"],\n",
    "        \"κµ¬ν„ λ³µμ΅λ„\": [\"λ‚®μ\", \"μ¤‘κ°„\", \"λ†’μ\", \"μ¤‘κ°„\", \"λ†’μ\", \"λ†’μ\", \"λ‚®μ\"],\n",
    "        \"μ ν•©ν• νƒμ¤ν¬\": [\n",
    "            \"λ¨λ“  νƒμ¤ν¬\",\n",
    "            \"μ–Έμ–΄ μƒμ„±, QA\", \n",
    "            \"λ™μ  μ¤‘μ”λ„ νƒμ¤ν¬\",\n",
    "            \"λ¶„λ¥, κ°μ •λ¶„μ„\",\n",
    "            \"μƒμ„± νƒμ¤ν¬\",\n",
    "            \"μ΄ν•΄/μƒμ„± νƒμ¤ν¬\",\n",
    "            \"κ°„λ‹¨ν• νƒμ¤ν¬\"\n",
    "        ],\n",
    "        \"μ£Όμ” μ¥μ \": [\n",
    "            \"μµκ³  μ„±λ¥\",\n",
    "            \"ν¨μ¨μ„±κ³Ό μ„±λ¥ κ· ν•\",\n",
    "            \"λ™μ  rank μ΅°μ •\",\n",
    "            \"μ•μ •μ  μ„±λ¥\",\n",
    "            \"μƒμ„± ν’μ§ ν–¥μƒ\",\n",
    "            \"λ²”μ©μ  μ μ©\",\n",
    "            \"μ΄κ³ ν¨μ¨\"\n",
    "        ],\n",
    "        \"μ£Όμ” λ‹¨μ \": [\n",
    "            \"λ©”λ¨λ¦¬/λΉ„μ© κ³Όλ‹¤\",\n",
    "            \"ν•μ΄νΌνλΌλ―Έν„° λ―Όκ°\",\n",
    "            \"κµ¬ν„ λ³µμ΅\",\n",
    "            \"μ¶”κ°€ λ μ΄μ–΄ ν•„μ”\",\n",
    "            \"μ‹ν€€μ¤ κΈΈμ΄ μ ν•\",\n",
    "            \"ν† ν°λ³„ μµμ ν™” ν•„μ”\",\n",
    "            \"λ³µμ΅ νƒμ¤ν¬ ν•κ³„\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.DataFrame(peft_methods)\n",
    "    \n",
    "    print(\"π” PEFT κΈ°λ²• μΆ…ν•© λΉ„κµ\")\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # ν‘ μ¶λ ¥ (κ°€λ…μ„±μ„ μ„ν•΄ λ¶„ν•  μ¶λ ¥)\n",
    "    print(\"\\nπ“ κΈ°λ³Έ μ •λ³΄:\")\n",
    "    basic_info = df[['λ°©λ²•', 'ν•™μµ νλΌλ―Έν„° λΉ„μ¨', 'λ©”λ¨λ¦¬ ν¨μ¨μ„±', 'μ„±λ¥ μ μ§€λ„', 'κµ¬ν„ λ³µμ΅λ„']]\n",
    "    print(basic_info.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nπ― μ μ© μ •λ³΄:\")\n",
    "    application_info = df[['λ°©λ²•', 'μ ν•©ν• νƒμ¤ν¬', 'μ£Όμ” μ¥μ ', 'μ£Όμ” λ‹¨μ ']]\n",
    "    for idx, row in application_info.iterrows():\n",
    "        print(f\"\\n{row['λ°©λ²•']}:\")\n",
    "        print(f\"  μ ν•©ν• νƒμ¤ν¬: {row['μ ν•©ν• νƒμ¤ν¬']}\")\n",
    "        print(f\"  μ£Όμ” μ¥μ : {row['μ£Όμ” μ¥μ ']}\")\n",
    "        print(f\"  μ£Όμ” λ‹¨μ : {row['μ£Όμ” λ‹¨μ ']}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# PEFT λΉ„κµν‘ μƒμ„±\n",
    "peft_comparison = create_peft_comparison_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. β–οΈ νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§\n",
    "\n",
    "### π¤” μ–Έμ  νμΈνλ‹μ„ μ„ νƒν•΄μ•Ό ν• κΉ?\n",
    "\n",
    "νμΈνλ‹κ³Ό ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§μ μ μ ν• μ„ νƒ κΈ°μ¤€μ„ μ•μ•„λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_vs_prompting_guide():\n",
    "    \"\"\"\n",
    "    νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ„ νƒ κ°€μ΄λ“\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"π― νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ„ νƒ κ°€μ΄λ“\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # μ„ νƒ κΈ°μ¤€ν‘\n",
    "    criteria = {\n",
    "        \"κΈ°μ¤€\": [\n",
    "            \"λ°μ΄ν„° μ–‘\",\n",
    "            \"λ„λ©”μΈ νΉμμ„±\", \n",
    "            \"μ„±λ¥ μ”κµ¬μ‚¬ν•­\",\n",
    "            \"μ§€μ—°μ‹κ°„ μ”κµ¬μ‚¬ν•­\",\n",
    "            \"κ°λ° λ¦¬μ†μ¤\",\n",
    "            \"μ μ§€λ³΄μμ„±\",\n",
    "            \"λΉ„μ© μ μ•½\",\n",
    "            \"κ°μΈμ •λ³΄ λ³΄νΈ\"\n",
    "        ],\n",
    "        \"ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§\": [\n",
    "            \"< 100 μμ \",\n",
    "            \"μΌλ°μ  λ„λ©”μΈ\",\n",
    "            \"μ¤‘κ°„ μμ¤€ μ¶©λ¶„\",\n",
    "            \"μ‹¤μ‹κ°„ ν•„μ”\",\n",
    "            \"μ ν•μ \",\n",
    "            \"λ†’μ (μ‰¬μ΄ μμ •)\",\n",
    "            \"λ‚®μ€ λΉ„μ©\",\n",
    "            \"μ™Έλ¶€ API μ‚¬μ©\"\n",
    "        ],\n",
    "        \"νμΈνλ‹\": [\n",
    "            \"> 1,000 μμ \",\n",
    "            \"κ³ λ„λ΅ μ „λ¬Έν™”\",\n",
    "            \"λ†’μ€ μ„±λ¥ ν•„μ”\",\n",
    "            \"λ°°μΉ μ²λ¦¬ κ°€λ¥\",\n",
    "            \"μ¶©λ¶„ν• λ¦¬μ†μ¤\",\n",
    "            \"μ¤‘κ°„ (λ¨λΈ μ¬ν›λ ¨)\",\n",
    "            \"μ¤‘κ°„-λ†’μ€ λΉ„μ©\",\n",
    "            \"μ¨ν”„λ λ―Έμ¤ κ°€λ¥\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    import pandas as pd\n",
    "    criteria_df = pd.DataFrame(criteria)\n",
    "    print(criteria_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # μ‹¤μ  μ‚¬μ© μ‚¬λ΅€\n",
    "    use_cases = {\n",
    "        \"ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ¶”μ²\": [\n",
    "            \"π’¬ μΌλ°μ μΈ μ±—λ΄‡ μ„λΉ„μ¤\",\n",
    "            \"π“ κ°„λ‹¨ν• ν…μ¤νΈ λ¶„λ¥\", \n",
    "            \"π”„ ν”„λ΅ν† νƒ€μ… λΉ λ¥Έ κ°λ°\",\n",
    "            \"π“ λ‹¤μ–‘ν• νƒμ¤ν¬ μ‹¤ν—\",\n",
    "            \"β΅ μ‹¤μ‹κ°„ μ‘λ‹µ ν•„μ”\",\n",
    "            \"π’° μμ‚° μ μ•½μ΄ ν° κ²½μ°\"\n",
    "        ],\n",
    "        \"νμΈνλ‹ μ¶”μ²\": [\n",
    "            \"π¥ μλ£μ§„ μ „λ¬Έ μƒλ‹΄ AI\",\n",
    "            \"β–οΈ λ²•λ¥  λ¬Έμ„ λ¶„μ„ AI\",\n",
    "            \"π’Ό κΈ°μ—… νΉν™” μ—…λ¬΄ μλ™ν™”\",\n",
    "            \"π― λ†’μ€ μ •ν™•λ„κ°€ μ¤‘μ”ν• νƒμ¤ν¬\",\n",
    "            \"π”’ λ°μ΄ν„° λ³΄μ•μ΄ μ¤‘μ”ν• κ²½μ°\",\n",
    "            \"π“ μ¥κΈ°μ  μ„λΉ„μ¤ μ΄μ\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nπ― μ‹¤μ  μ‚¬μ© μ‚¬λ΅€:\")\n",
    "    \n",
    "    print(\"\\nπ¦ ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§μ΄ μ ν•©ν• κ²½μ°:\")\n",
    "    for case in use_cases[\"ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ¶”μ²\"]:\n",
    "        print(f\"  {case}\")\n",
    "    \n",
    "    print(\"\\nπ© νμΈνλ‹μ΄ μ ν•©ν• κ²½μ°:\")\n",
    "    for case in use_cases[\"νμΈνλ‹ μ¶”μ²\"]:\n",
    "        print(f\"  {case}\")\n",
    "    \n",
    "    # ν•μ΄λΈλ¦¬λ“ μ ‘κ·Όλ²•\n",
    "    print(\"\\nπ”„ ν•μ΄λΈλ¦¬λ“ μ ‘κ·Όλ²•:\")\n",
    "    print(\"  1οΈβƒ£ ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§μΌλ΅ λΉ λ¥Έ ν”„λ΅ν† νƒ€μ…\")\n",
    "    print(\"  2οΈβƒ£ μ„±λ¥ ν•κ³„ λ„λ‹¬ μ‹ νμΈνλ‹ μ μ©\")\n",
    "    print(\"  3οΈβƒ£ νμΈνλ‹λ λ¨λΈμ— ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ¶”κ°€ μ μ©\")\n",
    "    print(\"  4οΈβƒ£ RAG + νμΈνλ‹μΌλ΅ μµμ  μ„±λ¥ λ‹¬μ„±\")\n",
    "    \n",
    "    return criteria_df, use_cases\n",
    "\n",
    "# μ„ νƒ κ°€μ΄λ“ μƒμ„±\n",
    "selection_guide, use_case_examples = create_finetuning_vs_prompting_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. π—οΈ νμΈνλ‹ νμ΄ν”„λΌμΈ μ „μ²΄ κµ¬μ΅°\n",
    "\n",
    "### π“‹ μ‹¤μ  ν”„λ΅λ•μ…μ—μ„μ νμΈνλ‹ μ›ν¬ν”λ΅μ°\n",
    "\n",
    "μ „μ²΄ νμΈνλ‹ κ³Όμ •μ„ λ‹¨κ³„λ³„λ΅ μ΄ν•΄ν•΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_pipeline_overview():\n",
    "    \"\"\"\n",
    "    νμΈνλ‹ νμ΄ν”„λΌμΈ μ „μ²΄ κµ¬μ΅° μ„¤λ…\n",
    "    \"\"\"\n",
    "    \n",
    "    pipeline_stages = {\n",
    "        \"1. λ°μ΄ν„° μ¤€λΉ„\": {\n",
    "            \"μ„¤λ…\": \"κ³ ν’μ§ ν•™μµ λ°μ΄ν„° μμ§‘ λ° μ „μ²λ¦¬\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"π“ λ°μ΄ν„° μμ§‘ λ° κ²€μ¦\",\n",
    "                \"π§Ή λ°μ΄ν„° ν΄λ¦¬λ‹ λ° ν•„ν„°λ§\",\n",
    "                \"π“ ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ μ„¤κ³„\",\n",
    "                \"β‚οΈ λ°μ΄ν„° λ¶„ν•  (train/val/test)\",\n",
    "                \"π” λ°μ΄ν„° ν’μ§ κ²€μ¦\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"λ°μ΄ν„° ν’μ§κ³Ό μ–‘μ΄ μ¶©λ¶„ν•κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"νΈν–¥λ λ°μ΄ν„°, ν’μ§ λ¶λ‰, μ–‘ λ¶€μ΅±\"\n",
    "        },\n",
    "        \"2. λ¨λΈ μ„ νƒ\": {\n",
    "            \"μ„¤λ…\": \"νƒμ¤ν¬μ— μ ν•©ν• λ² μ΄μ¤ λ¨λΈ μ„ νƒ\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"π― νƒμ¤ν¬ μ ν• λ¶„μ„\",\n",
    "                \"π“ λ¨λΈ ν¬κΈ° vs μ„±λ¥ νΈλ μ΄λ“μ¤ν”„\",\n",
    "                \"π’» ν•λ“μ›¨μ–΄ μ μ•½μ‚¬ν•­ κ³ λ ¤\",\n",
    "                \"π μ–Έμ–΄ λ° λ„λ©”μΈ μ ν•©μ„± ν‰κ°€\",\n",
    "                \"π“ λΌμ΄μ„ μ¤ ν™•μΈ\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"μ„ νƒν• λ¨λΈμ΄ νƒμ¤ν¬μ™€ ν™κ²½μ— μ ν•©ν•κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"μ¤λ²„μ¤ν™, μ–Έλ”μ¤ν™, λΌμ΄μ„ μ¤ μ΄μ\"\n",
    "        },\n",
    "        \"3. PEFT κΈ°λ²• μ„ νƒ\": {\n",
    "            \"μ„¤λ…\": \"ν¨μ¨μ  νμΈνλ‹ λ°©λ²• κ²°μ •\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"β–οΈ Full vs PEFT λ°©μ‹ μ„ νƒ\",\n",
    "                \"π”§ LoRA rank μ„¤μ •\",\n",
    "                \"π“ ν•™μµ νλΌλ―Έν„° μ κ³„μ‚°\",\n",
    "                \"π’Ύ λ©”λ¨λ¦¬ μ”κµ¬λ‰ μ¶”μ •\",\n",
    "                \"π›οΈ ν•μ΄νΌνλΌλ―Έν„° μ„¤κ³„\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"λ©”λ¨λ¦¬μ™€ μ„±λ¥ μ”κµ¬μ‚¬ν•­μ„ λ§μ΅±ν•λ”κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"λ¶€μ μ ν• rank, λ©”λ¨λ¦¬ λ¶€μ΅±\"\n",
    "        },\n",
    "        \"4. ν•™μµ μ‹¤ν–‰\": {\n",
    "            \"μ„¤λ…\": \"μ‹¤μ  νμΈνλ‹ ν•™μµ κ³Όμ •\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"πƒβ€β™‚οΈ ν•™μµλ¥  μ¤μΌ€μ¤„λ§\",\n",
    "                \"π“ μ†μ‹¤ ν•¨μ λ¨λ‹ν„°λ§\",\n",
    "                \"π’Ύ μ²΄ν¬ν¬μΈνΈ μ €μ¥\",\n",
    "                \"π“ κ²€μ¦ λ°μ΄ν„° ν‰κ°€\",\n",
    "                \"β° μ΅°κΈ° μΆ…λ£ μ΅°κ±΄ ν™•μΈ\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"ν•™μµμ΄ μ•μ •μ μΌλ΅ μλ ΄ν•κ³  μλ”κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"κ³Όμ ν•©, λ°μ‚°, λ©”λ¨λ¦¬ λ¶€μ΅±\"\n",
    "        },\n",
    "        \"5. ν‰κ°€ λ° κ²€μ¦\": {\n",
    "            \"μ„¤λ…\": \"λ¨λΈ μ„±λ¥ μΆ…ν•© ν‰κ°€\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"π“ μ •λ‰μ  μ§€ν‘ μΈ΅μ •\",\n",
    "                \"π‘€ μ •μ„±μ  κ²°κ³Ό λ¶„μ„\",\n",
    "                \"β–οΈ λ² μ΄μ¤λΌμΈ λ€λΉ„ μ„±λ¥ λΉ„κµ\",\n",
    "                \"π” μ‹¤ν¨ μΌ€μ΄μ¤ λ¶„μ„\",\n",
    "                \"π§ A/B ν…μ¤νΈ μ¤€λΉ„\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"λ©ν‘ μ„±λ¥μ„ λ‹¬μ„±ν–λ”κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"κ³Όμ ν•©, μΌλ°ν™” λ¶€μ΅±, νΈν–¥\"\n",
    "        },\n",
    "        \"6. λ°°ν¬ λ° λ¨λ‹ν„°λ§\": {\n",
    "            \"μ„¤λ…\": \"ν”„λ΅λ•μ… ν™κ²½ λ°°ν¬ λ° μ΄μ\",\n",
    "            \"μ£Όμ” μ‘μ—…\": [\n",
    "                \"π€ λ¨λΈ λ°°ν¬ νμ΄ν”„λΌμΈ\",\n",
    "                \"π“ μ‹¤μ‹κ°„ μ„±λ¥ λ¨λ‹ν„°λ§\",\n",
    "                \"π”„ λ¨λΈ λ²„μ „ κ΄€λ¦¬\",\n",
    "                \"π“ μ‚¬μ©μ ν”Όλ“λ°± μμ§‘\",\n",
    "                \"π”„ μ§€μ†μ  κ°μ„  κ³„ν\"\n",
    "            ],\n",
    "            \"μ²΄ν¬ν¬μΈνΈ\": \"μ‹¤μ  ν™κ²½μ—μ„ μ•μ •μ μΌλ΅ λ™μ‘ν•λ”κ°€?\",\n",
    "            \"μΌλ°μ  λ¬Έμ \": \"μ„±λ¥ μ €ν•, λ“λ¦¬ν”„νΈ, ν™•μ¥μ„± μ΄μ\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"π—οΈ νμΈνλ‹ νμ΄ν”„λΌμΈ μ „μ²΄ κµ¬μ΅°\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for stage_name, stage_info in pipeline_stages.items():\n",
    "        print(f\"\\n{stage_name}\")\n",
    "        print(f\"π“‹ {stage_info['μ„¤λ…']}\")\n",
    "        print(f\"\\nμ£Όμ” μ‘μ—…:\")\n",
    "        for task in stage_info['μ£Όμ” μ‘μ—…']:\n",
    "            print(f\"  {task}\")\n",
    "        print(f\"\\nβ… μ²΄ν¬ν¬μΈνΈ: {stage_info['μ²΄ν¬ν¬μΈνΈ']}\")\n",
    "        print(f\"β οΈ μΌλ°μ  λ¬Έμ : {stage_info['μΌλ°μ  λ¬Έμ ']}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # μ„±κ³µμ„ μ„ν• ν•µμ‹¬ ν\n",
    "    success_tips = {\n",
    "        \"λ°μ΄ν„° ν’μ§\": \"μ–‘λ³΄λ‹¤ μ§! κ³ ν’μ§ λ°μ΄ν„° 1000κ°κ°€ μ €ν’μ§ 10000κ°λ³΄λ‹¤ λ‚«λ‹¤\",\n",
    "        \"μ μ§„μ  μ ‘κ·Ό\": \"μ‘μ€ λ¨λΈλ΅ μ‹μ‘ν•΄μ„ μ μ§„μ μΌλ΅ ν™•μ¥\",\n",
    "        \"μ²΄κ³„μ  μ‹¤ν—\": \"λ¨λ“  μ‹¤ν—μ„ κΈ°λ΅ν•κ³  μ¬ν„ κ°€λ¥ν•κ² κ΄€λ¦¬\",\n",
    "        \"μ§€μ†μ  λ¨λ‹ν„°λ§\": \"λ°°ν¬ ν›„μ—λ„ μ„±λ¥κ³Ό νΈν–¥μ„±μ„ μ§€μ†μ μΌλ΅ κ΄€μ°°\",\n",
    "        \"λ„λ©”μΈ μ „λ¬Έκ°€ ν‘μ—…\": \"κΈ°μ μ  κµ¬ν„λΏλ§ μ•„λ‹λΌ λ„λ©”μΈ μ§€μ‹ ν™μ©\"\n",
    "    }\n",
    "    \n",
    "    print(\"\\nπ― μ„±κ³µμ„ μ„ν• ν•µμ‹¬ ν:\")\n",
    "    for tip_name, tip_content in success_tips.items():\n",
    "        print(f\"  π’΅ {tip_name}: {tip_content}\")\n",
    "    \n",
    "    return pipeline_stages, success_tips\n",
    "\n",
    "# νμ΄ν”„λΌμΈ κµ¬μ΅° μ„¤λ…\n",
    "pipeline_overview, success_guidelines = create_finetuning_pipeline_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. π“ μ‹¤μ  ν”„λ΅λ•μ… μ‚¬λ΅€ μ—°κµ¬\n",
    "\n",
    "### πΆ κΈ°μ—…μ—μ„μ νμΈνλ‹ ν™μ© μ‚¬λ΅€\n",
    "\n",
    "μ‹¤μ  κΈ°μ—… ν™κ²½μ—μ„ νμΈνλ‹μ΄ μ–΄λ–»κ² ν™μ©λλ”μ§€ μ‚΄ν΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showcase_production_cases():\n",
    "    \"\"\"\n",
    "    μ‹¤μ  ν”„λ΅λ•μ… νμΈνλ‹ μ‚¬λ΅€λ“¤\n",
    "    \"\"\"\n",
    "    \n",
    "    production_cases = {\n",
    "        \"π¥ μλ£ AI μ–΄μ‹μ¤ν„΄νΈ\": {\n",
    "            \"λ°°κ²½\": \"λ€ν• λ³‘μ›μ μλ£μ§„ μ—…λ¬΄ μ§€μ› AI κ°λ°\",\n",
    "            \"λ°μ΄ν„°\": \"μλ£ λ¬Έν— 10λ§κ±΄ + μ§„λ£ κΈ°λ΅ 5λ§κ±΄ (κ°μΈμ •λ³΄ μ κ±°)\",\n",
    "            \"λ² μ΄μ¤ λ¨λΈ\": \"Llama 2 7B (μλ£ λ„λ©”μΈ μ‚¬μ „ ν•™μµ λ¨λΈ)\",\n",
    "            \"PEFT λ°©λ²•\": \"LoRA (rank=16, Ξ±=32)\",\n",
    "            \"ν•™μµ μ‹κ°„\": \"Tesla V100 4μ¥μΌλ΅ 48μ‹κ°„\",\n",
    "            \"μ„±κ³Ό\": {\n",
    "                \"μ •ν™•λ„\": \"μλ£ μ§μμ‘λ‹µ 85% β†’ 94% ν–¥μƒ\",\n",
    "                \"ν¨μ¨μ„±\": \"μλ£μ§„ λ¬Έμ„ μ‘μ—… μ‹κ°„ 40% λ‹¨μ¶•\",\n",
    "                \"μ•μ „μ„±\": \"μλ»λ μν•™ μ •λ³΄ μ κ³µλ¥  90% κ°μ†\"\n",
    "            },\n",
    "            \"μ£Όμ” λ„μ „κ³Όμ \": [\n",
    "                \"κ°μΈμ •λ³΄ λ³΄νΈ κ·μ • μ¤€μ\",\n",
    "                \"μν•™μ  μ •ν™•μ„± λ³΄μ¥\",\n",
    "                \"μ „λ¬Έ μ©μ–΄ μ •ν™•ν• μ΄ν•΄\"\n",
    "            ]\n",
    "        },\n",
    "        \"π’Ό κΈμµ λ¬Έμ„ λ¶„μ„ AI\": {\n",
    "            \"λ°°κ²½\": \"ν¬μμ€ν–‰μ λ¦¬μ„μΉ λ³΄κ³ μ„ μλ™ μƒμ„± μ‹μ¤ν…\",\n",
    "            \"λ°μ΄ν„°\": \"κΈμµ λ¦¬ν¬νΈ 50λ§κ±΄ + μ‹μ¥ λ°μ΄ν„° μ—°λ™\",\n",
    "            \"λ² μ΄μ¤ λ¨λΈ\": \"GPT-3.5 Turbo (OpenAI API)\",\n",
    "            \"PEFT λ°©λ²•\": \"Few-shot learning + Function calling\",\n",
    "            \"ν•™μµ μ‹κ°„\": \"API νμΈνλ‹ μ„λΉ„μ¤ μ΄μ© (24μ‹κ°„)\",\n",
    "            \"μ„±κ³Ό\": {\n",
    "                \"ν’μ§\": \"λ¦¬ν¬νΈ ν’μ§ μ μ 7.2/10 β†’ 8.8/10\",\n",
    "                \"μ†λ„\": \"λ¦¬ν¬νΈ μ‘μ„± μ‹κ°„ 5μΌ β†’ 2μ‹κ°„ λ‹¨μ¶•\",\n",
    "                \"λΉ„μ©\": \"λ¦¬μ„μΉ μΈλ ¥ λΉ„μ© 60% μ κ°\"\n",
    "            },\n",
    "            \"μ£Όμ” λ„μ „κ³Όμ \": [\n",
    "                \"μ‹¤μ‹κ°„ μ‹μ¥ λ°μ΄ν„° λ°μ\",\n",
    "                \"κ·μ  μ”κµ¬μ‚¬ν•­ μ¤€μ\",\n",
    "                \"μ‹μ¥ λ³€λ™μ„±μ— λ€ν• μ μ‘\"\n",
    "            ]\n",
    "        },\n",
    "        \"π›’ E-commerce μƒν’ μ¶”μ² AI\": {\n",
    "            \"λ°°κ²½\": \"λ€ν• μ‡Όν•‘λ°μ κ°μΈν™” μƒν’ μ„¤λ… μƒμ„±\",\n",
    "            \"λ°μ΄ν„°\": \"μƒν’ μ •λ³΄ 100λ§κ±΄ + μ‚¬μ©μ λ¦¬λ·° 500λ§κ±΄\",\n",
    "            \"λ² μ΄μ¤ λ¨λΈ\": \"KoAlpaca 13B (ν•κµ­μ–΄ νΉν™”)\",\n",
    "            \"PEFT λ°©λ²•\": \"LoRA (rank=8) + Adapter (μƒν’ μΉ΄ν…κ³ λ¦¬λ³„)\",\n",
    "            \"ν•™μµ μ‹κ°„\": \"RTX 4090 8μ¥μΌλ΅ 72μ‹κ°„\",\n",
    "            \"μ„±κ³Ό\": {\n",
    "                \"μ „ν™μ¨\": \"μƒν’ κµ¬λ§¤ μ „ν™μ¨ 2.3% β†’ 3.8% μƒμΉ\",\n",
    "                \"λ§μ΅±λ„\": \"κ³ κ° λ§μ΅±λ„ 4.2/5 β†’ 4.7/5 ν–¥μƒ\",\n",
    "                \"λ§¤μ¶\": \"μ›” λ§¤μ¶ 15% μ¦κ°€\"\n",
    "            },\n",
    "            \"μ£Όμ” λ„μ „κ³Όμ \": [\n",
    "                \"λ‹¤μ–‘ν• μƒν’ μΉ΄ν…κ³ λ¦¬ λ€μ‘\",\n",
    "                \"κ³„μ μ„± λ° νΈλ λ“ λ°μ\",\n",
    "                \"μ‹¤μ‹κ°„ μ¶”μ² μ‹μ¤ν… ν†µν•©\"\n",
    "            ]\n",
    "        },\n",
    "        \"π“ κµμ΅ μ½ν…μΈ  AI\": {\n",
    "            \"λ°°κ²½\": \"μ¨λΌμΈ κµμ΅ ν”λ«νΌμ λ§μ¶¤ν• ν•™μµ λ„μ°λ―Έ\",\n",
    "            \"λ°μ΄ν„°\": \"κµμ΅ μ½ν…μΈ  20λ§κ±΄ + ν•™μµμ μƒνΈμ‘μ© λ°μ΄ν„°\",\n",
    "            \"λ² μ΄μ¤ λ¨λΈ\": \"EXAONE 7.8B (ν•κµ­μ–΄ κµμ΅ λ„λ©”μΈ)\",\n",
    "            \"PEFT λ°©λ²•\": \"AdaLoRA (λ™μ  rank μ΅°μ •)\",\n",
    "            \"ν•™μµ μ‹κ°„\": \"A100 2μ¥μΌλ΅ 36μ‹κ°„\",\n",
    "            \"μ„±κ³Ό\": {\n",
    "                \"ν•™μµ ν¨κ³Ό\": \"ν•™μµμ μ΄ν•΄λ„ ν‰κ°€ μ μ 20% ν–¥μƒ\",\n",
    "                \"μ°Έμ—¬λ„\": \"μμ—… μ™„μ£Όμ¨ 65% β†’ 82% μ¦κ°€\",\n",
    "                \"κ°μΈν™”\": \"κ°λ³„ ν•™μµμ λ§μ¶¤ μ½ν…μΈ  μ κ³µλ¥  95%\"\n",
    "            },\n",
    "            \"μ£Όμ” λ„μ „κ³Όμ \": [\n",
    "                \"μ—°λ Ήλ³„ ν•™μµ μμ¤€ μ°¨μ΄ λ€μ‘\",\n",
    "                \"κµμ΅ν•™μ  ν¨κ³Όμ„± κ²€μ¦\",\n",
    "                \"λ‹¤κµ­μ–΄ μ§€μ› ν™•μ¥\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"πΆ μ‹¤μ  ν”„λ΅λ•μ… νμΈνλ‹ μ‚¬λ΅€ μ—°κµ¬\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for case_name, case_info in production_cases.items():\n",
    "        print(f\"\\n{case_name}\")\n",
    "        print(f\"π“‹ λ°°κ²½: {case_info['λ°°κ²½']}\")\n",
    "        print(f\"π“ λ°μ΄ν„°: {case_info['λ°μ΄ν„°']}\")\n",
    "        print(f\"π¤– λ² μ΄μ¤ λ¨λΈ: {case_info['λ² μ΄μ¤ λ¨λΈ']}\")\n",
    "        print(f\"β™οΈ PEFT λ°©λ²•: {case_info['PEFT λ°©λ²•']}\")\n",
    "        print(f\"β° ν•™μµ μ‹κ°„: {case_info['ν•™μµ μ‹κ°„']}\")\n",
    "        \n",
    "        print(f\"\\nπ“ μ£Όμ” μ„±κ³Ό:\")\n",
    "        for metric, value in case_info['μ„±κ³Ό'].items():\n",
    "            print(f\"  β€Ά {metric}: {value}\")\n",
    "        \n",
    "        print(f\"\\nπ§ μ£Όμ” λ„μ „κ³Όμ :\")\n",
    "        for challenge in case_info['μ£Όμ” λ„μ „κ³Όμ ']:\n",
    "            print(f\"  β€Ά {challenge}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # κ³µν†µ μ„±κ³µ μ”μΈ\n",
    "    success_factors = [\n",
    "        \"π― λ…ν™•ν• λΉ„μ¦λ‹μ¤ λ©ν‘ μ„¤μ •\",\n",
    "        \"π“ κ³ ν’μ§ λ„λ©”μΈ λ°μ΄ν„° ν™•λ³΄\",\n",
    "        \"π¤ λ„λ©”μΈ μ „λ¬Έκ°€μ™€μ λ°€μ ‘ν• ν‘μ—…\",\n",
    "        \"π“ μ²΄κ³„μ μΈ μ„±λ¥ μΈ΅μ • λ° λ¨λ‹ν„°λ§\",\n",
    "        \"π”„ μ§€μ†μ μΈ λ¨λΈ κ°μ„  λ° μ—…λ°μ΄νΈ\",\n",
    "        \"β–οΈ μ¤λ¦¬μ  AI μ‚¬μ© κ°€μ΄λ“λΌμΈ μ¤€μ\",\n",
    "        \"π›΅οΈ κ°•λ ¥ν• λ³΄μ• λ° κ°μΈμ •λ³΄ λ³΄νΈ μ²΄κ³„\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nπ― κ³µν†µ μ„±κ³µ μ”μΈ:\")\n",
    "    for factor in success_factors:\n",
    "        print(f\"  {factor}\")\n",
    "    \n",
    "    return production_cases, success_factors\n",
    "\n",
    "# ν”„λ΅λ•μ… μ‚¬λ΅€ μ†κ°\n",
    "cases, success_keys = showcase_production_cases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. π€ Day 1 μ‹¤μµ λ―Έλ¦¬λ³΄κΈ°\n",
    "\n",
    "### π“‹ μ¤λ μ§„ν–‰ν•  μ‹¤μµ λ‚΄μ©\n",
    "\n",
    "μ΄λ΅ μ„ λ°”νƒ•μΌλ΅ μ‹¤μ λ΅ μ§„ν–‰ν•  νμΈνλ‹ μ‹¤μµμ„ λ―Έλ¦¬ μ‚΄ν΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_day1_practicals():\n",
    "    \"\"\"\n",
    "    Day 1 μ‹¤μµ λ‚΄μ© λ―Έλ¦¬λ³΄κΈ°\n",
    "    \"\"\"\n",
    "    \n",
    "    practicals = {\n",
    "        \"01_dataset_preparation.ipynb\": {\n",
    "            \"μ λ©\": \"π“ κ³ ν’μ§ ν•™μµ λ°μ΄ν„°μ…‹ μ¤€λΉ„\",\n",
    "            \"λ©ν‘\": \"RAFT ν•μ‹μ ν•κµ­μ–΄ QA λ°μ΄ν„°μ…‹ κµ¬μ¶•\",\n",
    "            \"μ£Όμ” λ‚΄μ©\": [\n",
    "                \"π” λ‹¤μ–‘ν• λ„λ©”μΈμ ν•κµ­μ–΄ λ°μ΄ν„° μμ§‘\",\n",
    "                \"π§Ή λ°μ΄ν„° ν’μ§ κ²€μ¦ λ° ν΄λ¦¬λ‹\",\n",
    "                \"π“ RAFT ν”„λ΅¬ν”„νΈ ν…ν”λ¦Ώ μ μ©\",\n",
    "                \"β‚οΈ μ μ ν• κΈΈμ΄λ΅ λ°μ΄ν„° λ¶„ν• \",\n",
    "                \"π“ λ°μ΄ν„° λ¶„ν¬ λ¶„μ„ λ° μ‹κ°ν™”\"\n",
    "            ],\n",
    "            \"μ‹¤μµ μ‹κ°„\": \"45λ¶„\",\n",
    "            \"λ‚μ΄λ„\": \"μ΄κΈ‰\"\n",
    "        },\n",
    "        \"02_model_setup.ipynb\": {\n",
    "            \"μ λ©\": \"π¤– EXAONE λ¨λΈ μ„¤μ • λ° μ¤€λΉ„\",\n",
    "            \"λ©ν‘\": \"νμΈνλ‹μ„ μ„ν• λ¨λΈ ν™κ²½ κµ¬μ¶•\",\n",
    "            \"μ£Όμ” λ‚΄μ©\": [\n",
    "                \"π—οΈ EXAONE-3.0-7.8B-Instruct λ¨λΈ λ΅λ“\",\n",
    "                \"π”§ ν† ν¬λ‚μ΄μ € μ„¤μ • λ° νΉμ ν† ν° μ¶”κ°€\",\n",
    "                \"π’Ύ λ¨λΈ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μµμ ν™”\",\n",
    "                \"β™οΈ PEFT μ„¤μ • (LoRA) κµ¬μ„±\",\n",
    "                \"π§ λ¨λΈ κΈ°λ³Έ λ™μ‘ ν…μ¤νΈ\"\n",
    "            ],\n",
    "            \"μ‹¤μµ μ‹κ°„\": \"30λ¶„\",\n",
    "            \"λ‚μ΄λ„\": \"μ΄κΈ‰-μ¤‘κΈ‰\"\n",
    "        },\n",
    "        \"03_fine_tuning_with_lora.ipynb\": {\n",
    "            \"μ λ©\": \"π― LoRA κΈ°λ° ν¨μ¨μ  νμΈνλ‹\",\n",
    "            \"λ©ν‘\": \"μ‹¤μ  νμΈνλ‹ ν•™μµ κ³Όμ • μ™„μ£Ό\",\n",
    "            \"μ£Όμ” λ‚΄μ©\": [\n",
    "                \"β™οΈ LoRA ν•μ΄νΌνλΌλ―Έν„° μ„¤μ • (rank, alpha)\",\n",
    "                \"πƒβ€β™‚οΈ ν•™μµλ¥  μ¤μΌ€μ¤„λ§ λ° μµν‹°λ§μ΄μ € μ„¤μ •\",\n",
    "                \"π“ ν•™μµ μ§„ν–‰ μƒν™© μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§\",\n",
    "                \"π’Ύ μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ° κ΄€λ¦¬\",\n",
    "                \"π” ν•™μµ κ³΅μ„  λ¶„μ„ λ° ν•΄μ„\"\n",
    "            ],\n",
    "            \"μ‹¤μµ μ‹κ°„\": \"60λ¶„\",\n",
    "            \"λ‚μ΄λ„\": \"μ¤‘κΈ‰\"\n",
    "        },\n",
    "        \"04_evaluation_and_comparison.ipynb\": {\n",
    "            \"μ λ©\": \"π“ λ¨λΈ μ„±λ¥ ν‰κ°€ λ° λΉ„κµ\",\n",
    "            \"λ©ν‘\": \"νμΈνλ‹ μ „ν›„ μ„±λ¥ μ°¨μ΄ μ •λ‰μ  λ¶„μ„\",\n",
    "            \"μ£Όμ” λ‚΄μ©\": [\n",
    "                \"π“‹ λ‹¤μ–‘ν• ν‰κ°€ λ©”νΈλ¦­ μ μ©\",\n",
    "                \"π“ λ² μ΄μ¤λΌμΈ vs νμΈνλ‹ λ¨λΈ λΉ„κµ\",\n",
    "                \"π― λ„λ©”μΈλ³„ μ„±λ¥ λ¶„μ„\",\n",
    "                \"π“ μ„±λ¥ ν–¥μƒ μ”μΈ λ¶„μ„\",\n",
    "                \"π” μ‹¤ν¨ μΌ€μ΄μ¤ λ¶„μ„ λ° κ°μ„  λ°©ν–¥ λ„μ¶\"\n",
    "            ],\n",
    "            \"μ‹¤μµ μ‹κ°„\": \"45λ¶„\",\n",
    "            \"λ‚μ΄λ„\": \"μ¤‘κΈ‰\"\n",
    "        },\n",
    "        \"05_deployment_and_serving.ipynb\": {\n",
    "            \"μ λ©\": \"π€ λ¨λΈ λ°°ν¬ λ° μ„λΉ™\",\n",
    "            \"λ©ν‘\": \"νμΈνλ‹λ λ¨λΈμ μ‹¤μ  λ°°ν¬\",\n",
    "            \"μ£Όμ” λ‚΄μ©\": [\n",
    "                \"π”— Hugging Face Hub μ—…λ΅λ“\",\n",
    "                \"β΅ μ¶”λ΅  μµμ ν™” (μ–‘μν™”, μΊμ‹±)\",\n",
    "                \"π FastAPI κΈ°λ° μ„λΉ„μ¤ API κµ¬μ¶•\",\n",
    "                \"π“ μ‹¤μ‹κ°„ μ„±λ¥ λ¨λ‹ν„°λ§ μ„¤μ •\",\n",
    "                \"π”„ λ¨λΈ λ²„μ „ κ΄€λ¦¬ λ° λ΅¤λ°± μ „λµ\"\n",
    "            ],\n",
    "            \"μ‹¤μµ μ‹κ°„\": \"50λ¶„\",\n",
    "            \"λ‚μ΄λ„\": \"μ¤‘κΈ‰-κ³ κΈ‰\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"π€ Day 1 μ‹¤μµ κ³Όμ • λ―Έλ¦¬λ³΄κΈ°\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    total_time = 0\n",
    "    \n",
    "    for notebook, info in practicals.items():\n",
    "        time_minutes = int(info['μ‹¤μµ μ‹κ°„'].replace('λ¶„', ''))\n",
    "        total_time += time_minutes\n",
    "        \n",
    "        print(f\"\\nπ“– {notebook}\")\n",
    "        print(f\"π― {info['μ λ©']}\")\n",
    "        print(f\"π“‹ λ©ν‘: {info['λ©ν‘']}\")\n",
    "        print(f\"β° μ†μ”μ‹κ°„: {info['μ‹¤μµ μ‹κ°„']}\")\n",
    "        print(f\"ποΈ λ‚μ΄λ„: {info['λ‚μ΄λ„']}\")\n",
    "        \n",
    "        print(f\"\\nμ£Όμ” μ‹¤μµ λ‚΄μ©:\")\n",
    "        for content in info['μ£Όμ” λ‚΄μ©']:\n",
    "            print(f\"  {content}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"\\nβ° μ΄ μμƒ μ‹¤μµ μ‹κ°„: {total_time}λ¶„ ({total_time//60}μ‹κ°„ {total_time%60}λ¶„)\")\n",
    "    \n",
    "    # μ‹¤μµ μ¤€λΉ„μ‚¬ν•­\n",
    "    requirements = {\n",
    "        \"ν•λ“μ›¨μ–΄\": [\n",
    "            \"π–¥οΈ GPU λ©”λ¨λ¦¬ 16GB μ΄μƒ κ¶μ¥ (RTX 4090, A100 λ“±)\",\n",
    "            \"π’» RAM 32GB μ΄μƒ\",\n",
    "            \"π’½ μ €μ¥κ³µκ°„ 50GB μ΄μƒ\"\n",
    "        ],\n",
    "        \"μ†ν”„νΈμ›¨μ–΄\": [\n",
    "            \"π Python 3.8+\",\n",
    "            \"π”¥ PyTorch 2.0+\",\n",
    "            \"π¤— Transformers 4.35+\",\n",
    "            \"π“ Dataset, PEFT, Accelerate λΌμ΄λΈλ¬λ¦¬\"\n",
    "        ],\n",
    "        \"κ³„μ •\": [\n",
    "            \"π¤— Hugging Face κ³„μ • (λ¨λΈ λ‹¤μ΄λ΅λ“/μ—…λ΅λ“)\",\n",
    "            \"π“ Weights & Biases κ³„μ • (μ„ νƒμ‚¬ν•­, μ‹¤ν— μ¶”μ )\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"\\nπ› οΈ μ‹¤μµ μ¤€λΉ„μ‚¬ν•­:\")\n",
    "    for category, items in requirements.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  {item}\")\n",
    "    \n",
    "    # ν•™μµ λ©ν‘ λ‹¬μ„± μ²΄ν¬λ¦¬μ¤νΈ\n",
    "    objectives = [\n",
    "        \"β… νμΈνλ‹μ κΈ°λ³Έ κ°λ…κ³Ό μ›λ¦¬λ¥Ό μ΄ν•΄ν•λ‹¤\",\n",
    "        \"β… LoRAλ¥Ό μ΄μ©ν• ν¨μ¨μ  νμΈνλ‹μ„ μ‹¤μµν•λ‹¤\",\n",
    "        \"β… ν•κµ­μ–΄ λ„λ©”μΈ λ°μ΄ν„°λ΅ μ‹¤μ  λ¨λΈμ„ ν•™μµμ‹ν‚¨λ‹¤\",\n",
    "        \"β… νμΈνλ‹ μ „ν›„μ μ„±λ¥ μ°¨μ΄λ¥Ό μ •λ‰μ μΌλ΅ λ¶„μ„ν•λ‹¤\",\n",
    "        \"β… νμΈνλ‹λ λ¨λΈμ„ μ‹¤μ  μ„λΉ„μ¤ κ°€λ¥ν• ν•νƒλ΅ λ°°ν¬ν•λ‹¤\",\n",
    "        \"β… ν”„λ΅λ•μ… ν™κ²½μ—μ„μ κ³ λ ¤μ‚¬ν•­λ“¤μ„ μ΄ν•΄ν•λ‹¤\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nπ― Day 1 μΆ…λ£ ν›„ λ‹¬μ„± λ©ν‘:\")\n",
    "    for objective in objectives:\n",
    "        print(f\"  {objective}\")\n",
    "    \n",
    "    return practicals, requirements, objectives\n",
    "\n",
    "# Day 1 μ‹¤μµ λ―Έλ¦¬λ³΄κΈ°\n",
    "day1_preview, prep_requirements, learning_objectives = preview_day1_practicals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. π“ κ°λ… ν•™μµ μ •λ¦¬\n",
    "\n",
    "### β… ν•µμ‹¬ κ°λ… μ²΄ν¬λ¦¬μ¤νΈ\n",
    "\n",
    "μ§€κΈκΉμ§€ ν•™μµν• νμΈνλ‹ ν•µμ‹¬ κ°λ…λ“¤μ„ μ •λ¦¬ν•΄λ΄…μ‹λ‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_concept_summary_quiz():\n",
    "    \"\"\"\n",
    "    ν•™μµν• κ°λ…λ“¤μ— λ€ν• κ°„λ‹¨ν• ν€΄μ¦μ™€ μ •λ¦¬\n",
    "    \"\"\"\n",
    "    \n",
    "    # ν•µμ‹¬ κ°λ… μ²΄ν¬λ¦¬μ¤νΈ\n",
    "    concept_checklist = {\n",
    "        \"νμΈνλ‹ κΈ°λ³Έ κ°λ…\": [\n",
    "            \"μ‚¬μ „ ν›λ ¨ vs νμΈνλ‹μ μ°¨μ΄μ μ„ μ„¤λ…ν•  μ μλ‹¤\",\n",
    "            \"νμΈνλ‹μ΄ ν•„μ”ν• μƒν™©κ³Ό μ ν•©ν• νƒμ¤ν¬λ¥Ό κµ¬λ¶„ν•  μ μλ‹¤\",\n",
    "            \"Full Fine-tuningμ μ¥λ‹¨μ μ„ μ΄ν•΄ν•λ‹¤\"\n",
    "        ],\n",
    "        \"PEFT μ΄ν•΄\": [\n",
    "            \"Parameter Efficient Fine-Tuningμ ν•„μ”μ„±μ„ μ„¤λ…ν•  μ μλ‹¤\",\n",
    "            \"LoRAμ μν•™μ  μ›λ¦¬ (μ €μ°¨μ› λ¶„ν•΄)λ¥Ό μ΄ν•΄ν•λ‹¤\",\n",
    "            \"λ‹¤μ–‘ν• PEFT κΈ°λ²•λ“¤μ νΉμ§•κ³Ό μ μ© μƒν™©μ„ κµ¬λ¶„ν•  μ μλ‹¤\"\n",
    "        ],\n",
    "        \"μ‹¤λ¬΄ μ μ©\": [\n",
    "            \"νμΈνλ‹ vs ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ„ νƒ κΈ°μ¤€μ„ μ•λ‹¤\",\n",
    "            \"νμΈνλ‹ νμ΄ν”„λΌμΈμ μ „μ²΄ κ³Όμ •μ„ μ΄ν•΄ν•λ‹¤\",\n",
    "            \"ν”„λ΅λ•μ… ν™κ²½μ—μ„μ μ£Όμ” κ³ λ ¤μ‚¬ν•­μ„ νμ•…ν•λ‹¤\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"π“‹ νμΈνλ‹ ν•µμ‹¬ κ°λ… μ²΄ν¬λ¦¬μ¤νΈ\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for category, items in concept_checklist.items():\n",
    "        print(f\"\\nπ― {category}:\")\n",
    "        for item in items:\n",
    "            print(f\"  β {item}\")\n",
    "    \n",
    "    # κ°„λ‹¨ν• κ°λ… ν™•μΈ λ¬Έμ \n",
    "    quiz_questions = [\n",
    "        {\n",
    "            \"μ§λ¬Έ\": \"LoRAμ—μ„ rank κ°’μ„ λ†’μ΄λ©΄ μ–΄λ–¤ λ³€ν™”κ°€ μΌμ–΄λ‚ κΉμ”?\",\n",
    "            \"μ„ νƒμ§€\": [\n",
    "                \"A) ν•™μµ νλΌλ―Έν„° μκ°€ μ¤„μ–΄λ“ λ‹¤\",\n",
    "                \"B) ν•™μµ νλΌλ―Έν„° μκ°€ λμ–΄λ‚κ³  ν‘ν„λ ¥μ΄ μ¦κ°€ν•λ‹¤\",\n",
    "                \"C) ν•™μµ μ†λ„κ°€ λΉ¨λΌμ§„λ‹¤\",\n",
    "                \"D) λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ μ¤„μ–΄λ“ λ‹¤\"\n",
    "            ],\n",
    "            \"μ •λ‹µ\": \"B\",\n",
    "            \"ν•΄μ„¤\": \"rankκ°€ λ†’μ•„μ§€λ©΄ Aμ™€ B ν–‰λ ¬μ ν¬κΈ°κ°€ μ»¤μ Έμ„ ν•™μµ νλΌλ―Έν„°κ°€ λμ–΄λ‚κ³ , λ” λ³µμ΅ν• λ³€ν™”λ¥Ό ν‘ν„ν•  μ μμµλ‹λ‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"μ§λ¬Έ\": \"λ‹¤μ μ¤‘ νμΈνλ‹μ΄ ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§λ³΄λ‹¤ μ ν•©ν• κ²½μ°λ”?\",\n",
    "            \"μ„ νƒμ§€\": [\n",
    "                \"A) 100κ° λ―Έλ§μ μμ  λ°μ΄ν„°\",\n",
    "                \"B) μ‹¤μ‹κ°„ μ‘λ‹µμ΄ μ¤‘μ”ν• μ„λΉ„μ¤\",\n",
    "                \"C) μλ£ λ„λ©”μΈμ κ³ λ„λ΅ μ „λ¬Έν™”λ νƒμ¤ν¬\",\n",
    "                \"D) λΉ λ¥Έ ν”„λ΅ν† νƒ€μ… κ°λ°\"\n",
    "            ],\n",
    "            \"μ •λ‹µ\": \"C\",\n",
    "            \"ν•΄μ„¤\": \"μλ£μ²λΌ κ³ λ„λ΅ μ „λ¬Έν™”λκ³  μ •ν™•μ„±μ΄ μ¤‘μ”ν• λ„λ©”μΈμ—μ„λ” μ¶©λ¶„ν• λ°μ΄ν„°λ΅ νμΈνλ‹ν•λ” κ²ƒμ΄ ν¨κ³Όμ μ…λ‹λ‹¤.\"\n",
    "        },\n",
    "        {\n",
    "            \"μ§λ¬Έ\": \"PEFT κΈ°λ²•μ μ£Όμ” μ¥μ μ΄ μ•„λ‹ κ²ƒμ€?\",\n",
    "            \"μ„ νƒμ§€\": [\n",
    "                \"A) λ©”λ¨λ¦¬ ν¨μ¨μ„±\",\n",
    "                \"B) ν•™μµ μ†λ„ ν–¥μƒ\",\n",
    "                \"C) μ¬μ•™μ  λ§κ° λ°©μ§€\",\n",
    "                \"D) ν•­μƒ Full Fine-tuningλ³΄λ‹¤ λ†’μ€ μ„±λ¥\"\n",
    "            ],\n",
    "            \"μ •λ‹µ\": \"D\",\n",
    "            \"ν•΄μ„¤\": \"PEFTλ” ν¨μ¨μ„± λ©΄μ—μ„ μ¥μ μ΄ μμ§€λ§, μ„±λ¥μ€ νƒμ¤ν¬μ™€ λ°μ΄ν„°μ— λ”°λΌ Full Fine-tuningλ³΄λ‹¤ λ‚®μ„ μ μμµλ‹λ‹¤.\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\\nπ§  κ°λ… ν™•μΈ ν€΄μ¦\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, q in enumerate(quiz_questions, 1):\n",
    "        print(f\"\\nβ“ λ¬Έμ  {i}: {q['μ§λ¬Έ']}\")\n",
    "        for choice in q['μ„ νƒμ§€']:\n",
    "            print(f\"   {choice}\")\n",
    "        print(f\"\\nπ’΅ μ •λ‹µ: {q['μ •λ‹µ']}\")\n",
    "        print(f\"π“ ν•΄μ„¤: {q['ν•΄μ„¤']}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    # λ‹¤μ λ‹¨κ³„ μ¤€λΉ„\n",
    "    next_steps = [\n",
    "        \"π› οΈ κ°λ° ν™κ²½ μ„¤μ • (GPU, Python, λΌμ΄λΈλ¬λ¦¬)\",\n",
    "        \"π¤— Hugging Face κ³„μ • μƒμ„± λ° ν† ν° μ„¤μ •\",\n",
    "        \"π“ μ‹¤μµμ© λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“ μ¤€λΉ„\",\n",
    "        \"π” EXAONE λ¨λΈ λ¬Έμ„ λ° μ‚¬μ©λ²• μ™μ§€\",\n",
    "        \"β™οΈ LoRA ν•μ΄νΌνλΌλ―Έν„° μ‹¤ν— κ³„ν μλ¦½\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nπ€ μ‹¤μµ μ „ μ¤€λΉ„ν•  κ²ƒλ“¤:\")\n",
    "    for step in next_steps:\n",
    "        print(f\"  {step}\")\n",
    "    \n",
    "    return concept_checklist, quiz_questions, next_steps\n",
    "\n",
    "# κ°λ… μ •λ¦¬ λ° ν€΄μ¦\n",
    "checklist, quiz, preparation_steps = create_concept_summary_quiz()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"π― νμΈνλ‹ κ°λ… ν•™μµ μ™„λ£!\")\n",
    "print(\"μ΄μ  μ‹¤μ  μ‹¤μµμΌλ΅ λ„μ–΄κ°€μ„ μ΄λ΅ μ„ μ½”λ“λ΅ κµ¬ν„ν•΄λ³΄κ² μµλ‹λ‹¤.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## π‰ κ°λ… ν•™μµ μ™„λ£!\n",
    "\n",
    "### π“ μ¶•ν•ν•©λ‹λ‹¤!\n",
    "\n",
    "νμΈνλ‹μ ν•µμ‹¬ κ°λ…λ“¤μ„ μ„±κ³µμ μΌλ΅ ν•™μµν•μ…¨μµλ‹λ‹¤:\n",
    "\n",
    "β… **νμΈνλ‹ κΈ°λ³Έ μ›λ¦¬** - μ‚¬μ „ ν›λ ¨ λ¨λΈμ„ νΉμ • νƒμ¤ν¬μ— λ§κ² μ΅°μ •ν•λ” λ°©λ²•  \n",
    "β… **LoRA μ΄ν•΄** - ν¨μ¨μ μΈ μ €μ°¨μ› λ¶„ν•΄ κΈ°λ° νλΌλ―Έν„° μ—…λ°μ΄νΈ  \n",
    "β… **PEFT κΈ°λ²• λΉ„κµ** - λ‹¤μ–‘ν• ν¨μ¨μ  νμΈνλ‹ λ°©λ²•λ“¤μ νΉμ§•  \n",
    "β… **μ‹¤λ¬΄ μ μ©** - ν”„λ΅λ•μ… ν™κ²½μ—μ„μ κ³ λ ¤μ‚¬ν•­κ³Ό μ„ νƒ κΈ°μ¤€  \n",
    "\n",
    "### π€ λ‹¤μ λ‹¨κ³„: μ‹¤μµ\n",
    "\n",
    "μ΄μ  λ°°μ΄ κ°λ…λ“¤μ„ μ‹¤μ  μ½”λ“λ΅ κµ¬ν„ν•΄λ³΄κ² μµλ‹λ‹¤!\n",
    "\n",
    "**π“ λ‹¤μ μ‹¤μµ λ…ΈνΈλ¶:**\n",
    "- `01_dataset_preparation.ipynb` - κ³ ν’μ§ ν•κµ­μ–΄ λ°μ΄ν„°μ…‹ μ¤€λΉ„\n",
    "- `02_model_setup.ipynb` - EXAONE λ¨λΈ μ„¤μ •\n",
    "- `03_fine_tuning_with_lora.ipynb` - μ‹¤μ  νμΈνλ‹ μ‹¤ν–‰\n",
    "- `04_evaluation_and_comparison.ipynb` - μ„±λ¥ ν‰κ°€\n",
    "- `05_deployment_and_serving.ipynb` - λ¨λΈ λ°°ν¬\n",
    "\n",
    "**π’ μ—¬λ¬λ¶„μ΄ λ§λ“¤ κ²°κ³Όλ¬Ό:**\n",
    "- ν•κµ­μ–΄ λ„λ©”μΈμ— νΉν™”λ κ³ μ„±λ¥ μ–Έμ–΄ λ¨λΈ\n",
    "- Hugging Faceμ— μ—…λ΅λ“λ λ‚λ§μ νμΈνλ‹ λ¨λΈ\n",
    "- μ‹¤μ  μ„λΉ„μ¤ κ°€λ¥ν• API μ—”λ“ν¬μΈνΈ\n",
    "\n",
    "**π― μµμΆ… λ©ν‘:**\n",
    "μ—¬λ¬λ¶„μ νμΈνλ‹ λ¨λΈμ€ Day 2-3μ RAGμ™€ Advanced RAG μ‹¤μµμ—μ„λ„ κ³„μ† ν™μ©λ©λ‹λ‹¤!\n",
    "\n",
    "---\n",
    "\n",
    "*\"μ΄λ΅ μ€ μ‹μ‘μ— λ¶κ³Όν•λ‹¤. μ‹¤μµμ—μ„ μ§„μ •ν• λ°°μ›€μ΄ μΌμ–΄λ‚λ‹¤.\"* π€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}