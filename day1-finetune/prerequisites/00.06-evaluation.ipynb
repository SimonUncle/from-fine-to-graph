{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1-00.06: ëª¨ë¸ í‰ê°€ ê°œë… ì •ë¦¬\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **ëª©ì—… ë°ì´í„°**ë¡œ í‰ê°€ ì§€í‘œ ê³„ì‚° íë¦„ë§Œ ì—°ìŠµí•©ë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ ì‘ë‹µì„ ë„£ì–´ í‰ê°€í•˜ê³  ì‹¶ë‹¤ë©´ main-practice/04 ë…¸íŠ¸ë¶ì„ ì°¸ì¡°í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. í‰ê°€ì— ì‚¬ìš©í•  ì˜ˆì‹œ ë°ì´í„°\n",
    "- ì§ˆë¬¸/ì •ë‹µ(Reference)ê³¼ ê¸°ì¤€ ëª¨ë¸/LoRA ëª¨ë¸ ë‹µë³€ì´ ì¤€ë¹„ë¼ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "- ì‹¤ì œ ëª¨ë¸ ì‘ë‹µì„ ì–»ì—ˆë‹¤ë©´ ì´ ë°ì´í„° ëŒ€ì‹  ë™ì¼í•œ êµ¬ì¡°ë¡œ êµì²´í•˜ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_data = [\n",
    "    {\n",
    "        \"question\": \"ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"reference\": \"ì¸ê³µì§€ëŠ¥ì€ ë°ì´í„°ë¥¼ í•™ìŠµí•´ íŒ¨í„´ì„ ì°¾ê³  ì˜ì‚¬ê²°ì •ì„ ìë™í™”í•˜ëŠ” ì»´í“¨í„° ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "        \"baseline_answer\": \"ì¸ê³µì§€ëŠ¥ì€ ì‚¬ëŒì´ ë§Œë“  ê·œì¹™ì„ ì‹¤í–‰í•˜ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.\",\n",
    "        \"lora_answer\": \"ì¸ê³µì§€ëŠ¥ì€ ë°ì´í„°ë¥¼ í•™ìŠµí•´ ìŠ¤ìŠ¤ë¡œ íŒ¨í„´ì„ ì°¾ì•„ ì˜ì‚¬ê²°ì •ì„ ë•ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ì§ˆë¬¸: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€?\",\n",
    "        \"reference\": \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì‚¬ëŒì´ íŠ¹ì§•ì„ ì •ì˜í•œ ë’¤ í•™ìŠµì‹œí‚¤ê³ , ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì´ íŠ¹ì§• ì¶”ì¶œê¹Œì§€ í•¨ê»˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.\",\n",
    "        \"baseline_answer\": \"ë¨¸ì‹ ëŸ¬ë‹ì€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ë”¥ëŸ¬ë‹ì€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\",\n",
    "        \"lora_answer\": \"ë¨¸ì‹ ëŸ¬ë‹ì€ ì‚¬ëŒì´ íŠ¹ì§•ì„ ì„¤ê³„í•˜ê³ , ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì´ íŠ¹ì§• ì¶”ì¶œê¹Œì§€ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"ì§ˆë¬¸: ìì—°ì–´ ì²˜ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "        \"reference\": \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ìƒì„±í•˜ë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "        \"baseline_answer\": \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì–¸ì–´ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "        \"lora_answer\": \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ìƒì„±í•˜ë„ë¡ ë•ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì…ë‹ˆë‹¤.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "pd.DataFrame(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ ì •ì˜\n",
    "- **ROUGE-1**: ë‹¨ì–´ ì¤‘ë³µ ê¸°ë°˜ ë¦¬ì½œ\n",
    "- **BLEU**: n-ê·¸ë¨ ì •ë°€ë„ ê¸°ë°˜ ì ìˆ˜ (ë‹¨ìˆœ 1~4ê·¸ë¨ êµ¬í˜„)\n",
    "- **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**: ë‹¨ì–´ ë¹ˆë„ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•´ ê°ë„ë¥¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOKEN_PATTERN = re.compile(r\"[\\wê°€-í£]+\", re.UNICODE)\n",
    "\n",
    "def tokenize(text):\n",
    "    return TOKEN_PATTERN.findall(text.lower())\n",
    "\n",
    "\n",
    "def compute_rouge1(reference, candidate):\n",
    "    ref_tokens = tokenize(reference)\n",
    "    cand_tokens = tokenize(candidate)\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "    overlap = 0\n",
    "    for token in cand_tokens:\n",
    "        if ref_counts[token] > 0:\n",
    "            overlap += 1\n",
    "            ref_counts[token] -= 1\n",
    "    return overlap / len(ref_tokens) if ref_tokens else 0.0\n",
    "\n",
    "\n",
    "def compute_bleu(reference, candidate):\n",
    "    ref_tokens = tokenize(reference)\n",
    "    cand_tokens = tokenize(candidate)\n",
    "    if not cand_tokens:\n",
    "        return 0.0\n",
    "\n",
    "    precisions = []\n",
    "    for n in range(1, 5):\n",
    "        ref_ngrams = Counter(tuple(ref_tokens[i:i+n]) for i in range(len(ref_tokens) - n + 1))\n",
    "        cand_ngrams = Counter(tuple(cand_tokens[i:i+n]) for i in range(len(cand_tokens) - n + 1))\n",
    "        if len(cand_ngrams) == 0:\n",
    "            precisions.append(0.0)\n",
    "            continue\n",
    "        overlap = 0\n",
    "        for ngram, count in cand_ngrams.items():\n",
    "            overlap += min(count, ref_ngrams.get(ngram, 0))\n",
    "        precisions.append(overlap / sum(cand_ngrams.values()))\n",
    "\n",
    "    if any(p == 0 for p in precisions):\n",
    "        geo_mean = 0.0\n",
    "    else:\n",
    "        geo_mean = math.exp(sum(math.log(p) for p in precisions) / 4)\n",
    "\n",
    "    ref_len = len(ref_tokens)\n",
    "    cand_len = len(cand_tokens)\n",
    "    if cand_len == 0:\n",
    "        bp = 0.0\n",
    "    elif cand_len > ref_len:\n",
    "        bp = 1.0\n",
    "    else:\n",
    "        bp = math.exp(1 - ref_len / cand_len)\n",
    "\n",
    "    return bp * geo_mean\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(reference, candidate):\n",
    "    ref_tokens = tokenize(reference)\n",
    "    cand_tokens = tokenize(candidate)\n",
    "    vocab = set(ref_tokens) | set(cand_tokens)\n",
    "    if not vocab:\n",
    "        return 0.0\n",
    "\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "    cand_counts = Counter(cand_tokens)\n",
    "    dot = sum(ref_counts[token] * cand_counts[token] for token in vocab)\n",
    "    ref_norm = math.sqrt(sum(count * count for count in ref_counts.values()))\n",
    "    cand_norm = math.sqrt(sum(count * count for count in cand_counts.values()))\n",
    "    if ref_norm == 0 or cand_norm == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return dot / (ref_norm * cand_norm)\n",
    "\n",
    "print(\"âœ… í‰ê°€ ì§€í‘œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ê¸°ì¤€ ëª¨ë¸ê³¼ LoRA ëª¨ë¸ ì ìˆ˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for row in sample_data:\n",
    "    reference = row[\"reference\"]\n",
    "    baseline = row[\"baseline_answer\"]\n",
    "    lora = row[\"lora_answer\"]\n",
    "\n",
    "    results.append({\n",
    "        \"ì§ˆë¬¸\": row[\"question\"],\n",
    "        \"ê¸°ì¤€ ROUGE-1\": compute_rouge1(reference, baseline),\n",
    "        \"LoRA ROUGE-1\": compute_rouge1(reference, lora),\n",
    "        \"ê¸°ì¤€ BLEU\": compute_bleu(reference, baseline),\n",
    "        \"LoRA BLEU\": compute_bleu(reference, lora),\n",
    "        \"ê¸°ì¤€ ì½”ì‚¬ì¸\": compute_cosine_similarity(reference, baseline),\n",
    "        \"LoRA ì½”ì‚¬ì¸\": compute_cosine_similarity(reference, lora),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).round(3)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. í‰ê·  ì ìˆ˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"ROUGE-1\", \"BLEU\", \"ì½”ì‚¬ì¸ ìœ ì‚¬ë„\"],\n",
    "    \"Baseline\": [\n",
    "        results_df[\"ê¸°ì¤€ ROUGE-1\"].mean(),\n",
    "        results_df[\"ê¸°ì¤€ BLEU\"].mean(),\n",
    "        results_df[\"ê¸°ì¤€ ì½”ì‚¬ì¸\"].mean(),\n",
    "    ],\n",
    "    \"LoRA\": [\n",
    "        results_df[\"LoRA ROUGE-1\"].mean(),\n",
    "        results_df[\"LoRA BLEU\"].mean(),\n",
    "        results_df[\"LoRA ì½”ì‚¬ì¸\"].mean(),\n",
    "    ],\n",
    "}).round(3)\n",
    "\n",
    "display(metric_summary)\n",
    "\n",
    "for metric, delta in zip(metric_summary[\"Metric\"], metric_summary[\"LoRA\"] - metric_summary[\"Baseline\"]):\n",
    "    arrow = \"ğŸ”¼\" if delta > 0 else (\"ğŸ”½\" if delta < 0 else \"â–\")\n",
    "    print(f\"{arrow} {metric}: {delta:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ê²°ê³¼ í•´ì„ ë° ì‹¤ì œ ì ìš© ë°©ë²•\n",
    "- ì˜ˆì‹œì—ì„œëŠ” LoRA ë‹µë³€ì´ ê¸°ì¤€ ëª¨ë¸ë³´ë‹¤ ëª¨ë“  ì§€í‘œì—ì„œ ë” ë†’ë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì‹¤ì œ í‰ê°€ë¥¼ í•˜ë ¤ë©´ `sample_data` ëŒ€ì‹  **ëª¨ë¸ì´ ìƒì„±í•œ ì‘ë‹µ**ì„ ë„£ì–´ ë™ì¼í•œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "- ì¶”ê°€ ì§€í‘œê°€ í•„ìš”í•˜ë©´ METEOR, BERTScore ë“±ë„ ê°™ì€ êµ¬ì¡°ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë§ˆë¬´ë¦¬\n",
    "- ê°œë… ì´í•´ê°€ ëë‚¬ë‹¤ë©´ main-practice/04 ë…¸íŠ¸ë¶ì—ì„œ ì‹¤ì œ LoRA ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ í‰ê°€ ì§€í‘œë¥¼ ê³„ì‚°í•´ ë³´ì„¸ìš”.\n",
    "- ëª¨ë¸ ë¡œë“œ ë° ì§„ì§œ ì‘ë‹µ ìƒì„±ì€ main-practice/03 + 04, ì´ ë…¸íŠ¸ë¶ì€ â€œì§€í‘œ ê³„ì‚° íë¦„â€ì„ ìµíˆëŠ” ìš©ë„ì…ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}