{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔄 Day 1-00.03: RAFT 전처리하기 (초보자용)\n",
        "\n",
        "## 🎯 이번 노트북에서 할 일\n",
        "- **RAFT 방법론** 이해하기\n",
        "- **Distractor Documents** 포함한 훈련 데이터 생성\n",
        "- **데이터를 파인튜닝용으로 변환**하기\n",
        "- **최종 데이터 저장**하기\n",
        "\n",
        "## 💡 RAFT란?\n",
        "**Retrieval Augmented Fine Tuning**의 줄임말로, 도메인 특화 RAG 성능을 향상시키는 파인튜닝 기법입니다.\n",
        "\n",
        "### 🔧 RAFT의 핵심 아이디어\n",
        "1. **\"Open Book\" 시험**에 비유: 모델이 문서를 참조하면서 답변\n",
        "2. **Distractor Documents**: 관련 없는 방해 요소 문서들을 무시하도록 학습\n",
        "3. **올바른 시퀀스 인용**: 관련 문서에서 직접 인용하여 답변 생성\n",
        "4. **도메인 특화 지식**: 특정 도메인의 문서 집합에 특화된 학습\n",
        "\n",
        "### 🎯 RAFT의 목적\n",
        "- **문서 필터링**: 관련 있는 문서와 관련 없는 문서를 구분\n",
        "- **인용 기반 답변**: 관련 문서에서 직접 인용하여 정확한 답변 생성\n",
        "- **도메인 적응**: 특정 도메인의 문서 집합에 특화된 RAG 성능 향상\n",
        "\n",
        "### 📝 RAFT 훈련 데이터 예시\n",
        "```\n",
        "질문: 인공지능이란 무엇인가요?\n",
        "\n",
        "문서 1: 인공지능(AI)은 컴퓨터가 인간의 지능을 모방하는 기술입니다. [관련 문서]\n",
        "문서 2: 요리는 재료를 조리하여 맛있는 음식을 만드는 기술입니다. [Distractor]\n",
        "문서 3: 자동차는 바퀴가 달린 교통수단입니다. [Distractor]\n",
        "\n",
        "답변: 인공지능(AI)은 컴퓨터가 인간의 지능을 모방하는 기술입니다. [문서 1에서 인용]\n",
        "```\n",
        "\n",
        "1️⃣ RAFT의 기본 아이디어\n",
        "\n",
        "RAG(Retrieval-Augmented Generation)는 질문 → 검색된 문서(context) → 답변 흐름을 전제로 하죠.\n",
        "\n",
        "하지만 실제 서비스 환경에서는 항상 “좋은 문서”가 검색되는 게 아닙니다.\n",
        "\n",
        "관련 문서가 전혀 안 잡히거나,\n",
        "\n",
        "잡히긴 했지만 엉뚱한 내용만 있을 수 있습니다.\n",
        "\n",
        "그래서 RAFT 학습 시에는 “관련 문서가 없는 경우에도 어떻게 답할지”를 모델이 경험하게 합니다.\n",
        "\n",
        "2️⃣ 왜 관련 문서 없이도 답을 주게 만드나?\n",
        "\n",
        "현실적 시뮬레이션\n",
        "\n",
        "실제 운영 환경에서 retriever가 실패할 확률은 꽤 높습니다.\n",
        "\n",
        "이때 모델이 “모르겠습니다”라고 하든, 또는 일반 지식으로 답변을 보완하든 일관된 행동을 해야 합니다.\n",
        "\n",
        "모델의 fallback 전략 학습\n",
        "\n",
        "모델이 context에 전적으로 의존하게만 학습하면 → 문서가 없을 때 완전히 무력화됩니다.\n",
        "\n",
        "그래서 “문서가 없으면 일반 지식으로 답하기” 또는 “문서가 없으면 모른다고 말하기” 중 하나를 학습시키는 겁니다.\n",
        "\n",
        "Hallucination 제어\n",
        "\n",
        "관련 없는 문서가 들어왔을 때도 억지로 맞춰서 답하는 대신,\n",
        "\n",
        "“이 문서는 질문과 관련이 없습니다. 따라서 답변할 수 없습니다.”라는 식으로 행동하도록 fine-tuning 합니다.\n",
        "\n",
        "3️⃣ 샘플링 방식 (간단 예시)\n",
        "\n",
        "Positive sample: 관련 문서 + 질문 + 정답\n",
        "\n",
        "Negative sample: 무관한 문서 + 질문 + (정답 or “없음”)\n",
        "\n",
        "No-context sample: 문서 없이 질문만 + 정답\n",
        "\n",
        "이렇게 섞어서 학습시키면,\n",
        "\n",
        "모델은 문서가 있을 때는 근거를 활용하고,\n",
        "\n",
        "문서가 없거나 무관할 때는 fallback 동작(“없음” 또는 일반 지식 활용)을 익히게 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 필요한 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAFT 전처리에 필요한 라이브러리들을 불러옵니다\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset, load_from_disk\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ RAFT 전처리 라이브러리가 준비되었습니다!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 이전 단계에서 저장한 데이터 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 이전 단계에서 저장한 데이터를 불러옵니다\n",
        "print(\"📥 이전 단계 데이터를 불러오는 중...\")\n",
        "\n",
        "# 데이터셋 불러오기\n",
        "dataset = load_from_disk(\"data/rag_dataset\")\n",
        "\n",
        "# 통계 정보 불러오기\n",
        "with open(\"data/dataset_stats.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    stats = json.load(f)\n",
        "\n",
        "print(f\"✅ 데이터 로드 완료!\")\n",
        "print(f\"📊 총 데이터 개수: {len(dataset):,}개\")\n",
        "print(f\"📝 평균 질문 길이: {stats['avg_question_length']:.1f} 글자\")\n",
        "print(f\"💬 평균 답변 길이: {stats['avg_answer_length']:.1f} 글자\")\n",
        "print(f\"📄 평균 문서 개수: {stats['avg_context_count']:.1f}개\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. RAFT 템플릿 만들기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RAFT 훈련 데이터를 생성하는 함수들\n",
        "import random\n",
        "\n",
        "def create_raft_training_sample(question, answer, context, all_contexts, num_distractors=2):\n",
        "    \"\"\"\n",
        "    RAFT 훈련 샘플 생성: 관련 문서 + Distractor 문서들 + 인용 기반 답변\n",
        "    \n",
        "    Args:\n",
        "        question: 사용자 질문\n",
        "        answer: 정답\n",
        "        context: 관련 문서 (문자열)\n",
        "        all_contexts: 전체 데이터의 모든 문서들\n",
        "        num_distractors: Distractor 문서 개수\n",
        "    \n",
        "    Returns:\n",
        "        RAFT 훈련 샘플 딕셔너리\n",
        "    \"\"\"\n",
        "    # 관련 문서는 이미 하나의 문자열\n",
        "    relevant_doc = context\n",
        "    \n",
        "    # Distractor 문서 선택 (현재 문서와 다른 것들)\n",
        "    distractor_docs = []\n",
        "    for ctx in all_contexts:\n",
        "        if ctx != relevant_doc and len(distractor_docs) < num_distractors:\n",
        "            distractor_docs.append(ctx)\n",
        "    \n",
        "    # 모든 문서 결합 (관련 문서 + Distractor 문서)\n",
        "    all_docs = [relevant_doc] + distractor_docs\n",
        "    random.shuffle(all_docs)  # 문서 순서를 랜덤하게 섞기\n",
        "    \n",
        "    # 문서들을 하나의 컨텍스트로 결합\n",
        "    context_text = \"\\n\\n\".join(all_docs)\n",
        "    \n",
        "    # 인용 기반 답변 생성 (간단한 예시)\n",
        "    # 실제로는 관련 문서에서 직접 인용해야 함\n",
        "    cited_answer = f\"{answer} [관련 문서에서 인용]\"\n",
        "    \n",
        "    # RAFT 훈련 템플릿\n",
        "    text = f\"질문: {question}\\n\\n문서들:\\n{context_text}\\n\\n답변: {cited_answer}\"\n",
        "    \n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"question\": question,\n",
        "        \"answer\": cited_answer,\n",
        "        \"relevant_doc\": relevant_doc,\n",
        "        \"distractor_docs\": distractor_docs,\n",
        "        \"all_docs\": all_docs\n",
        "    }\n",
        "\n",
        "# 테스트해보기\n",
        "print(\"🧪 RAFT 훈련 샘플 생성 테스트:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 첫 번째 샘플로 테스트\n",
        "sample = dataset[0]\n",
        "print(\"원본 데이터:\")\n",
        "print(f\"질문: {sample['question']}\")\n",
        "print(f\"답변: {sample['answer'][:100]}...\")\n",
        "print(f\"관련 문서 개수: {len(sample['context'])}\")\n",
        "print(f\"context 타입: {type(sample['context'])}\")\n",
        "\n",
        "# context가 문자열인지 확인\n",
        "if isinstance(sample['context'], str):\n",
        "    print(f\"\\n📝 Context는 문자열입니다. 길이: {len(sample['context'])}\")\n",
        "    print(f\"문자열 미리보기: {sample['context'][:200]}...\")\n",
        "elif isinstance(sample['context'], list):\n",
        "    print(f\"\\n📝 Context는 리스트입니다. 항목 수: {len(sample['context'])}\")\n",
        "    if sample['context']:\n",
        "        print(f\"첫 번째 항목: {sample['context'][0][:100]}...\")\n",
        "\n",
        "# 모든 문서 수집 (Distractor 생성을 위해)\n",
        "print(f\"\\n📚 모든 문서 수집 중...\")\n",
        "all_contexts = []\n",
        "for item in dataset:\n",
        "    context = item['context']\n",
        "    if isinstance(context, str):\n",
        "        all_contexts.append(context)\n",
        "    elif isinstance(context, list):\n",
        "        if context and isinstance(context[0], str):\n",
        "            all_contexts.extend(context)\n",
        "        else:\n",
        "            all_contexts.append(\"\".join(context))\n",
        "\n",
        "print(f\"총 수집된 문서 개수: {len(all_contexts):,}개\")\n",
        "\n",
        "# RAFT 훈련 샘플 생성\n",
        "raft_sample = create_raft_training_sample(\n",
        "    sample['question'], \n",
        "    sample['answer'], \n",
        "    sample['context'],\n",
        "    all_contexts,\n",
        "    num_distractors=2\n",
        ")\n",
        "\n",
        "print(f\"\\n🎯 RAFT 훈련 샘플:\")\n",
        "print(f\"관련 문서: 1개\")\n",
        "print(f\"Distractor 문서 개수: {len(raft_sample['distractor_docs'])}\")\n",
        "print(f\"전체 문서 개수: {len(raft_sample['all_docs'])}\")\n",
        "print(f\"관련 문서 미리보기: {raft_sample['relevant_doc'][:200]}...\")\n",
        "print(f\"Distractor 문서 미리보기: {raft_sample['distractor_docs'][0][:200]}...\")\n",
        "print(f\"전체 내용: {raft_sample['text'][:500]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 전체 데이터를 RAFT 형식으로 변환하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전체 데이터를 RAFT 형식으로 변환합니다 (Distractor Documents 포함!)\n",
        "print(\"🔄 전체 데이터를 RAFT 형식으로 변환하는 중...\")\n",
        "\n",
        "# 모든 문서를 수집 (Distractor 생성을 위해)\n",
        "print(\"📚 모든 문서 수집 중...\")\n",
        "all_contexts = []\n",
        "for item in tqdm(dataset, desc=\"문서 수집\"):\n",
        "    context = item['context']\n",
        "    if isinstance(context, str):\n",
        "        all_contexts.append(context)\n",
        "    else:\n",
        "        # 리스트인 경우 문자열로 합치기\n",
        "        all_contexts.append(\"\".join(context))\n",
        "\n",
        "print(f\"✅ 총 {len(all_contexts):,}개의 문서 수집 완료!\")\n",
        "\n",
        "# 변환된 데이터를 저장할 리스트\n",
        "raft_data = []\n",
        "\n",
        "# 진행 상황을 보여주는 프로그레스 바로 변환\n",
        "for i, sample in enumerate(tqdm(dataset, desc=\"RAFT 훈련 샘플 생성\")):\n",
        "    # RAFT 훈련 샘플 생성 (관련 문서 + Distractor 문서 + 인용 답변)\n",
        "    raft_sample = create_raft_training_sample(\n",
        "        sample['question'],\n",
        "        sample['answer'], \n",
        "        sample['context'],\n",
        "        all_contexts,\n",
        "        num_distractors=2  # Distractor 문서 2개 추가\n",
        "    )\n",
        "    raft_data.append(raft_sample)\n",
        "\n",
        "print(f\"✅ RAFT 훈련 샘플 생성 완료!\")\n",
        "print(f\"📊 생성된 샘플 개수: {len(raft_data):,}개\")\n",
        "\n",
        "# 샘플 확인\n",
        "print(f\"\\n🔍 생성된 RAFT 샘플 예시:\")\n",
        "print(f\"내용: {raft_data[0]['text'][:300]}...\")\n",
        "print(f\"관련 문서: 1개\")\n",
        "print(f\"Distractor 문서: {len(raft_data[0]['distractor_docs'])}개\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 변환된 데이터 통계 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 변환된 RAFT 데이터의 통계를 확인해봅시다\n",
        "print(\"📊 RAFT 훈련 데이터 통계:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 텍스트 길이 분석\n",
        "text_lengths = [len(item['text']) for item in raft_data]\n",
        "\n",
        "print(f\"📝 텍스트 길이 분석:\")\n",
        "print(f\"   평균: {np.mean(text_lengths):.1f} 글자\")\n",
        "print(f\"   최소: {np.min(text_lengths)} 글자\")\n",
        "print(f\"   최대: {np.max(text_lengths)} 글자\")\n",
        "\n",
        "# 문서 개수 분석\n",
        "distractor_doc_counts = [len(item['distractor_docs']) for item in raft_data]\n",
        "total_doc_counts = [len(item['all_docs']) for item in raft_data]\n",
        "\n",
        "print(f\"\\n📄 문서 개수 분석:\")\n",
        "print(f\"   관련 문서: 1개 (고정)\")\n",
        "print(f\"   평균 Distractor 문서: {np.mean(distractor_doc_counts):.1f}개\")\n",
        "print(f\"   평균 전체 문서: {np.mean(total_doc_counts):.1f}개\")\n",
        "\n",
        "# 길이 분포 확인\n",
        "short_texts = sum(1 for length in text_lengths if length < 1000)\n",
        "medium_texts = sum(1 for length in text_lengths if 1000 <= length < 2000)\n",
        "long_texts = sum(1 for length in text_lengths if length >= 2000)\n",
        "\n",
        "print(f\"\\n📏 길이별 분포:\")\n",
        "print(f\"   짧은 텍스트 (<1000자): {short_texts:,}개 ({short_texts/len(raft_data)*100:.1f}%)\")\n",
        "print(f\"   중간 텍스트 (1000-2000자): {medium_texts:,}개 ({medium_texts/len(raft_data)*100:.1f}%)\")\n",
        "print(f\"   긴 텍스트 (≥2000자): {long_texts:,}개 ({long_texts/len(raft_data)*100:.1f}%)\")\n",
        "\n",
        "# 샘플 확인\n",
        "print(f\"\\n🔍 RAFT 샘플 예시:\")\n",
        "sample = raft_data[0]\n",
        "print(f\"   질문: {sample['question']}\")\n",
        "print(f\"   관련 문서: 1개\")\n",
        "print(f\"   Distractor 문서 개수: {len(sample['distractor_docs'])}\")\n",
        "print(f\"   전체 문서 개수: {len(sample['all_docs'])}\")\n",
        "print(f\"   답변: {sample['answer']}\")\n",
        "print(f\"   텍스트 길이: {len(sample['text'])} 글자\")\n",
        "print(f\"   관련 문서 미리보기: {sample['relevant_doc'][:200]}...\")\n",
        "print(f\"   전체 내용 미리보기: {sample['text'][:300]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 파인튜닝용 데이터셋으로 변환하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hugging Face Dataset 형식으로 변환합니다\n",
        "print(\"🔄 파인튜닝용 데이터셋으로 변환하는 중...\")\n",
        "\n",
        "# RAFT 데이터를 Hugging Face Dataset으로 변환\n",
        "raft_dataset = Dataset.from_list(raft_data)\n",
        "\n",
        "print(f\"✅ 데이터셋 변환 완료!\")\n",
        "print(f\"📊 최종 데이터셋 정보:\")\n",
        "print(f\"   - 데이터 개수: {len(raft_dataset):,}개\")\n",
        "print(f\"   - 필드: {list(raft_dataset.features.keys())}\")\n",
        "print(f\"   - 첫 번째 샘플 키: {list(raft_dataset[0].keys())}\")\n",
        "\n",
        "# 데이터셋 구조 확인\n",
        "print(f\"\\n🔍 데이터셋 구조:\")\n",
        "print(f\"   - text: {raft_dataset.features['text']}\")\n",
        "print(f\"   - question: {raft_dataset.features['question']}\")\n",
        "print(f\"   - answer: {raft_dataset.features['answer']}\")\n",
        "print(f\"   - relevant_doc: {raft_dataset.features['relevant_doc']}\")\n",
        "print(f\"   - distractor_docs: {raft_dataset.features['distractor_docs']}\")\n",
        "print(f\"   - all_docs: {raft_dataset.features['all_docs']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 최종 데이터 저장하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 변환된 RAFT 데이터를 저장합니다\n",
        "print(\"💾 RAFT 훈련 데이터를 저장하는 중...\")\n",
        "\n",
        "# 1. RAFT 데이터셋 저장 (다음 단계에서 사용)\n",
        "raft_dataset.save_to_disk(\"data/raft_dataset\")\n",
        "\n",
        "# 2. 통계 정보 저장 (NumPy 타입을 Python 기본 타입으로 변환)\n",
        "raft_stats = {\n",
        "    \"total_samples\": int(len(raft_dataset)),\n",
        "    \"avg_text_length\": float(np.mean(text_lengths)),\n",
        "    \"relevant_docs\": 1,  # 고정값\n",
        "    \"avg_distractor_docs\": float(np.mean(distractor_doc_counts)),\n",
        "    \"avg_total_docs\": float(np.mean(total_doc_counts)),\n",
        "    \"min_text_length\": int(np.min(text_lengths)),\n",
        "    \"max_text_length\": int(np.max(text_lengths)),\n",
        "    \"short_texts\": int(short_texts),\n",
        "    \"medium_texts\": int(medium_texts),\n",
        "    \"long_texts\": int(long_texts),\n",
        "    \"text_lengths\": [int(length) for length in text_lengths]  # 리스트도 변환\n",
        "}\n",
        "\n",
        "with open(\"data/raft_stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(raft_stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# 3. 샘플 데이터도 저장 (테스트용)\n",
        "sample_data = raft_dataset.select(range(min(10, len(raft_dataset))))\n",
        "sample_data.save_to_disk(\"data/raft_sample\")\n",
        "\n",
        "print(\"✅ 데이터 저장 완료!\")\n",
        "print(\"   - data/raft_dataset/: 전체 RAFT 훈련 데이터셋\")\n",
        "print(\"   - data/raft_sample/: 샘플 데이터 (10개)\")\n",
        "print(\"   - data/raft_stats.json: 통계 정보\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 다음 단계 안내\n",
        "\n",
        "### 🎯 다음 노트북에서 할 일\n",
        "**00.04-model-setup.ipynb**에서:\n",
        "1. **EXAONE 모델** 로드하기\n",
        "2. **토크나이저** 설정하기\n",
        "3. **LoRA 설정**하기\n",
        "4. **모델 준비** 완료하기\n",
        "\n",
        "### 💡 지금까지 배운 것\n",
        "- ✅ RAFT 방법론의 핵심 개념 이해\n",
        "- ✅ Distractor Documents 포함한 훈련 데이터 생성\n",
        "- ✅ \"Open Book\" 시험 환경 시뮬레이션\n",
        "- ✅ 파인튜닝용 데이터셋 준비\n",
        "- ✅ 데이터 통계 분석 및 저장\n",
        "\n",
        "### 🔧 RAFT의 핵심 원리\n",
        "- **\"Open Book\" 시험**: 모델이 문서를 참조하면서 답변하는 환경\n",
        "- **Distractor Documents**: 관련 없는 방해 요소 문서들을 무시하도록 학습\n",
        "- **인용 기반 답변**: 관련 문서에서 직접 인용하여 정확한 답변 생성\n",
        "- **도메인 특화**: 특정 도메인의 문서 집합에 특화된 RAG 성능 향상\n",
        "\n",
        "### 🎯 RAFT의 장점\n",
        "- **문서 필터링**: 관련 있는 문서와 관련 없는 문서를 구분하는 능력 향상\n",
        "- **인용 정확도**: 관련 문서에서 직접 인용하여 신뢰할 수 있는 답변 생성\n",
        "- **도메인 적응**: 특정 도메인의 문서 집합에 특화된 성능 향상\n",
        "- **RAG 견고성**: 검색의 불완전성에 대응하여 견고한 성능 발휘\n",
        "\n",
        "### 🚀 준비 완료!\n",
        "이제 다음 노트북으로 넘어가서 모델을 준비해보겠습니다!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
