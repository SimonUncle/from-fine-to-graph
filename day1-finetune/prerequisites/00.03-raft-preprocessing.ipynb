{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1-00.03: RAFT ì „ì²˜ë¦¬ ë¹ ë¥´ê²Œ ë”°ë¼ê°€ê¸°\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” Hugging Faceì˜ í•œêµ­ì–´ RAG ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ **RAFT(Retrieval-Augmented Fine-Tuning)** í…œí”Œë¦¿ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì˜¤ëŠ˜ íë¦„\n",
    "1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n",
    "2. RAFT í…œí”Œë¦¿ ìƒ˜í”Œ ìƒì„±\n",
    "3. í†µê³„ í™•ì¸ ë° ì €ì¥ (ë¡œì»¬ / Google Drive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hugging Faceì—ì„œ ë°ì´í„°ì…‹ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"neural-bridge/rag-dataset-12000\"\n",
    "print(f\"ğŸ“¥ {DATASET_NAME} ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
    "print(f\"âœ… ì´ ìƒ˜í”Œ ìˆ˜: {len(dataset):,}\")\n",
    "print(f\"âœ… í¬í•¨ëœ í•„ë“œ: {dataset.column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAFT í…œí”Œë¦¿ì´ë€?\n",
    "**Retrieval-Augmented Fine-Tuning**ì€ ì§ˆë¬¸ê³¼ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•¨ê»˜ ì œì‹œí•´ ëª¨ë¸ì´ ì •ë‹µ ë¬¸ì„œë¥¼ ìŠ¤ìŠ¤ë¡œ êµ¬ë¶„í•˜ë„ë¡ í›ˆë ¨í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "- **Positive ë¬¸ì„œ**: ì‹¤ì œ ì •ë‹µì´ ë‹´ê¸´ ë¬¸ì„œ (ëª¨ë¸ì´ ì°¸ê³ í•´ì•¼ í•˜ëŠ” ë¬¸ì„œ)\n",
    "- **Distractor ë¬¸ì„œ**: ì¼ë¶€ëŸ¬ í¬í•¨í•œ ì˜¤ë‹µ ë¬¸ì„œ (ëª¨ë¸ì´ ë¬´ì‹œí•´ì•¼ í•˜ëŠ” ë¬¸ì„œ)\n",
    "- **ì…ë ¥ í¬ë§·**: ì§ˆë¬¸ + ì •ë‹µ ë¬¸ì„œ + ì˜¤ë‹µ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë¬¶ê³ , ëª¨ë¸ì—ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë ‡ê²Œ í•™ìŠµí•˜ë©´ ëª¨ë¸ì€ â€œì–´ë–¤ ì •ë³´ë¥¼ ë¯¿ì–´ì•¼ í•˜ëŠ”ì§€â€ê¹Œì§€ íŒŒì•…í•˜ê²Œ ë˜ë©°, ê²€ìƒ‰ ê¸°ë°˜ ì‘ìš©ì— ì í•©í•´ì§‘ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RAFT í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raft_training_sample(question, answer, context, all_contexts, num_distractors=2):\n",
    "    \"\"\"ì£¼ì–´ì§„ ì§ˆë¬¸/ë‹µë³€/ì •ë‹µ ë¬¸ì„œì™€ ì „ì²´ ë¬¸ì„œë¥¼ ì´ìš©í•´ RAFT ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "    distractors = []\n",
    "    while len(distractors) < num_distractors:\n",
    "        candidate = random.choice(all_contexts)\n",
    "        if candidate != context and candidate not in distractors:\n",
    "            distractors.append(candidate)\n",
    "\n",
    "    text = \"\".join([\n",
    "        \"ì§ˆë¬¸: \" + question,\n",
    "        \"ì •ë‹µ ë¬¸ì„œ: \" + context,\n",
    "        \"ì˜¤ë‹µ ë¬¸ì„œ: \" + \" || \".join(distractors),\n",
    "        \"ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.\",\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"context\": context,\n",
    "        \"distractors\": distractors,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column(column_names, candidates, description):\n",
    "    for name in candidates:\n",
    "        if name in column_names:\n",
    "            return name\n",
    "    raise KeyError(f\"í•„ë“œ {description} í›„ë³´ {candidates} ì¤‘ í•˜ë‚˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "def to_string(value):\n",
    "    if isinstance(value, dict):\n",
    "        for key in [\"text\", \"passage\", \"content\", \"answer\", \"response\"]:\n",
    "            if key in value:\n",
    "                return str(value[key])\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        return str(value[0]) if value else \"\"\n",
    "    return str(value)\n",
    "\n",
    "\n",
    "def to_raft_dataset(dataset, num_distractors=2):\n",
    "    print(\"ğŸ”„ RAFT í…œí”Œë¦¿ ë³€í™˜ ì¤‘...\")\n",
    "    column_names = dataset.column_names\n",
    "\n",
    "    question_col = find_column(column_names, [\"question\", \"query\", \"prompt\"], \"question\")\n",
    "    answer_col = find_column(column_names, [\"answer\", \"positive_answer\", \"response\"], \"answer\")\n",
    "    context_col = find_column(\n",
    "        column_names,\n",
    "        [\"positive_ctx\", \"positive_context\", \"context\", \"document\", \"passage\", \"answer_text\"],\n",
    "        \"context\",\n",
    "    )\n",
    "\n",
    "    all_contexts = [to_string(item[context_col]) for item in dataset]\n",
    "    raft_records = []\n",
    "\n",
    "    for item in tqdm(dataset, total=len(dataset)):\n",
    "        question = to_string(item[question_col])\n",
    "        answer = to_string(item[answer_col])\n",
    "        context = to_string(item[context_col])\n",
    "\n",
    "        raft_records.append(\n",
    "            create_raft_training_sample(\n",
    "                question=question,\n",
    "                answer=answer,\n",
    "                context=context,\n",
    "                all_contexts=all_contexts,\n",
    "                num_distractors=num_distractors,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    print(\"âœ… RAFT í˜•ì‹ ë³€í™˜ ì™„ë£Œ\")\n",
    "    return raft_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ì‹¤ì œë¡œ ë³€í™˜ì„ ì‹¤í–‰í•˜ê³  ìƒ˜í”Œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_records = to_raft_dataset(dataset, num_distractors=2)\n",
    "print(f\"ì´ RAFT ìƒ˜í”Œ ìˆ˜: {len(raft_records):,}\")\n",
    "\n",
    "for idx in range(2):\n",
    "    sample = raft_records[idx]\n",
    "    print(\"â”\" * 40)\n",
    "    print(f\"ìƒ˜í”Œ {idx + 1}\")\n",
    "    print(f\"ì§ˆë¬¸: {sample['question'][:80]}...\")\n",
    "    print(f\"ì •ë‹µ: {sample['answer'][:80]}...\")\n",
    "    print(f\"Distractors ê°œìˆ˜: {len(sample['distractors'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. í…ìŠ¤íŠ¸ ê¸¸ì´ ë“± ê°„ë‹¨í•œ í†µê³„ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = [len(record[\"text\"]) for record in raft_records]\n",
    "question_lengths = [len(record[\"question\"]) for record in raft_records]\n",
    "answer_lengths = [len(record[\"answer\"]) for record in raft_records]\n",
    "\n",
    "print(\"ğŸ“Š ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\")\n",
    "print(f\"  â€¢ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {np.mean(text_lengths):.1f}\")\n",
    "print(f\"  â€¢ í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {np.mean(question_lengths):.1f}\")\n",
    "print(f\"  â€¢ í‰ê·  ë‹µë³€ ê¸¸ì´: {np.mean(answer_lengths):.1f}\")\n",
    "print(f\"  â€¢ distractor ë¬¸ì„œ ìˆ˜ (per sample): 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hugging Face Dataset í˜•íƒœë¡œ ë³€í™˜ í›„ ì €ì¥í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_dataset = Dataset.from_list(raft_records)\n",
    "\n",
    "SAVE_DIR = \"data/raft_dataset\"\n",
    "raft_dataset.save_to_disk(SAVE_DIR)\n",
    "\n",
    "stats = {\n",
    "    \"total_samples\": len(raft_records),\n",
    "    \"avg_text_length\": float(np.mean(text_lengths)),\n",
    "    \"avg_question_length\": float(np.mean(question_lengths)),\n",
    "    \"avg_answer_length\": float(np.mean(answer_lengths)),\n",
    "    \"num_distractors\": 2,\n",
    "}\n",
    "\n",
    "with open(\"data/raft_dataset_stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: data/raft_dataset/ ë° data/raft_dataset_stats.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. (ì„ íƒ) Google Driveì—ë„ ì €ì¥í•´ ë‘ê¸°\n",
    "Colabì—ì„œ ì‹¤í–‰í•œë‹¤ë©´ ì•„ë˜ ì…€ì„ ì‹¤í–‰í•´ Driveì— ë™ì¼í•œ í´ë”ë¥¼ ë³µì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_DRIVE_DIR = \"/content/drive/MyDrive/exaone_day1/data/raft_dataset\"\n",
    "\n",
    "try:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    import shutil\n",
    "    drive.mount('/content/drive')\n",
    "    shutil.copytree(\"data/raft_dataset\", GOOGLE_DRIVE_DIR, dirs_exist_ok=True)\n",
    "    shutil.copy(\"data/raft_dataset_stats.json\", GOOGLE_DRIVE_DIR + \"_stats.json\")\n",
    "    print(f\"âœ… Google Driveì— ì €ì¥ ì™„ë£Œ: {GOOGLE_DRIVE_DIR}\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"âš ï¸ Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. í•„ìš”í•˜ë©´ ì§ì ‘ ê²½ë¡œë¥¼ ìˆ˜ì •í•´ ì €ì¥í•˜ì„¸ìš”.\")\n",
    "except NotImplementedError:\n",
    "    print(\"âš ï¸ ì´ í™˜ê²½ì—ì„œëŠ” drive.mount()ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Colab ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset\n",
    "\n",
    "# # Arrow íŒŒì¼ ì§ì ‘ ë¡œë“œ\n",
    "# dataset = Dataset.from_file(\"data-00000-of-00001.arrow\")\n",
    "\n",
    "# # ìƒ˜í”Œ ë³´ê¸°\n",
    "# print(dataset)\n",
    "# print(dataset[0])   # ì²« ë²ˆì§¸ row ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. ë‹¤ìŒ ë‹¨ê³„\n",
    "- ì €ì¥ëœ `data/raft_dataset`ì„ main-practice/03 ë…¸íŠ¸ë¶ì—ì„œ ë¶ˆëŸ¬ì™€ íŒŒì¸íŠœë‹ì— ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- Driveì—ë„ ë³µì‚¬í•´ ë‘ì—ˆë‹¤ë©´ ë‹¤ë¥¸ ëŸ°íƒ€ì„ì—ì„œë„ ì¦‰ì‹œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
