{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Day 1-00.01: 파인튜닝 사전 준비 (초보자용)\n",
        "\n",
        "## 🎯 이번 실습에서 배울 것\n",
        "- **파인튜닝이 뭔지** 간단하게 이해하기\n",
        "- **왜 파인튜닝이 필요한지** 알아보기\n",
        "- **Hugging Face**로 쉽게 모델 다루기\n",
        "- **실제로 모델을 파인튜닝**해보기\n",
        "\n",
        "## 💡 파인튜닝이란?\n",
        "**이미 잘 훈련된 AI 모델을 우리가 원하는 일에 특화시키는 것**\n",
        "\n",
        "예시: \n",
        "- 일반적인 AI → 한국어 질문답변에 특화된 AI\n",
        "- 범용 AI → 의료 분야 전문 AI\n",
        "- 기본 AI → 우리 회사 업무에 맞는 AI\n",
        "\n",
        "## 🔧 오늘 사용할 도구들\n",
        "- **Hugging Face**: AI 모델을 쉽게 다운로드하고 사용\n",
        "- **EXAONE**: 한국어에 특화된 AI 모델\n",
        "- **LoRA**: 적은 메모리로 효율적으로 파인튜닝\n",
        "- **RAFT**: RAG 성능을 높이는 파인튜닝 방법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 필요한 라이브러리 설치하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리들을 설치합니다\n",
        "%pip install -q transformers datasets torch peft accelerate bitsandbytes rouge-score nltk scikit-learn matplotlib seaborn pandas numpy tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 파인튜닝에 필요한 라이브러리들을 불러옵니다\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import (\n",
        "    AutoTokenizer,           # 텍스트를 토큰으로 변환\n",
        "    AutoModelForCausalLM,    # 언어 모델\n",
        "    TrainingArguments,       # 학습 설정\n",
        "    Trainer,                 # 학습 실행\n",
        "    DataCollatorForLanguageModeling  # 데이터 정리\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,              # LoRA 설정\n",
        "    get_peft_model,          # LoRA 모델 생성\n",
        "    TaskType                 # 태스크 타입\n",
        ")\n",
        "from datasets import Dataset\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ 모든 라이브러리가 성공적으로 불러와졌습니다!\")\n",
        "print(f\"🔥 PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"🚀 CUDA 사용 가능: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. GPU 메모리 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU가 있는지 확인하고 메모리 상태를 봅니다\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(f\"🔄 사용 가능한 메모리: {torch.cuda.memory_reserved(0) / 1024**3:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ GPU를 찾을 수 없습니다. CPU로 실행됩니다.\")\n",
        "    print(\"💡 Google Colab에서 실행하시려면 '런타임 > 런타임 유형 변경 > GPU'를 선택하세요\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 파인튜닝 개념 이해하기\n",
        "\n",
        "### 🤔 파인튜닝이 왜 필요할까요?\n",
        "\n",
        "1. **기본 AI 모델의 한계**\n",
        "   - 일반적인 대화는 잘함\n",
        "   - 특정 분야 질문은 부정확함\n",
        "   - 우리가 원하는 형식으로 답변하지 않음\n",
        "\n",
        "2. **파인튜닝의 효과**\n",
        "   - 특정 분야에 정확한 답변\n",
        "   - 원하는 형식으로 답변\n",
        "   - 더 나은 성능\n",
        "\n",
        "### 📊 오늘 할 일\n",
        "1. **데이터 준비**: 한국어 질문-답변 데이터\n",
        "2. **모델 로드**: EXAONE 모델 다운로드\n",
        "3. **파인튜닝**: 우리 데이터로 모델 학습\n",
        "4. **테스트**: 학습된 모델로 질문해보기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 실습 환경 설정\n",
        "\n",
        "### 📁 작업 디렉토리 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 작업할 폴더를 만듭니다\n",
        "import os\n",
        "\n",
        "# 결과를 저장할 폴더들\n",
        "os.makedirs(\"data\", exist_ok=True)           # 데이터 저장\n",
        "os.makedirs(\"models\", exist_ok=True)         # 모델 저장\n",
        "os.makedirs(\"results\", exist_ok=True)        # 결과 저장\n",
        "\n",
        "print(\"📁 작업 폴더가 준비되었습니다!\")\n",
        "print(\"   - data/: 데이터 저장소\")\n",
        "print(\"   - models/: 모델 저장소\")\n",
        "print(\"   - results/: 결과 저장소\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 다음 단계 안내\n",
        "\n",
        "### 🎯 다음 노트북에서 할 일\n",
        "1. **00.02-data-exploration.ipynb**: 한국어 데이터셋 살펴보기\n",
        "2. **00.03-raft-preprocessing.ipynb**: 데이터를 파인튜닝용으로 변환\n",
        "3. **00.04-model-setup.ipynb**: EXAONE 모델 준비하기\n",
        "4. **00.05-fine-tuning.ipynb**: 실제 파인튜닝 실행\n",
        "5. **00.06-evaluation.ipynb**: 결과 확인하기\n",
        "\n",
        "### 💡 팁\n",
        "- 각 단계를 차근차근 따라해보세요\n",
        "- 코드를 실행할 때마다 결과를 확인하세요\n",
        "- 궁금한 점이 있으면 언제든 질문하세요!\n",
        "\n",
        "## 🚀 준비 완료!\n",
        "이제 다음 노트북으로 넘어가서 데이터를 살펴보겠습니다!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
