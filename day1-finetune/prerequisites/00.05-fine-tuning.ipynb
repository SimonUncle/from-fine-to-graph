{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Day 1-00.05: LoRA íŒŒì¸íŠœë‹ ê°œë… ì´í•´í•˜ê¸° (ì´ˆë³´ììš©)\n",
    "\n",
    "## ğŸ¯ ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ í•  ì¼\n",
    "- **LoRAì˜ í•µì‹¬ ê°œë…** ì´í•´í•˜ê¸°\n",
    "- **íŒŒì¸íŠœë‹ ê³¼ì •** ì‹œê°í™”ë¡œ ë³´ê¸°\n",
    "- **ì‹¤ì œ ì½”ë“œ** ë§›ë³´ê¸° (ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)\n",
    "- **ë©”ëª¨ë¦¬ ì ˆì•½** ì›ë¦¬ ì´í•´í•˜ê¸°\n",
    "\n",
    "## ğŸ’¡ LoRAë€ ë¬´ì—‡ì¸ê°€?\n",
    "\n",
    "### ğŸ”§ LoRA (Low-Rank Adaptation)\n",
    "**ì „ì²´ ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ì§€ ì•Šê³ , ì‘ì€ ì–´ëŒ‘í„°ë§Œ ì¶”ê°€í•´ì„œ í•™ìŠµí•˜ëŠ” ë°©ë²•**\n",
    "\n",
    "### ğŸ¯ ì™œ LoRAë¥¼ ì‚¬ìš©í• ê¹Œ?\n",
    "\n",
    "#### âŒ ì¼ë°˜ íŒŒì¸íŠœë‹ì˜ ë¬¸ì œì \n",
    "- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: 7B ëª¨ë¸ = 28GB+ ë©”ëª¨ë¦¬ í•„ìš”\n",
    "- **ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼**: ì „ì²´ ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµ\n",
    "- **ë¹„ìš© ë†’ìŒ**: GPU ë¦¬ì†ŒìŠ¤ ë§ì´ ì‚¬ìš©\n",
    "- **ê³¼ì í•© ìœ„í—˜**: ì‘ì€ ë°ì´í„°ë¡œ í° ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "#### âœ… LoRAì˜ ì¥ì \n",
    "- **ë©”ëª¨ë¦¬ ì ˆì•½**: 1%ë§Œ í•™ìŠµ (28GB â†’ 2GB)\n",
    "- **ë¹ ë¥¸ í•™ìŠµ**: ì‘ì€ ì–´ëŒ‘í„°ë§Œ ì—…ë°ì´íŠ¸\n",
    "- **ì•ˆì •ì **: ì›ë³¸ ëª¨ë¸ ì„±ëŠ¥ ìœ ì§€\n",
    "- **íš¨ìœ¨ì **: ì—¬ëŸ¬ íƒœìŠ¤í¬ì— ì¬ì‚¬ìš© ê°€ëŠ¥\n",
    "\n",
    "### ğŸ§  LoRA ì‘ë™ ì›ë¦¬\n",
    "\n",
    "#### 1ï¸âƒ£ ê¸°ì¡´ ë°©ì‹ (Full Fine-tuning)\n",
    "```\n",
    "ì›ë³¸ ëª¨ë¸ (7B íŒŒë¼ë¯¸í„°)\n",
    "    â†“ ì „ì²´ í•™ìŠµ\n",
    "ìƒˆë¡œìš´ ëª¨ë¸ (7B íŒŒë¼ë¯¸í„°)\n",
    "```\n",
    "\n",
    "#### 2ï¸âƒ£ LoRA ë°©ì‹\n",
    "```\n",
    "ì›ë³¸ ëª¨ë¸ (7B íŒŒë¼ë¯¸í„°) + LoRA ì–´ëŒ‘í„° (0.1B íŒŒë¼ë¯¸í„°)\n",
    "    â†“ ì–´ëŒ‘í„°ë§Œ í•™ìŠµ\n",
    "ì›ë³¸ ëª¨ë¸ + í•™ìŠµëœ ì–´ëŒ‘í„°\n",
    "```\n",
    "\n",
    "### ğŸ” LoRA ì–´ëŒ‘í„° êµ¬ì¡°\n",
    "```\n",
    "ì…ë ¥ â†’ [ì›ë³¸ ë ˆì´ì–´] â†’ [LoRA A] â†’ [LoRA B] â†’ ì¶œë ¥\n",
    "           (ê³ ì •)        (í•™ìŠµ)     (í•™ìŠµ)\n",
    "```\n",
    "\n",
    "- **ì›ë³¸ ë ˆì´ì–´**: í•™ìŠµí•˜ì§€ ì•ŠìŒ (ê³ ì •)\n",
    "- **LoRA A, B**: ì‘ì€ í–‰ë ¬ë“¤ë§Œ í•™ìŠµ\n",
    "- **ê²°ê³¼**: ì›ë³¸ + ì–´ëŒ‘í„°ì˜ ì¡°í•©\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LoRA íŒŒë¼ë¯¸í„° ì´í•´í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAì˜ í•µì‹¬ íŒŒë¼ë¯¸í„°ë“¤ì„ ì´í•´í•´ë´…ì‹œë‹¤\n",
    "print(\"ğŸ”§ LoRA íŒŒë¼ë¯¸í„° ì„¤ëª…\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. r (rank) - LoRAì˜ í•µì‹¬ íŒŒë¼ë¯¸í„°\n",
    "print(\"1ï¸âƒ£ r (rank): LoRAì˜ 'í¬ê¸°'\")\n",
    "print(\"   - ì‘ì„ìˆ˜ë¡: ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ ì ê²Œ ì‚¬ìš©, ì •í™•ë„ ë‚®ìŒ\")\n",
    "print(\"   - í´ìˆ˜ë¡: ëŠë¦¬ê³  ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©, ì •í™•ë„ ë†’ìŒ\")\n",
    "print(\"   - ì¼ë°˜ì  ë²”ìœ„: 4, 8, 16, 32, 64\")\n",
    "print(\"   - ì˜ˆì‹œ: r=16 â†’ 16ì°¨ì› ì–´ëŒ‘í„°\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ lora_alpha: í•™ìŠµ ê°•ë„ ì¡°ì ˆ\")\n",
    "print(\"   - ë†’ì„ìˆ˜ë¡: ë” ê°•í•˜ê²Œ í•™ìŠµ\")\n",
    "print(\"   - ë‚®ì„ìˆ˜ë¡: ë” ë¶€ë“œëŸ½ê²Œ í•™ìŠµ\")\n",
    "print(\"   - ì¼ë°˜ì  ê°’: rì˜ 2ë°° (r=16 â†’ alpha=32)\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ target_modules: ì–´ë–¤ ë ˆì´ì–´ë¥¼ í•™ìŠµí• ì§€\")\n",
    "print(\"   - 'q_proj': Query í”„ë¡œì ì…˜ (ì–´í…ì…˜ì˜ ì§ˆë¬¸ ë¶€ë¶„)\")\n",
    "print(\"   - 'v_proj': Value í”„ë¡œì ì…˜ (ì–´í…ì…˜ì˜ ê°’ ë¶€ë¶„)\")\n",
    "print(\"   - 'k_proj': Key í”„ë¡œì ì…˜ (ì–´í…ì…˜ì˜ í‚¤ ë¶€ë¶„)\")\n",
    "print(\"   - 'o_proj': Output í”„ë¡œì ì…˜ (ì–´í…ì…˜ ì¶œë ¥)\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ lora_dropout: ê³¼ì í•© ë°©ì§€\")\n",
    "print(\"   - 0.05~0.1: ì¼ë°˜ì  ë²”ìœ„\")\n",
    "print(\"   - ë†’ì„ìˆ˜ë¡: ê³¼ì í•© ë°©ì§€, í•™ìŠµ ì–´ë ¤ì›€\")\n",
    "print(\"   - ë‚®ì„ìˆ˜ë¡: í•™ìŠµ ì‰¬ì›€, ê³¼ì í•© ìœ„í—˜\")\n",
    "\n",
    "# ì‹¤ì œ LoRA ì„¤ì • ì˜ˆì‹œ\n",
    "print(\"\\nğŸ“‹ ì‹¤ì œ LoRA ì„¤ì • ì˜ˆì‹œ:\")\n",
    "print(\"   r=16                    # ì ë‹¹í•œ í¬ê¸°\")\n",
    "print(\"   lora_alpha=32           # rì˜ 2ë°°\")\n",
    "print(\"   target_modules=['q_proj', 'v_proj']  # ì–´í…ì…˜ ë ˆì´ì–´ë“¤\")\n",
    "print(\"   lora_dropout=0.05       # ê³¼ì í•© ë°©ì§€\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ ì‹œê°í™”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAì˜ ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ë¥¼ ì‹œê°í™”í•´ë´…ì‹œë‹¤\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š LoRA ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ ë¹„êµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ëª¨ë¸ í¬ê¸°ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (GB)\n",
    "models = ['7B ëª¨ë¸', '13B ëª¨ë¸', '30B ëª¨ë¸', '70B ëª¨ë¸']\n",
    "full_tuning = [28, 52, 120, 280]  # Full fine-tuning ë©”ëª¨ë¦¬\n",
    "lora_tuning = [2, 4, 8, 16]       # LoRA ë©”ëª¨ë¦¬\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, full_tuning, width, label='Full Fine-tuning', color='red', alpha=0.7)\n",
    "bars2 = ax1.bar(x + width/2, lora_tuning, width, label='LoRA', color='green', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('ëª¨ë¸ í¬ê¸°')\n",
    "ax1.set_ylabel('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (GB)')\n",
    "ax1.set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{int(height)}GB', ha='center', va='bottom')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{int(height)}GB', ha='center', va='bottom')\n",
    "\n",
    "# 2. ì ˆì•½ë¥  ê³„ì‚°\n",
    "savings = [(f-l)/f*100 for f, l in zip(full_tuning, lora_tuning)]\n",
    "bars3 = ax2.bar(models, savings, color='blue', alpha=0.7)\n",
    "\n",
    "ax2.set_xlabel('ëª¨ë¸ í¬ê¸°')\n",
    "ax2.set_ylabel('ë©”ëª¨ë¦¬ ì ˆì•½ë¥  (%)')\n",
    "ax2.set_title('LoRA ë©”ëª¨ë¦¬ ì ˆì•½ë¥ ')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# ê°’ í‘œì‹œ\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ì ˆì•½ íš¨ê³¼ ìš”ì•½\n",
    "print(\"\\nğŸ’¡ LoRA ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼:\")\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"   {model}: {full_tuning[i]}GB â†’ {lora_tuning[i]}GB ({savings[i]:.1f}% ì ˆì•½)\")\n",
    "\n",
    "print(f\"\\nğŸ¯ í•µì‹¬ í¬ì¸íŠ¸:\")\n",
    "print(f\"   - 7B ëª¨ë¸: 28GB â†’ 2GB (93% ì ˆì•½!)\")\n",
    "print(f\"   - 70B ëª¨ë¸: 280GB â†’ 16GB (94% ì ˆì•½!)\")\n",
    "print(f\"   - ì¼ë°˜ì ì¸ GPUë¡œë„ ëŒ€í˜• ëª¨ë¸ íŒŒì¸íŠœë‹ ê°€ëŠ¥\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‹¤ì œ íŒŒì¸íŠœë‹ ì½”ë“œ ë§›ë³´ê¸° (ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ íŒŒì¸íŠœë‹ ì½”ë“œë¥¼ ë§›ë³´ê¸°ë¡œ ì‚´í´ë´…ì‹œë‹¤ (ì‹¤í–‰í•˜ì§€ ì•ŠìŒ!)\n",
    "print(\"ğŸ“ ì‹¤ì œ íŒŒì¸íŠœë‹ ì½”ë“œ êµ¬ì¡°\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„:\")\n",
    "print(\"\"\"\n",
    "# RAFT ë°ì´í„° ë¡œë“œ\n",
    "raft_dataset = load_from_disk(\"data/raft_dataset\")\n",
    "\n",
    "# í† í°í™” í•¨ìˆ˜\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "# ë°ì´í„°ì…‹ í† í°í™”\n",
    "tokenized_dataset = raft_dataset.map(tokenize_function, batched=True)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ í•™ìŠµ ì„¤ì • ë‹¨ê³„:\")\n",
    "print(\"\"\"\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,           # 3ë²ˆ ë°˜ë³µ í•™ìŠµ\n",
    "    per_device_train_batch_size=4, # ë°°ì¹˜ í¬ê¸°\n",
    "    gradient_accumulation_steps=4, # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì \n",
    "    warmup_steps=100,             # ì›Œë°ì—…\n",
    "    learning_rate=2e-4,           # í•™ìŠµë¥ \n",
    "    fp16=True,                    # 16ë¹„íŠ¸ í•™ìŠµ\n",
    "    logging_steps=10,             # ë¡œê¹… ì£¼ê¸°\n",
    "    save_steps=500,               # ì €ì¥ ì£¼ê¸°\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n3ï¸âƒ£ í•™ìŠµ ì‹¤í–‰ ë‹¨ê³„:\")\n",
    "print(\"\"\"\n",
    "# ë°ì´í„° ì •ë¦¬ê¸°\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # ì–¸ì–´ ëª¨ë¸ë§\n",
    ")\n",
    "\n",
    "# íŠ¸ë ˆì´ë„ˆ ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# ì‹¤ì œ í•™ìŠµ ì‹¤í–‰ (ì´ ë¶€ë¶„ì´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼!)\n",
    "print(\"ğŸš€ íŒŒì¸íŠœë‹ ì‹œì‘...\")\n",
    "trainer.train()\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n4ï¸âƒ£ ëª¨ë¸ ì €ì¥ ë‹¨ê³„:\")\n",
    "print(\"\"\"\n",
    "# í•™ìŠµëœ ëª¨ë¸ ì €ì¥\n",
    "model.save_pretrained(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
    "\n",
    "print(\"âœ… íŒŒì¸íŠœë‹ ì™„ë£Œ!\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì‹¤ì œ ì‹¤í–‰ ì‹œ ì£¼ì˜ì‚¬í•­:\")\n",
    "print(\"   - GPU ë©”ëª¨ë¦¬: ìµœì†Œ 8GB ì´ìƒ í•„ìš”\")\n",
    "print(\"   - í•™ìŠµ ì‹œê°„: ë°ì´í„° í¬ê¸°ì— ë”°ë¼ 1-10ì‹œê°„\")\n",
    "print(\"   - ëª¨ë‹ˆí„°ë§: í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸\")\n",
    "print(\"   - ì €ì¥: ì •ê¸°ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LoRA vs Full Fine-tuning ë¹„êµ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ğŸ’¡ **ì°¸ê³ **: ì´ ë…¸íŠ¸ë¶ì€ ê°œë… í•™ìŠµìš©ì…ë‹ˆë‹¤. ì•„ë˜ ì…€ì€ í† í°í™”ë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•´ë³´ê³  ì‹¶ì„ ë•Œë§Œ ëŒë¦¬ì„¸ìš”.\n",
    "> ì €ì¥ëœ RAFT ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‘ì€ ìƒ˜í”Œì„ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ ì„¤ëª…ë§Œ ì§„í–‰í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAì™€ Full Fine-tuningì„ ë¹„êµí•´ë´…ì‹œë‹¤\n",
    "print(\"âš–ï¸ LoRA vs Full Fine-tuning ë¹„êµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# RAFT ë°ì´í„°ì™€ í† í°í™” í•¨ìˆ˜ ì¤€ë¹„ (í•„ìš” ì‹œ ìƒì„±)\n",
    "try:\n",
    "    from datasets import Dataset, load_from_disk\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install datasets`ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.\") from exc\n",
    "\n",
    "if 'raft_dataset' not in globals():\n",
    "    print(\"ğŸ“¥ RAFT ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°...\")\n",
    "    try:\n",
    "        raft_dataset = load_from_disk(\"data/raft_dataset\")\n",
    "        print(\"âœ… RAFT ë°ì´í„° ë¡œë“œ ì™„ë£Œ!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"âš ï¸ ì €ì¥ëœ RAFT ë°ì´í„°ê°€ ì—†ì–´ ë¯¸ë‹ˆ ìƒ˜í”Œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.\")\n",
    "        raft_dataset = Dataset.from_dict({\n",
    "            \"text\": [\n",
    "                \"ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "                \"ì§ˆë¬¸: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ëŠ”?\"\n",
    "            ]\n",
    "        })\n",
    "        print(\"âœ… 2ê°œ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ìƒ˜í”Œ ë°ì´í„°ì…‹ ìƒì„±\")\n",
    "\n",
    "if 'tokenizer' not in globals():\n",
    "    raise NameError(\"tokenizerê°€ ì•„ì§ ì •ì˜ë˜ì§€ ì•Šì•˜ì–´ìš”. 00.04 ëª¨ë¸ ì„¤ì • ë…¸íŠ¸ë¶ì„ ë¨¼ì € ì‹¤í–‰í•´ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "if 'tokenize_function' not in globals():\n",
    "    print(\"ğŸ› ï¸ í† í°í™” í•¨ìˆ˜ë¥¼ ìƒˆë¡œ ì •ì˜í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        )\n",
    "else:\n",
    "    print(\"â„¹ï¸ ê¸°ì¡´ tokenize_functionì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# ë¹„êµí‘œ ìƒì„±\n",
    "data = {\n",
    "    'í•­ëª©': [\n",
    "        'ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰',\n",
    "        'í•™ìŠµ ì‹œê°„',\n",
    "        'ëª¨ë¸ í¬ê¸°',\n",
    "        'í•™ìŠµ íŒŒë¼ë¯¸í„°',\n",
    "        'ì •í™•ë„',\n",
    "        'ì•ˆì •ì„±',\n",
    "        'ë¹„ìš©',\n",
    "        'ì¬ì‚¬ìš©ì„±'\n",
    "    ],\n",
    "    'Full Fine-tuning': [\n",
    "        '28GB+ (7B ëª¨ë¸)',\n",
    "        'ë§¤ìš° ì˜¤ë˜ (10+ ì‹œê°„)',\n",
    "        '7B íŒŒë¼ë¯¸í„°',\n",
    "        '7B íŒŒë¼ë¯¸í„°',\n",
    "        'ë§¤ìš° ë†’ìŒ',\n",
    "        'ë‚®ìŒ (ê³¼ì í•© ìœ„í—˜)',\n",
    "        'ë§¤ìš° ë†’ìŒ',\n",
    "        'ì–´ë ¤ì›€'\n",
    "    ],\n",
    "    'LoRA': [\n",
    "        '2GB (7B ëª¨ë¸)',\n",
    "        'ë¹ ë¦„ (1-3 ì‹œê°„)',\n",
    "        '7B + 0.1B ì–´ëŒ‘í„°',\n",
    "        '0.1B íŒŒë¼ë¯¸í„°',\n",
    "        'ë†’ìŒ (95% ìˆ˜ì¤€)',\n",
    "        'ë†’ìŒ (ì›ë³¸ ìœ ì§€)',\n",
    "        'ë‚®ìŒ',\n",
    "        'ì‰¬ì›€ (ì–´ëŒ‘í„°ë§Œ êµì²´)'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"ğŸ¯ í•µì‹¬ ì°¨ì´ì :\")\n",
    "print(\"1ï¸âƒ£ ë©”ëª¨ë¦¬: LoRAê°€ 93% ì ˆì•½\")\n",
    "print(\"2ï¸âƒ£ ì‹œê°„: LoRAê°€ 3-5ë°° ë¹ ë¦„\")\n",
    "print(\"3ï¸âƒ£ ì •í™•ë„: LoRAê°€ 95% ìˆ˜ì¤€ ìœ ì§€\")\n",
    "print(\"4ï¸âƒ£ ë¹„ìš©: LoRAê°€ 10ë°° ì €ë ´\")\n",
    "\n",
    "print(\"ğŸ’¡ ì–¸ì œ ë¬´ì—‡ì„ ì‚¬ìš©í• ê¹Œ?\")\n",
    "print(\"âœ… LoRA ì‚¬ìš© ì‹œê¸°:\")\n",
    "print(\"   - ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ë•Œ\")\n",
    "print(\"   - ë¹ ë¥¸ ì‹¤í—˜ì´ í•„ìš”í•  ë•Œ\")\n",
    "print(\"   - ì—¬ëŸ¬ íƒœìŠ¤í¬ë¥¼ ì‹œë„í•  ë•Œ\")\n",
    "print(\"   - ë¹„ìš©ì„ ì ˆì•½í•˜ê³  ì‹¶ì„ ë•Œ\")\n",
    "\n",
    "print(\"âœ… Full Fine-tuning ì‚¬ìš© ì‹œê¸°:\")\n",
    "print(\"   - ìµœê³  ì •í™•ë„ê°€ í•„ìš”í•  ë•Œ\")\n",
    "print(\"   - ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ìˆì„ ë•Œ\")\n",
    "print(\"   - í•œ ë²ˆë§Œ í•™ìŠµí•  ë•Œ\")\n",
    "print(\"   - ì—°êµ¬ ëª©ì ì¼ ë•Œ\")\n",
    "\n",
    "# ë°ì´í„°ì…‹ í† í°í™” (í•„ìš” ì‹œ ì‹¤í–‰)\n",
    "print(\"ğŸ“ í† í°í™” ì‹¤í–‰ ì¤‘...\")\n",
    "tokenized_dataset = raft_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=raft_dataset.column_names if hasattr(raft_dataset, 'column_names') else []\n",
    ")\n",
    "\n",
    "print(\"âœ… í† í°í™” ì™„ë£Œ!\")\n",
    "print(f\"   - í† í°í™”ëœ ë°ì´í„° ê°œìˆ˜: {len(tokenized_dataset):,}ê°œ\")\n",
    "\n",
    "if 'input_ids' in tokenized_dataset[0]:\n",
    "    sequence_length = len(tokenized_dataset[0]['input_ids'])\n",
    "else:\n",
    "    sequence_length = 'ì•Œ ìˆ˜ ì—†ìŒ'\n",
    "print(f\"   - í† í° ê¸¸ì´: {sequence_length}ê°œ\")\n",
    "\n",
    "# ìƒ˜í”Œ í™•ì¸\n",
    "print(\"ğŸ” í† í°í™” ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "sample_tokens = tokenized_dataset[0]['input_ids'][:20]\n",
    "if hasattr(sample_tokens, 'tolist'):\n",
    "    sample_token_list = sample_tokens.tolist()\n",
    "else:\n",
    "    sample_token_list = list(sample_tokens)\n",
    "\n",
    "sample_text = tokenizer.decode(sample_tokens, skip_special_tokens=True) if hasattr(tokenizer, 'decode') else 'ë””ì½”ë”© ë¶ˆê°€'\n",
    "print(f\"   - í† í° ID: {sample_token_list}\")\n",
    "print(f\"   - ë””ì½”ë”©ëœ í…ìŠ¤íŠ¸: {sample_text[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ (ë§¤ìš° ê°„ë‹¨í•˜ê²Œ!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´ ë° ìš”ì•½\n",
    "print(\"ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"ğŸ“š ì´ì œ ë‹¤ìŒ ë…¸íŠ¸ë¶ë“¤ë¡œ ë„˜ì–´ê°€ì„¸ìš”:\")\n",
    "print(\"1ï¸âƒ£ 00.06-evaluation.ipynb: ëª¨ë¸ í‰ê°€í•˜ê¸°\")\n",
    "print(\"2ï¸âƒ£ main-practice/03_fine_tuning_with_lora.ipynb: ì‹¤ì œ íŒŒì¸íŠœë‹ ì‹¤í–‰\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ LoRA í•µì‹¬ ê°œë…:\")\n",
    "print(\"âœ… LoRAë€: ì‘ì€ ì–´ëŒ‘í„°ë§Œ ì¶”ê°€í•´ì„œ í•™ìŠµí•˜ëŠ” ë°©ë²•\")\n",
    "print(\"âœ… ë©”ëª¨ë¦¬ ì ˆì•½: 93% ì ˆì•½ (28GB â†’ 2GB)\")\n",
    "print(\"âœ… ì‹œê°„ ë‹¨ì¶•: 3-5ë°° ë¹ ë¦„\")\n",
    "print(\"âœ… ì •í™•ë„: 95% ìˆ˜ì¤€ ìœ ì§€\")\n",
    "print(\"âœ… ë¹„ìš© ì ˆì•½: 10ë°° ì €ë ´\")\n",
    "\n",
    "print(\"\\nğŸ”§ LoRA í•µì‹¬ íŒŒë¼ë¯¸í„°:\")\n",
    "print(\"âœ… r (rank): 16 (ì ë‹¹í•œ í¬ê¸°)\")\n",
    "print(\"âœ… lora_alpha: 32 (rì˜ 2ë°°)\")\n",
    "print(\"âœ… target_modules: ì–´í…ì…˜ ë ˆì´ì–´ë“¤\")\n",
    "print(\"âœ… lora_dropout: 0.05 (ê³¼ì í•© ë°©ì§€)\")\n",
    "\n",
    "print(\"\\nğŸ“ RAFT + LoRA ì¡°í•©ì˜ ì¥ì :\")\n",
    "print(\"âœ… RAG ì„±ëŠ¥ í–¥ìƒ: ë¬¸ì„œ í•„í„°ë§ + ì¸ìš© ì •í™•ë„\")\n",
    "print(\"âœ… íš¨ìœ¨ì  í•™ìŠµ: LoRAë¡œ ë¹ ë¥´ê³  ì €ë ´í•˜ê²Œ\")\n",
    "print(\"âœ… ë„ë©”ì¸ íŠ¹í™”: íŠ¹ì • ë°ì´í„°ì— íŠ¹í™”ëœ ì„±ëŠ¥\")\n",
    "print(\"âœ… ì‹¤ìš©ì : ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°”ë¡œ ì ìš© ê°€ëŠ¥\")\n",
    "\n",
    "print(\"\\nğŸš€ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"ì´ì œ ì‹¤ì œ íŒŒì¸íŠœë‹ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì½œë ˆì´í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤ (ë°°ì¹˜ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ëŠ” ë„êµ¬)\n",
    "print(\"ğŸ“¦ ë°ì´í„° ì½œë ˆì´í„° ì„¤ì • ì¤‘...\")\n",
    "\n",
    "# ë°ì´í„° ì½œë ˆì´í„° ìƒì„±\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,        # í† í¬ë‚˜ì´ì €\n",
    "    mlm=False,                  # ë§ˆìŠ¤í¬ ì–¸ì–´ ëª¨ë¸ë§ ì‚¬ìš© ì•ˆí•¨ (GPT ìŠ¤íƒ€ì¼)\n",
    "    pad_to_multiple_of=8        # 8ì˜ ë°°ìˆ˜ë¡œ íŒ¨ë”© (GPU íš¨ìœ¨ì„±)\n",
    ")\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ì½œë ˆì´í„° ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"   - ì–¸ì–´ ëª¨ë¸ë§: GPT ìŠ¤íƒ€ì¼ (ë‹¤ìŒ í† í° ì˜ˆì¸¡)\")\n",
    "print(\"   - íŒ¨ë”©: 8ì˜ ë°°ìˆ˜ë¡œ ì •ë ¬\")\n",
    "print(\"   - ë§ˆìŠ¤í‚¹: ì‚¬ìš© ì•ˆí•¨\")\n",
    "\n",
    "# ë°ì´í„° ì½œë ˆì´í„° í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ§ª ë°ì´í„° ì½œë ˆì´í„° í…ŒìŠ¤íŠ¸:\")\n",
    "test_batch = [tokenized_dataset[i] for i in range(2)]  # 2ê°œ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸\n",
    "collated = data_collator(test_batch)\n",
    "print(f\"   - ë°°ì¹˜ í¬ê¸°: {collated['input_ids'].shape[0]}\")\n",
    "print(f\"   - ì‹œí€€ìŠ¤ ê¸¸ì´: {collated['input_ids'].shape[1]}\")\n",
    "print(f\"   - ë¼ë²¨ í¬ê¸°: {collated['labels'].shape}\")\n",
    "print(f\"   - íŒ¨ë”© í† í° ID: {tokenizer.pad_token_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. íŠ¸ë ˆì´ë„ˆ ìƒì„±í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŠ¸ë ˆì´ë„ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ì‹¤ì œ í•™ìŠµì„ ì‹¤í–‰í•˜ëŠ” ë„êµ¬)\n",
    "print(\"ğŸƒ íŠ¸ë ˆì´ë„ˆ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# íŠ¸ë ˆì´ë„ˆ ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,                    # í•™ìŠµí•  ëª¨ë¸\n",
    "    args=training_args,             # í•™ìŠµ ì„¤ì •\n",
    "    train_dataset=tokenized_dataset, # í•™ìŠµ ë°ì´í„°\n",
    "    data_collator=data_collator,    # ë°ì´í„° ì½œë ˆì´í„°\n",
    "    tokenizer=tokenizer             # í† í¬ë‚˜ì´ì €\n",
    ")\n",
    "\n",
    "print(\"âœ… íŠ¸ë ˆì´ë„ˆ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"   - ëª¨ë¸: LoRA íŒŒì¸íŠœë‹ ëª¨ë¸\")\n",
    "print(f\"   - ë°ì´í„°: {len(tokenized_dataset):,}ê°œ ìƒ˜í”Œ\")\n",
    "print(f\"   - ì—í¬í¬: {training_args.num_train_epochs}íšŒ\")\n",
    "print(f\"   - ì´ ìŠ¤í…: {len(tokenized_dataset) * training_args.num_train_epochs // training_args.gradient_accumulation_steps:,}ê°œ\")\n",
    "\n",
    "# í•™ìŠµ ì „ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "print(f\"\\nğŸ§ª í•™ìŠµ ì „ ëª¨ë¸ í…ŒìŠ¤íŠ¸:\")\n",
    "test_prompt = \"ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\\në‹µë³€:\"\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=30,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"   - ì…ë ¥: {test_prompt}\")\n",
    "print(f\"   - ì¶œë ¥: {generated_text}\")\n",
    "print(f\"   - ìƒì„±ëœ ë¶€ë¶„: {generated_text[len(test_prompt):]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹¤ì œ íŒŒì¸íŠœë‹ ì‹¤í–‰í•˜ê¸°! ğŸš€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë“œë””ì–´ ì‹¤ì œ íŒŒì¸íŠœë‹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤!\n",
    "print(\"ğŸš€ íŒŒì¸íŠœë‹ ì‹œì‘!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ’¡ ì´ ê³¼ì •ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"ğŸ’¡ GPUë¥¼ ì‚¬ìš©í•˜ë©´ ë” ë¹ ë¥´ê²Œ í•™ìŠµë©ë‹ˆë‹¤.\")\n",
    "print(\"ğŸ’¡ í•™ìŠµ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ì‹¤í–‰\n",
    "try:\n",
    "    # ì‹¤ì œ í•™ìŠµ ì‹œì‘!\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\nğŸ‰ íŒŒì¸íŠœë‹ ì™„ë£Œ!\")\n",
    "    print(\"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ íŒŒì¸íŠœë‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ğŸ’¡ GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.\")\n",
    "    print(\"ğŸ’¡ ë˜ëŠ” Google Colabì˜ GPUë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ê°œì„ ë˜ì—ˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•´ë´…ì‹œë‹¤!\n",
    "print(\"ğŸ§ª í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
    "test_questions = [\n",
    "    \"ì§ˆë¬¸: ì¸ê³µì§€ëŠ¥ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\\në‹µë³€:\",\n",
    "    \"ì§ˆë¬¸: ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\\në‹µë³€:\",\n",
    "    \"ì§ˆë¬¸: ìì—°ì–´ ì²˜ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\\në‹µë³€:\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ“ í•™ìŠµ ì „í›„ ë¹„êµ:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ {i}: {question.split('ì§ˆë¬¸: ')[1].split('\\\\n')[0]}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ì…ë ¥ í† í°í™”\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ìƒì„±\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,        # ìµœëŒ€ 50ê°œ í† í° ìƒì„±\n",
    "            temperature=0.7,          # ì°½ì˜ì„± ì¡°ì ˆ\n",
    "            do_sample=True,           # ìƒ˜í”Œë§ ì‚¬ìš©\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # ìƒì„±ëœ í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = generated_text[len(question):].strip()\n",
    "    \n",
    "    print(f\"ë‹µë³€: {answer}\")\n",
    "    print(f\"ì „ì²´: {generated_text}\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ í•™ìŠµëœ ëª¨ë¸ì´ ë” ë‚˜ì€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. í•™ìŠµëœ ëª¨ë¸ ì €ì¥í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤ (ë‚˜ì¤‘ì— ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ!)\n",
    "print(\"ğŸ’¾ í•™ìŠµëœ ëª¨ë¸ ì €ì¥ ì¤‘...\")\n",
    "\n",
    "# 1. LoRA ì–´ëŒ‘í„°ë§Œ ì €ì¥ (ê°€ë²¼ì›€)\n",
    "model.save_pretrained(\"models/fine_tuned_lora\")\n",
    "\n",
    "# 2. í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "tokenizer.save_pretrained(\"models/fine_tuned_lora\")\n",
    "\n",
    "# 3. í•™ìŠµ ì„¤ì • ì €ì¥\n",
    "training_config = {\n",
    "    \"model_name\": model_name,\n",
    "    \"lora_config\": model_config['lora_config'],\n",
    "    \"training_args\": {\n",
    "        \"num_train_epochs\": training_args.num_train_epochs,\n",
    "        \"per_device_train_batch_size\": training_args.per_device_train_batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"gradient_accumulation_steps\": training_args.gradient_accumulation_steps,\n",
    "        \"warmup_steps\": training_args.warmup_steps,\n",
    "        \"weight_decay\": training_args.weight_decay\n",
    "    },\n",
    "    \"dataset_info\": {\n",
    "        \"total_samples\": len(tokenized_dataset),\n",
    "        \"max_length\": 512\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"models/training_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(training_config, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(\"   - models/fine_tuned_lora/: LoRA ì–´ëŒ‘í„°\")\n",
    "print(\"   - models/training_config.json: í•™ìŠµ ì„¤ì •\")\n",
    "print(\"   - ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì´ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ì €ì¥ëœ íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "print(f\"\\nğŸ“ ì €ì¥ëœ íŒŒì¼ë“¤:\")\n",
    "for root, dirs, files in os.walk(\"models/fine_tuned_lora\"):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "        print(f\"   - {file_path}: {file_size:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ í•  ì¼\n",
    "**00.06-evaluation.ipynb**ì—ì„œ:\n",
    "1. **í•™ìŠµëœ ëª¨ë¸** ë¡œë“œí•˜ê¸°\n",
    "2. **ì„±ëŠ¥ í‰ê°€**í•˜ê¸°\n",
    "3. **ì›ë³¸ ëª¨ë¸ê³¼ ë¹„êµ**í•˜ê¸°\n",
    "4. **ê²°ê³¼ ë¶„ì„**í•˜ê¸°\n",
    "\n",
    "### ğŸ’¡ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ê²ƒ\n",
    "- âœ… RAFT ë°ì´í„° ë¡œë“œ ë° í† í°í™”\n",
    "- âœ… LoRA íŒŒì¸íŠœë‹ ì„¤ì •\n",
    "- âœ… ì‹¤ì œ íŒŒì¸íŠœë‹ ì‹¤í–‰\n",
    "- âœ… í•™ìŠµ ê³¼ì • ëª¨ë‹ˆí„°ë§\n",
    "- âœ… í•™ìŠµëœ ëª¨ë¸ ì €ì¥\n",
    "\n",
    "### ğŸ”§ íŒŒì¸íŠœë‹ì˜ í•µì‹¬\n",
    "- **ë°ì´í„°**: RAFT í˜•ì‹ì˜ ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°\n",
    "- **ëª¨ë¸**: EXAONE + LoRA ì–´ëŒ‘í„°\n",
    "- **í•™ìŠµ**: 3 ì—í¬í¬, ë°°ì¹˜ í¬ê¸° 1, ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  4\n",
    "- **ê²°ê³¼**: RAG ì„±ëŠ¥ í–¥ìƒëœ ëª¨ë¸\n",
    "\n",
    "### ğŸš€ ì¤€ë¹„ ì™„ë£Œ!\n",
    "ì´ì œ ë‹¤ìŒ ë…¸íŠ¸ë¶ìœ¼ë¡œ ë„˜ì–´ê°€ì„œ í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•´ë³´ê² ìŠµë‹ˆë‹¤!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
