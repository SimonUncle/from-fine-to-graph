{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📊 Day 1-00.02: 데이터 탐색하기 (초보자용)\n",
        "\n",
        "## 🎯 이번 노트북에서 할 일\n",
        "- **한국어 데이터셋**을 Hugging Face에서 가져오기\n",
        "- **데이터가 어떤 모양**인지 살펴보기\n",
        "- **질문과 답변**이 어떻게 구성되어 있는지 확인하기\n",
        "- **데이터 시각화**로 이해하기 쉽게 만들기\n",
        "\n",
        "## 💡 오늘 사용할 데이터\n",
        "- **데이터셋**: `neural-bridge/rag-dataset-12000`\n",
        "- **언어**: 한국어\n",
        "- **용도**: RAG(검색 증강 생성) 파인튜닝\n",
        "- **구조**: 질문 + 답변 + 관련 문서\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 필요한 라이브러리 불러오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 탐색에 필요한 라이브러리들을 불러옵니다\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정 (matplotlib) - 그래프에서 한글이 깨지지 않도록 설정\n",
        "# Colab 환경에서 나눔 글꼴을 설치하고 matplotlib에 적용\n",
        "print(\"🔧 한글 폰트 설정 중...\")\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum -qq > /dev/null\n",
        "\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 나눔바른고딕 폰트 경로 설정\n",
        "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "# 폰트 매니저에 폰트 추가 - 그래프에서 한글 표시를 위해 필요\n",
        "fm.fontManager.addfont(fontpath)\n",
        "\n",
        "# matplotlib 설정 업데이트 - 모든 그래프에서 한글이 정상적으로 표시됨\n",
        "plt.rcParams.update({\n",
        "    'font.family': 'NanumBarunGothic',  # 기본 폰트를 나눔바른고딕으로 설정\n",
        "    'axes.unicode_minus': False         # 음수 기호 표시 문제 해결\n",
        "})\n",
        "\n",
        "print(\"✅ 한글 폰트 설정 완료 - 그래프에서 한글이 정상 표시됩니다\")\n",
        "print(\"📦 라이브러리 import 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Hugging Face에서 데이터셋 가져오기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hugging Face에서 한국어 RAG 데이터셋을 가져옵니다\n",
        "print(\"📥 데이터셋을 다운로드하는 중...\")\n",
        "\n",
        "# 데이터셋 로드 (처음에는 작은 샘플만 가져와서 확인)\n",
        "dataset = load_dataset(\"neural-bridge/rag-dataset-12000\", split=\"train\")\n",
        "\n",
        "print(f\"✅ 데이터셋 로드 완료!\")\n",
        "print(f\"📊 총 데이터 개수: {len(dataset):,}개\")\n",
        "print(f\"🔍 데이터 타입: {type(dataset)}\")\n",
        "print(f\"📋 데이터 구조: {dataset.features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 데이터 구조 살펴보기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 첫 번째 데이터 샘플을 자세히 살펴봅시다\n",
        "print(\"🔍 첫 번째 데이터 샘플:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 첫 번째 샘플 가져오기\n",
        "sample = dataset[0]\n",
        "\n",
        "# 각 필드별로 출력\n",
        "for key, value in sample.items():\n",
        "    print(f\"\\n📌 {key}:\")\n",
        "    print(f\"   타입: {type(value)}\")\n",
        "    if isinstance(value, str):\n",
        "        # 문자열인 경우 길이와 일부 내용 표시\n",
        "        print(f\"   길이: {len(value)} 글자\")\n",
        "        print(f\"   내용 미리보기: {value[:100]}...\")\n",
        "    elif isinstance(value, list):\n",
        "        # 리스트인 경우 길이와 첫 번째 항목 표시\n",
        "        print(f\"   개수: {len(value)}개\")\n",
        "        if value:\n",
        "            print(f\"   첫 번째 항목: {value[0][:100]}...\")\n",
        "    else:\n",
        "        print(f\"   값: {value}\")\n",
        "    print(\"-\" * 30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 여러 샘플 살펴보기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 처음 3개의 샘플을 예쁘게 표시해봅시다\n",
        "print(\"📚 처음 3개 샘플:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i in range(min(3, len(dataset))):\n",
        "    sample = dataset[i]\n",
        "    print(f\"\\n🔹 샘플 {i+1}:\")\n",
        "    print(f\"   질문: {sample['question']}\")\n",
        "    print(f\"   답변: {sample['answer'][:150]}...\")\n",
        "    print(f\"   관련 문서 개수: {len(sample['context'])}\")\n",
        "    if sample['context']:\n",
        "        print(f\"   첫 번째 문서: {sample['context'][0][:100]}...\")\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 데이터 통계 분석하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터의 기본 통계를 계산해봅시다\n",
        "print(\"📊 데이터 통계 분석:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 먼저 None 값이 있는지 확인해보겠습니다\n",
        "print(\"🔍 데이터 품질 확인:\")\n",
        "none_questions = sum(1 for sample in dataset if sample['question'] is None)\n",
        "none_answers = sum(1 for sample in dataset if sample['answer'] is None)\n",
        "none_contexts = sum(1 for sample in dataset if sample['context'] is None)\n",
        "\n",
        "print(f\"   None 질문: {none_questions}개\")\n",
        "print(f\"   None 답변: {none_answers}개\") \n",
        "print(f\"   None 컨텍스트: {none_contexts}개\")\n",
        "\n",
        "# None이 아닌 값들만으로 통계 계산\n",
        "question_lengths = [len(sample['question']) for sample in dataset if sample['question'] is not None]\n",
        "answer_lengths = [len(sample['answer']) for sample in dataset if sample['answer'] is not None]\n",
        "context_counts = [len(sample['context']) for sample in dataset if sample['context'] is not None]\n",
        "\n",
        "print(f\"\\n📝 질문 길이:\")\n",
        "print(f\"   평균: {np.mean(question_lengths):.1f} 글자\")\n",
        "print(f\"   최소: {np.min(question_lengths)} 글자\")\n",
        "print(f\"   최대: {np.max(question_lengths)} 글자\")\n",
        "\n",
        "print(f\"\\n💬 답변 길이:\")\n",
        "print(f\"   평균: {np.mean(answer_lengths):.1f} 글자\")\n",
        "print(f\"   최소: {np.min(answer_lengths)} 글자\")\n",
        "print(f\"   최대: {np.max(answer_lengths)} 글자\")\n",
        "\n",
        "print(f\"\\n📄 관련 문서 개수:\")\n",
        "print(f\"   평균: {np.mean(context_counts):.1f}개\")\n",
        "print(f\"   최소: {np.min(context_counts)}개\")\n",
        "print(f\"   최대: {np.max(context_counts)}개\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 데이터 시각화하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 분포를 그래프로 그려봅시다\n",
        "# 한글 폰트 설정 확인 및 적용\n",
        "plt.rcParams.update({\n",
        "    'font.family': 'NanumBarunGothic',\n",
        "    'axes.unicode_minus': False\n",
        "})\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('📊 RAG 데이터셋 분석', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. 질문 길이 분포\n",
        "axes[0, 0].hist(question_lengths, bins=30, alpha=0.7, color='skyblue')\n",
        "axes[0, 0].set_title('질문 길이 분포')\n",
        "axes[0, 0].set_xlabel('글자 수')\n",
        "axes[0, 0].set_ylabel('개수')\n",
        "\n",
        "# 2. 답변 길이 분포\n",
        "axes[0, 1].hist(answer_lengths, bins=30, alpha=0.7, color='lightgreen')\n",
        "axes[0, 1].set_title('답변 길이 분포')\n",
        "axes[0, 1].set_xlabel('글자 수')\n",
        "axes[0, 1].set_ylabel('개수')\n",
        "\n",
        "# 3. 관련 문서 개수 분포\n",
        "axes[1, 0].hist(context_counts, bins=20, alpha=0.7, color='orange')\n",
        "axes[1, 0].set_title('관련 문서 개수 분포')\n",
        "axes[1, 0].set_xlabel('문서 개수')\n",
        "axes[1, 0].set_ylabel('개수')\n",
        "\n",
        "# 4. 질문 vs 답변 길이 관계\n",
        "axes[1, 1].scatter(question_lengths, answer_lengths, alpha=0.5, color='purple')\n",
        "axes[1, 1].set_title('질문 길이 vs 답변 길이')\n",
        "axes[1, 1].set_xlabel('질문 길이 (글자)')\n",
        "axes[1, 1].set_ylabel('답변 길이 (글자)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ 데이터 시각화 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 데이터 저장하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 탐색한 데이터를 저장해둡시다 (다음 단계에서 사용할 예정)\n",
        "print(\"💾 데이터를 저장하는 중...\")\n",
        "\n",
        "# 전체 데이터셋을 저장\n",
        "dataset.save_to_disk(\"data/rag_dataset\")\n",
        "\n",
        "# 통계 정보도 저장\n",
        "stats = {\n",
        "    \"total_samples\": len(dataset),\n",
        "    \"avg_question_length\": np.mean(question_lengths),\n",
        "    \"avg_answer_length\": np.mean(answer_lengths),\n",
        "    \"avg_context_count\": np.mean(context_counts),\n",
        "    \"question_lengths\": question_lengths,\n",
        "    \"answer_lengths\": answer_lengths,\n",
        "    \"context_counts\": context_counts\n",
        "}\n",
        "\n",
        "with open(\"data/dataset_stats.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(stats, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ 데이터 저장 완료!\")\n",
        "print(\"   - data/rag_dataset/: 전체 데이터셋\")\n",
        "print(\"   - data/dataset_stats.json: 통계 정보\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 다음 단계 안내\n",
        "\n",
        "### 🎯 다음 노트북에서 할 일\n",
        "**00.03-raft-preprocessing.ipynb**에서:\n",
        "1. **RAFT 템플릿** 만들기\n",
        "2. **데이터를 파인튜닝용으로 변환**하기\n",
        "3. **토큰화** 준비하기\n",
        "\n",
        "### 💡 지금까지 배운 것\n",
        "- ✅ 한국어 RAG 데이터셋의 구조 이해\n",
        "- ✅ 질문-답변-문서의 관계 파악\n",
        "- ✅ 데이터 분포와 통계 분석\n",
        "- ✅ 시각화를 통한 데이터 이해\n",
        "\n",
        "### 🚀 준비 완료!\n",
        "이제 다음 노트북으로 넘어가서 데이터를 파인튜닝용으로 변환해보겠습니다!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
