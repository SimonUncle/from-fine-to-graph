{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Modular RAG - 기능 맛보기!\n",
    "\n",
    "## 🎯 학습 목표\n",
    "- **Query Routing**: LLM이 질문 유형을 판별하여 자동 분류\n",
    "- **Self-RAG Critic**: LLM이 자신의 답변을 평가하고 개선점 찾기\n",
    "- **Retry with Refine**: 부족한 부분을 보강해서 재시도하는 지능형 시스템\n",
    "\n",
    "## 📋 실습 구성\n",
    "1. **Query Routing 맛보기** (10분) - 질문을 single/multi/clarify로 분류\n",
    "2. **Self-RAG Critic 맛보기** (10분) - 답변을 스스로 평가하고 개선점 찾기  \n",
    "3. **Retry with Refine 맛보기** (10분) - 누락된 부분 보강해서 재시도\n",
    "\n",
    "---\n",
    "\n",
    "> 💡 **핵심 아이디어**: LLM이 스스로 분류→평가→보강하는 **메타인지 능력**을 체험해보세요! 05번 환경을 그대로 사용하면서 간단한 기능들을 독립적으로 맛봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05번 환경 재사용 (Day1FinetunedLLM + 항공 코퍼스)\n",
    "!pip install -q langchain-community faiss-cpu sentence-transformers matplotlib pandas numpy transformers torch rank-bm25\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 🤖 Day1 파인튜닝 모델 관련 import\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.llms.base import LLM\n",
    "from pydantic import Field\n",
    "\n",
    "# LangChain 관련 import\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "print(\"✅ 라이브러리 설정 완료!\")\n",
    "\n",
    "# Day 1 파인튜닝 모델 클래스 (05번과 동일)\n",
    "class Day1FinetunedLLM(LLM):\n",
    "    \"\"\"Day 1 파인튜닝 모델을 사용하는 LLM 클래스\"\"\"\n",
    "    \n",
    "    # Pydantic 필드 선언\n",
    "    model_name: str = Field(default=\"ryanu/my-exaone-raft-model\")\n",
    "    tokenizer: Any = Field(default=None)\n",
    "    model: Any = Field(default=None)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    def __init__(self, model_name: str = \"ryanu/my-exaone-raft-model\", **kwargs):\n",
    "        super().__init__(model_name=model_name, **kwargs)\n",
    "        print(f\"🎯 Day 1 파인튜닝 모델 로드: {self.model_name}\")\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"모델 로드\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        print(\"✅ 모델 로드 완료!\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"day1_finetuned_llm\"\n",
    "    \n",
    "    def _call(self, prompt: str, stop=None, run_manager=None, **kwargs) -> str:\n",
    "        \"\"\"실제 모델 추론\"\"\"\n",
    "        # EXAONE 프롬프트 템플릿 적용\n",
    "        formatted_prompt = f\"[|system|]당신은 도움이 되는 AI 어시스턴트입니다.[|endofturn|]\\n[|user|]{prompt}[|endofturn|]\\n[|assistant|]\"\n",
    "        \n",
    "        inputs = self.tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs, max_new_tokens=512, temperature=0.7, do_sample=True,\n",
    "                pad_token_id=self.tokenizer.pad_token_id, eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "        return response if response else \"적절한 답변을 생성할 수 없습니다.\"\n",
    "\n",
    "# LLM 초기화\n",
    "llm = Day1FinetunedLLM()\n",
    "\n",
    "print(\"✅ Day1FinetunedLLM 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05번 항공 코퍼스 재사용 + 벡터스토어 구축\n",
    "def create_aviation_corpus():\n",
    "    \"\"\"05번과 동일한 항공사 + 공항 코퍼스\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"content\": \"\"\"에어민트 항공 수하물 정책 (2024-05-10)\n",
    "- 위탁수하물: 15kg 무료, 초과 1kg당 8,000원\n",
    "- 기내수하물: 7kg 1개\n",
    "- 노선: 국내선 동일 기준\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"에어민트\", \"source\": \"official\", \"updated_at\": \"2024-05-10\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"김포공항 보안검색 혼잡도 안내 (2024-04-15)\n",
    "- 일요일: 08~10시 혼잡, 12~14시는 비교적 한산\n",
    "- 평일: 출근시간대 07~09시 혼잡\n",
    "- 오후 시간대는 전반적으로 여유로움\"\"\",\n",
    "            \"metadata\": {\"type\": \"airport_info\", \"airport\": \"김포\", \"source\": \"official\", \"updated_at\": \"2024-04-15\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"인천공항 보안검색 혼잡도 (2024-04-20)\n",
    "- 주말: 09~11시 피크, 15~17시 한산\n",
    "- 국제선 터미널은 별도 시간대 적용\"\"\",\n",
    "            \"metadata\": {\"type\": \"airport_info\", \"airport\": \"인천\", \"source\": \"official\", \"updated_at\": \"2024-04-20\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"스카이블루 항공 수하물 정책 (2024-03-01)\n",
    "- 위탁수하물: 20kg 무료\n",
    "- 기내수하물: 10kg 1개\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"스카이블루\", \"source\": \"official\", \"updated_at\": \"2024-03-01\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"공항 빠르게 통과하는 여행 팁\n",
    "- 수하물 가볍게 준비하기\n",
    "- 이른 시간 도착 추천\n",
    "- 주말 오전 피크타임은 피하기\"\"\",\n",
    "            \"metadata\": {\"type\": \"blog\", \"source\": \"blog\", \"updated_at\": \"2024-08-01\"}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# 벡터스토어 구축\n",
    "aviation_docs = create_aviation_corpus()\n",
    "lc_documents = [Document(page_content=doc[\"content\"], metadata=doc[\"metadata\"]) for doc in aviation_docs]\n",
    "\n",
    "# 임베딩 + 벡터스토어 (05번과 동일)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "vectorstore = FAISS.from_documents(lc_documents, embeddings)\n",
    "\n",
    "# 간단한 RAG 체인용 리트리버\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "print(f\"✅ 항공 코퍼스 벡터스토어 구축 완료! ({len(aviation_docs)}개 문서)\")\n",
    "print(\"\\n📋 문서 목록:\")\n",
    "for i, doc in enumerate(aviation_docs, 1):\n",
    "    doc_type = doc[\"metadata\"].get(\"type\", \"unknown\")\n",
    "    entity = doc[\"metadata\"].get(\"airline\") or doc[\"metadata\"].get(\"airport\", \"일반\")\n",
    "    first_line = doc[\"content\"].strip().split('\\n')[0]\n",
    "    print(f\"  {i}. [{doc_type}|{entity}] {first_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Step 1: Query Routing 맛보기 - 하드코딩 vs LLM\n",
    "\n",
    "# 📋 1. 하드코딩 라우팅 (규칙 기반)\n",
    "def hardcoded_routing(query):\n",
    "    \"\"\"키워드 기반 간단한 라우팅\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    if \"수하물\" in query_lower or \"짐\" in query_lower:\n",
    "        return \"baggage_fee_search\", \"수하물 요금 검색 함수\"\n",
    "    elif \"보안검색\" in query_lower or \"검색대\" in query_lower:\n",
    "        return \"security_time_search\", \"보안검색 시간 검색 함수\"  \n",
    "    elif \"계산\" in query_lower or \"더하기\" in query_lower or \"빼기\" in query_lower:\n",
    "        return \"calculator\", \"계산기 함수\"\n",
    "    elif \"날씨\" in query_lower:\n",
    "        return \"weather_search\", \"날씨 검색 함수\"\n",
    "    else:\n",
    "        return \"general_rag_search\", \"일반 RAG 검색 함수\"\n",
    "\n",
    "# 🤖 2. LLM 라우팅 (의미 기반)\n",
    "def llm_routing(llm, query):\n",
    "    \"\"\"LLM이 어떤 함수로 보낼지 결정\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"다음 질문을 보고 어떤 함수로 보내야 할지 결정하세요.\n",
    "\n",
    "가능한 함수들:\n",
    "- baggage_fee_search: 수하물 요금 관련\n",
    "- security_time_search: 공항 보안검색 시간 관련  \n",
    "- calculator: 계산 관련\n",
    "- weather_search: 날씨 관련\n",
    "- general_rag_search: 일반적인 정보 검색\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "답변 형식: 함수명|이유\n",
    "예: baggage_fee_search|수하물 요금을 묻고 있음\"\"\"\n",
    "\n",
    "    response = llm._call(prompt)\n",
    "    \n",
    "    # 간단하게 파싱 (|로 분리)\n",
    "    if \"|\" in response:\n",
    "        func_name, reason = response.split(\"|\", 1)\n",
    "        return func_name.strip(), reason.strip()\n",
    "    else:\n",
    "        return \"general_rag_search\", \"LLM 파싱 실패\"\n",
    "\n",
    "# 🔎 하드코딩 vs LLM 라우팅 비교 테스트\n",
    "print(\"🎯 Query Routing 맛보기: 하드코딩 vs LLM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_queries = [\n",
    "    \"에어민트 수하물 요금 알려줘\",\n",
    "    \"김포공항 보안검색 언제가 빨라?\", \n",
    "    \"2+3은 얼마야?\",\n",
    "    \"내일 서울 날씨 어때?\",\n",
    "    \"항공사 정책에 대해 알고 싶어\"\n",
    "]\n",
    "\n",
    "print(\"💡 같은 질문, 다른 라우팅 방식!\")\n",
    "print()\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"{i}. 질문: '{query}'\")\n",
    "    \n",
    "    # 하드코딩 라우팅\n",
    "    hard_func, hard_reason = hardcoded_routing(query)\n",
    "    print(f\"   🔧 하드코딩: {hard_func} ({hard_reason})\")\n",
    "    \n",
    "    # LLM 라우팅  \n",
    "    llm_func, llm_reason = llm_routing(llm, query)\n",
    "    print(f\"   🤖 LLM: {llm_func} ({llm_reason})\")\n",
    "    \n",
    "    # 결과 비교\n",
    "    if hard_func == llm_func:\n",
    "        print(\"   ✅ 결과 일치!\")\n",
    "    else:\n",
    "        print(\"   🔄 결과 다름 (LLM이 더 유연한 이해)\")\n",
    "    print()\n",
    "\n",
    "print(\"🚀 하드코딩 vs LLM 라우팅 비교:\")\n",
    "print(\"• 하드코딩: 빠름, 명확함, 하지만 제한적\")\n",
    "print(\"• LLM: 느림, 유연함, 복잡한 상황 대응\")\n",
    "print(\"• 실무: 명확한 케이스는 하드코딩, 애매한 케이스는 LLM!\")\n",
    "\n",
    "print(\"\\n💡 핵심: '라우팅 = 적절한 함수 선택'\")\n",
    "print(\"• 수하물 문의 → baggage_fee_search() 호출\")\n",
    "print(\"• 계산 요청 → calculator() 호출\")\n",
    "print(\"• 목적지 함수만 정확히 찾으면 성공!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Step 2: Self-RAG Critic 맛보기\n",
    "\n",
    "# (A) 기본 RAG로 답변 생성 (Step 1 라우팅 결과 활용 가능)\n",
    "STRICT_PROMPT = PromptTemplate.from_template(\n",
    "\"\"\"아래 컨텍스트에 있는 내용만 근거로 한국어로 간결히 답하세요.\n",
    "없으면 '근거 불충분: (무엇이 필요한지)' 한 줄로 말하고, 필요한 추가정보 1~2개만 물어보세요.\n",
    "\n",
    "[컨텍스트]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변]\"\"\")\n",
    "\n",
    "def answer_with_context(llm, docs, question):\n",
    "    \"\"\"컨텍스트 기반 RAG 답변\"\"\"\n",
    "    context = \"\\n\\n---\\n\\n\".join([d.page_content[:1000] for d in docs]) or \"(빈 컨텍스트)\"\n",
    "    prompt_text = STRICT_PROMPT.format(context=context, question=question)\n",
    "    response = llm._call(prompt_text)\n",
    "    return response.strip()\n",
    "\n",
    "# (B) Self-RAG Critic: LLM이 답변을 자가평가\n",
    "CRITIC_PROMPT = PromptTemplate.from_template(\n",
    "\"\"\"당신은 품질 심사관입니다. 아래를 보고 JSON만 출력하세요.\n",
    "\n",
    "- coverage: 0.0~1.0 (질문 요구 파셋을 얼마나 근거로 커버?)\n",
    "- missing_facets: 누락된 축 목록\n",
    "- hallucination_risk: \"low\"|\"medium\"|\"high\"\n",
    "- ask: 사용자에게 물어볼 1~2개 질문\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[답변]\n",
    "{answer}\n",
    "\n",
    "[컨텍스트 요약]\n",
    "{ctx}\n",
    "\n",
    "JSON:\"\"\")\n",
    "\n",
    "def self_rag_critic(llm, question, answer, docs):\n",
    "    \"\"\"LLM이 Self-RAG로 답변 품질 평가\"\"\"\n",
    "    ctx = \"\\n---\\n\".join([d.page_content[:400] for d in docs[:3]])\n",
    "    prompt_text = CRITIC_PROMPT.format(question=question, answer=answer, ctx=ctx)\n",
    "    response = llm._call(prompt_text)\n",
    "    return _safe_json(response, {\n",
    "        \"coverage\": 0.0, \n",
    "        \"missing_facets\": [], \n",
    "        \"hallucination_risk\": \"medium\", \n",
    "        \"ask\": []\n",
    "    })\n",
    "\n",
    "# 🔎 Self-RAG Critic 테스트  \n",
    "print(\"🧠 Self-RAG Critic 맛보기\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_query = \"김포공항에서 에어민트 타고 수하물 요금이랑 보안검색 시간도 알려줘\"\n",
    "print(f\"질문: '{test_query}'\\n\")\n",
    "\n",
    "# Step 1에서 라우팅한 결과도 활용 가능\n",
    "routing_result = llm_route_query(llm, test_query)\n",
    "print(f\"📍 Step 1 라우팅 결과: {routing_result['route']} (핵심축: {routing_result['facets']})\")\n",
    "\n",
    "# 1차: 기본 RAG 답변\n",
    "docs = retriever.get_relevant_documents(test_query)\n",
    "print(f\"\\n🔍 검색된 문서:\")\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    doc_type = doc.metadata.get(\"type\", \"unknown\")\n",
    "    entity = doc.metadata.get(\"airline\") or doc.metadata.get(\"airport\", \"-\")\n",
    "    print(f\"  {i}. [{doc_type}|{entity}] {doc.page_content[:50]}...\")\n",
    "\n",
    "answer = answer_with_context(llm, docs, test_query)\n",
    "print(f\"\\n💬 RAG 답변:\\n{answer}\")\n",
    "\n",
    "# 2차: Self-RAG 평가\n",
    "critic_result = self_rag_critic(llm, test_query, answer, docs)\n",
    "\n",
    "coverage = critic_result.get(\"coverage\", 0.0)\n",
    "missing_facets = critic_result.get(\"missing_facets\", [])\n",
    "hallucination_risk = critic_result.get(\"hallucination_risk\", \"medium\")\n",
    "ask_questions = critic_result.get(\"ask\", [])\n",
    "\n",
    "print(f\"\\n🤔 LLM Self-RAG 평가:\")\n",
    "print(f\"   커버리지: {coverage:.1f} (0.0~1.0)\")\n",
    "print(f\"   누락된 축: {missing_facets}\")\n",
    "print(f\"   할루시네이션 위험: {hallucination_risk}\")\n",
    "print(f\"   추가 질문: {ask_questions}\")\n",
    "\n",
    "# 품질 해석\n",
    "if coverage >= 0.8 and hallucination_risk == \"low\":\n",
    "    quality = \"✅ 우수\"\n",
    "elif coverage >= 0.6:\n",
    "    quality = \"⚠️ 보통\"\n",
    "else:\n",
    "    quality = \"❌ 개선 필요\"\n",
    "\n",
    "print(f\"   종합 평가: {quality}\")\n",
    "\n",
    "print(f\"\\n💡 Self-RAG의 메타인지 능력:\")\n",
    "print(f\"• LLM이 스스로 답변의 완성도를 객관 평가\")\n",
    "print(f\"• 누락 파셋을 정확히 감지 (Step 1 라우팅과 연계)\") \n",
    "print(f\"• 할루시네이션 위험도를 사전 경고\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Step 3: Retry with Refine 맛보기\n",
    "\n",
    "# 누락된 파셋으로 정밀 쿼리 생성\n",
    "REFINE_PROMPT = PromptTemplate.from_template(\n",
    "\"\"\"아래 질문의 누락된 파셋을 메우는 '정밀 검색쿼리' 2개만 JSON 배열로 출력하세요.\n",
    "- 각 쿼리는 파셋을 명시적으로 포함(브랜드/도시/요일/정책명 등)\n",
    "- 중복 금지\n",
    "- 쿼리로 유추할 수 있는 필요한 내용만 적으세요\n",
    "\n",
    "[질문]\n",
    "{question}\n",
    "\n",
    "[누락 파셋]\n",
    "{missing_facets}\n",
    "\n",
    "JSON:\"\"\")\n",
    "\n",
    "def refine_queries(llm, question, missing_facets):\n",
    "    \"\"\"누락 파셋으로 보강 쿼리 생성\"\"\"\n",
    "    if not missing_facets: \n",
    "        return []\n",
    "    prompt_text = REFINE_PROMPT.format(question=question, missing_facets=missing_facets)\n",
    "    response = llm._call(prompt_text)\n",
    "    arr = _safe_json(response, [])\n",
    "    return [q for q in arr if isinstance(q, str)][:2]\n",
    "\n",
    "def retry_once_with_refine(llm, retriever, question):\n",
    "    \"\"\"1회 재시도로 답변 품질 개선\"\"\"\n",
    "    \n",
    "    # 1차 시도\n",
    "    print(\"🔵 1차 시도:\")\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    answer = answer_with_context(llm, docs, question)\n",
    "    critic_result = self_rag_critic(llm, question, answer, docs)\n",
    "    \n",
    "    print(f\"   답변: {answer}\")\n",
    "    print(f\"   평가: 커버리지 {critic_result['coverage']:.1f}, 위험도 {critic_result['hallucination_risk']}\")\n",
    "    \n",
    "    # 품질이 충분하면 종료\n",
    "    if critic_result[\"coverage\"] >= 0.8 and critic_result[\"hallucination_risk\"] == \"low\":\n",
    "        print(\"   ✅ 품질 충분! 1차 답변으로 완료\")\n",
    "        return answer\n",
    "    \n",
    "    # 보강이 필요하면 재시도\n",
    "    print(\"   ⚠️ 품질 개선 필요, 재시도 진행...\")\n",
    "    \n",
    "    # 보강 쿼리 생성\n",
    "    refine_queries_list = refine_queries(llm, question, critic_result[\"missing_facets\"])\n",
    "    if not refine_queries_list:\n",
    "        return f\"근거 불충분. 추가정보 필요: {' / '.join(critic_result.get('ask', []))}\"\n",
    "    \n",
    "    print(f\"\\n🟢 2차 시도 (보강 쿼리: {refine_queries_list}):\")\n",
    "    \n",
    "    # 보강 문서 수집\n",
    "    additional_docs = []\n",
    "    for refine_query in refine_queries_list:\n",
    "        additional_docs += retriever.get_relevant_documents(refine_query)[:2]\n",
    "    \n",
    "    # 중복 제거 (간단하게 content 기준)\n",
    "    seen_content = set()\n",
    "    unique_docs = []\n",
    "    for doc in additional_docs:\n",
    "        content_key = doc.page_content[:100]  # 앞 100자로 중복 판단\n",
    "        if content_key not in seen_content:\n",
    "            seen_content.add(content_key)\n",
    "            unique_docs.append(doc)\n",
    "    \n",
    "    # 2차 답변 생성\n",
    "    final_answer = answer_with_context(llm, unique_docs[:6], question)\n",
    "    final_critic = self_rag_critic(llm, question, final_answer, unique_docs[:6])\n",
    "    \n",
    "    print(f\"   답변: {final_answer}\")\n",
    "    print(f\"   평가: 커버리지 {final_critic['coverage']:.1f}, 위험도 {final_critic['hallucination_risk']}\")\n",
    "    \n",
    "    # 개선 효과 표시\n",
    "    improvement = final_critic[\"coverage\"] - critic_result[\"coverage\"]\n",
    "    print(f\"   📈 개선도: {improvement:+.1f} 포인트\")\n",
    "    \n",
    "    return final_answer\n",
    "\n",
    "# 🔎 Retry with Refine 전체 테스트\n",
    "print(\"🔄 Retry with Refine 맛보기\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "complex_query = \"김포공항에서 에어민트 타고 수하물 요금이랑 보안검색 시간도 알려줘\"\n",
    "print(f\"복합 질문: '{complex_query}'\\n\")\n",
    "\n",
    "final_answer = retry_once_with_refine(llm, retriever, complex_query)\n",
    "\n",
    "print(f\"\\n✅ 최종 결과:\\n{final_answer}\")\n",
    "\n",
    "print(f\"\\n💡 Retry with Refine 핵심:\")\n",
    "print(f\"• 1차 답변을 Self-RAG가 품질 평가\")\n",
    "print(f\"• 누락된 파셋을 LLM이 자동 감지\") \n",
    "print(f\"• 정밀 검색쿼리로 보강 정보 수집\")\n",
    "print(f\"• 2차 답변으로 품질 향상 달성\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Modular RAG 기능 맛보기 완료!\n",
    "\n",
    "### 📊 3단계 기능 체험 성과\n",
    "- **🎯 Query Routing**: LLM이 질문을 single/multi/clarify로 자동 분류\n",
    "- **🧠 Self-RAG Critic**: LLM이 자신의 답변을 객관적으로 평가 (커버리지/할루시네이션/누락 파셋)\n",
    "- **🔄 Retry with Refine**: 부족한 부분을 정밀 검색으로 보강해서 재시도\n",
    "\n",
    "### 💡 핵심 인사이트\n",
    "1. **메타인지 능력**: LLM이 분류→평가→보강의 고차원적 사고 수행\n",
    "2. **자가 개선**: 스스로 부족함을 감지하고 개선하는 능력\n",
    "3. **모듈화**: 각 기능이 독립적이면서도 유기적으로 연결\n",
    "\n",
    "### 🛠 실무 적용 팁\n",
    "- **Query Routing**: coverage 기준을 0.8→0.6으로 낮춰 민감도 조절\n",
    "- **Self-RAG**: 할루시네이션 임계치로 답변 신뢰성 보장\n",
    "- **Retry**: k=3→k=5로 늘려 보강 문서 수 조절\n",
    "\n",
    "### 🚀 다음 단계 확장\n",
    "- 더 정교한 라우팅 전략 (BM25 vs Vector vs Hybrid 선택)\n",
    "- Multi-hop Self-RAG (여러 번 반복 개선)\n",
    "- 성능 기반 Adaptive Selection (잘 되는 전략 학습)\n",
    "\n",
    "---\n",
    "\n",
    "🎉 **06번 모듈러 RAG 맛보기 완료!** 이제 LLM의 메타인지 능력을 활용한 지능형 RAG 시스템을 경험하셨습니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
