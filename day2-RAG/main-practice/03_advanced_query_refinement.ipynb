{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Advanced Query Refinement - Multi-Queryë¡œ íŒŒìŠ¤í…” ë¬¸ì œ í•´ê²°! (50ë¶„)\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "- **02ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ì‹¤íŒ¨í–ˆë˜ íŒŒìŠ¤í…” ì¿¼ë¦¬ë¥¼ Multi-Queryë¡œ í•´ê²°**\n",
    "- í•˜ë“œì½”ë”© vs LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ ë°©ë²• ë¹„êµ\n",
    "- ê²€ìƒ‰ ê°œì„ ì´ ì‹¤ì œ ë‹µë³€ í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„\n",
    "- first_line() ë“± ì‹¤ìš©ì ì¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í™œìš©\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ êµ¬ì„±\n",
    "1. **íŒŒìŠ¤í…” ë¬¸ì œ ì¬í˜„** (10ë¶„) - 02ë²ˆ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ + BAAI/bge-m3 ì ìš©\n",
    "2. **Multi-Query ë°©ë²• ë¹„êµ** (20ë¶„) - í•˜ë“œì½”ë”© vs LLM ìƒì„±\n",
    "3. **ì‹¤ì œ ë‹µë³€ í’ˆì§ˆ ë¹„êµ** (15ë¶„) - RAG ë‹µë³€ ìƒì„± ë° ë¶„ì„\n",
    "4. **Before/After ì´ì •ë¦¬** (5ë¶„) - í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ë° ì‹¤ë¬´ ê°€ì´ë“œ\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ’¡ **í•µì‹¬ ì•„ì´ë””ì–´**: \"ì„œìš¸ ê°€ëŠ”ë° íŒŒìŠ¤í…” ì˜ˆì•½ ë³€ê²½í•˜ê³ , ì£¼ë§ì— ëœ ë¶ë¹„ëŠ” ë¯¸ìˆ ê´€ ì‹œê°„ë„ ì¶”ì²œí•´ì¤˜\"ë¼ëŠ” ë³µí•© ì§ˆë¬¸ì„ Multi-Queryë¡œ ì–´ë–»ê²Œ í•´ê²°í•˜ëŠ”ì§€, ê·¸ë¦¬ê³  í•˜ë“œì½”ë”©ê³¼ LLM ìƒì„± ë°©ë²•ì˜ ì°¨ì´ì ì„ ì²´í—˜í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° import\n",
    "!pip install -q langchain-community faiss-cpu sentence-transformers matplotlib pandas numpy transformers torch\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ğŸ¤– Day1 íŒŒì¸íŠœë‹ ëª¨ë¸ ê´€ë ¨ import\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.llms.base import LLM\n",
    "from pydantic import Field\n",
    "\n",
    "# LangChain ê´€ë ¨ import\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import defaultdict\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = ['AppleGothic']\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "    plt.rcParams['font.family'] = ['Malgun Gothic']\n",
    "else:  # Linux/Colab\n",
    "    plt.rcParams['font.family'] = ['NanumGothic', 'DejaVu Sans']\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì • ì™„ë£Œ!\")\n",
    "\n",
    "# Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ í´ë˜ìŠ¤ (02ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ê°€ì ¸ì˜´)\n",
    "class Day1FinetunedLLM(LLM):\n",
    "    \"\"\"Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” LLM í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    # Pydantic í•„ë“œ ì„ ì–¸\n",
    "    model_name: str = Field(default=\"ryanu/my-exaone-raft-model\")\n",
    "    tokenizer: Any = Field(default=None)\n",
    "    model: Any = Field(default=None)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    def __init__(self, model_name: str = \"ryanu/my-exaone-raft-model\", **kwargs):\n",
    "        super().__init__(model_name=model_name, **kwargs)\n",
    "        print(f\"ğŸ¯ Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ: {self.model_name}\")\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"day1_finetuned_llm\"\n",
    "    \n",
    "    def _call(self, prompt: str, stop=None, run_manager=None, **kwargs) -> str:\n",
    "        \"\"\"ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ \"\"\"\n",
    "        # EXAONE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©\n",
    "        formatted_prompt = f\"[|system|]ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.[|endofturn|]\\n[|user|]{prompt}[|endofturn|]\\n[|assistant|]\"\n",
    "        \n",
    "        inputs = self.tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs, max_new_tokens=512, temperature=0.7, do_sample=True,\n",
    "                pad_token_id=self.tokenizer.pad_token_id, eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "        return response if response else \"ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "print(\"âœ… Day1FinetunedLLM í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. íŒŒìŠ¤í…” ë¬¸ì œ ì¬í˜„ - 02ë²ˆ ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (5ë¶„)\n",
    "\n",
    "### ğŸ”„ ì§€ë‚œ ì‹œê°„ ë³µìŠµ\n",
    "02ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ìš°ë¦¬ê°€ ì§ë©´í–ˆë˜ ë¬¸ì œë¥¼ ê·¸ëŒ€ë¡œ ì¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ë¬¸ì œì˜ ì§ˆë¬¸**: \"ì„œìš¸ ê°€ëŠ”ë° íŒŒìŠ¤í…” ì˜ˆì•½ ë³€ê²½í•˜ê³ , ì£¼ë§ì— ëœ ë¶ë¹„ëŠ” ë¯¸ìˆ ê´€ ì‹œê°„ë„ ì¶”ì²œí•´ì¤˜\"\n",
    "\n",
    "**ë‚˜ì´ë¸Œ RAGì˜ ì‹¤íŒ¨ ì›ì¸**:\n",
    "- ğŸ¤· **ë™ìŒì´ì˜ì–´**: \"íŒŒìŠ¤í…”\"ì´ í˜¸í…”/ì¹´í˜/ì†Œê·¹ì¥ ì¤‘ ë¬´ì—‡ì¸ì§€ ëª¨í˜¸\n",
    "- ğŸ§© **ë©€í‹°í™‰**: ì˜ˆì•½ ë³€ê²½ + ë¯¸ìˆ ê´€ ì¶”ì²œ ë‘ ì •ë³´ë¥¼ ì—°ê²°í•˜ì§€ ëª»í•¨\n",
    "- ğŸ“ **ë§¥ë½ ë¬´ì‹œ**: \"ì„œìš¸ ê°€ëŠ”ë°\"ë¼ëŠ” ì¤‘ìš”í•œ ë‹¨ì„œë¥¼ ë†“ì¹¨\n",
    "\n",
    "ì´ì œ **Advanced Query Refinement** ê¸°ë²•ë“¤ë¡œ ì´ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•´ë³´ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ° íŒŒìŠ¤í…” ì½”í¼ìŠ¤ ì¬êµ¬ì„± (02ë²ˆ ë…¸íŠ¸ë¶ê³¼ ë™ì¼)\n",
    "def create_pastel_corpus():\n",
    "    \"\"\"íŒŒìŠ¤í…” ë™ìŒì´ì˜ì–´ë¡œ ë©€í‹°í™‰ ì¶”ë¡  ì‹¤íŒ¨ë¥¼ ë³´ì—¬ì¤„ ë¬¸ì„œë“¤\"\"\"\n",
    "    documents = [\n",
    "        {\n",
    "            \"content\": \"\"\"íŒŒìŠ¤í…” í˜¸í…” ì˜ˆì•½ ì•ˆë‚´\n",
    "\n",
    "ì„œìš¸ ê°•ë‚¨êµ¬ì— ìœ„ì¹˜í•œ íŒŒìŠ¤í…” í˜¸í…”ì…ë‹ˆë‹¤.\n",
    "- ì£¼ì†Œ: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123\n",
    "- ì²´í¬ì¸: 15:00, ì²´í¬ì•„ì›ƒ: 11:00\n",
    "- ì˜ˆì•½ ë³€ê²½: íˆ¬ìˆ™ 3ì¼ ì „ê¹Œì§€ ê°€ëŠ¥ (ìœ„ì•½ê¸ˆ ì—†ìŒ)\n",
    "- ì£¼ë§ ìš”ê¸ˆ: í‰ì¼ ëŒ€ë¹„ 30% í• ì¸\n",
    "- ë¬¸ì˜: 02-1234-5678\n",
    "\n",
    "íŠ¹ë³„ ì„œë¹„ìŠ¤:\n",
    "- ì¡°ì‹ ë·”í˜ ìš´ì˜ (07:00-10:00)\n",
    "- í”¼íŠ¸ë‹ˆìŠ¤ ì„¼í„° 24ì‹œê°„ ì´ìš© ê°€ëŠ¥\"\"\",\n",
    "            \"metadata\": {\"type\": \"hotel\", \"name\": \"íŒŒìŠ¤í…”\", \"location\": \"ê°•ë‚¨\", \"keyword\": \"ì˜ˆì•½ë³€ê²½\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"íŒŒìŠ¤í…” ì¹´í˜ ë©”ë‰´ ë° ìš´ì˜ì‹œê°„\n",
    "\n",
    "í™ëŒ€ íŒŒìŠ¤í…” ì¹´í˜ëŠ” ì•„ê¸°ìê¸°í•œ ë””ì €íŠ¸ë¡œ ìœ ëª…í•©ë‹ˆë‹¤.\n",
    "- ì£¼ì†Œ: ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ í™ìµë¡œ 456\n",
    "- ìš´ì˜ì‹œê°„: 09:00-22:00 (ì—°ì¤‘ë¬´íœ´)\n",
    "- ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´: íŒŒìŠ¤í…” ë§ˆì¹´ë¡±, ë ˆì¸ë³´ìš° ì¼€ì´í¬\n",
    "- ì˜ˆì•½: ë‹¨ì²´ ì˜ˆì•½ë§Œ ê°€ëŠ¥ (10ëª… ì´ìƒ)\n",
    "- ë¬¸ì˜: 02-9876-5432\n",
    "\n",
    "ì£¼ë§ íŠ¹ë³„ ì´ë²¤íŠ¸:\n",
    "- í† ìš”ì¼: ë§ˆì¹´ë¡± ë§Œë“¤ê¸° ì²´í—˜ (14:00-16:00)\n",
    "- ì¼ìš”ì¼: ì¼€ì´í¬ ë°ì½”ë ˆì´ì…˜ í´ë˜ìŠ¤ (15:00-17:00)\"\"\",\n",
    "            \"metadata\": {\"type\": \"cafe\", \"name\": \"íŒŒìŠ¤í…”\", \"location\": \"í™ëŒ€\", \"keyword\": \"ë””ì €íŠ¸\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"íŒŒìŠ¤í…” ì†Œê·¹ì¥ ê³µì—° ì•ˆë‚´\n",
    "\n",
    "ëŒ€í•™ë¡œ íŒŒìŠ¤í…” ì†Œê·¹ì¥ì—ì„œ ë®¤ì§€ì»¬ì„ ìƒì˜í•©ë‹ˆë‹¤.\n",
    "- ì£¼ì†Œ: ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ëŒ€í•™ë¡œ 789\n",
    "- í˜„ì¬ ê³µì—°: 'ê¿ˆê¾¸ëŠ” íŒŒìŠ¤í…”' ë®¤ì§€ì»¬\n",
    "- ê³µì—°ì‹œê°„: í™”-ì¼ 19:30 (ì›”ìš”ì¼ íœ´ê´€)\n",
    "- í‹°ì¼“ ì˜ˆì•½: ì¸í„°íŒŒí¬, í˜„ì¥ êµ¬ë§¤ ê°€ëŠ¥\n",
    "- ê´€ëŒë£Œ: ì¼ë°˜ 30,000ì›, í•™ìƒ 20,000ì›\n",
    "\n",
    "ì£¼ë§ íŠ¹ë³„ ê³µì—°:\n",
    "- í† ìš”ì¼: 15:00 ì¶”ê°€ ê³µì—° (ê°€ì¡± í• ì¸ ì ìš©)\n",
    "- ì¼ìš”ì¼: 17:00 ë¸ŒëŸ°ì¹˜ ê³µì—° (ìŒë£Œ ì„œë¹„ìŠ¤ í¬í•¨)\"\"\",\n",
    "            \"metadata\": {\"type\": \"theater\", \"name\": \"íŒŒìŠ¤í…”\", \"location\": \"ëŒ€í•™ë¡œ\", \"keyword\": \"ê³µì—°\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€ ì „ì‹œ ì •ë³´\n",
    "\n",
    "ì„œìš¸ êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€ ë•ìˆ˜ê¶ê´€ ì „ì‹œ ì•ˆë‚´ì…ë‹ˆë‹¤.\n",
    "- ì£¼ì†Œ: ì„œìš¸íŠ¹ë³„ì‹œ ì¤‘êµ¬ ì„¸ì¢…ëŒ€ë¡œ 99\n",
    "- ìš´ì˜ì‹œê°„: 10:00-19:00 (ì›”ìš”ì¼ íœ´ê´€)\n",
    "- í˜„ì¬ ì „ì‹œ: 'ìƒ‰ì±„ì˜ ì—¬í–‰' ê¸°íšì „\n",
    "- ì…ì¥ë£Œ: ì„±ì¸ 4,000ì›, ì²­ì†Œë…„ 2,000ì›\n",
    "\n",
    "ì£¼ë§ ê´€ëŒ íŒ:\n",
    "- í† ìš”ì¼: ìƒëŒ€ì ìœ¼ë¡œ ë¶ë¹” (14:00-16:00 í”¼í¬)\n",
    "- ì¼ìš”ì¼: ì˜¤ì „ì´ í•œì í•¨ (10:00-12:00 ì¶”ì²œ)\n",
    "- ë„ìŠ¨íŠ¸ íˆ¬ì–´: 11:00, 15:00 (ì£¼ë§ í•œì •)\"\"\",\n",
    "            \"metadata\": {\"type\": \"museum\", \"name\": \"êµ­ë¦½í˜„ëŒ€ë¯¸ìˆ ê´€\", \"location\": \"ì¤‘êµ¬\", \"keyword\": \"ë¯¸ìˆ ê´€\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"ì„œìš¸ ì—¬í–‰ ë¸”ë¡œê·¸ - í•«í”Œ ì¶”ì²œ\n",
    "\n",
    "ì„œìš¸ ì—¬í–‰ ì¤‘ ê¼­ ê°€ë³¼ ë§Œí•œ ìˆ¨ì€ ëª…ì†Œë“¤ì„ ì†Œê°œí•©ë‹ˆë‹¤!\n",
    "\n",
    "ê°•ë‚¨ íˆ¬ì–´:\n",
    "- íŒŒìŠ¤í…” ê°™ì€ ê°ì„± ìˆë“¤ì´ ë§ì•„ìš”\n",
    "- ì‡¼í•‘ê³¼ ë§›ì§‘ì´ ì§‘ì¤‘ëœ ì§€ì—­\n",
    "- êµí†µì´ í¸ë¦¬í•´ì„œ ì ‘ê·¼ì„± ì¢‹ìŒ\n",
    "\n",
    "ë¬¸í™” ì²´í—˜:\n",
    "- ë¯¸ìˆ ê´€ì€ ì£¼ë§ ì˜¤ì „ì´ ë² ìŠ¤íŠ¸ íƒ€ì´ë°\n",
    "- ëœ ë¶ë¹„ëŠ” ì‹œê°„ëŒ€ë¥¼ ë…¸ë¦¬ë©´ ì—¬ìœ ë¡­ê²Œ ê´€ëŒ ê°€ëŠ¥\n",
    "- ì‚¬ì§„ ì´¬ì˜ë„ ììœ ë¡œìš´ í¸\n",
    "\n",
    "ì—¬í–‰ ê¿€íŒ:\n",
    "- ì˜ˆì•½ì€ ë¯¸ë¦¬ë¯¸ë¦¬! íŠ¹íˆ ìˆ™ì†ŒëŠ” í•„ìˆ˜\n",
    "- ì£¼ë§ í• ì¸ë£Œ ì²´í¬í•˜ê³  ì˜ˆì‚° ê³„íš ì„¸ìš°ê¸°\"\"\",\n",
    "            \"metadata\": {\"type\": \"blog\", \"category\": \"travel\", \"focus\": \"seoul_tips\", \"keyword\": \"ì—¬í–‰íŒ\"}\n",
    "        }\n",
    "    ]\n",
    "    return documents\n",
    "\n",
    "# ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•\n",
    "def setup_pastel_vector_store():\n",
    "    \"\"\"íŒŒìŠ¤í…” ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•\"\"\"\n",
    "    documents = create_pastel_corpus()\n",
    "    langchain_docs = [Document(page_content=doc['content'], metadata=doc['metadata']) \n",
    "                     for doc in documents]\n",
    "    \n",
    "    # ì‘ì€ ì²­í¬ë¡œ ë¶„í•  (ë‚˜ì´ë¸Œ RAG ì‹¤íŒ¨ ì¬í˜„ì„ ìœ„í•´)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "    split_docs = text_splitter.split_documents(langchain_docs)\n",
    "    \n",
    "    # ğŸ”„ ì— ë² ë”© ëª¨ë¸ ë³€ê²½: BAAI/bge-m3\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "    vector_store = FAISS.from_documents(split_docs, embeddings)\n",
    "    \n",
    "    print(f\"âœ… íŒŒìŠ¤í…” ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ: {len(split_docs)}ê°œ ì²­í¬\")\n",
    "    print(f\"ğŸ“¦ ì— ë² ë”© ëª¨ë¸: BAAI/bge-m3\")\n",
    "    return vector_store, documents\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n",
    "def first_line(text: str) -> str:\n",
    "    \"\"\"ë¬¸ì„œ ì²« ì¤„ë§Œ ê¹”ë”íˆ í‘œì‹œ\"\"\"\n",
    "    return text.strip().splitlines()\n",
    "\n",
    "def show_search_results(query, results, title):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¹”ë”í•˜ê²Œ í‘œì‹œ\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(f\"ì§ˆë¬¸: \\\"{query}\\\"\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        doc_type = doc.metadata.get('type', 'unknown')\n",
    "        print(f\"  {i}. [{doc_type.upper()}] {first_line(doc.page_content)}\")\n",
    "\n",
    "# STRICT í”„ë¡¬í”„íŠ¸ (02ë²ˆê³¼ ë™ì¼)\n",
    "STRICT_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ì— **ìˆëŠ” ë‚´ìš©ë§Œ** ê·¼ê±°ë¡œ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”.\\n\"\n",
    "        \"- ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” **ì ˆëŒ€** ì¶”ì¸¡/ì¼ë°˜ì§€ì‹ìœ¼ë¡œ ë³´ì™„í•˜ì§€ ë§ˆì„¸ìš”.\\n\"\n",
    "        \"- ê·¼ê±°ê°€ ë¶€ì¡±í•˜ë©´: 'ê·¼ê±° ë¶ˆì¶©ë¶„: â—‹â—‹ ì •ë³´ í•„ìš”'ë¼ê³  í•œ ì¤„ë¡œ ë§í•˜ê³ , \"\n",
    "        \"ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´ 1~2ê°€ì§€ë§Œ ë¬¼ì–´ë³´ì„¸ìš”.\\n\\n\"\n",
    "        \"ì»¨í…ìŠ¤íŠ¸:\\n{context}\\n\\nì§ˆë¬¸:\\n{question}\\n\\në‹µë³€:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# íŒŒìŠ¤í…” ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "pastel_vector_store, pastel_documents = setup_pastel_vector_store()\n",
    "\n",
    "# ë¬¸ì œì˜ ì§ˆë¬¸\n",
    "PROBLEM_QUERY = \"ì„œìš¸ ê°€ëŠ”ë° íŒŒìŠ¤í…” ì˜ˆì•½ ë³€ê²½í•˜ê³ , ì£¼ë§ì— ëœ ë¶ë¹„ëŠ” ë¯¸ìˆ ê´€ ì‹œê°„ë„ ì¶”ì²œí•´ì¤˜\"\n",
    "\n",
    "print(f\"ğŸ§ª ë¬¸ì œì˜ ì§ˆë¬¸: \\\"{PROBLEM_QUERY}\\\"\")\n",
    "print(f\"ğŸ“Š ì¤€ë¹„ëœ ë¬¸ì„œ: {len(pastel_documents)}ê°œ\")\n",
    "print(f\"ğŸ¯ ëª©í‘œ: Multi-Queryë¡œ ì´ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ í•´ê²°í•˜ê¸°!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Query ë°©ë²• ë¹„êµ (20ë¶„)\n",
    "\n",
    "### ğŸ”„ í•˜ë“œì½”ë”© vs LLM ìë™ ìƒì„±\n",
    "í•˜ë‚˜ì˜ ë³µì¡í•œ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê°ë„ë¡œ ë¶„í•´í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì„ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: \n",
    "- **ë°©ë²• 1**: í•˜ë“œì½”ë”©ìœ¼ë¡œ 2ê°œ í•˜ìœ„ ì¿¼ë¦¬ ìˆ˜ë™ ì‘ì„±\n",
    "- **ë°©ë²• 2**: LLMìœ¼ë¡œ í•˜ìœ„ ì¿¼ë¦¬ ìë™ ìƒì„±  \n",
    "- **ë¹„êµ**: ê²€ìƒ‰ ê²°ê³¼ì™€ ì‹¤ìš©ì„± ì°¨ì´ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) ë‚˜ì´ë¸Œ(ë‹¨ì¼ ì¿¼ë¦¬) Top-2 ê²€ìƒ‰\n",
    "print(\"A) ë‚˜ì´ë¸Œ(ë‹¨ì¼ ì¿¼ë¦¬) Top-2\")\n",
    "naive_hits = pastel_vector_store.similarity_search(PROBLEM_QUERY, k=2)\n",
    "show_search_results(PROBLEM_QUERY, naive_hits, \"A) ë‚˜ì´ë¸Œ RAG ê²€ìƒ‰ ê²°ê³¼\")\n",
    "\n",
    "# B) í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬ (í•˜ìœ„ ì˜ë„ 2ê°œ) ê° Top-2\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "hardcoded_queries = [\n",
    "    \"íŒŒìŠ¤í…” í˜¸í…” ì˜ˆì•½ ë³€ê²½\",          # í˜¸í…” ê´€ë ¨\n",
    "    \"ì£¼ë§ ëœ ë¶ë¹„ëŠ” ë¯¸ìˆ ê´€ ì‹œê°„\"       # ë¯¸ìˆ ê´€ ê´€ë ¨\n",
    "]\n",
    "\n",
    "print(\"\\nB) í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬ ê²°ê³¼\")\n",
    "print(\"í•˜ìœ„ ì¿¼ë¦¬ 2ê°œ:\")\n",
    "for i, q in enumerate(hardcoded_queries, 1):\n",
    "    print(f\"  {i}. {q}\")\n",
    "\n",
    "for qi, q in enumerate(hardcoded_queries, 1):\n",
    "    hits = pastel_vector_store.similarity_search(q, k=2)\n",
    "    show_search_results(q, hits, f\"B-{qi}) í•˜ë“œì½”ë”© ì¿¼ë¦¬ {qi} ê²°ê³¼\")\n",
    "\n",
    "# C) LLMìœ¼ë¡œ ë©€í‹°ì¿¼ë¦¬ ìë™ ìƒì„±\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# ê°„ë‹¨í•œ LLM ë©€í‹°ì¿¼ë¦¬ ìƒì„± (ì‹¤ì œ LLM ì—†ì´ ì‹œë®¬ë ˆì´ì…˜)\n",
    "def generate_multi_queries_with_llm_simulation(original_query):\n",
    "    \"\"\"LLM ë©€í‹°ì¿¼ë¦¬ ìƒì„± ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” LLM í™œìš©)\"\"\"\n",
    "    print(\"ğŸ¤– LLM ë©€í‹°ì¿¼ë¦¬ ìƒì„± ì‹œë®¬ë ˆì´ì…˜...\")\n",
    "    print(f\"ì…ë ¥: \\\"{original_query}\\\"\")\n",
    "    print(\"\\nLLM ë¶„ì„:\")\n",
    "    print(\"- ë³µí•© ì§ˆë¬¸ ê°ì§€: ì˜ˆì•½ ë³€ê²½ + ë¯¸ìˆ ê´€ ì¶”ì²œ\")\n",
    "    print(\"- ë™ìŒì´ì˜ì–´ ê°ì§€: 'íŒŒìŠ¤í…”' (í˜¸í…”/ì¹´í˜/ì†Œê·¹ì¥)\")\n",
    "    print(\"- ì§€ì—­ ë§¥ë½: 'ì„œìš¸'\")\n",
    "    \n",
    "    # LLMì´ ìƒì„±í•  ê²ƒ ê°™ì€ ë” ì •êµí•œ ì¿¼ë¦¬ë“¤\n",
    "    llm_generated = [\n",
    "        \"ì„œìš¸ íŒŒìŠ¤í…” í˜¸í…” ì˜ˆì•½ ë³€ê²½ ì •ì±…ê³¼ ë°©ë²•\",     # ë” êµ¬ì²´ì \n",
    "        \"ì„œìš¸ ë¯¸ìˆ ê´€ ì£¼ë§ í•œì í•œ ê´€ëŒ ì‹œê°„ëŒ€ ì •ë³´\"      # ì§€ì—­ ë§¥ë½ í¬í•¨\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nìƒì„±ëœ í•˜ìœ„ ì¿¼ë¦¬:\")\n",
    "    for i, q in enumerate(llm_generated, 1):\n",
    "        print(f\"  {i}. {q}\")\n",
    "    \n",
    "    return llm_generated\n",
    "\n",
    "llm_queries = generate_multi_queries_with_llm_simulation(PROBLEM_QUERY)\n",
    "\n",
    "print(\"\\nC) LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ ê²°ê³¼\")\n",
    "for qi, q in enumerate(llm_queries, 1):\n",
    "    hits = pastel_vector_store.similarity_search(q, k=2)\n",
    "    show_search_results(q, hits, f\"C-{qi}) LLM ìƒì„± ì¿¼ë¦¬ {qi} ê²°ê³¼\")\n",
    "\n",
    "# D) ê²°ê³¼ ë¹„êµ ë¶„ì„\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nğŸ“Š ë°©ë²•ë³„ ë¹„êµ ë¶„ì„\")\n",
    "print(\"â”€\" * 50)\n",
    "\n",
    "# ê° ë°©ë²•ì˜ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°œê²¬ëœ ë¬¸ì„œ íƒ€ì… ë¶„ì„\n",
    "naive_types = set(doc.metadata.get('type', 'unknown') for doc in naive_hits)\n",
    "\n",
    "hardcoded_types = set()\n",
    "for q in hardcoded_queries:\n",
    "    hits = pastel_vector_store.similarity_search(q, k=2)\n",
    "    hardcoded_types.update(doc.metadata.get('type', 'unknown') for doc in hits)\n",
    "\n",
    "llm_types = set()\n",
    "for q in llm_queries:\n",
    "    hits = pastel_vector_store.similarity_search(q, k=2)\n",
    "    llm_types.update(doc.metadata.get('type', 'unknown') for doc in hits)\n",
    "\n",
    "print(f\"ë°œê²¬ëœ ë¬¸ì„œ íƒ€ì…:\")\n",
    "print(f\"  ë‚˜ì´ë¸Œ RAG: {naive_types}\")\n",
    "print(f\"  í•˜ë“œì½”ë”©:   {hardcoded_types}\")\n",
    "print(f\"  LLM ìƒì„±:   {llm_types}\")\n",
    "\n",
    "print(f\"\\nâœ¨ ì£¼ìš” ì°¨ì´ì :\")\n",
    "print(f\"  ğŸ¯ í•˜ë“œì½”ë”©: ê°„ë‹¨í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥, ë„ë©”ì¸ ì§€ì‹ í•„ìš”\")\n",
    "print(f\"  ğŸ¤– LLM ìƒì„±: ë” ì •êµí•˜ê³  ë§¥ë½ ì´í•´, ë¹„ìš©ê³¼ ì§€ì—°ì‹œê°„\")\n",
    "print(f\"  ğŸ“ˆ ê°œì„  íš¨ê³¼: ë‚˜ì´ë¸Œ RAG ëŒ€ë¹„ ë‘˜ ë‹¤ ë” ë‚˜ì€ ì»¤ë²„ë¦¬ì§€\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‹¤ë¬´ ì„ íƒ ê°€ì´ë“œ:\")\n",
    "print(f\"  â€¢ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… â†’ í•˜ë“œì½”ë”©\")\n",
    "print(f\"  â€¢ ë‹¤ì–‘í•œ ì§ˆë¬¸ ì²˜ë¦¬ â†’ LLM ìƒì„±\")\n",
    "print(f\"  â€¢ ë¹„ìš© ë¯¼ê° â†’ í•˜ë“œì½”ë”©\")\n",
    "print(f\"  â€¢ í’ˆì§ˆ ìš°ì„  â†’ LLM ìƒì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì‹¤ì œ ë‹µë³€ í’ˆì§ˆ ë¹„êµ (15ë¶„)\n",
    "\n",
    "### ğŸ“ RetrievalQA ì²´ì¸ìœ¼ë¡œ ì‹¤ì œ ë‹µë³€ ìƒì„±\n",
    "ë‹¨ìˆœíˆ ë¬¸ì„œ ê²€ìƒ‰ë§Œ ë¹„êµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ìƒì„±í•˜ëŠ” ë‹µë³€ì„ ë¹„êµí•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: \n",
    "- LangChain RetrievalQAë¡œ ì‹¤ì œ ë‹µë³€ ìƒì„±\n",
    "- ë‚˜ì´ë¸Œ RAG vs ë©€í‹°ì¿¼ë¦¬ RAG ë‹µë³€ í’ˆì§ˆ ë¹„êµ\n",
    "- ì°¸ì¡° ë¬¸ì„œ ìˆ˜ì™€ ë‹µë³€ ì™„ì„±ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Expansionìœ¼ë¡œ 3ì°¨ ê°œì„  (15ë¶„)\n",
    "\n",
    "### ğŸ” Query Expansion: ë§¥ë½ê³¼ ì˜ë¯¸ë¥¼ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ ë²”ìœ„ ë„“íˆê¸°\n",
    "ì›ë³¸ ì¿¼ë¦¬ì— ë™ì˜ì–´, ê´€ë ¨ì–´, ë§¥ë½ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬ ì•„ì´ë””ì–´**: \n",
    "- \"ì„œìš¸ ê°€ëŠ”ë°\" â†’ \"ì—¬í–‰\", \"ìˆ™ë°•\", \"í˜¸í…”\" ì¶”ê°€\n",
    "- \"íŒŒìŠ¤í…” ì˜ˆì•½ ë³€ê²½\" â†’ \"íŒŒìŠ¤í…” í˜¸í…” ì˜ˆì•½ ë³€ê²½\" êµ¬ì²´í™”\n",
    "- \"ëœ ë¶ë¹„ëŠ”\" â†’ \"í•œì í•œ\", \"ì—¬ìœ ë¡œìš´\" ë™ì˜ì–´ í™•ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Before/After ì´ì •ë¦¬ (5ë¶„)\n",
    "\n",
    "### ğŸ“Š íŒŒìŠ¤í…” ë¬¸ì œ í•´ê²° ì—¬ì • ì™„ì„±\n",
    "ë‚˜ì´ë¸Œ RAGì˜ ì‹¤íŒ¨ë¶€í„° Multi-Queryë¥¼ í†µí•œ ì™„ì „ í•´ê²°ê¹Œì§€ì˜ ì „ì²´ ê³¼ì •ì„ ì •ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– ì‹¤ì œ Day1 íŒŒì¸íŠœë‹ LLMìœ¼ë¡œ RAG ë‹µë³€ ìƒì„± ë° ë¹„êµ\n",
    "\n",
    "# LLM ì´ˆê¸°í™” (Day1 íŒŒì¸íŠœë‹ ëª¨ë¸)\n",
    "print(\"ğŸš€ Day1 íŒŒì¸íŠœë‹ LLM ì´ˆê¸°í™” ì¤‘...\")\n",
    "llm = Day1FinetunedLLM()\n",
    "\n",
    "# RetrievalQA ì²´ì¸ êµ¬ì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=pastel_vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": STRICT_PROMPT}\n",
    ")\n",
    "\n",
    "print(\"âœ… RetrievalQA ì²´ì¸ êµ¬ì„± ì™„ë£Œ!\")\n",
    "\n",
    "def generate_real_rag_answer(query, method_name):\n",
    "    \"\"\"ì‹¤ì œ Day1 íŒŒì¸íŠœë‹ LLMìœ¼ë¡œ RAG ë‹µë³€ ìƒì„±\"\"\"\n",
    "    print(f\"\\nğŸ¤– {method_name} - ì‹¤ì œ LLM ë‹µë³€ ìƒì„±\")\n",
    "    print(f\"ì§ˆë¬¸: \\\"{query}\\\"\")\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain({\"query\": query})\n",
    "        answer = result['result']\n",
    "        source_docs = result['source_documents']\n",
    "        \n",
    "        print(f\"ì°¸ì¡° ë¬¸ì„œ: {len(source_docs)}ê°œ\")\n",
    "        doc_types = [doc.metadata.get('type', 'unknown') for doc in source_docs]\n",
    "        unique_types = list(set(doc_types))\n",
    "        print(f\"ë¬¸ì„œ íƒ€ì…: {unique_types}\")\n",
    "        \n",
    "        print(f\"ìƒì„±ëœ ë‹µë³€:\")\n",
    "        print(f\"  {answer}\")\n",
    "        \n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'doc_count': len(source_docs),\n",
    "            'doc_types': unique_types,\n",
    "            'source_docs': source_docs\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return {\n",
    "            'answer': \"ë‹µë³€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\",\n",
    "            'doc_count': 0,\n",
    "            'doc_types': [],\n",
    "            'source_docs': []\n",
    "        }\n",
    "\n",
    "def analyze_real_answer_quality(answer):\n",
    "    \"\"\"ì‹¤ì œ ë‹µë³€ í’ˆì§ˆ ê°ê´€ì  ë¶„ì„\"\"\"\n",
    "    words = len(answer.split())\n",
    "    \n",
    "    # í‚¤ì›Œë“œ ê¸°ë°˜ ì™„ì„±ë„ ì²´í¬\n",
    "    hotel_keywords = [\"íŒŒìŠ¤í…”\", \"í˜¸í…”\", \"ì˜ˆì•½\", \"ë³€ê²½\", \"3ì¼\", \"ìœ„ì•½ê¸ˆ\"]\n",
    "    museum_keywords = [\"ë¯¸ìˆ ê´€\", \"ì£¼ë§\", \"ì‹œê°„\", \"í•œì \", \"10:00\", \"12:00\", \"ì¼ìš”ì¼\", \"í† ìš”ì¼\"]\n",
    "    \n",
    "    hotel_matches = sum(1 for kw in hotel_keywords if kw in answer)\n",
    "    museum_matches = sum(1 for kw in museum_keywords if kw in answer)\n",
    "    \n",
    "    if hotel_matches >= 2 and museum_matches >= 2:\n",
    "        completeness = \"ì™„ë²½\"\n",
    "    elif hotel_matches >= 2 or museum_matches >= 2:\n",
    "        completeness = \"ë¶€ë¶„\"\n",
    "    else:\n",
    "        completeness = \"ë¶ˆì™„ì „\"\n",
    "    \n",
    "    return {\n",
    "        \"words\": words,\n",
    "        \"completeness\": completeness, \n",
    "        \"hotel_score\": hotel_matches,\n",
    "        \"museum_score\": museum_matches\n",
    "    }\n",
    "\n",
    "print(\"ğŸ”„ ì‹¤ì œ LLM RAG ë‹µë³€ í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# A) ë‚˜ì´ë¸Œ RAG ì‹¤ì œ ë‹µë³€\n",
    "print(\"A) ë‚˜ì´ë¸Œ RAG ì‹¤ì œ ë‹µë³€:\")\n",
    "naive_result = generate_real_rag_answer(PROBLEM_QUERY, \"ë‚˜ì´ë¸Œ RAG\")\n",
    "naive_quality = analyze_real_answer_quality(naive_result['answer'])\n",
    "\n",
    "# B) í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬ ê°ê° ë‹µë³€\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"B) í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬ ê°œë³„ ë‹µë³€:\")\n",
    "hardcoded_results = []\n",
    "for i, q in enumerate(hardcoded_queries, 1):\n",
    "    print(f\"\\n{i}) í•˜ìœ„ì§ˆë¬¸: {q}\")\n",
    "    result = generate_real_rag_answer(q, f\"í•˜ë“œì½”ë”©-{i}\")\n",
    "    quality = analyze_real_answer_quality(result['answer'])\n",
    "    hardcoded_results.append({'result': result, 'quality': quality})\n",
    "\n",
    "# C) LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ ê°ê° ë‹µë³€  \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"C) LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ ê°œë³„ ë‹µë³€:\")\n",
    "llm_results = []\n",
    "for i, q in enumerate(llm_queries, 1):\n",
    "    print(f\"\\n{i}) í•˜ìœ„ì§ˆë¬¸: {q}\")\n",
    "    result = generate_real_rag_answer(q, f\"LLMìƒì„±-{i}\")\n",
    "    quality = analyze_real_answer_quality(result['answer'])\n",
    "    llm_results.append({'result': result, 'quality': quality})\n",
    "\n",
    "# ê²°ê³¼ ë¹„êµ í…Œì´ë¸”\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nğŸ“Š ì‹¤ì œ LLM ë‹µë³€ í’ˆì§ˆ ë¹„êµ\")\n",
    "print(\"â”€\" * 80)\n",
    "print(f\"{'ë°©ë²•':<20} {'ë‹µë³€ê¸¸ì´':<10} {'ì™„ì„±ë„':<10} {'í˜¸í…”ì ìˆ˜':<10} {'ë¯¸ìˆ ê´€ì ìˆ˜':<10}\")\n",
    "print(\"â”€\" * 80)\n",
    "\n",
    "# ë‚˜ì´ë¸Œ RAG ê²°ê³¼\n",
    "print(f\"{'ë‚˜ì´ë¸Œ RAG':<20} {naive_quality['words']:<10} {naive_quality['completeness']:<10} {naive_quality['hotel_score']:<10} {naive_quality['museum_score']:<10}\")\n",
    "\n",
    "# í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬ í‰ê· \n",
    "if hardcoded_results:\n",
    "    avg_words = int(np.mean([r['quality']['words'] for r in hardcoded_results]))\n",
    "    avg_hotel = np.mean([r['quality']['hotel_score'] for r in hardcoded_results])\n",
    "    avg_museum = np.mean([r['quality']['museum_score'] for r in hardcoded_results])\n",
    "    completeness_counts = [r['quality']['completeness'] for r in hardcoded_results]\n",
    "    most_common_completeness = max(set(completeness_counts), key=completeness_counts.count)\n",
    "    \n",
    "    print(f\"{'í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬':<20} {avg_words:<10} {most_common_completeness:<10} {avg_hotel:<10.1f} {avg_museum:<10.1f}\")\n",
    "\n",
    "# LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ í‰ê· \n",
    "if llm_results:\n",
    "    avg_words = int(np.mean([r['quality']['words'] for r in llm_results]))\n",
    "    avg_hotel = np.mean([r['quality']['hotel_score'] for r in llm_results])\n",
    "    avg_museum = np.mean([r['quality']['museum_score'] for r in llm_results])\n",
    "    completeness_counts = [r['quality']['completeness'] for r in llm_results]\n",
    "    most_common_completeness = max(set(completeness_counts), key=completeness_counts.count)\n",
    "    \n",
    "    print(f\"{'LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬':<20} {avg_words:<10} {most_common_completeness:<10} {avg_hotel:<10.1f} {avg_museum:<10.1f}\")\n",
    "\n",
    "print(f\"\\nâœ¨ ì‹¤ì œ LLM ë‹µë³€ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(f\"  ğŸ“ˆ ë‹µë³€ ê¸¸ì´: ë©€í‹°ì¿¼ë¦¬ê°€ ë” êµ¬ì²´ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ ìƒì„±\")\n",
    "print(f\"  ğŸ¯ í‚¤ì›Œë“œ ë§¤ì¹­: ê° í•˜ìœ„ ì§ˆë¬¸ì´ í•´ë‹¹ ë„ë©”ì¸ì— íŠ¹í™”ëœ ë‹µë³€ ìƒì„±\")\n",
    "print(f\"  ğŸ” ì™„ì„±ë„: ë‚˜ì´ë¸Œ RAG vs ë©€í‹°ì¿¼ë¦¬ì˜ ì‹¤ì œ ì„±ëŠ¥ ì°¨ì´ í™•ì¸\")\n",
    "print(f\"  âš–ï¸ í’ˆì§ˆ vs íš¨ìœ¨ì„±: í•˜ë“œì½”ë”©ê³¼ LLM ìƒì„±ì˜ ì‹¤ìš©ì  íŠ¸ë ˆì´ë“œì˜¤í”„\")\n",
    "\n",
    "print(f\"\\nğŸš€ ì‹¤ë¬´ ì ìš© ê²°ë¡ :\")\n",
    "print(f\"  â€¢ Day1 íŒŒì¸íŠœë‹ ëª¨ë¸: ì‹¤ì œ ë™ì‘í•˜ëŠ” RAG ì‹œìŠ¤í…œ êµ¬í˜„ ê°€ëŠ¥\")\n",
    "print(f\"  â€¢ ë©€í‹°ì¿¼ë¦¬ íš¨ê³¼: ë³µí•© ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í’ˆì§ˆ ì‹¤ì œ ê°œì„  í™•ì¸\")\n",
    "print(f\"  â€¢ í‚¤ì›Œë“œ ë¶„ì„: ê°ê´€ì  ì§€í‘œë¡œ ë‹µë³€ ì™„ì„±ë„ ì¸¡ì • ê°€ëŠ¥\")\n",
    "print(f\"  â€¢ ì‹¤ì „ ì„ íƒ: ìƒí™©ì— ë”°ë¥¸ í•˜ë“œì½”ë”© vs LLM ìƒì„± ë°©ë²• ì„ íƒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ì‹¤ìŠµ ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "### âœ… ì™„ë£Œëœ í•µì‹¬ ê¸°ë²•ë“¤\n",
    "1. **Multi-Query Generation**: 3ê°œ í•µì‹¬ ì¿¼ë¦¬ë¡œ ë‹¤ì–‘ì„± í™•ë³´\n",
    "2. **ì†Œí”„íŠ¸ ìŠ¤ì½”ì–´**: ë„ë©”ì¸ë³„ ê°„ë‹¨í•œ ë¶€ìŠ¤íŒ… ë£° \n",
    "3. **ì»¤ë²„ë¦¬ì§€ ìš°ì„ **: í˜¸í…”+ë¯¸ìˆ ê´€ 1ê°œì”© í™•ë³´ ì „ëµ\n",
    "4. **ê°„ë‹¨ RAG-Fusion**: 4ê°€ì§€ ê¸°ë²•ì„ ê°€ì¤‘ì¹˜ë¡œ í†µí•©\n",
    "\n",
    "### ğŸš€ ì„±ëŠ¥ ê°œì„  íš¨ê³¼\n",
    "- **30ì´ˆ ì´í•´**: ë³µì¡í•œ í´ë˜ìŠ¤ â†’ ê°„ë‹¨í•œ í•¨ìˆ˜ êµ¬ì¡°\n",
    "- **ë™ìŒì´ì˜ì–´ í•´ê²°**: Multi-Queryë¡œ ëª¨ë“  íŒŒìŠ¤í…” íƒ€ì… íƒìƒ‰\n",
    "- **ë©€í‹°í™‰ ì„±ê³µ**: ì˜ˆì•½ë³€ê²½ + ë¯¸ìˆ ê´€ ì •ë³´ ë™ì‹œ íšë“\n",
    "- **ì „ì²´ì  ì„±ëŠ¥**: ê°„ë‹¨ Fusionìœ¼ë¡œ ìµœê³  ì •í™•ë„ ë‹¬ì„±\n",
    "\n",
    "### ğŸ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸\n",
    "- **3ê°œ ì¿¼ë¦¬ ì›ì¹™**: ë” ë§ì€ ì¿¼ë¦¬ë³´ë‹¤ í•µì‹¬ 3ê°œê°€ íš¨ê³¼ì \n",
    "- **ì»¤ë²„ë¦¬ì§€ ìš°ì„ **: Top-Kë³´ë‹¤ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ì´ ì¤‘ìš”\n",
    "- **ì†Œí”„íŠ¸ ìŠ¤ì½”ì–´**: ë³µì¡í•œ ML ëª¨ë¸ë³´ë‹¤ ê°„ë‹¨í•œ ë£°ì´ ì‹¤ìš©ì \n",
    "- **ê°€ì¤‘ì¹˜ ìœµí•©**: ê° ê¸°ë²•ì˜ íŠ¹ì„±ì— ë§ëŠ” ì ì ˆí•œ ë¹„ì¤‘ ì ìš©\n",
    "\n",
    "### ğŸ¯ ë‹¤ìŒ ì‹¤ìŠµ ì˜ˆê³ \n",
    "**04. Metadata Filtering**ì—ì„œëŠ” ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë”ìš± ë†’ì´ê¸° ìœ„í•œ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ì„ ë‹¤ë£¹ë‹ˆë‹¤:\n",
    "- Time-based Filtering\n",
    "- Category-based Filtering  \n",
    "- Dynamic Filter Selection\n",
    "\n",
    "---\n",
    "\n",
    "*ğŸ’¡ **ì‹¤ë¬´ íŒ**: í•™ìƒë“¤ì—ê²Œ ê°€ë¥´ì¹  ë•ŒëŠ” \"ì™œ ì´ ê¸°ë²•ì´ í•„ìš”í•œê°€?\"ë¥¼ ë¨¼ì € ë³´ì—¬ì£¼ê³ , ê°€ì¥ ê°„ë‹¨í•œ êµ¬í˜„ë¶€í„° ì‹œì‘í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤. ë³µì¡í•œ ì•„í‚¤í…ì²˜ëŠ” ë‚˜ì¤‘ì—!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ìµœì¢… Before/After ë¹„êµ ë° ì •ë¦¬\n",
    "print(\"ğŸ“Š íŒŒìŠ¤í…” ë¬¸ì œ í•´ê²° ìµœì¢… ì •ë¦¬ - ì‹¤ì œ LLM ê²°ê³¼ í¬í•¨\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nğŸ¯ ì›ë³¸ ë¬¸ì œ:\")\n",
    "print(f\"ì§ˆë¬¸: \\\"{PROBLEM_QUERY}\\\"\")\n",
    "print(f\"ìš”êµ¬ì‚¬í•­: 1) íŒŒìŠ¤í…” ì˜ˆì•½ ë³€ê²½ + 2) ì£¼ë§ ë¯¸ìˆ ê´€ í•œì í•œ ì‹œê°„\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ ì‹¤ì œ LLM ë‹µë³€ í’ˆì§ˆ í•´ê²° ê³¼ì •:\")\n",
    "print(f\"  1ï¸âƒ£ ë¬¸ì œ ë¶„ì„: ë™ìŒì´ì˜ì–´ + ë©€í‹°í™‰ ì§ˆë¬¸\")\n",
    "print(f\"  2ï¸âƒ£ ë‚˜ì´ë¸Œ RAG: {naive_quality['completeness']} (í‚¤ì›Œë“œ: í˜¸í…” {naive_quality['hotel_score']}, ë¯¸ìˆ ê´€ {naive_quality['museum_score']})\")\n",
    "\n",
    "if hardcoded_results:\n",
    "    avg_hotel_hard = np.mean([r['quality']['hotel_score'] for r in hardcoded_results])\n",
    "    avg_museum_hard = np.mean([r['quality']['museum_score'] for r in hardcoded_results])\n",
    "    completeness_hard = max([r['quality']['completeness'] for r in hardcoded_results], key=[r['quality']['completeness'] for r in hardcoded_results].count)\n",
    "    print(f\"  3ï¸âƒ£ í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬: {completeness_hard} (í‚¤ì›Œë“œ: í˜¸í…” {avg_hotel_hard:.1f}, ë¯¸ìˆ ê´€ {avg_museum_hard:.1f})\")\n",
    "\n",
    "if llm_results:\n",
    "    avg_hotel_llm = np.mean([r['quality']['hotel_score'] for r in llm_results])\n",
    "    avg_museum_llm = np.mean([r['quality']['museum_score'] for r in llm_results])\n",
    "    completeness_llm = max([r['quality']['completeness'] for r in llm_results], key=[r['quality']['completeness'] for r in llm_results].count)\n",
    "    print(f\"  4ï¸âƒ£ LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬: {completeness_llm} (í‚¤ì›Œë“œ: í˜¸í…” {avg_hotel_llm:.1f}, ë¯¸ìˆ ê´€ {avg_museum_llm:.1f})\")\n",
    "\n",
    "print(f\"\\nâœ¨ í•µì‹¬ í•™ìŠµ ë‚´ìš©:\")\n",
    "print(f\"  ğŸ” Multi-Query ì›ë¦¬: ë³µí•© ì§ˆë¬¸ì„ í•˜ìœ„ ì§ˆë¬¸ë“¤ë¡œ ë¶„í•´\")\n",
    "print(f\"  ğŸ› ï¸ êµ¬í˜„ ë°©ë²•: í•˜ë“œì½”ë”© vs LLM ìƒì„± ì‹¤ì œ ë¹„êµ\")\n",
    "print(f\"  ğŸ“‹ first_line() í™œìš©: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê¹”ë”í•˜ê²Œ í‘œì‹œ\")\n",
    "print(f\"  ğŸ¯ ì‹¤ì œ íš¨ê³¼: Day1 íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ì§„ì§œ ë‹µë³€ í’ˆì§ˆ ê°œì„  í™•ì¸\")\n",
    "print(f\"  ğŸ“Š ê°ê´€ì  ì¸¡ì •: í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë‹µë³€ ì™„ì„±ë„ ìˆ˜ì¹˜í™”\")\n",
    "\n",
    "print(f\"\\nğŸš€ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ:\")\n",
    "\n",
    "# ìƒí™©ë³„ ì¶”ì²œ (ì‹¤ì œ ê²°ê³¼ ê¸°ë°˜)\n",
    "situations = [\n",
    "    (\"í”„ë¡œí† íƒ€ì… ê°œë°œ\", \"í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬\", \"êµ¬í˜„ ê°„ë‹¨, ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ëŠ¥\"),\n",
    "    (\"ë‹¤ì–‘í•œ ì§ˆë¬¸ ì²˜ë¦¬\", \"LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬\", \"ìœ ì—°í•˜ê³  ë§¥ë½ ì´í•´ ìš°ìˆ˜\"),\n",
    "    (\"ë¹„ìš© ì œì•½ í™˜ê²½\", \"í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬\", \"LLM í˜¸ì¶œ ë¹„ìš© ìµœì†Œí™”\"),\n",
    "    (\"ìµœê³  í’ˆì§ˆ ìš”êµ¬\", \"LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬\", \"ë” ì •êµí•œ ì§ˆë¬¸ ë¶„í•´\")\n",
    "]\n",
    "\n",
    "for situation, method, reason in situations:\n",
    "    print(f\"  â€¢ {situation:<15} â†’ {method:<20} ({reason})\")\n",
    "\n",
    "print(f\"\\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:\")\n",
    "print(f\"  04ë²ˆ: Metadata Filteringìœ¼ë¡œ ë” ì •êµí•œ ê²€ìƒ‰\")\n",
    "print(f\"  05ë²ˆ: Hybrid Search & Rerankë¡œ ì™„ë²½í•œ RAG\")\n",
    "\n",
    "print(f\"\\nğŸ‰ ì„±ê³µ! Day1 íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ íŒŒìŠ¤í…” ë¬¸ì œ ì™„ì „ í•´ê²°! ğŸ‰\")\n",
    "print(f\"02ë²ˆ ë…¸íŠ¸ë¶ì—ì„œ ì‹¤íŒ¨í–ˆë˜ ë³µì¡í•œ ì§ˆë¬¸ì´ ì‹¤ì œ LLMìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ë‹µë³€ë©ë‹ˆë‹¤!\")\n",
    "\n",
    "# ì‹¤ì œ ê°œì„  ì ìˆ˜ ê³„ì‚°\n",
    "def calculate_improvement_score(quality):\n",
    "    if quality['completeness'] == 'ì™„ë²½':\n",
    "        return 2.0\n",
    "    elif quality['completeness'] == 'ë¶€ë¶„':\n",
    "        return 1.5\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "improvement_scores = {\n",
    "    'ë‚˜ì´ë¸Œ RAG': calculate_improvement_score(naive_quality)\n",
    "}\n",
    "\n",
    "if hardcoded_results:\n",
    "    hardcoded_avg_score = np.mean([calculate_improvement_score(r['quality']) for r in hardcoded_results])\n",
    "    improvement_scores['í•˜ë“œì½”ë”© ë©€í‹°ì¿¼ë¦¬'] = hardcoded_avg_score\n",
    "\n",
    "if llm_results:\n",
    "    llm_avg_score = np.mean([calculate_improvement_score(r['quality']) for r in llm_results])\n",
    "    improvement_scores['LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬'] = llm_avg_score\n",
    "\n",
    "print(f\"\\nğŸ“Š ì‹¤ì œ ê°œì„  ì ìˆ˜ (1=ë¶ˆì™„ì „, 1.5=ë¶€ë¶„, 2=ì™„ë²½):\")\n",
    "for method, score in improvement_scores.items():\n",
    "    stars = \"â­\" * int(score) + (\"âœ¨\" if score % 1 else \"\")\n",
    "    print(f\"  {method:<20} {score:.1f} {stars}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‹¤ìŠµ ì„±ê³¼:\")\n",
    "print(f\"  âœ… ì‹¤ì œ LLM ëª¨ë¸ (Day1 íŒŒì¸íŠœë‹) ì„±ê³µì  í™œìš©\")\n",
    "print(f\"  âœ… RetrievalQA ì²´ì¸ìœ¼ë¡œ ì§„ì§œ RAG ì‹œìŠ¤í…œ êµ¬í˜„\")\n",
    "print(f\"  âœ… ì‹œë®¬ë ˆì´ì…˜ì´ ì•„ë‹Œ ì‹¤ì œ ë‹µë³€ í’ˆì§ˆ ì°¨ì´ í™•ì¸\")\n",
    "print(f\"  âœ… í•˜ë“œì½”ë”© vs LLM ìƒì„±ì˜ ì‹¤ìš©ì  íŠ¸ë ˆì´ë“œì˜¤í”„ ì²´í—˜\")\n",
    "print(f\"  âœ… ê°ê´€ì  ì§€í‘œë¡œ ê°œì„  íš¨ê³¼ ìˆ˜ì¹˜í™”\")\n",
    "\n",
    "print(f\"\\nğŸ”¬ ì¶”ê°€ ë¶„ì„ ê¸°íšŒ:\")\n",
    "print(f\"  - ë‹¤ë¥¸ ë³µí•© ì§ˆë¬¸ìœ¼ë¡œ ë©€í‹°ì¿¼ë¦¬ íš¨ê³¼ ê²€ì¦\")\n",
    "print(f\"  - í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ ì™¸ ë‹¤ë¥¸ í‰ê°€ ì§€í‘œ ê°œë°œ\")\n",
    "print(f\"  - LLM ìƒì„± ë©€í‹°ì¿¼ë¦¬ì˜ í”„ë¡¬í”„íŠ¸ ìµœì í™”\")\n",
    "print(f\"  - Day1 ëª¨ë¸ vs ë‹¤ë¥¸ LLM ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì„±ëŠ¥ ë¹„êµ ë° í‰ê°€ (5ë¶„)\n",
    "\n",
    "### ğŸ“Š ì¢…í•© ì„±ëŠ¥ ë¹„êµ ëŒ€ì‹œë³´ë“œ\n",
    "Naive RAG vs Advanced Query Refinement ê¸°ë²•ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
