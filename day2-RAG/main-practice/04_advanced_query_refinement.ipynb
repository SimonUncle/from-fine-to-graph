{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# π€ Day 2 μ‹¤μµ 4: κ³ κΈ‰ μΏΌλ¦¬ μ—”μ§€λ‹μ–΄λ§\n",
    "\n",
    "**λ©ν‘**: λ³µμ΅ν• μ§λ¬Έμ„ RAGκ°€ μ΄ν•΄ν•κΈ° μ‰½κ² λ³€ν™ν•λ” 3κ°€μ§€ κΈ°λ²• μ‹¤μµ\n",
    "\n",
    "**μ†μ” μ‹κ°„**: 60λ¶„\n",
    "\n",
    "---\n",
    "\n",
    "## π“ λ°°μΈ λ‚΄μ©\n",
    "\n",
    "1. **Multi-Query**: λ³µν•© μ§λ¬Έ β†’ μ—¬λ¬ κ° λ‹¨μ μ§λ¬ΈμΌλ΅ λ¶„ν•΄\n",
    "2. **HyDE**: μ§λ¬Έ β†’ κ°€μƒμ λ‹µλ³€ μƒμ„± β†’ λ‹µλ³€μΌλ΅ κ²€μƒ‰\n",
    "3. **Step-Back**: κµ¬μ²΄μ  μ§λ¬Έ β†’ μ¶”μƒμ  μ§λ¬ΈμΌλ΅ λ³€ν™\n",
    "\n",
    "---\n",
    "\n",
    "## β¨ μ‹¤μµ λ°©μ‹\n",
    "\n",
    "- κ° κΈ°λ²•λ§λ‹¤ **κ±°μ μ™„μ„±λ μ½”λ“** μ κ³µ\n",
    "- μ—¬λ¬λ¶„μ€ **ν”„λ΅¬ν”„νΈ 1-2μ¤„λ§ μμ •**ν•λ©΄ λ©λ‹λ‹¤!\n",
    "- κ° μΌ€μ΄μ¤λ§λ‹¤ κ΄€λ ¨ λ¬Έμ„λ¥Ό λ…ν™•ν λ³΄μ—¬λ“λ¦½λ‹λ‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ\n",
    "!pip install -q langchain-community sentence-transformers faiss-cpu langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# κ³µν†µ μ„¤μ •\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Embedding λ¨λΈ λ΅λ”©\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "print(\"β… Embedding λ¨λΈ λ΅λ”© μ™„λ£\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM λ΅λ”© (EXAONE 2.4B)\n",
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "print(\"β… LLM λ΅λ”© μ™„λ£\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ν—¬νΌ ν•¨μ\n",
    "import re\n",
    "\n",
    "def parse_queries(response, max_queries=3):\n",
    "    \"\"\"LLM μ‘λ‹µμ—μ„ μΏΌλ¦¬ μ¶”μ¶\"\"\"\n",
    "    # μ‰Όν‘ λλ” μ¤„λ°”κΏμΌλ΅ split\n",
    "    if ',' in response:\n",
    "        queries = [q.strip() for q in response.split(',') if q.strip()]\n",
    "    else:\n",
    "        queries = [q.strip() for q in response.split('\\n') if q.strip() and len(q.strip()) > 10]\n",
    "    \n",
    "    # μ«μ μ κ±°\n",
    "    queries = [re.sub(r'^[\\d\\.\\)]+\\s*', '', q) for q in queries][:max_queries]\n",
    "    return queries\n",
    "\n",
    "def check_result(found_types, needed_types):\n",
    "    \"\"\"κ²€μƒ‰ κ²°κ³Ό ν™•μΈ\"\"\"\n",
    "    found = sum(1 for t in needed_types if t in found_types)\n",
    "    print(f\"   κ²€μƒ‰λ λ¬Έμ„: {found_types}\")\n",
    "    print(f\"   μ„±κ³µλ¥ : {found}/{len(needed_types)}\")\n",
    "    return found\n",
    "\n",
    "print(\"β… ν—¬νΌ ν•¨μ μ¤€λΉ„ μ™„λ£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π”Ή Part 1: Multi-Query - λ³µν•© μ§λ¬Έ λ¶„ν•΄ (20λ¶„)\n",
    "\n",
    "### π“‹ μΌ€μ΄μ¤: μ£Όλ§ νμ¤ν…” μ—¬ν–‰ κ³„ν\n",
    "\n",
    "**μ§λ¬Έ**: \"μ£Όλ§μ— νμ¤ν…”μ—μ„ κ³µμ—° λ³΄κ³  νΈν…” μ™λ°•ν•κ³  μΉ΄ν μ²΄ν—ν•κ³  μ‹¶μ–΄μ”\"\n",
    "\n",
    "**λ©ν‘**: 3κ°€μ§€ μ •λ³΄λ¥Ό λ¨λ‘ μ°Ύμ•„μ•Ό ν•©λ‹λ‹¤\n",
    "1. π¨ **νΈν…”** μ •λ³΄\n",
    "2. β• **μΉ΄ν** μ •λ³΄\n",
    "3. π­ **κ·Ήμ¥** μ •λ³΄\n",
    "\n",
    "**κ΄€λ ¨ λ¬Έμ„**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Query μΌ€μ΄μ¤ - νμ¤ν…” μ—¬ν–‰ (λ¬Έμ„ 10κ°)\n",
    "mq_docs_raw = [\n",
    "    # μ •λ‹µ λ¬Έμ„ 3κ° (νμ¤ν…”λ§ ν¬ν•¨)\n",
    "    {\"content\": \"νμ¤ν…” νΈν…”: μ„μΈ κ°•λ‚¨κµ¬ μ„μΉ, κ°μ‹¤ 50κ°, μ£Όλ§ νΉκ°€ μ΄λ²¤νΈ μ§„ν–‰ μ¤‘. μ²΄ν¬μΈ 14μ‹, μ²΄ν¬μ•„μ›ƒ 11μ‹. μ΅°μ‹ ν¬ν•¨.\", \"type\": \"hotel\"},\n",
    "    {\"content\": \"νμ¤ν…” μΉ΄ν: μ μ£Όλ„ μ• μ›”μ μ„μΉ, μ¤μ…λ·° μΆμ„, μμ  λ””μ €νΈ νΉν™”. μμ—…μ‹κ°„ 10-22μ‹. μ£Όμ°¨ κ°€λ¥.\", \"type\": \"cafe\"},\n",
    "    {\"content\": \"νμ¤ν…” μ†κ·Ήμ¥: λ¶€μ‚° ν•΄μ΄λ€ μ„μΉ, μΆμ„ 100μ„, λ§¤μ£Ό ν† μ”μΌ μ €λ… 8μ‹ κ³µμ—°. μλ§¤λ” ν™νμ΄μ§€μ—μ„.\", \"type\": \"theater\"},\n",
    "    # Noise λ¬Έμ„ 7κ° (νμ¤ν…” μ—†μ)\n",
    "    {\"content\": \"μ£Όλ§ κ°•λ‚¨ μ—¬ν–‰ κ°€μ΄λ“: λ§›μ§‘ ν¬μ–΄, μ™λ°• μ‹μ„¤, μΉ΄ν κ±°λ¦¬ μ¶”μ² μ½”μ¤.\", \"type\": \"blog\"},\n",
    "    {\"content\": \"μ„μΈ λ¬Έν™”μƒν™ μ•λ‚΄: νΈν…”, μΉ΄ν, μ†κ·Ήμ¥μ„ ν•¨κ» μ¦κΈ°λ” λ°©λ²•.\", \"type\": \"intro\"},\n",
    "    {\"content\": \"μ£Όλ§ μ΄λ²¤νΈ νΉκ°€: κ³µμ—° ν• μΈ, μ™λ°• ν• μΈ, λ””μ €νΈ μ²΄ν— ν–‰μ‚¬.\", \"type\": \"event\"},\n",
    "    {\"content\": \"μ μ£Όλ„ μ• μ›” μΉ΄ν κ±°λ¦¬: μ¤μ…λ·° μΉ΄ν μ¶”μ², μ£Όμ°¨ μ •λ³΄.\", \"type\": \"travel\"},\n",
    "    {\"content\": \"λ¶€μ‚° ν•΄μ΄λ€ κ³µμ—° μΌμ •: μ†κ·Ήμ¥ λ®¤μ§€μ»¬, ν† μ”μΌ μ €λ… κ³µμ—°.\", \"type\": \"culture\"},\n",
    "    {\"content\": \"νΈν…” μμ•½ κΏ€ν: μ£Όλ§ νΉκ°€ μ°ΎκΈ°, μ²΄ν¬μΈ μ‹κ°„ ν™•μΈ λ°©λ²•.\", \"type\": \"tips\"},\n",
    "    {\"content\": \"μΉ΄ν μ²΄ν— ν”„λ΅κ·Έλ¨: μμ  λ””μ €νΈ λ§λ“¤κΈ°, μμ•½ λ°©λ²• μ•λ‚΄.\", \"type\": \"program\"},\n",
    "]\n",
    "\n",
    "mq_docs = [Document(page_content=d[\"content\"], metadata={\"type\": d[\"type\"]}) for d in mq_docs_raw]\n",
    "mq_vectorstore = FAISS.from_documents(mq_docs, embeddings)\n",
    "\n",
    "print(f\"π“ Multi-Query λ¬Έμ„ {len(mq_docs_raw)}κ° λ΅λ”©:\")\n",
    "print(\"  μ •λ‹µ λ¬Έμ„ 3κ°: 'νμ¤ν…”' ν¬ν•¨ (hotel, cafe, theater)\")\n",
    "print(\"  Noise λ¬Έμ„ 7κ°: 'νμ¤ν…”' μ—†μ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Query λ°λ¨ μ‹¤ν–‰\n",
    "mq_query = \"μ£Όλ§μ— νμ¤ν…”μ—μ„ κ³µμ—° λ³΄κ³  νΈν…” μ™λ°•ν•κ³  μΉ΄ν μ²΄ν—ν•κ³  μ‹¶μ–΄μ”\"\n",
    "\n",
    "# 1) Naive RAG (λΉ„κµμ©)\n",
    "print(\"π” Naive RAG (μ›λ³Έ μ§λ¬Έ κ·Έλ€λ΅):\")\n",
    "naive_results = mq_vectorstore.similarity_search(mq_query, k=3)\n",
    "naive_types = [r.metadata[\"type\"] for r in naive_results]\n",
    "check_result(naive_types, [\"hotel\", \"cafe\", \"theater\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 2) Multi-Query (μ •λ‹µ μμ‹)\n",
    "print(\"\\nπ€ Multi-Query (μ§λ¬Έ λ¶„ν•΄):\")\n",
    "\n",
    "# μ „λ¬Έκ°€κ°€ λ¶„ν•΄ν• μμ‹\n",
    "sub_queries = [\n",
    "    \"νμ¤ν…” νΈν…”\",\n",
    "    \"νμ¤ν…” μΉ΄ν\",\n",
    "    \"νμ¤ν…” μ†κ·Ήμ¥\"\n",
    "]\n",
    "\n",
    "print(f\"   λ¶„ν•΄λ μ§λ¬Έ {len(sub_queries)}κ°:\")\n",
    "for i, q in enumerate(sub_queries, 1):\n",
    "    print(f\"   {i}. {q}\")\n",
    "\n",
    "# κ° μ§λ¬ΈμΌλ΅ κ²€μƒ‰ (k=1μ”©)\n",
    "all_results = []\n",
    "for q in sub_queries:\n",
    "    results = mq_vectorstore.similarity_search(q, k=1)\n",
    "    all_results.extend(results)\n",
    "\n",
    "mq_types = [r.metadata[\"type\"] for r in all_results]\n",
    "print(\"\\nπ“ Multi-Query κ²°κ³Ό:\")\n",
    "check_result(mq_types, [\"hotel\", \"cafe\", \"theater\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π”„ Part 1: Multi-Query (λ³µν•© μ§λ¬Έ λ¶„ν•΄)\n",
    "\n",
    "### π“ μ–Έμ  μ‚¬μ©ν•λ‚μ”?\n",
    "\n",
    "λ³µν•©μ μΈ μ”κµ¬μ‚¬ν•­μ΄ μ—¬λ¬ κ° μ„μ—¬μμ„ λ• μ μ©ν•©λ‹λ‹¤:\n",
    "\n",
    "**β… μ‚¬μ©ν•κΈ° μΆ‹μ€ κ²½μ°:**\n",
    "- \"νΈν…” μ™λ°•ν•κ³  μΉ΄ν κ°€κ³  κ³µμ—° λ³΄κ³  μ‹¶μ–΄μ”\" β† 3κ°€μ§€ λ…λ¦½μ  μ”μ²­\n",
    "- \"μ‡Όν•‘ν•κ³  λ μ¤ν† λ‘ κ°€κ³  λ†€μ΄κΈ°κµ¬ νƒ€κ³  μ‹¶μ–΄μ”\"\n",
    "- \"Aλ„ κ¶κΈν•κ³  Bλ„ κ¶κΈν•κ³  Cλ„ μ•κ³  μ‹¶μ–΄μ”\"\n",
    "\n",
    "**β ν¨κ³Όκ°€ μ μ€ κ²½μ°:**\n",
    "- \"νμ¤ν…” νΈν…” μ„μΉ μ•λ ¤μ¤\" β† λ‹¨μΌ μ§λ¬Έ\n",
    "- \"μ²΄ν¬μΈ μ‹κ°„μ΄ μ–Έμ μΈκ°€μ”?\" β† κµ¬μ²΄μ μΈ λ‹¨μΌ μ§λ¬Έ\n",
    "\n",
    "### π― ν•µμ‹¬ μ•„μ΄λ””μ–΄\n",
    "\n",
    "1κ°μ λ³µν•© μ§λ¬Έ β†’ **μ—¬λ¬ κ°μ κ°„κ²°ν• κ²€μƒ‰μ–΄**λ΅ λ¶„ν•΄\n",
    "- \"νμ¤ν…” κ³µμ—°, νμ¤ν…” νΈν…”, νμ¤ν…” μΉ΄ν\" κ°κ° κ²€μƒ‰\n",
    "- κ²€μƒ‰ κ²°κ³Όλ¥Ό ν•©μ³μ„ λ” ν’λ¶€ν• μ •λ³΄ μ κ³µ\n",
    "\n",
    "---\n",
    "\n",
    "### π’΅ μ‹¤μµ 1: λ³µν•© μ§λ¬Έ λ¶„ν•΄ν•κΈ°\n",
    "\n",
    "**λ―Έμ…**: ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ 3/3 μ„±κ³µμ‹ν‚¤κΈ°!\n",
    "\n",
    "**μ”κµ¬μ‚¬ν•­**: λ³µν•© μ§λ¬Έμ„ μ‰Όν‘λ΅ κµ¬λ¶„λ κ°„κ²°ν• κ²€μƒ‰μ–΄λ΅ λ¶„ν•΄ν•μ„Έμ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# μ—¬κΈ°λ¥Ό μμ •ν•μ„Έμ”! π‘‡\n",
    "# TODO: Few-shot ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ λ³µν•© μ§λ¬Έμ„ κ°„κ²°ν• κ²€μƒ‰μ–΄λ΅ λ¶„ν•΄ν•μ„Έμ”\n",
    "\n",
    "my_query = \"μ£Όλ§μ— νμ¤ν…”μ—μ„ κ³µμ—° λ³΄κ³  νΈν…” μ™λ°•ν•κ³  μΉ΄ν μ²΄ν—ν•κ³  μ‹¶μ–΄μ”\"\n",
    "\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ μ‘μ„±\n",
    "prompt = \"\"\"\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"μ¶λ ¥:\" in response:\n",
    "    last_output = response.split(\"μ¶λ ¥:\")[-1].strip()\n",
    "    sub_queries = parse_queries(last_output)\n",
    "else:\n",
    "    sub_queries = parse_queries(response)\n",
    "\n",
    "print(f\"μƒμ„±λ κ²€μƒ‰μ–΄: {sub_queries}\")\n",
    "\n",
    "# μƒμ„±λ κ²€μƒ‰μ–΄λ΅ μ‹¤μ  κ²€μƒ‰\n",
    "all_results = []\n",
    "for sq in sub_queries:\n",
    "    results = mq_vectorstore.similarity_search(sq, k=1)\n",
    "    all_results.extend(results)\n",
    "\n",
    "# κ²°κ³Ό ν™•μΈ\n",
    "found_types = set(doc.metadata['type'] for doc in all_results)\n",
    "target_types = {'theater', 'hotel', 'cafe'}\n",
    "success = len(found_types & target_types)\n",
    "\n",
    "print(f\"κ²€μƒ‰λ λ¬Έμ„: {list(found_types)}\")\n",
    "print(f\"μ„±κ³µλ¥ : {success}/3 {'β…' if success >= 2 else 'β'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>π“ μ •λ‹µ μ½”λ“ λ³΄κΈ° (ν΄λ¦­)</summary>\n",
    "\n",
    "```python\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ\n",
    "prompt = \"\"\"λ‹Ήμ‹ μ€ λ³µν•© μ§λ¬Έμ„ κ°„κ²°ν• κ²€μƒ‰μ–΄λ΅ λ¶„ν•΄ν•λ” μ „λ¬Έκ°€μ…λ‹λ‹¤.\n",
    "\n",
    "[μμ‹ 1]\n",
    "μ…λ ¥: λ΅―λ°μ›”λ“ λ†€μ΄κΈ°κµ¬ νƒ€κ³  λ μ¤ν† λ‘ κ°€κ³  μ‹¶μ–΄μ”\n",
    "μ¶λ ¥: λ΅―λ°μ›”λ“ λ†€μ΄κΈ°κµ¬, λ΅―λ°μ›”λ“ λ μ¤ν† λ‘\n",
    "\n",
    "[μμ‹ 2]\n",
    "μ…λ ¥: λ…λ™μ—μ„ μ‡Όν•‘ν•κ³  νΈν…” λ¬µκ³  κ³µμ—° λ³΄κ³  μ‹¶μ–΄μ”\n",
    "μ¶λ ¥: λ…λ™ μ‡Όν•‘, λ…λ™ νΈν…”, λ…λ™ κ³µμ—°\n",
    "\n",
    "[μ‹¤μ  μ‘μ—…]\n",
    "μ…λ ¥: {query}\n",
    "μ¶λ ¥:\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"μ¶λ ¥:\" in response:\n",
    "    last_output = response.split(\"μ¶λ ¥:\")[-1].strip()\n",
    "    sub_queries = parse_queries(last_output)\n",
    "else:\n",
    "    sub_queries = parse_queries(response)\n",
    "\n",
    "print(f\"μƒμ„±λ κ²€μƒ‰μ–΄: {sub_queries}\")\n",
    "\n",
    "# μƒμ„±λ κ²€μƒ‰μ–΄λ΅ μ‹¤μ  κ²€μƒ‰\n",
    "all_results = []\n",
    "for sq in sub_queries:\n",
    "    results = mq_vectorstore.similarity_search(sq, k=1)\n",
    "    all_results.extend(results)\n",
    "\n",
    "# κ²°κ³Ό ν™•μΈ\n",
    "found_types = set(doc.metadata['type'] for doc in all_results)\n",
    "target_types = {'theater', 'hotel', 'cafe'}\n",
    "success = len(found_types & target_types)\n",
    "\n",
    "print(f\"κ²€μƒ‰λ λ¬Έμ„: {list(found_types)}\")\n",
    "print(f\"μ„±κ³µλ¥ : {success}/3 {'β…' if success >= 2 else 'β'}\")\n",
    "```\n",
    "\n",
    "**ν•µμ‹¬ ν¬μΈνΈ:**\n",
    "- Few-shot μμ‹ 2κ°λ΅ μ¶λ ¥ ν•μ‹ ν•™μµ\n",
    "- μ‰Όν‘λ΅ κµ¬λ¶„λ κ°„κ²°ν• κ²€μƒ‰μ–΄ μƒμ„±\n",
    "- κ° κ²€μƒ‰μ–΄λ΅ κ²€μƒ‰ ν›„ μ„±κ³µλ¥  ν™•μΈ\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π”Ή Part 2: HyDE - κ°€μƒ λ‹µλ³€ μƒμ„± (20λ¶„)\n",
    "\n",
    "### π“‹ μΌ€μ΄μ¤: νμ¤ν…” νΈν…” κ°μ‹¤ μ •λ³΄\n",
    "\n",
    "**μ§λ¬Έ**: \"νμ¤ν…” νΈν…” κ°μ‹¤ μ •λ³΄ μ•λ ¤μ¤\"\n",
    "\n",
    "**λ©ν‘**: νΈν…” μ •λ³΄ μ°ΎκΈ°\n",
    "- π¨ **νΈν…”** λ¬Έμ„λ¥Ό μ°Ύμ•„μ•Ό ν•©λ‹λ‹¤ (μΉ΄ν/κ·Ήμ¥ μ•„λ‹)\n",
    "\n",
    "**κ΄€λ ¨ λ¬Έμ„**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE μΌ€μ΄μ¤ - νΈν…” μ •λ³΄ (λ¬Έμ„ 10κ°)\n",
    "hyde_docs_raw = [\n",
    "    # μ •λ‹µ λ¬Έμ„ (νμ¤ν…” νΈν…” κ°μ‹¤ 50κ°)\n",
    "    {\"content\": \"νμ¤ν…” νΈν…”: μ„μΈ κ°•λ‚¨κµ¬ μ„μΉ, κ°μ‹¤ 50κ°, μ£Όλ§ νΉκ°€ μ΄λ²¤νΈ. μ²΄ν¬μΈ 14μ‹, μ²΄ν¬μ•„μ›ƒ 11μ‹. μ΅°μ‹ ν¬ν•¨. λ¬΄λ£ μ™€μ΄νμ΄, ν”ΌνΈλ‹μ¤ μ„Όν„°.\", \"type\": \"hotel\"},\n",
    "    # Noise λ¬Έμ„ 9κ° (νμ¤ν…” + κ°μ‹¤ μ–ΈκΈ‰μΌλ΅ νΌλ™)\n",
    "    {\"content\": \"λΈ”λ£¨λ¬Έ νΈν…”: μ μ£Όλ„ μ„κ·€ν¬ μ„μΉ, κ°μ‹¤ 80κ°, μ¤μ…λ·°, μμμ¥, μ¤ν. κ°€μ΅± λ‹¨μ„ μ—¬ν–‰κ°μ—κ² μΈκΈ°.\", \"type\": \"other_hotel\"},\n",
    "    {\"content\": \"νμ¤ν…” λΈλλ“ μ†κ°: νΈν…”, μΉ΄ν, μ†κ·Ήμ¥μ„ μ΄μν•λ” λ³µν•© λ¬Έν™” κ³µκ°„. κ°μ‹¤ μλ” κ° μ§€μ λ§λ‹¤ λ‹¤λ¦„.\", \"type\": \"brand\"},\n",
    "    {\"content\": \"νμ¤ν…” μΉ΄ν: μ μ£Ό μ• μ›” μ„μΉ, μΆμ„ 50κ°, μ¤μ…λ·°. λ””μ €νΈμ™€ μλ£ νλ§¤.\", \"type\": \"cafe\"},\n",
    "    {\"content\": \"νΈν…” κ°μ‹¤ μ •λ³΄ ν™•μΈ λ°©λ²•: ν™νμ΄μ§€ μ ‘μ† ν›„ κ°μ‹¤ ν„ν™© μ΅°ν, μ „ν™” λ¬Έμ κ°€λ¥.\", \"type\": \"guide\"},\n",
    "    {\"content\": \"κ°•λ‚¨κµ¬ μ™λ°• μ‹μ„¤: λ‹¤μ–‘ν• νΈν…”, κ²μ¤νΈν•μ°μ¤, μ—μ–΄λΉ„μ•¤λΉ„ μµμ… μ κ³µ. κ°μ‹¤ κ·λ¨ λ‹¤μ–‘.\", \"type\": \"area\"},\n",
    "    {\"content\": \"νμ¤ν…” μ΄μ© ν›„κΈ°: κ°μ‹¤μ΄ κΉ¨λ—ν•κ³  μ§μ› μΉμ . μ¶”μ²ν•©λ‹λ‹¤.\", \"type\": \"review\"},\n",
    "    {\"content\": \"νΈν…” κ°μ‹¤ μμ•½ ν: μ²΄ν¬μΈ μ‹κ°„ ν™•μΈ, κ°μ‹¤ νƒ€μ… μ„ νƒ, μ΅°μ‹ ν¬ν•¨ μ—¬λ¶€ ν™•μΈ.\", \"type\": \"tips\"},\n",
    "    {\"content\": \"νμ¤ν…” μ†κ·Ήμ¥: λ¶€μ‚° ν•΄μ΄λ€ μ„μΉ, μΆμ„ 100μ„, ν† μ”μΌ κ³µμ—°.\", \"type\": \"theater\"},\n",
    "    {\"content\": \"κ°μ‹¤ μ λΉ„κµ: νμ¤ν…” νΈν…” 50κ°, λΈ”λ£¨λ¬Έ νΈν…” 80κ°, μ¤μΉ΄μ΄ νΈν…” 120κ°.\", \"type\": \"comparison\"},\n",
    "]\n",
    "\n",
    "hyde_docs = [Document(page_content=d[\"content\"], metadata={\"type\": d[\"type\"]}) for d in hyde_docs_raw]\n",
    "hyde_vectorstore = FAISS.from_documents(hyde_docs, embeddings)\n",
    "\n",
    "print(f\"π“ HyDE λ¬Έμ„ {len(hyde_docs_raw)}κ° λ΅λ”©:\")\n",
    "print(\"  μ •λ‹µ: hotel (νμ¤ν…” νΈν…” κ°μ‹¤ 50κ°)\")\n",
    "print(\"  Noise: 9κ° (νμ¤ν…”/κ°μ‹¤ ν‚¤μ›λ“ ν¬ν•¨μΌλ΅ νΌλ™ μ λ°)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyDE λ°λ¨ μ‹¤ν–‰\n",
    "hyde_query = \"νμ¤ν…” κ°μ‹¤ λ‡κ°μ„?\"\n",
    "\n",
    "# 1) Naive RAG (λΉ„κµμ©)\n",
    "print(\"π” Naive RAG (κµ¬μ–΄μ²΄ μ§λ¬Έ):\")\n",
    "naive_results = hyde_vectorstore.similarity_search(hyde_query, k=1)\n",
    "print(f\"   μ°Ύμ€ λ¬Έμ„: {naive_results[0].metadata['type']}\")\n",
    "print(f\"   λ‚΄μ©: {naive_results[0].page_content[:50]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 2) HyDE (μ •λ‹µ μμ‹)\n",
    "print(\"\\nπ€ HyDE (κ°€μƒ λ‹µλ³€ μƒμ„±):\")\n",
    "\n",
    "# μ „λ¬Έκ°€κ°€ μ‘μ„±ν• κ°€μƒ λ‹µλ³€\n",
    "hypothetical_answer = \"\"\"νμ¤ν…” νΈν…”μ€ μ„μΈ κ°•λ‚¨κµ¬μ— μ„μΉν•κ³  μμµλ‹λ‹¤. \n",
    "κ°μ‹¤μ€ μ΄ 50κ°μ΄λ©°, μ²΄ν¬μΈμ€ μ¤ν›„ 2μ‹, μ²΄ν¬μ•„μ›ƒμ€ μ¤μ „ 11μ‹μ…λ‹λ‹¤.\n",
    "λ¬΄λ£ μ΅°μ‹μ΄ ν¬ν•¨λμ–΄ μμΌλ©°, λ¬΄λ£ μ™€μ΄νμ΄μ™€ ν”ΌνΈλ‹μ¤ μ„Όν„°λ¥Ό μ΄μ©ν•μ‹¤ μ μμµλ‹λ‹¤.\"\"\"\n",
    "\n",
    "print(f\"   μƒμ„±λ κ°€μƒ λ‹µλ³€: {hypothetical_answer[:80]}...\")\n",
    "\n",
    "# κ°€μƒ λ‹µλ³€μΌλ΅ κ²€μƒ‰\n",
    "hyde_results = hyde_vectorstore.similarity_search(hypothetical_answer, k=1)\n",
    "print(f\"\\n   μ°Ύμ€ λ¬Έμ„: {hyde_results[0].metadata['type']}\")\n",
    "if hyde_results[0].metadata['type'] == 'hotel':\n",
    "    print(\"   β… μ„±κ³µ! νμ¤ν…” νΈν…” λ¬Έμ„λ¥Ό μ°Ύμ•μµλ‹λ‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### π“ μ–Έμ  μ‚¬μ©ν•λ‚μ”?\n",
    "\n",
    "μ§λ¬Έμ΄ μ§§κ³  μ• λ§¤ν•  λ•, λ‹µλ³€μ„ λ¨Όμ € μƒμƒν•΄μ„ κ²€μƒ‰ν•λ©΄ λ” μ •ν™•ν•©λ‹λ‹¤:\n",
    "\n",
    "**β… μ‚¬μ©ν•κΈ° μΆ‹μ€ κ²½μ°:**\n",
    "- \"νμ¤ν…” κ°μ‹¤ λ‡κ°μ„?\" β† κµ¬μ–΄μ²΄, μ§§μ\n",
    "- \"νΈν…” μ •λ³΄\" β† λ„λ¬΄ κ°„κ²°ν•¨\n",
    "- \"μ²΄ν¬μΈ μ‹κ°„μ€?\" β† μ •λ³΄κ°€ λ¶€μ΅±ν•¨\n",
    "\n",
    "**β ν¨κ³Όκ°€ μ μ€ κ²½μ°:**\n",
    "- \"νμ¤ν…” νΈν…”μ κ°μ‹¤ μ, μ„μΉ, μ‹μ„¤ μ •λ³΄λ¥Ό μμ„Έν μ•λ ¤μ£Όμ„Έμ”\" β† μ΄λ―Έ μ¶©λ¶„ν μƒμ„Έν•¨\n",
    "- \"μ„μΈ κ°•λ‚¨κµ¬ νμ¤ν…” νΈν…” 50κ° κ°μ‹¤...\" β† μ΄λ―Έ ν‚¤μ›λ“κ°€ ν’λ¶€ν•¨\n",
    "\n",
    "### π― ν•µμ‹¬ μ•„μ΄λ””μ–΄\n",
    "\n",
    "μ§§μ€ μ§λ¬Έ β†’ **κ°€μƒμ μƒμ„Έν• λ‹µλ³€** μƒμ„± β†’ λ‹µλ³€μΌλ΅ κ²€μƒ‰\n",
    "- \"νμ¤ν…” κ°μ‹¤?\" β†’ \"νμ¤ν…” νΈν…”μ€ μ„μΈ κ°•λ‚¨κµ¬μ— μ„μΉν•κ³  μμµλ‹λ‹¤. κ°μ‹¤μ€ 50κ°μ΄λ©°...\" μƒμ„±\n",
    "- μ΄ κ°€μƒ λ‹µλ³€μΌλ΅ κ²€μƒ‰ν•λ©΄ μ‹¤μ  νΈν…” λ¬Έμ„μ™€ μ μ‚¬λ„κ°€ λ†’μ•„μ§\n",
    "\n",
    "---\n",
    "\n",
    "### π’΅ μ‹¤μµ 2: κ°€μƒ λ‹µλ³€ μ‘μ„±ν•κΈ°\n",
    "\n",
    "**λ―Έμ…**: ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ νΈν…” μ •λ³΄λ¥Ό μ°Ύλ„λ΅ λ§λ“¤κΈ°!\n",
    "\n",
    "**μ”κµ¬μ‚¬ν•­**: κµ¬μ–΄μ²΄ μ§λ¬Έμ— λ€ν• μƒμ„Έν• κ°€μƒ λ‹µλ³€μ„ μƒμ„±ν•μ„Έμ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# μ—¬κΈ°λ¥Ό μμ •ν•μ„Έμ”! π‘‡\n",
    "# TODO: Few-shot ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ κµ¬μ–΄μ²΄ μ§λ¬Έμ„ μƒμ„Έν• νΈν…” μ•λ‚΄λ¬ΈμΌλ΅ λ³€ν™ν•μ„Έμ”\n",
    "\n",
    "my_query = \"νμ¤ν…” κ°μ‹¤ λ‡κ°μ„?\"\n",
    "\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ μ‘μ„±\n",
    "prompt = \"\"\"\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"λ‹µλ³€:\" in response:\n",
    "    hypothetical_answer = response.split(\"λ‹µλ³€:\")[-1].strip()\n",
    "else:\n",
    "    hypothetical_answer = response.strip()\n",
    "\n",
    "print(f\"μƒμ„±λ κ°€μƒ λ‹µλ³€: {hypothetical_answer[:100]}...\")\n",
    "\n",
    "# κ°€μƒ λ‹µλ³€μΌλ΅ μ‹¤μ  κ²€μƒ‰\n",
    "results = hyde_vectorstore.similarity_search(hypothetical_answer, k=1)\n",
    "found_type = results[0].metadata['type']\n",
    "\n",
    "print(f\"μ°Ύμ€ λ¬Έμ„: {found_type} {'β…' if found_type == 'hotel' else 'β'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>π“ μ •λ‹µ μ½”λ“ λ³΄κΈ° (ν΄λ¦­)</summary>\n",
    "\n",
    "```python\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ\n",
    "prompt = \"\"\"λ‹Ήμ‹ μ€ νΈν…” μ •λ³΄λ¥Ό μ •ν™•ν•κ² μ•λ‚΄ν•λ” μ§μ›μ…λ‹λ‹¤.\n",
    "\n",
    "[μμ‹]\n",
    "μ§λ¬Έ: μ‹ λΌνΈν…” κ°μ‹¤ λ‡κ°μ„?\n",
    "λ‹µλ³€: μ‹ λΌνΈν…”μ€ μ„μΈ μ¤‘κµ¬μ— μ„μΉν•κ³  μμµλ‹λ‹¤. κ°μ‹¤μ€ 464κ°μ΄λ©°, μ²΄ν¬μΈμ€ 15μ‹, μ²΄ν¬μ•„μ›ƒμ€ 12μ‹μ…λ‹λ‹¤. λ¬΄λ£ μ΅°μ‹κ³Ό μμμ¥, μ¤ν μ‹μ„¤μ„ μ΄μ©ν•μ‹¤ μ μμµλ‹λ‹¤.\n",
    "\n",
    "[μ‹¤μ  μ‘μ—…]\n",
    "μ§λ¬Έ: {query}\n",
    "λ‹µλ³€:\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"λ‹µλ³€:\" in response:\n",
    "    hypothetical_answer = response.split(\"λ‹µλ³€:\")[-1].strip()\n",
    "else:\n",
    "    hypothetical_answer = response.strip()\n",
    "\n",
    "print(f\"μƒμ„±λ κ°€μƒ λ‹µλ³€: {hypothetical_answer[:100]}...\")\n",
    "\n",
    "# κ°€μƒ λ‹µλ³€μΌλ΅ μ‹¤μ  κ²€μƒ‰\n",
    "results = hyde_vectorstore.similarity_search(hypothetical_answer, k=1)\n",
    "found_type = results[0].metadata['type']\n",
    "\n",
    "print(f\"μ°Ύμ€ λ¬Έμ„: {found_type} {'β…' if found_type == 'hotel' else 'β'}\")\n",
    "```\n",
    "\n",
    "**ν•µμ‹¬ ν¬μΈνΈ:**\n",
    "- κµ¬μ–΄μ²΄ μ§λ¬Έ β†’ μƒμ„Έν• νΈν…” μ•λ‚΄λ¬Έ ν•μ‹μΌλ΅ λ³€ν™\n",
    "- μ„μΉ, κ°μ‹¤ μ, μ‹μ„¤ λ“± ν’λ¶€ν• ν‚¤μ›λ“ ν¬ν•¨\n",
    "- κ°€μƒ λ‹µλ³€μΌλ΅ κ²€μƒ‰ν•λ©΄ μ‹¤μ  νΈν…” λ¬Έμ„μ™€ λ§¤μΉ­ μλ¨\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π”Ή Part 3: Step-Back - μ¶”μƒν™” (15λ¶„)\n",
    "\n",
    "### π“‹ μΌ€μ΄μ¤: μ£Όλ§ μ²΄ν¬μΈ λ³€κ²½ κ·μ •\n",
    "\n",
    "**μ§λ¬Έ**: \"νμ¤ν…” νΈν…” μ£Όλ§ μ²΄ν¬μΈ λ³€κ²½ κ·μ •μ€?\"\n",
    "\n",
    "**λ©ν‘**: νΈν…” μ •μ±… λ¬Έμ„ μ°ΎκΈ°\n",
    "- π“‹ **μ •μ±…** λ¬Έμ„λ¥Ό μ°Ύμ•„μ•Ό ν•©λ‹λ‹¤ (κ°μ‹¤ μ •λ³΄ μ•„λ‹)\n",
    "\n",
    "**κ΄€λ ¨ λ¬Έμ„**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-Back μΌ€μ΄μ¤ - νΈν…” μ •μ±… (λ¬Έμ„ 10κ°)\n",
    "sb_docs_raw = [\n",
    "    # μ •λ‹µ λ¬Έμ„ (μΌλ°μ μΈ λ‚΄μ©)\n",
    "    {\"content\": \"νμ¤ν…” νΈν…” μ΄μ© κ·μ •: μμ•½ λ³€κ²½ λ° μ·¨μ† μ •μ±…, ν™λ¶ κ·μ •, μ²΄ν¬μΈ/μ²΄ν¬μ•„μ›ƒ κ·μ • μ•λ‚΄.\", \"type\": \"policy\"},\n",
    "    # Noise λ¬Έμ„ 9κ° (κµ¬μ²΄μ  ν‚¤μ›λ“ λ§μ΄ ν¬ν•¨)\n",
    "    {\"content\": \"νμ¤ν…” νΈν…” κ°μ‹¤: 50κ°, μ²΄ν¬μΈ 14μ‹, μ²΄ν¬μ•„μ›ƒ 11μ‹. μ΅°μ‹ ν¬ν•¨, λ¬΄λ£ μ£Όμ°¨.\", \"type\": \"room_info\"},\n",
    "    {\"content\": \"ν† μ”μΌ μ²΄ν¬μΈ νΌμ΅ μ•λ‚΄: ν† μ”μΌ μ¤μ „ μ²΄ν¬μΈ μ‹ λ€κΈ° μ‹κ°„ 30λ¶„ μμƒ. μ¨λΌμΈ μ²΄ν¬μΈ κ¶μ¥.\", \"type\": \"saturday_info\"},\n",
    "    {\"content\": \"μ²΄ν¬μΈ μ‹κ°„ μ—°μ¥ μ„λΉ„μ¤: 12μ‹κΉμ§€ μ²΄ν¬μΈ μ—°μ¥ κ°€λ¥. μ¶”κ°€ λΉ„μ© 5,000μ›.\", \"type\": \"late_checkin\"},\n",
    "    {\"content\": \"νμ¤ν…” νΈν…” ν† μ”μΌ μ΄λ²¤νΈ: ν† μ”μΌ μ™λ°• μ‹ μ΅°μ‹ λ¬΄λ£ μ—…κ·Έλ μ΄λ“.\", \"type\": \"saturday_event\"},\n",
    "    {\"content\": \"μ¤μ „ 11μ‹ μ²΄ν¬μΈ μ•λ‚΄: μ •μƒ μ²΄ν¬μΈμ€ 14μ‹. 11μ‹ μ–Όλ¦¬ μ²΄ν¬μΈμ€ μ‚¬μ „ λ¬Έμ ν•„μ”.\", \"type\": \"early_checkin\"},\n",
    "    {\"content\": \"μ£Όλ§ μ²΄ν¬μΈ ν: ν† μ”μΌ-μΌμ”μΌ μ²΄ν¬μΈμ€ νΌμ΅. 12μ‹ μ΄μ „ λ„μ°© κ¶μ¥.\", \"type\": \"weekend_tip\"},\n",
    "    {\"content\": \"μ²΄ν¬μΈ μ‹κ°„ λ³€κ²½ λ°©λ²•: λ§μ΄νμ΄μ§€μ—μ„ μ²΄ν¬μΈ μ‹κ°„ λ³€κ²½ κ°€λ¥. λ‹ΉμΌ λ³€κ²½ λ¶κ°€.\", \"type\": \"change_method\"},\n",
    "    {\"content\": \"νμ¤ν…” νΈν…” λΉ„μ© μ•λ‚΄: κ°μ‹¤ μ”κΈ, μ¶”κ°€ μ„λΉ„μ¤ λΉ„μ©, μ—°μ¥ μ”κΈ μ•λ‚΄.\", \"type\": \"cost_info\"},\n",
    "    {\"content\": \"ν† μ”μΌ 12μ‹ μ²΄ν¬μΈ κ°€λ¥ μ—¬λ¶€: μ‚¬μ „ μ”μ²­ μ‹ κ°€λ¥. κ°μ‹¤ μƒν™©μ— λ”°λΌ λ‹¤λ¦„.\", \"type\": \"noon_checkin\"},\n",
    "]\n",
    "\n",
    "sb_docs = [Document(page_content=d[\"content\"], metadata={\"type\": d[\"type\"]}) for d in sb_docs_raw]\n",
    "sb_vectorstore = FAISS.from_documents(sb_docs, embeddings)\n",
    "\n",
    "print(f\"π“ Step-Back λ¬Έμ„ {len(sb_docs_raw)}κ° λ΅λ”©:\")\n",
    "print(\"  μ •λ‹µ: policy (μΌλ°μ μΈ μ΄μ© κ·μ •)\")\n",
    "print(\"  Noise: 9κ° (κµ¬μ²΄μ  ν‚¤μ›λ“λ΅ νΌλ™ μ λ°)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-Back λ°λ¨ μ‹¤ν–‰\n",
    "sb_query = \"νμ¤ν…” νΈν…” ν† μ”μΌ μ¤μ „ 11μ‹ μ²΄ν¬μΈμ„ 12μ‹λ΅ λ¦μ¶”λ ¤λ©΄ λΉ„μ©μ΄ μ–Όλ§λ‚ λ“λ‚μ”?\"\n",
    "\n",
    "# 1) Naive RAG (λΉ„κµμ©)\n",
    "print(\"π” Naive RAG (λ§¤μ° κµ¬μ²΄μ μΈ μ§λ¬Έ):\")\n",
    "naive_results = sb_vectorstore.similarity_search(sb_query, k=1)\n",
    "print(f\"   μ°Ύμ€ λ¬Έμ„: {naive_results[0].metadata['type']}\")\n",
    "print(f\"   λ‚΄μ©: {naive_results[0].page_content[:50]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 2) Step-Back (μ •λ‹µ μμ‹)\n",
    "print(\"\\nπ€ Step-Back (μ¶”μƒν™”):\")\n",
    "\n",
    "# μ „λ¬Έκ°€κ°€ μ¶”μƒν™”ν• μ§λ¬Έ\n",
    "abstract_query = \"νμ¤ν…” νΈν…” μ΄μ© κ·μ •\"\n",
    "\n",
    "print(f\"   μ¶”μƒν™”λ μ§λ¬Έ: {abstract_query}\")\n",
    "print(\"   (κµ¬μ²΄μ : 'ν† μ”μΌ 11μ‹β†’12μ‹ λΉ„μ©' β†’ μ¶”μƒμ : 'μ΄μ© κ·μ •')\")\n",
    "\n",
    "# μ¶”μƒν™”λ μ§λ¬ΈμΌλ΅ κ²€μƒ‰\n",
    "sb_results = sb_vectorstore.similarity_search(abstract_query, k=1)\n",
    "print(f\"\\n   μ°Ύμ€ λ¬Έμ„: {sb_results[0].metadata['type']}\")\n",
    "if sb_results[0].metadata['type'] == 'policy':\n",
    "    print(\"   β… μ„±κ³µ! μ •μ±… λ¬Έμ„λ¥Ό μ°Ύμ•μµλ‹λ‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### π“ μ–Έμ  μ‚¬μ©ν•λ‚μ”?\n",
    "\n",
    "μ§λ¬Έμ΄ λ„λ¬΄ κµ¬μ²΄μ μΌ λ•, μΌλ°μ μΈ μ£Όμ λ΅ μ¶”μƒν™”ν•λ©΄ λ” λ„“μ€ λ¬Έμ„λ¥Ό μ°Ύμ„ μ μμµλ‹λ‹¤:\n",
    "\n",
    "**β… μ‚¬μ©ν•κΈ° μΆ‹μ€ κ²½μ°:**\n",
    "- \"ν† μ”μΌ μ¤μ „ 11μ‹ μ²΄ν¬μΈμ„ 12μ‹λ΅ λ¦μ¶”λ ¤λ©΄ λΉ„μ©μ€?\" β† λ„λ¬΄ κµ¬μ²΄μ  (μ‹κ°„, μ”μΌ)\n",
    "- \"μΌμ”μΌ 3μ‹ κ°μ‹¤ μμ•½ μ·¨μ†ν•λ©΄ μμλ£λ”?\" β† μ„Έλ¶€ μ •λ³΄ λ§μ\n",
    "- \"κΈμ”μΌ μ €λ… 7μ‹ μ΅°μ‹ λ©”λ‰΄λ”?\" β† νΉμ • μ‹κ°„/μ”μΌ\n",
    "\n",
    "**β ν¨κ³Όκ°€ μ μ€ κ²½μ°:**\n",
    "- \"νΈν…” μ΄μ© κ·μ •\" β† μ΄λ―Έ μ¶©λ¶„ν μΌλ°μ \n",
    "- \"μμ•½ μ •μ±… μ•λ ¤μ¤\" β† μ¶”μƒν™” λ¶ν•„μ”\n",
    "\n",
    "### π― ν•µμ‹¬ μ•„μ΄λ””μ–΄\n",
    "\n",
    "κµ¬μ²΄μ  μ§λ¬Έ β†’ **μΌλ°μ μΈ μ£Όμ **λ΅ μ¶”μƒν™”\n",
    "- \"ν† μ”μΌ 11μ‹ μ²΄ν¬μΈ λ³€κ²½ λΉ„μ©\" β†’ \"νμ¤ν…” νΈν…” μμ•½ λ³€κ²½ λΉ„μ© μ•λ‚΄\"\n",
    "- μ‹κ°„/μ”μΌ κ°™μ€ κµ¬μ²΄μ  μ •λ³΄ μ κ±°\n",
    "- μΌλ°μ μΈ μ •μ±… λ¬Έμ„λ¥Ό μ°Ύμ\n",
    "\n",
    "---\n",
    "\n",
    "### π’΅ μ‹¤μµ 3: μ¶”μƒν™”ν•κΈ°\n",
    "\n",
    "**λ―Έμ…**: ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ μ •μ±… λ¬Έμ„λ¥Ό μ°Ύλ„λ΅ λ§λ“¤κΈ°!\n",
    "\n",
    "**μ”κµ¬μ‚¬ν•­**: κµ¬μ²΄μ  μ§λ¬Έμ„ μΌλ°μ μΈ μ£Όμ λ΅ μ¶”μƒν™”ν•μ„Έμ” (νΈν…” μ΄λ¦„μ€ μ μ§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# μ—¬κΈ°λ¥Ό μμ •ν•μ„Έμ”! π‘‡\n",
    "# TODO: Few-shot ν”„λ΅¬ν”„νΈλ¥Ό μ‘μ„±ν•΄μ„ κµ¬μ²΄μ μΈ μ§λ¬Έμ„ μΌλ°μ μΈ μ£Όμ λ΅ μ¶”μƒν™”ν•μ„Έμ”\n",
    "\n",
    "my_query = \"νμ¤ν…” νΈν…” ν† μ”μΌ μ¤μ „ 11μ‹ μ²΄ν¬μΈμ„ 12μ‹λ΅ λ¦μ¶”λ ¤λ©΄ λΉ„μ©μ΄ μ–Όλ§λ‚ λ“λ‚μ”?\"\n",
    "\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ μ‘μ„±\n",
    "prompt = \"\"\"\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"μ¶λ ¥:\" in response:\n",
    "    abstract_query = response.split(\"μ¶λ ¥:\")[-1].strip()\n",
    "else:\n",
    "    abstract_query = response.strip()\n",
    "\n",
    "abstract_query = abstract_query.split('\\n')[0].strip()\n",
    "print(f\"μ¶”μƒν™”λ μ§λ¬Έ: {abstract_query}\")\n",
    "\n",
    "# μ¶”μƒν™”λ μ§λ¬ΈμΌλ΅ μ‹¤μ  κ²€μƒ‰\n",
    "results = sb_vectorstore.similarity_search(abstract_query, k=1)\n",
    "found_type = results[0].metadata['type']\n",
    "\n",
    "print(f\"μ°Ύμ€ λ¬Έμ„: {found_type} {'β…' if found_type == 'policy' else 'β'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>π“ μ •λ‹µ μ½”λ“ λ³΄κΈ° (ν΄λ¦­)</summary>\n",
    "\n",
    "```python\n",
    "# Few-shot ν”„λ΅¬ν”„νΈ\n",
    "prompt = \"\"\"λ‹Ήμ‹ μ€ κµ¬μ²΄μ μΈ μ§λ¬Έμ„ μΌλ°μ μΈ μ£Όμ λ΅ μ¶”μƒν™”ν•λ” μ „λ¬Έκ°€μ…λ‹λ‹¤.\n",
    "\n",
    "[μμ‹ 1]\n",
    "μ…λ ¥: μ‹ λΌνΈν…” ν† μ”μΌ μ•„μΉ¨ 7μ‹ μ΅°μ‹ λ©”λ‰΄λ”?\n",
    "μ¶λ ¥: μ‹ λΌνΈν…” μ΄μ© μ•λ‚΄\n",
    "\n",
    "[μμ‹ 2]\n",
    "μ…λ ¥: λ΅―λ°νΈν…” μΌμ”μΌ μ¤ν›„ 3μ‹ κ°μ‹¤ μμ•½ μ·¨μ†ν•λ©΄ μμλ£λ”?\n",
    "μ¶λ ¥: λ΅―λ°νΈν…” μ΄μ© κ·μ •\n",
    "\n",
    "[μ‹¤μ  μ‘μ—…]\n",
    "μ…λ ¥: {query}\n",
    "\n",
    "κ·μΉ™:\n",
    "1. νΈν…” μ΄λ¦„μ€ λ°λ“μ‹ μ μ§€ν•μ„Έμ” (νμ¤ν…” νΈν…”)\n",
    "2. κµ¬μ²΄μ μΈ λ‹¨μ–΄λ§ μ κ±°ν•μ„Έμ” (ν† μ”μΌ, 11μ‹, 12μ‹, λΉ„μ©)\n",
    "3. \"μ΄μ© κ·μ •\" λλ” \"μ΄μ© μ•λ‚΄\"λ΅ λ°”κΎΈμ„Έμ”\n",
    "\n",
    "μ¶λ ¥:\"\"\"\n",
    "\n",
    "# LLM νΈμ¶\n",
    "response = llm.invoke(prompt.format(query=my_query))\n",
    "\n",
    "# μ‘λ‹µ νμ‹±\n",
    "if \"μ¶λ ¥:\" in response:\n",
    "    abstract_query = response.split(\"μ¶λ ¥:\")[-1].strip()\n",
    "else:\n",
    "    abstract_query = response.strip()\n",
    "\n",
    "abstract_query = abstract_query.split('\\n')[0].strip()\n",
    "print(f\"μ¶”μƒν™”λ μ§λ¬Έ: {abstract_query}\")\n",
    "\n",
    "# μ¶”μƒν™”λ μ§λ¬ΈμΌλ΅ μ‹¤μ  κ²€μƒ‰\n",
    "results = sb_vectorstore.similarity_search(abstract_query, k=1)\n",
    "found_type = results[0].metadata['type']\n",
    "\n",
    "print(f\"μ°Ύμ€ λ¬Έμ„: {found_type} {'β…' if found_type == 'policy' else 'β'}\")\n",
    "```\n",
    "\n",
    "**ν•µμ‹¬ ν¬μΈνΈ:**\n",
    "- κµ¬μ²΄μ  μ§λ¬Έ β†’ μΌλ°μ  μ£Όμ λ΅ μ¶”μƒν™”\n",
    "- νΈν…” μ΄λ¦„μ€ μ μ§€, μ‹κ°„/μ”μΌ/κΈμ•΅ μ κ±°\n",
    "- \"μ΄μ© κ·μ •\", \"μ΄μ© μ•λ‚΄\" κ°™μ€ μΌλ° μ©μ–΄ μ‚¬μ©\n",
    "- μΌλ°μ μΈ μ •μ±… λ¬Έμ„λ¥Ό μ°Ύλ” λ° ν¨κ³Όμ \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π“ Part 4: 3κ°€μ§€ κΈ°λ²• μΆ…ν•© λΉ„κµ\n",
    "\n",
    "### π― μ–Έμ  μ–΄λ–¤ κΈ°λ²•μ„ μ“ΈκΉ?\n",
    "\n",
    "| κΈ°λ²• | μ–Έμ  μ‚¬μ©? | μμ‹ |\n",
    "|------|-----------|------|\n",
    "| **Multi-Query** | λ³µν•©μ μΈ μ§λ¬Έ | \"νΈν…” μ™λ°•ν•κ³  μΉ΄ν κ°€κ³  κ³µμ—° λ³΄κ³  μ‹¶μ–΄μ”\" |\n",
    "| **HyDE** | μ§§κ³  μ• λ§¤ν• μ§λ¬Έ | \"νμ¤ν…” νΈν…” κ°μ‹¤ μ •λ³΄\" |\n",
    "| **Step-Back** | λ„λ¬΄ κµ¬μ²΄μ μΈ μ§λ¬Έ | \"μ£Όλ§ μ²΄ν¬μΈ λ³€κ²½ κ·μ •\" β†’ \"μ²΄ν¬μΈ μ •μ±…\" |\n",
    "\n",
    "### π’΅ μ΅°ν•© μ „λµ\n",
    "\n",
    "1. **λ¨Όμ € Multi-Queryλ΅ λ¶„ν•΄**\n",
    "2. **κ° sub-queryμ— HyDEλ‚ Step-Back μ μ©**\n",
    "3. **λ¨λ“  κ²°κ³Ό ν•©μ³μ„ μ¬μμ„ν™”** (λ‹¤μ μ‹κ°„μ—!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π― Part 5: λ‚λ§μ μ§λ¬ΈμΌλ΅ μ‹¤ν—ν•κΈ°\n",
    "\n",
    "**λ―Έμ…**: μ—¬λ¬λ¶„λ§μ μ§λ¬Έκ³Ό λ¬Έμ„λ΅ 3κ°€μ§€ κΈ°λ²•μ„ ν…μ¤νΈν•΄λ³΄μ„Έμ”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# μ—¬κΈ°λ¥Ό μμ λ΅­κ² μμ •ν•μ„Έμ”! π‘‡\n",
    "\n",
    "# 1) λ‚λ§μ λ¬Έμ„ λ§λ“¤κΈ°\n",
    "my_docs_raw = [\n",
    "    {\"content\": \"μ—¬κΈ°μ— λ¬Έμ„ λ‚΄μ©μ„ μ…λ ¥ν•μ„Έμ”\", \"type\": \"doc1\"},\n",
    "    {\"content\": \"μ—¬κΈ°μ— λ¬Έμ„ λ‚΄μ©μ„ μ…λ ¥ν•μ„Έμ”\", \"type\": \"doc2\"},\n",
    "]\n",
    "\n",
    "my_docs = [Document(page_content=d[\"content\"], metadata={\"type\": d[\"type\"]}) for d in my_docs_raw]\n",
    "my_vectorstore = FAISS.from_documents(my_docs, embeddings)\n",
    "\n",
    "# 2) λ‚λ§μ μ§λ¬Έ\n",
    "my_query = \"μ—¬κΈ°μ— μ§λ¬Έμ„ μ…λ ¥ν•μ„Έμ”\"\n",
    "\n",
    "# 3) μ›ν•λ” κΈ°λ²• μ„ νƒ (Multi-Query, HyDE, Step-Back)\n",
    "# ...\n",
    "\n",
    "print(\"π‰ μ‹¤ν—μ„ μ‹μ‘ν•μ„Έμ”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## π‰ 04λ² μ™„λ£!\n",
    "\n",
    "### β… λ°°μ΄ λ‚΄μ©\n",
    "\n",
    "1. **Multi-Query**: λ³µν•© μ§λ¬Έ λ¶„ν•΄\n",
    "2. **HyDE**: κ°€μƒ λ‹µλ³€ μƒμ„±\n",
    "3. **Step-Back**: μ¶”μƒν™”\n",
    "\n",
    "### π€ λ‹¤μ μ‹κ°„ μκ³ \n",
    "\n",
    "**05λ²: ν•μ΄λΈλ¦¬λ“ κ²€μƒ‰ & μ¬μμ„ν™”**\n",
    "- BM25 ν‚¤μ›λ“ κ²€μƒ‰\n",
    "- Vector + BM25 κ²°ν•© (RRF)\n",
    "- Cross-encoder μ¬μμ„ν™”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}