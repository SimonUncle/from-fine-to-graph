{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Hybrid Search + Re-ranking - ë³µí•© ì§ˆë¬¸ ì™„ë²½ í•´ê²°! (30ë¶„)\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "- **BM25(í‚¤ì›Œë“œ) + Vector Search(ì˜ë¯¸) ê²°í•©ìœ¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ ê·¹ëŒ€í™”**\n",
    "- Reciprocal Rank Fusionìœ¼ë¡œ ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§€ëŠ¥ì  í†µí•©\n",
    "- ë©”íƒ€ë°ì´í„° ê¸°ë°˜ Re-rankingìœ¼ë¡œ ìµœì¢… ì •í™•ë„ í–¥ìƒ\n",
    "- Day1 íŒŒì¸íŠœë‹ ëª¨ë¸ë¡œ ì‹¤ì œ ë‹µë³€ í’ˆì§ˆ ì°¨ì´ ì²´í—˜\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ êµ¬ì„±\n",
    "1. **ë³µì¡í•œ í•­ê³µ+ê³µí•­ ì§ˆë¬¸** (10ë¶„) - ì—ì–´ë¯¼íŠ¸ ìˆ˜í•˜ë¬¼ + ê¹€í¬ê³µí•­ í˜¼ì¡ ì‹œê°„\n",
    "2. **3ë‹¨ê³„ ê²€ìƒ‰ ë°©ë²• ë¹„êµ** (15ë¶„) - BM25 â†’ Vector â†’ Hybrid+Rerank\n",
    "3. **Before/After ì´ì •ë¦¬** (5ë¶„) - ê²€ìƒ‰ ì •í™•ë„ ê·¹ì  ê°œì„  í™•ì¸\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ’¡ **í•µì‹¬ ì•„ì´ë””ì–´**: \"ê¹€í¬ ì¶œë°œ ì—ì–´ë¯¼íŠ¸ ìœ„íƒìˆ˜í•˜ë¬¼ ìš”ê¸ˆì´ë‘ ì¼ìš”ì¼ ë³´ì•ˆê²€ìƒ‰ëŒ€ ëœ ë¶ë¹„ëŠ” ì‹œê°„ ì•Œë ¤ì¤˜\" ê°™ì€ ë³µí•© ì§ˆë¬¸ì—ì„œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ì–´ë–»ê²Œ ì™„ë²½í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ”ì§€ ì²´í—˜í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° import (04ë²ˆ + BM25 ì¶”ê°€)\n",
    "!pip install -q langchain-community faiss-cpu sentence-transformers matplotlib pandas numpy transformers torch rank-bm25\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ğŸ¤– Day1 íŒŒì¸íŠœë‹ ëª¨ë¸ ê´€ë ¨ import\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.llms.base import LLM\n",
    "from pydantic import Field\n",
    "\n",
    "# LangChain ê´€ë ¨ import\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from collections import defaultdict\n",
    "\n",
    "# ğŸ” Hybrid Search ê´€ë ¨\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = ['AppleGothic']\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "    plt.rcParams['font.family'] = ['Malgun Gothic']\n",
    "else:  # Linux/Colab\n",
    "    plt.rcParams['font.family'] = ['NanumGothic', 'DejaVu Sans']\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì • ì™„ë£Œ!\")\n",
    "\n",
    "# Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ í´ë˜ìŠ¤ (04ë²ˆê³¼ ë™ì¼)\n",
    "class Day1FinetunedLLM(LLM):\n",
    "    \"\"\"Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” LLM í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    # Pydantic í•„ë“œ ì„ ì–¸\n",
    "    model_name: str = Field(default=\"ryanu/my-exaone-raft-model\")\n",
    "    tokenizer: Any = Field(default=None)\n",
    "    model: Any = Field(default=None)\n",
    "    \n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "    \n",
    "    def __init__(self, model_name: str = \"ryanu/my-exaone-raft-model\", **kwargs):\n",
    "        super().__init__(model_name=model_name, **kwargs)\n",
    "        print(f\"ğŸ¯ Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ: {self.model_name}\")\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"ëª¨ë¸ ë¡œë“œ\"\"\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, trust_remote_code=True)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"day1_finetuned_llm\"\n",
    "    \n",
    "    def _call(self, prompt: str, stop=None, run_manager=None, **kwargs) -> str:\n",
    "        \"\"\"ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ \"\"\"\n",
    "        # EXAONE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©\n",
    "        formatted_prompt = f\"[|system|]ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.[|endofturn|]\\n[|user|]{prompt}[|endofturn|]\\n[|assistant|]\"\n",
    "        \n",
    "        inputs = self.tokenizer(formatted_prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs, max_new_tokens=512, temperature=0.7, do_sample=True,\n",
    "                pad_token_id=self.tokenizer.pad_token_id, eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n",
    "        return response if response else \"ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "print(\"âœ… Day1FinetunedLLM í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ì–´ë¼ì¸ + ê³µí•­ ë³µí•© ì½”í¼ìŠ¤ êµ¬ì„±\n",
    "def create_aviation_corpus():\n",
    "    \"\"\"í•­ê³µì‚¬ + ê³µí•­ ë³µì¡í•œ ê²€ìƒ‰ì„ ìœ„í•œ ì½”í¼ìŠ¤\"\"\"\n",
    "    return [\n",
    "        # âœ… ìµœì‹  ê³µì‹: ì—ì–´ë¯¼íŠ¸ ìˆ˜í•˜ë¬¼\n",
    "        {\n",
    "            \"content\": \"\"\"ì—ì–´ë¯¼íŠ¸ í•­ê³µ ìˆ˜í•˜ë¬¼ ì •ì±… (2024-05-10)\n",
    "- ìœ„íƒìˆ˜í•˜ë¬¼: 15kg ë¬´ë£Œ, ì´ˆê³¼ 1kgë‹¹ 8,000ì›\n",
    "- ê¸°ë‚´ìˆ˜í•˜ë¬¼: 7kg 1ê°œ\n",
    "- ë…¸ì„ : êµ­ë‚´ì„  ë™ì¼ ê¸°ì¤€\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"ì—ì–´ë¯¼íŠ¸\", \"source\": \"official\", \"updated_at\": \"2024-05-10\"}\n",
    "        },\n",
    "        # âŒ êµ¬ë²„ì „ ê³µì‹\n",
    "        {\n",
    "            \"content\": \"\"\"ì—ì–´ë¯¼íŠ¸ ìˆ˜í•˜ë¬¼ ì•ˆë‚´ (2020-06-01)\n",
    "- ìœ„íƒìˆ˜í•˜ë¬¼: 10kg ë¬´ë£Œ, ì´ˆê³¼ 1kgë‹¹ 10,000ì›\n",
    "- ê¸°ë‚´ìˆ˜í•˜ë¬¼: 5kg 1ê°œ\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"ì—ì–´ë¯¼íŠ¸\", \"source\": \"official\", \"updated_at\": \"2020-06-01\"}\n",
    "        },\n",
    "        # âŒ ë£¨ë¨¸/ì»¤ë®¤ë‹ˆí‹°\n",
    "        {\n",
    "            \"content\": \"\"\"ì—ì–´ë¯¼íŠ¸ ìˆ˜í•˜ë¬¼ ìµœê·¼ì— ë‹¤ ë°”ë€Œì—ˆë‹¤ë˜ë°ìš”? (í™•ì¸ í•„ìš”)\n",
    "- ìœ„íƒ ë¬´ë£Œ ì—†ì–´ì¡Œë‹¤ëŠ” ì†Œë¬¸\n",
    "- ì´ˆê³¼ìš”ê¸ˆ ëŒ€í­ ì¸ìƒëë‹¤ëŠ” í›„ê¸° ë§ìŒ\"\"\",\n",
    "            \"metadata\": {\"type\": \"forum\", \"airline\": \"ì—ì–´ë¯¼íŠ¸\", \"source\": \"user_forum\", \"updated_at\": \"2024-07-01\"}\n",
    "        },\n",
    "        # âœ… ê¹€í¬ê³µí•­ í˜¼ì¡ ì‹œê°„(ê³µì‹)\n",
    "        {\n",
    "            \"content\": \"\"\"ê¹€í¬ê³µí•­ ë³´ì•ˆê²€ìƒ‰ í˜¼ì¡ë„ ì•ˆë‚´ (2024-04-15)\n",
    "- ì¼ìš”ì¼: 08~10ì‹œ í˜¼ì¡, 12~14ì‹œëŠ” ë¹„êµì  í•œì‚°\n",
    "- í‰ì¼: ì¶œê·¼ì‹œê°„ëŒ€ 07~09ì‹œ í˜¼ì¡\n",
    "- ì˜¤í›„ ì‹œê°„ëŒ€ëŠ” ì „ë°˜ì ìœ¼ë¡œ ì—¬ìœ ë¡œì›€\"\"\",\n",
    "            \"metadata\": {\"type\": \"airport_info\", \"airport\": \"ê¹€í¬\", \"source\": \"official\", \"updated_at\": \"2024-04-15\"}\n",
    "        },\n",
    "        # âŒ ì¸ì²œê³µí•­(ì§€ì—­ í˜¼ì„ )\n",
    "        {\n",
    "            \"content\": \"\"\"ì¸ì²œê³µí•­ ë³´ì•ˆê²€ìƒ‰ í˜¼ì¡ë„ (2024-04-20)\n",
    "- ì£¼ë§: 09~11ì‹œ í”¼í¬, 15~17ì‹œ í•œì‚°\n",
    "- êµ­ì œì„  í„°ë¯¸ë„ì€ ë³„ë„ ì‹œê°„ëŒ€ ì ìš©\"\"\",\n",
    "            \"metadata\": {\"type\": \"airport_info\", \"airport\": \"ì¸ì²œ\", \"source\": \"official\", \"updated_at\": \"2024-04-20\"}\n",
    "        },\n",
    "        # âŒ ë‹¤ë¥¸ í•­ê³µì‚¬(ë¸Œëœë“œ í˜¼ì„ )\n",
    "        {\n",
    "            \"content\": \"\"\"ìŠ¤ì¹´ì´ë¸”ë£¨ í•­ê³µ ìˆ˜í•˜ë¬¼ ì •ì±… (2024-03-01)\n",
    "- ìœ„íƒìˆ˜í•˜ë¬¼: 20kg ë¬´ë£Œ\n",
    "- ê¸°ë‚´ìˆ˜í•˜ë¬¼: 10kg 1ê°œ\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"ìŠ¤ì¹´ì´ë¸”ë£¨\", \"source\": \"official\", \"updated_at\": \"2024-03-01\"}\n",
    "        },\n",
    "        # âŒ ë¸”ë¡œê·¸ ì¼ë°˜ íŒ\n",
    "        {\n",
    "            \"content\": \"\"\"ê³µí•­ ë¹¨ë¦¬ í†µê³¼í•˜ëŠ” ì—¬í–‰ íŒ\n",
    "- ìˆ˜í•˜ë¬¼ ê°€ë³ê²Œ ì¤€ë¹„í•˜ê¸°\n",
    "- ì´ë¥¸ ì‹œê°„ ë„ì°© ì¶”ì²œ\n",
    "- ì£¼ë§ ì˜¤ì „ í”¼í¬íƒ€ì„ì€ í”¼í•˜ê¸°\"\"\",\n",
    "            \"metadata\": {\"type\": \"blog\", \"source\": \"blog\", \"updated_at\": \"2024-08-01\"}\n",
    "        },\n",
    "        # ì¶”ê°€ ì¡ìŒë“¤\n",
    "        {\n",
    "            \"content\": \"\"\"ë¶€ì‚°ê³µí•­ ë³´ì•ˆê²€ìƒ‰ íŒ\n",
    "- ì£¼ë§ ì˜¤ì „ í•œì‚°í•¨\n",
    "- êµ­ë‚´ì„  ìœ„ì£¼ë¼ ë¹ ë¥¸ í†µê³¼ ê°€ëŠ¥\"\"\",\n",
    "            \"metadata\": {\"type\": \"airport_info\", \"airport\": \"ë¶€ì‚°\", \"source\": \"blog\", \"updated_at\": \"2024-06-01\"}\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"\"\"ì—ì–´ì½”ë¦¬ì•„ ìœ„íƒìˆ˜í•˜ë¬¼ ìš”ê¸ˆ (2024-04-01)\n",
    "- 15kgê¹Œì§€ ë¬´ë£Œ\n",
    "- ì¶”ê°€ 1kgë‹¹ 7,000ì›\"\"\",\n",
    "            \"metadata\": {\"type\": \"airline_policy\", \"airline\": \"ì—ì–´ì½”ë¦¬ì•„\", \"source\": \"official\", \"updated_at\": \"2024-04-01\"}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# ì „ì²´ ë¬¸ì„œ ìƒì„±\n",
    "aviation_docs = create_aviation_corpus()\n",
    "\n",
    "print(f\"ğŸ“Š í•­ê³µ + ê³µí•­ ë¬¸ì„œ: {len(aviation_docs)}ê°œ ì¤€ë¹„ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“‹ ë¬¸ì„œ ì¢…ë¥˜:\")\n",
    "for doc in aviation_docs:\n",
    "    doc_type = doc[\"metadata\"].get(\"type\", \"unknown\")\n",
    "    entity = doc[\"metadata\"].get(\"airline\") or doc[\"metadata\"].get(\"airport\", \"ì¼ë°˜\")\n",
    "    source = doc[\"metadata\"].get(\"source\", \"?\")\n",
    "    updated = doc[\"metadata\"].get(\"updated_at\", \"?\")\n",
    "    first_line = doc[\"content\"].strip().split('\\n')[0]\n",
    "    print(f\"  - [{doc_type}|{entity}|{source}|{updated}] {first_line}\")\n",
    "\n",
    "# BM25 + Vector ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "print(\"\\nğŸ” BM25 + Vector ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...\")\n",
    "\n",
    "# LangChain Documentë¡œ ë³€í™˜\n",
    "lc_documents = [Document(page_content=doc[\"content\"], metadata=doc[\"metadata\"]) for doc in aviation_docs]\n",
    "\n",
    "# ì²­í‚¹ (ê°„ë‹¨í•˜ê²Œ)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(lc_documents)\n",
    "\n",
    "# Vector Store (FAISS + BGE-M3)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "# BM25 ì¸ë±ìŠ¤\n",
    "texts = [chunk.page_content for chunk in chunks]\n",
    "bm25 = BM25Okapi([text.split() for text in texts])\n",
    "\n",
    "print(f\"âœ… ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ! (ì²­í¬ ìˆ˜: {len(chunks)})\")\n",
    "\n",
    "# Day1 ëª¨ë¸ ì´ˆê¸°í™”\n",
    "day1_llm = Day1FinetunedLLM()\n",
    "\n",
    "# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "print(\"âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™˜ê²½ êµ¬ì¶• ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ¯ ê°„ë‹¨í•œ 3ë‹¨ê³„ ê²€ìƒ‰ ë¹„êµ\n\ndef simple_bm25_search(query, top_k=3):\n    \"\"\"BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê°•ì )\"\"\"\n    scores = bm25.get_scores(query.split())\n    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n    return [chunks[i] for i in top_indices]\n\ndef simple_vector_search(query, top_k=3):\n    \"\"\"Vector ê²€ìƒ‰ (ì˜ë¯¸ ê°•ì )\"\"\"\n    return vectorstore.similarity_search(query, k=top_k)\n\ndef simple_hybrid_search(query, top_k=3):\n    \"\"\"í•˜ì´ë¸Œë¦¬ë“œ + ë¦¬ë­í¬ (ìµœê³  ì„±ëŠ¥)\"\"\"\n    # BM25 + Vector ê°ê° 5ê°œì”©\n    bm25_docs = simple_bm25_search(query, top_k=5)\n    vector_docs = simple_vector_search(query, top_k=5)\n    \n    # ì¤‘ë³µ ì œê±°í•˜ì—¬ ëª¨ë“  í›„ë³´ ìˆ˜ì§‘\n    all_docs = []\n    seen_content = set()\n    for doc in bm25_docs + vector_docs:\n        if doc.page_content not in seen_content:\n            all_docs.append(doc)\n            seen_content.add(doc.page_content)\n    \n    # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ìŠ¤ì½”ì–´ë§ + ë¦¬ë­í¬\n    def get_relevance_score(doc):\n        metadata = doc.metadata\n        score = 0.0\n        \n        # ê¸°ë³¸ ì ìˆ˜\n        score += 1.0\n        \n        # ğŸ¯ í•µì‹¬ ê°€ì‚°ì  (ë” ê°•í•˜ê²Œ!)\n        if metadata.get(\"airline\") == \"ì—ì–´ë¯¼íŠ¸\":\n            score += 2.0  # ì—ì–´ë¯¼íŠ¸ ë¸Œëœë“œ ë§¤ì¹˜\n        if metadata.get(\"airport\") == \"ê¹€í¬\":\n            score += 2.0  # ê¹€í¬ê³µí•­ ë§¤ì¹˜\n        if metadata.get(\"source\") == \"official\":\n            score += 1.5  # ê³µì‹ ì†ŒìŠ¤\n        if metadata.get(\"updated_at\", \"0000\") >= \"2024-01-01\":\n            score += 1.0  # 2024ë…„ ìµœì‹ \n            \n        return score\n    \n    # ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì •ë ¬\n    scored_docs = [(doc, get_relevance_score(doc)) for doc in all_docs]\n    sorted_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n    \n    return [doc for doc, _ in sorted_docs[:top_k]]\n\ndef show_results(title, docs):\n    \"\"\"ê²°ê³¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\"\"\"\n    print(f\"\\n{title}\")\n    print(\"=\" * 60)\n    \n    for i, doc in enumerate(docs, 1):\n        metadata = doc.metadata\n        source = metadata.get(\"source\", \"?\")\n        entity = metadata.get(\"airline\") or metadata.get(\"airport\", \"-\")\n        updated = metadata.get(\"updated_at\", \"?\")\n        tag = f\"[{source}|{entity}|{updated}]\"\n        first_line = doc.page_content.strip().split('\\n')[0]\n        print(f\"  {i}. {tag} {first_line}\")\n\n# ğŸ¯ ë³µí•© ì§ˆë¬¸ìœ¼ë¡œ 3ë‹¨ê³„ ë¹„êµ\nmain_query = \"ê¹€í¬ ì¶œë°œ ì—ì–´ë¯¼íŠ¸ ìœ„íƒìˆ˜í•˜ë¬¼ ìš”ê¸ˆì´ë‘ ì¼ìš”ì¼ ë³´ì•ˆê²€ìƒ‰ëŒ€ ëœ ë¶ë¹„ëŠ” ì‹œê°„ ì•Œë ¤ì¤˜\"\n\nprint(f\"ğŸ¯ ë³µí•© ì§ˆë¬¸: '{main_query}'\")\nprint(\"ğŸ’¡ ì–´ë ¤ìš´ ì´ìœ : íŠ¹ì • í•­ê³µì‚¬ + íŠ¹ì • ê³µí•­ + ìµœì‹  ì •ë³´ + ë¸Œëœë“œ/ì§€ì—­ í˜¼ì„ \\n\")\n\n# A) BM25ë§Œ \nbm25_docs = simple_bm25_search(main_query, top_k=3)\nshow_results(\"âŒ A) BM25ë§Œ (í‚¤ì›Œë“œ ë§¤ì¹­ ê°•ì )\", bm25_docs)\n\n# B) Vectorë§Œ\nvector_docs = simple_vector_search(main_query, top_k=3)\nshow_results(\"âŒ B) Vectorë§Œ (ì˜ë¯¸ ì´í•´ ê°•ì )\", vector_docs)\n\n# C) Hybrid + Rerank\nhybrid_docs = simple_hybrid_search(main_query, top_k=3)\nshow_results(\"âœ… C) Hybrid + Rerank (ì™„ë²½í•œ ê²°ê³¼!)\", hybrid_docs)\n\nprint(\"\\nğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ í˜!\")\nprint(\"â€¢ BM25: 'ìœ„íƒìˆ˜í•˜ë¬¼' í‚¤ì›Œë“œ ì •í™•íˆ ì°¾ìŒ\")\nprint(\"â€¢ Vector: 'ëœ ë¶ë¹„ëŠ” ì‹œê°„' ì˜ë¯¸ ì •í™•íˆ ì´í•´\")  \nprint(\"â€¢ Hybrid: ë‘˜ ë‹¤ ì°¾ê³  + ë©”íƒ€ë°ì´í„°ë¡œ ìµœì‹  ì—ì–´ë¯¼íŠ¸+ê¹€í¬ ìš°ì„ !\")\n\n# ğŸ” ê° ë‹¨ê³„ë³„ ìƒì„¸ ë¶„ì„\nprint(\"\\nğŸ“Š ë‹¨ê³„ë³„ ë¶„ì„:\")\nprint(\"A) BM25: í‚¤ì›Œë“œ ë§¤ì¹­ â†—ï¸ í•˜ì§€ë§Œ ë‹¤ë¥¸ í•­ê³µì‚¬/êµ¬ë²„ì „ ì„ì„\")\nprint(\"B) Vector: ì˜ë¯¸ ì´í•´ â†—ï¸ í•˜ì§€ë§Œ ì¸ì²œê³µí•­ ë“± í˜¼ì„ \")\nprint(\"C) Hybrid: A+B ì¥ì  ê²°í•© + ë©”íƒ€ ë¦¬ë­í¬ë¡œ ì •ë‹µ ë³´ì¥! âœ¨\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ¯ ì‹¤ì œ RAG ë‹µë³€ ë¹„êµ\n\ndef get_rag_answer(docs, query):\n    \"\"\"ë¬¸ì„œë“¤ë¡œ ì§ì ‘ RAG ë‹µë³€ ìƒì„±\"\"\"\n    if not docs:\n        return \"ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n    \n    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n    context = \"\\n\\n\".join([doc.page_content for doc in docs[:2]])\n    \n    # í”„ë¡¬í”„íŠ¸ ìƒì„±\n    full_prompt = f\"\"\"ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n\nì»¨í…ìŠ¤íŠ¸: {context}\n\nì§ˆë¬¸: {query}\n\në‹µë³€:\"\"\"\n    \n    try:\n        answer = day1_llm._call(full_prompt)\n        return answer.strip() if answer else \"ë‹µë³€ ìƒì„± ì‹¤íŒ¨\"\n    except Exception as e:\n        return f\"[ì˜¤ë¥˜: {str(e)}]\"\n\nprint(\"ğŸ¤– ì‹¤ì œ RAG ë‹µë³€ ë¹„êµ\")\nprint(\"=\" * 50)\n\ntest_queries = [\n    \"ì—ì–´ë¯¼íŠ¸ ìœ„íƒìˆ˜í•˜ë¬¼ ìš”ê¸ˆì´ ì–¼ë§ˆì•¼?\",\n    \"ê¹€í¬ê³µí•­ ì¼ìš”ì¼ ë³´ì•ˆê²€ìƒ‰ ëœ ë¶ë¹„ëŠ” ì‹œê°„ì€?\",\n    main_query  # ë³µí•© ì§ˆë¬¸\n]\n\nfor query in test_queries:\n    print(f\"\\nğŸ“‹ ì§ˆë¬¸: '{query}'\")\n    print(\"-\" * 40)\n    \n    # ê° ê²€ìƒ‰ ë°©ë²•ìœ¼ë¡œ ë¬¸ì„œ ê°€ì ¸ì™€ì„œ ë‹µë³€ ìƒì„±\n    bm25_docs = simple_bm25_search(query, top_k=2)\n    vector_docs = simple_vector_search(query, top_k=2)\n    hybrid_docs = simple_hybrid_search(query, top_k=2)\n    \n    print(\"âŒ BM25 ê²€ìƒ‰ ë‹µë³€:\")\n    bm25_answer = get_rag_answer(bm25_docs, query)\n    print(f\"  {bm25_answer}\\n\")\n    \n    print(\"âŒ Vector ê²€ìƒ‰ ë‹µë³€:\")\n    vector_answer = get_rag_answer(vector_docs, query)\n    print(f\"  {vector_answer}\\n\")\n    \n    print(\"âœ… Hybrid + Rerank ë‹µë³€:\")\n    hybrid_answer = get_rag_answer(hybrid_docs, query)\n    print(f\"  {hybrid_answer}\\n\")\n\nprint(\"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ë‹µë³€ í’ˆì§ˆ ìš°ìˆ˜ì„±!\")\nprint(\"=\" * 40)\nprint(\"âœ… ì •í™•ì„±: ìµœì‹  ê³µì‹ ì •ë³´ ìš°ì„  í™œìš©\")\nprint(\"âœ… ì™„ì„±ë„: ë³µí•© ì§ˆë¬¸ì˜ ëª¨ë“  ë¶€ë¶„ì— ë‹µë³€\") \nprint(\"âœ… ì‹ ë¢°ì„±: ë£¨ë¨¸/êµ¬ë²„ì „ ì •ë³´ ë°°ì œ\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ì¬ìˆœìœ„í™” ì™„ë£Œ!\n",
    "\n",
    "### ğŸ“Š í•µì‹¬ í•™ìŠµ ì„±ê³¼\n",
    "- **BM25**: í‚¤ì›Œë“œ ë§¤ì¹­ ê°•ì  (\"ìœ„íƒìˆ˜í•˜ë¬¼\") â†’ í•˜ì§€ë§Œ ë¸”ë¡œê·¸/êµ¬ë²„ì „ í˜¼ì¬\n",
    "- **Vector**: ì˜ë¯¸ ì´í•´ ê°•ì  (\"ëœ ë¶ë¹„ëŠ” ì‹œê°„\") â†’ í•˜ì§€ë§Œ ë¸Œëœë“œ/ì§€ì—­ í˜¼ì„ \n",
    "- **Hybrid + Rerank**: ë‘ ë°©ì‹ì˜ ì¥ì  ê²°í•© + ë©”íƒ€ë°ì´í„°ë¡œ ìµœì¢… ì •í™•ë„ ë³´ì¥\n",
    "\n",
    "### ğŸ’¡ ê¸°ìˆ  ìŠ¤íƒ\n",
    "1. **BM25**: í‚¤ì›Œë“œ ê¸°ë°˜ ì •í™•í•œ ë§¤ì¹­\n",
    "2. **Vector Search**: BAAI/bge-m3ë¡œ ì˜ë¯¸ì  ìœ ì‚¬ë„ ì¸¡ì •\n",
    "3. **RRF**: Reciprocal Rank Fusionìœ¼ë¡œ ì§€ëŠ¥ì  ê²°ê³¼ ìœµí•©\n",
    "4. **Meta Rerank**: ê³µì‹ì„±/ë¸Œëœë“œ/ì§€ì—­/ìµœì‹ ì„± 4ì°¨ì› ê°€ì¤‘ì¹˜\n",
    "\n",
    "### ğŸš€ ì‹¤ë¬´ ì ìš© í¬ì¸íŠ¸\n",
    "- **ë³µí•© ì§ˆë¬¸**: ì—¬ëŸ¬ ê°œë…ì´ ì„ì¸ ì§ˆë¬¸ì—ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í•„ìˆ˜\n",
    "- **ë„ë©”ì¸ íŠ¹í™”**: ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì¬ìˆœìœ„í™”ë¡œ ë„ë©”ì¸ ì •í™•ë„ í–¥ìƒ\n",
    "- **ì„±ëŠ¥ ìµœì í™”**: ê° ê²€ìƒ‰ ë°©ì‹ì˜ ê°•ì ì„ ì‚´ë¦° ìµœì  ì¡°í•©\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‰ **05ë²ˆ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤ìŠµ ì™„ë£Œ!** ì´ì œ RAG ì‹œìŠ¤í…œì˜ ìµœê³  ì„±ëŠ¥ì„ ê²½í—˜í•˜ì…¨ìŠµë‹ˆë‹¤!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}