{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” 00.03: ê¸°ë³¸ RAG ë§›ë³´ê¸°\n",
    "\n",
    "## ğŸ’¡ ê²€ìƒ‰ + ìƒì„±ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ì²´í—˜!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì´ì „ ë‹¨ê³„ì—ì„œ ë§Œë“  ë²¡í„° ì €ì¥ì†Œ ì¬ì‚¬ìš©\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ê°„ë‹¨í•œ ë¬¸ì„œë“¤\n",
    "documents = [\n",
    "    \"íŒŒì´ì¬ì€ 1991ë…„ ê·€ë„ê°€ ë§Œë“  í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ì€ ë°ì´í„°ë¡œ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\",\n",
    "    \"RAGëŠ” ê²€ìƒ‰ê³¼ ìƒì„±ì„ í•©ì¹œ AIì…ë‹ˆë‹¤.\"\n",
    "]\n",
    "docs = [Document(page_content=text) for text in documents]\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\")\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "print(\"ğŸ—ƒï¸ ë²¡í„° ì €ì¥ì†Œ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ì§ˆë¬¸ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰í•˜ê¸°\n",
    "question = \"RAGê°€ ë­ì•¼?\"\n",
    "results = vectorstore.similarity_search(question, k=1)\n",
    "context = results[0].page_content\n",
    "print(f\"ğŸ” '{question}' ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "print(f\"â†’ ì°¾ì€ ë¬¸ì„œ: {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "from transformers import pipeline\n",
    "\n",
    "# ê°„ë‹¨í•œ ìƒì„± ëª¨ë¸ (ì‹¤ì œë¡  ë” í° ëª¨ë¸ ì‚¬ìš©)\n",
    "generator = pipeline('text-generation', \n",
    "                    model='gpt2', \n",
    "                    max_length=100, \n",
    "                    do_sample=True, \n",
    "                    temperature=0.7)\n",
    "\n",
    "prompt = f\"ì§ˆë¬¸: {question}\\nì»¨í…ìŠ¤íŠ¸: {context}\\në‹µë³€:\"\n",
    "response = generator(prompt, max_length=len(prompt)+50)[0]['generated_text']\n",
    "answer = response[len(prompt):].strip()\n",
    "\n",
    "print(f\"ğŸ¤– RAG ë‹µë³€:\")\n",
    "print(f\"â†’ {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. RAG ê³¼ì • ì •ë¦¬\n",
    "print(\"ğŸ‰ ê¸°ë³¸ RAG ì²´í—˜ ì™„ë£Œ!\")\n",
    "print(\"âœ… 1ë‹¨ê³„: ì§ˆë¬¸ ì…ë ¥\")\n",
    "print(\"âœ… 2ë‹¨ê³„: ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\")\n",
    "print(\"âœ… 3ë‹¨ê³„: ì»¨í…ìŠ¤íŠ¸ë¡œ ë‹µë³€ ìƒì„±\")\n",
    "print(\"ğŸ’¡ ë‹¤ìŒ: 00.04ì—ì„œ ê³ ê¸‰ RAG ê¸°ëŠ¥ë“¤ ë§›ë³´ê¸°!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
