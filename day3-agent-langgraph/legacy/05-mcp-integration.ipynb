{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 3 - MCP Integration with LangGraph\n",
        "# MCP(Model Context Protocol) í†µí•© ì‹¤ìŠµ\n",
        "\n",
        "ì´ ì‹¤ìŠµì—ì„œëŠ” LangGraphì™€ Day 1ì˜ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬\n",
        "MCP(Model Context Protocol)ë¥¼ í†µí•œ ì™¸ë¶€ ë„êµ¬ í†µí•© ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## í•µì‹¬ ê°œë…\n",
        "- MCP(Model Context Protocol) ì´í•´\n",
        "- ì™¸ë¶€ API ë° ë„êµ¬ í†µí•©\n",
        "- ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰ ì›Œí¬í”Œë¡œ\n",
        "- ê²°ê³¼ í†µí•© ë° ì‘ë‹µ ìƒì„±\n",
        "- ì—ëŸ¬ ì²˜ë¦¬ ë° ë°±ì—… ì „ëµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain langgraph requests beautifulsoup4 transformers torch python-dateutil wikipedia-api yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict, Any, Optional, TypedDict, Callable\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import wikipedia\n",
        "import yfinance as yf\n",
        "from dateutil import parser\n",
        "\n",
        "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Day1FinetunedLLM:\n",
        "    def __init__(self, model_name=\"ryanu/my-exaone-raft-model\"):\n",
        "        self.model_name = model_name\n",
        "        self.base_model = \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        print(f\"ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}\")\n",
        "        print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
        "        \n",
        "        # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.base_model,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # íŒŒì¸íŠœë‹ëœ ì–´ëŒ‘í„° ë¡œë“œ\n",
        "        try:\n",
        "            self.model = PeftModel.from_pretrained(self.model, model_name)\n",
        "            print(\"âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš©: {e}\")\n",
        "    \n",
        "    def generate(self, prompt: str, max_length: int = 512, temperature: float = 0.7) -> str:\n",
        "        \"\"\"í…ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            prompt, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=2048\n",
        "        ).to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=inputs['input_ids'].shape[1] + max_length,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        generated_text = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:], \n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        \n",
        "        return generated_text.strip()\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = Day1FinetunedLLM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MCP ë„êµ¬ ì •ì˜\n",
        "\n",
        "ë‹¤ì–‘í•œ ì™¸ë¶€ ì„œë¹„ìŠ¤ì™€ APIë¥¼ í†µí•©í•˜ëŠ” ë„êµ¬ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MCPTool:\n",
        "    \"\"\"MCP ë„êµ¬ ê¸°ë³¸ í´ë˜ìŠ¤\"\"\"\n",
        "    name: str\n",
        "    description: str\n",
        "    parameters: Dict[str, Any]\n",
        "    function: Callable\n",
        "\n",
        "class MCPToolRegistry:\n",
        "    \"\"\"MCP ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.tools = {}\n",
        "        self._register_default_tools()\n",
        "    \n",
        "    def register_tool(self, tool: MCPTool):\n",
        "        \"\"\"ë„êµ¬ ë“±ë¡\"\"\"\n",
        "        self.tools[tool.name] = tool\n",
        "    \n",
        "    def get_tool(self, name: str) -> Optional[MCPTool]:\n",
        "        \"\"\"ë„êµ¬ ê°€ì ¸ì˜¤ê¸°\"\"\"\n",
        "        return self.tools.get(name)\n",
        "    \n",
        "    def list_tools(self) -> List[str]:\n",
        "        \"\"\"ë“±ë¡ëœ ë„êµ¬ ëª©ë¡\"\"\"\n",
        "        return list(self.tools.keys())\n",
        "    \n",
        "    def get_tools_description(self) -> str:\n",
        "        \"\"\"ë„êµ¬ ì„¤ëª… í…ìŠ¤íŠ¸\"\"\"\n",
        "        descriptions = []\n",
        "        for name, tool in self.tools.items():\n",
        "            param_desc = \", \".join([f\"{k}: {v.get('description', v.get('type', ''))}\" \n",
        "                                    for k, v in tool.parameters.items()])\n",
        "            descriptions.append(f\"{name}: {tool.description} (ë§¤ê°œë³€ìˆ˜: {param_desc})\")\n",
        "        return \"\\n\".join(descriptions)\n",
        "    \n",
        "    def _register_default_tools(self):\n",
        "        \"\"\"ê¸°ë³¸ ë„êµ¬ë“¤ ë“±ë¡\"\"\"\n",
        "        \n",
        "        # ì›¹ ê²€ìƒ‰ ë„êµ¬\n",
        "        def web_search(query: str, max_results: int = 5) -> Dict[str, Any]:\n",
        "            \"\"\"ì›¹ ê²€ìƒ‰ (ê°„ë‹¨í•œ êµ¬í˜„)\"\"\"\n",
        "            try:\n",
        "                # ì‹¤ì œë¡œëŠ” Google Search APIë‚˜ ë‹¤ë¥¸ ê²€ìƒ‰ API ì‚¬ìš©\n",
        "                # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜\n",
        "                results = [\n",
        "                    {\n",
        "                        \"title\": f\"ê²€ìƒ‰ ê²°ê³¼ {i+1}: {query}\",\n",
        "                        \"url\": f\"https://example.com/result{i+1}\",\n",
        "                        \"snippet\": f\"{query}ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì›¹í˜ì´ì§€ì…ë‹ˆë‹¤.\"\n",
        "                    }\n",
        "                    for i in range(min(max_results, 3))\n",
        "                ]\n",
        "                return {\"success\": True, \"results\": results}\n",
        "            except Exception as e:\n",
        "                return {\"success\": False, \"error\": str(e)}\n",
        "        \n",
        "        self.register_tool(MCPTool(\n",
        "            name=\"web_search\",\n",
        "            description=\"ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\",\n",
        "            parameters={\n",
        "                \"query\": {\"type\": \"string\", \"description\": \"ê²€ìƒ‰í•  í‚¤ì›Œë“œ\"},\n",
        "                \"max_results\": {\"type\": \"integer\", \"description\": \"ìµœëŒ€ ê²°ê³¼ ìˆ˜\", \"default\": 5}\n",
        "            },\n",
        "            function=web_search\n",
        "        ))\n",
        "        \n",
        "        # ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰ ë„êµ¬\n",
        "        def wikipedia_search(query: str, lang: str = \"ko\") -> Dict[str, Any]:\n",
        "            \"\"\"ìœ„í‚¤í”¼ë””ì•„ ê²€ìƒ‰\"\"\"\n",
        "            try:\n",
        "                wikipedia.set_lang(lang)\n",
        "                # ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°\n",
        "                search_results = wikipedia.search(query, results=3)\n",
        "                \n",
        "                if not search_results:\n",
        "                    return {\"success\": False, \"error\": \"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"}\n",
        "                \n",
        "                # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°\n",
        "                try:\n",
        "                    summary = wikipedia.summary(search_results[0], sentences=3)\n",
        "                    page = wikipedia.page(search_results[0])\n",
        "                    \n",
        "                    return {\n",
        "                        \"success\": True,\n",
        "                        \"title\": page.title,\n",
        "                        \"summary\": summary,\n",
        "                        \"url\": page.url,\n",
        "                        \"related_topics\": search_results[1:]\n",
        "                    }\n",
        "                except wikipedia.DisambiguationError as e:\n",
        "                    return {\n",
        "                        \"success\": True,\n",
        "                        \"title\": f\"ì—¬ëŸ¬ ì˜ë¯¸: {query}\",\n",
        "                        \"summary\": f\"'{query}'ëŠ” ì—¬ëŸ¬ ì˜ë¯¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.\",\n",
        "                        \"options\": e.options[:5],\n",
        "                        \"related_topics\": e.options[:3]\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    return {\"success\": False, \"error\": f\"í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {str(e)}\"}\n",
        "                    \n",
        "            except Exception as e:\n",
        "                return {\"success\": False, \"error\": str(e)}\n",
        "        \n",
        "        self.register_tool(MCPTool(\n",
        "            name=\"wikipedia_search\",\n",
        "            description=\"ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤\",\n",
        "            parameters={\n",
        "                \"query\": {\"type\": \"string\", \"description\": \"ê²€ìƒ‰í•  ì£¼ì œ\"},\n",
        "                \"lang\": {\"type\": \"string\", \"description\": \"ì–¸ì–´ ì½”ë“œ\", \"default\": \"ko\"}\n",
        "            },\n",
        "            function=wikipedia_search\n",
        "        ))\n",
        "        \n",
        "        # ì£¼ì‹ ì •ë³´ ì¡°íšŒ ë„êµ¬\n",
        "        def get_stock_info(symbol: str, period: str = \"1d\") -> Dict[str, Any]:\n",
        "            \"\"\"ì£¼ì‹ ì •ë³´ ì¡°íšŒ\"\"\"\n",
        "            try:\n",
        "                stock = yf.Ticker(symbol)\n",
        "                hist = stock.history(period=period)\n",
        "                info = stock.info\n",
        "                \n",
        "                if hist.empty:\n",
        "                    return {\"success\": False, \"error\": f\"ì£¼ì‹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {symbol}\"}\n",
        "                \n",
        "                latest = hist.iloc[-1]\n",
        "                \n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"symbol\": symbol,\n",
        "                    \"company_name\": info.get('longName', symbol),\n",
        "                    \"current_price\": round(latest['Close'], 2),\n",
        "                    \"change\": round(latest['Close'] - latest['Open'], 2),\n",
        "                    \"change_percent\": round((latest['Close'] - latest['Open']) / latest['Open'] * 100, 2),\n",
        "                    \"volume\": int(latest['Volume']),\n",
        "                    \"high\": round(latest['High'], 2),\n",
        "                    \"low\": round(latest['Low'], 2),\n",
        "                    \"market_cap\": info.get('marketCap'),\n",
        "                    \"sector\": info.get('sector', 'N/A')\n",
        "                }\n",
        "                \n",
        "            except Exception as e:\n",
        "                return {\"success\": False, \"error\": str(e)}\n",
        "        \n",
        "        self.register_tool(MCPTool(\n",
        "            name=\"get_stock_info\",\n",
        "            description=\"ì£¼ì‹ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤\",\n",
        "            parameters={\n",
        "                \"symbol\": {\"type\": \"string\", \"description\": \"ì£¼ì‹ ì‹¬ë³¼ (ì˜ˆ: AAPL, GOOGL, 005930.KS)\"},\n",
        "                \"period\": {\"type\": \"string\", \"description\": \"ê¸°ê°„ (1d, 5d, 1mo, 3mo, 1y)\", \"default\": \"1d\"}\n",
        "            },\n",
        "            function=get_stock_info\n",
        "        ))\n",
        "        \n",
        "        # ë‚ ì”¨ ì •ë³´ ë„êµ¬ (ì‹œë®¬ë ˆì´ì…˜)\n",
        "        def get_weather(city: str, units: str = \"metric\") -> Dict[str, Any]:\n",
        "            \"\"\"ë‚ ì”¨ ì •ë³´ ì¡°íšŒ (ì‹œë®¬ë ˆì´ì…˜)\"\"\"\n",
        "            # ì‹¤ì œë¡œëŠ” OpenWeatherMap API ë“±ì„ ì‚¬ìš©\n",
        "            weather_data = {\n",
        "                \"ì„œìš¸\": {\"temp\": 15, \"humidity\": 60, \"description\": \"ë§‘ìŒ\"},\n",
        "                \"ë¶€ì‚°\": {\"temp\": 18, \"humidity\": 70, \"description\": \"êµ¬ë¦„ ë§ìŒ\"},\n",
        "                \"ì œì£¼\": {\"temp\": 20, \"humidity\": 80, \"description\": \"ë¹„\"},\n",
        "            }\n",
        "            \n",
        "            if city in weather_data:\n",
        "                data = weather_data[city]\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"city\": city,\n",
        "                    \"temperature\": data[\"temp\"],\n",
        "                    \"humidity\": data[\"humidity\"],\n",
        "                    \"description\": data[\"description\"],\n",
        "                    \"units\": units\n",
        "                }\n",
        "            else:\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"city\": city,\n",
        "                    \"temperature\": 22,\n",
        "                    \"humidity\": 65,\n",
        "                    \"description\": \"ë§‘ìŒ\",\n",
        "                    \"units\": units\n",
        "                }\n",
        "        \n",
        "        self.register_tool(MCPTool(\n",
        "            name=\"get_weather\",\n",
        "            description=\"íŠ¹ì • ë„ì‹œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤\",\n",
        "            parameters={\n",
        "                \"city\": {\"type\": \"string\", \"description\": \"ë„ì‹œëª…\"},\n",
        "                \"units\": {\"type\": \"string\", \"description\": \"ì˜¨ë„ ë‹¨ìœ„ (metric, imperial)\", \"default\": \"metric\"}\n",
        "            },\n",
        "            function=get_weather\n",
        "        ))\n",
        "        \n",
        "        # ê³„ì‚°ê¸° ë„êµ¬\n",
        "        def calculate(expression: str) -> Dict[str, Any]:\n",
        "            \"\"\"ìˆ˜í•™ ê³„ì‚°\"\"\"\n",
        "            try:\n",
        "                # ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ ë¬¸ìë§Œ ì‚¬ìš©\n",
        "                allowed_chars = set('0123456789+-*/.() ')\n",
        "                if not all(c in allowed_chars for c in expression):\n",
        "                    return {\"success\": False, \"error\": \"í—ˆìš©ë˜ì§€ ì•Šì€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤\"}\n",
        "                \n",
        "                result = eval(expression)\n",
        "                return {\n",
        "                    \"success\": True,\n",
        "                    \"expression\": expression,\n",
        "                    \"result\": result\n",
        "                }\n",
        "            except Exception as e:\n",
        "                return {\"success\": False, \"error\": str(e)}\n",
        "        \n",
        "        self.register_tool(MCPTool(\n",
        "            name=\"calculate\",\n",
        "            description=\"ìˆ˜í•™ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤\",\n",
        "            parameters={\n",
        "                \"expression\": {\"type\": \"string\", \"description\": \"ê³„ì‚°í•  ìˆ˜í•™ í‘œí˜„ì‹\"}\n",
        "            },\n",
        "            function=calculate\n",
        "        ))\n",
        "\n",
        "# MCP ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”\n",
        "mcp_registry = MCPToolRegistry()\n",
        "print(\"âœ… MCP ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "print(f\"ë“±ë¡ëœ ë„êµ¬: {mcp_registry.list_tools()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MCP ìƒíƒœ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MCPState(TypedDict):\n",
        "    \"\"\"MCP í†µí•© ì›Œí¬í”Œë¡œ ìƒíƒœ\"\"\"\n",
        "    user_query: str                    # ì‚¬ìš©ì ì§ˆë¬¸\n",
        "    intent_analysis: Dict[str, Any]    # ì˜ë„ ë¶„ì„ ê²°ê³¼\n",
        "    selected_tools: List[str]          # ì„ íƒëœ ë„êµ¬ë“¤\n",
        "    tool_calls: List[Dict[str, Any]]   # ë„êµ¬ í˜¸ì¶œ ì •ë³´\n",
        "    tool_results: List[Dict[str, Any]] # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼\n",
        "    aggregated_info: str               # í†µí•©ëœ ì •ë³´\n",
        "    final_response: str                # ìµœì¢… ì‘ë‹µ\n",
        "    confidence: float                  # ì‹ ë¢°ë„\n",
        "    errors: List[str]                  # ì˜¤ë¥˜ ëª©ë¡\n",
        "    retry_count: int                   # ì¬ì‹œë„ íšŸìˆ˜\n",
        "\n",
        "print(\"âœ… MCP ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. MCP ì›Œí¬í”Œë¡œ ë…¸ë“œë“¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_intent(state: MCPState) -> MCPState:\n",
        "    \"\"\"ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ë° í•„ìš”í•œ ë„êµ¬ ì‹ë³„\"\"\"\n",
        "    user_query = state[\"user_query\"]\n",
        "    \n",
        "    print(f\"ğŸ§  ì˜ë„ ë¶„ì„: {user_query}\")\n",
        "    \n",
        "    # ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸\n",
        "    tools_description = mcp_registry.get_tools_description()\n",
        "    \n",
        "    prompt = f\"\"\"ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n",
        "\n",
        "ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤:\n",
        "{tools_description}\n",
        "\n",
        "ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:\n",
        "ì˜ë„: [ì§ˆë¬¸ì˜ ì£¼ìš” ì˜ë„]\n",
        "í•„ìš”í•œ ë„êµ¬: [ë„êµ¬ëª…1, ë„êµ¬ëª…2, ...]\n",
        "ì´ìœ : [ë„êµ¬ ì„ íƒ ì´ìœ ]\n",
        "\n",
        "ë¶„ì„ ê²°ê³¼:\"\"\"\n",
        "    \n",
        "    analysis_text = llm.generate(prompt, max_length=300, temperature=0.3)\n",
        "    \n",
        "    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë„êµ¬ ì„ íƒ (ë°±ì—…)\n",
        "    selected_tools = []\n",
        "    query_lower = user_query.lower()\n",
        "    \n",
        "    if any(word in query_lower for word in ['ê²€ìƒ‰', 'ì°¾ì•„', 'ì•Œë ¤', 'ì •ë³´']):\n",
        "        if any(word in query_lower for word in ['ìœ„í‚¤', 'ë°±ê³¼']):\n",
        "            selected_tools.append('wikipedia_search')\n",
        "        else:\n",
        "            selected_tools.append('web_search')\n",
        "    \n",
        "    if any(word in query_lower for word in ['ì£¼ì‹', 'ì£¼ê°€', 'ì¦ê¶Œ', 'stock']):\n",
        "        selected_tools.append('get_stock_info')\n",
        "    \n",
        "    if any(word in query_lower for word in ['ë‚ ì”¨', 'weather']):\n",
        "        selected_tools.append('get_weather')\n",
        "    \n",
        "    if any(word in query_lower for word in ['ê³„ì‚°', 'ë”í•˜ê¸°', 'ë¹¼ê¸°', 'ê³±í•˜ê¸°', 'ë‚˜ëˆ„ê¸°', '+', '-', '*', '/']):\n",
        "        selected_tools.append('calculate')\n",
        "    \n",
        "    # ê¸°ë³¸ì ìœ¼ë¡œ ê²€ìƒ‰ ë„êµ¬ í¬í•¨\n",
        "    if not selected_tools:\n",
        "        selected_tools.append('web_search')\n",
        "    \n",
        "    intent_analysis = {\n",
        "        \"analysis_text\": analysis_text,\n",
        "        \"detected_keywords\": [word for word in ['ê²€ìƒ‰', 'ì£¼ì‹', 'ë‚ ì”¨', 'ê³„ì‚°', 'ìœ„í‚¤'] if word in query_lower],\n",
        "        \"query_type\": \"informational\" if any(word in query_lower for word in ['ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ']) else \"transactional\"\n",
        "    }\n",
        "    \n",
        "    print(f\"ğŸ“Š ì„ íƒëœ ë„êµ¬: {selected_tools}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"intent_analysis\": intent_analysis,\n",
        "        \"selected_tools\": selected_tools,\n",
        "        \"retry_count\": state.get(\"retry_count\", 0),\n",
        "        \"errors\": state.get(\"errors\", [])\n",
        "    }\n",
        "\n",
        "def prepare_tool_calls(state: MCPState) -> MCPState:\n",
        "    \"\"\"ë„êµ¬ í˜¸ì¶œ ë§¤ê°œë³€ìˆ˜ ì¤€ë¹„\"\"\"\n",
        "    user_query = state[\"user_query\"]\n",
        "    selected_tools = state[\"selected_tools\"]\n",
        "    \n",
        "    print(f\"ğŸ›  ë„êµ¬ í˜¸ì¶œ ì¤€ë¹„: {selected_tools}\")\n",
        "    \n",
        "    tool_calls = []\n",
        "    \n",
        "    for tool_name in selected_tools:\n",
        "        tool = mcp_registry.get_tool(tool_name)\n",
        "        if not tool:\n",
        "            continue\n",
        "        \n",
        "        # ë„êµ¬ë³„ ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
        "        if tool_name == \"web_search\":\n",
        "            tool_calls.append({\n",
        "                \"tool\": tool_name,\n",
        "                \"parameters\": {\n",
        "                    \"query\": user_query,\n",
        "                    \"max_results\": 5\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        elif tool_name == \"wikipedia_search\":\n",
        "            # ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ì–´ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)\n",
        "            search_query = user_query.replace('ìœ„í‚¤í”¼ë””ì•„ì—ì„œ', '').replace('ê²€ìƒ‰í•´', '').strip()\n",
        "            tool_calls.append({\n",
        "                \"tool\": tool_name,\n",
        "                \"parameters\": {\n",
        "                    \"query\": search_query,\n",
        "                    \"lang\": \"ko\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        elif tool_name == \"get_stock_info\":\n",
        "            # ì£¼ì‹ ì‹¬ë³¼ ì¶”ì¶œ ì‹œë„\n",
        "            symbols = []\n",
        "            query_upper = user_query.upper()\n",
        "            \n",
        "            # ì¼ë°˜ì ì¸ ì£¼ì‹ ì‹¬ë³¼ë“¤\n",
        "            common_symbols = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN', '005930.KS', '000660.KS']\n",
        "            for symbol in common_symbols:\n",
        "                if symbol in query_upper or symbol.replace('.KS', '') in query_upper:\n",
        "                    symbols.append(symbol)\n",
        "            \n",
        "            # í•œêµ­ ì£¼ì‹ëª… ë§¤í•‘\n",
        "            korean_stocks = {\n",
        "                'ì‚¼ì„±ì „ì': '005930.KS',\n",
        "                'ì• í”Œ': 'AAPL',\n",
        "                'êµ¬ê¸€': 'GOOGL',\n",
        "                'í…ŒìŠ¬ë¼': 'TSLA',\n",
        "                'ë§ˆì´í¬ë¡œì†Œí”„íŠ¸': 'MSFT',\n",
        "                'ì•„ë§ˆì¡´': 'AMZN'\n",
        "            }\n",
        "            \n",
        "            for korean_name, symbol in korean_stocks.items():\n",
        "                if korean_name in user_query:\n",
        "                    symbols.append(symbol)\n",
        "            \n",
        "            # ê¸°ë³¸ê°’\n",
        "            if not symbols:\n",
        "                symbols = ['AAPL']  # ê¸°ë³¸ìœ¼ë¡œ Apple ì£¼ì‹\n",
        "            \n",
        "            for symbol in symbols[:1]:  # ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©\n",
        "                tool_calls.append({\n",
        "                    \"tool\": tool_name,\n",
        "                    \"parameters\": {\n",
        "                        \"symbol\": symbol,\n",
        "                        \"period\": \"1d\"\n",
        "                    }\n",
        "                })\n",
        "        \n",
        "        elif tool_name == \"get_weather\":\n",
        "            # ë„ì‹œëª… ì¶”ì¶œ\n",
        "            cities = ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…', 'ì œì£¼']\n",
        "            detected_city = None\n",
        "            \n",
        "            for city in cities:\n",
        "                if city in user_query:\n",
        "                    detected_city = city\n",
        "                    break\n",
        "            \n",
        "            if not detected_city:\n",
        "                detected_city = \"ì„œìš¸\"  # ê¸°ë³¸ê°’\n",
        "            \n",
        "            tool_calls.append({\n",
        "                \"tool\": tool_name,\n",
        "                \"parameters\": {\n",
        "                    \"city\": detected_city,\n",
        "                    \"units\": \"metric\"\n",
        "                }\n",
        "            })\n",
        "        \n",
        "        elif tool_name == \"calculate\":\n",
        "            # ìˆ˜ì‹ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)\n",
        "            import re\n",
        "            # ìˆ«ìì™€ ì—°ì‚°ì íŒ¨í„´ ì°¾ê¸°\n",
        "            math_pattern = r'[0-9+\\-*/().\\s]+'\n",
        "            matches = re.findall(math_pattern, user_query)\n",
        "            \n",
        "            expression = None\n",
        "            for match in matches:\n",
        "                if any(op in match for op in ['+', '-', '*', '/']):\n",
        "                    expression = match.strip()\n",
        "                    break\n",
        "            \n",
        "            if not expression:\n",
        "                expression = \"2 + 2\"  # ê¸°ë³¸ê°’\n",
        "            \n",
        "            tool_calls.append({\n",
        "                \"tool\": tool_name,\n",
        "                \"parameters\": {\n",
        "                    \"expression\": expression\n",
        "                }\n",
        "            })\n",
        "    \n",
        "    print(f\"ğŸ“‹ ì¤€ë¹„ëœ ë„êµ¬ í˜¸ì¶œ: {len(tool_calls)}ê°œ\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"tool_calls\": tool_calls\n",
        "    }\n",
        "\n",
        "def execute_tools(state: MCPState) -> MCPState:\n",
        "    \"\"\"ë„êµ¬ ì‹¤í–‰\"\"\"\n",
        "    tool_calls = state[\"tool_calls\"]\n",
        "    \n",
        "    print(f\"âš¡ ë„êµ¬ ì‹¤í–‰ ì¤‘: {len(tool_calls)}ê°œ\")\n",
        "    \n",
        "    tool_results = []\n",
        "    errors = list(state.get(\"errors\", []))\n",
        "    \n",
        "    for call in tool_calls:\n",
        "        tool_name = call[\"tool\"]\n",
        "        parameters = call[\"parameters\"]\n",
        "        \n",
        "        print(f\"ğŸ”§ ì‹¤í–‰ ì¤‘: {tool_name} with {parameters}\")\n",
        "        \n",
        "        try:\n",
        "            tool = mcp_registry.get_tool(tool_name)\n",
        "            if tool:\n",
        "                result = tool.function(**parameters)\n",
        "                tool_results.append({\n",
        "                    \"tool\": tool_name,\n",
        "                    \"parameters\": parameters,\n",
        "                    \"result\": result,\n",
        "                    \"success\": result.get(\"success\", True)\n",
        "                })\n",
        "                \n",
        "                if result.get(\"success\", True):\n",
        "                    print(f\"âœ… {tool_name} ì„±ê³µ\")\n",
        "                else:\n",
        "                    print(f\"âŒ {tool_name} ì‹¤íŒ¨: {result.get('error', 'Unknown error')}\")\n",
        "                    errors.append(f\"{tool_name}: {result.get('error', 'Unknown error')}\")\n",
        "            else:\n",
        "                error_msg = f\"ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {tool_name}\"\n",
        "                errors.append(error_msg)\n",
        "                print(f\"âŒ {error_msg}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            error_msg = f\"{tool_name} ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\"\n",
        "            errors.append(error_msg)\n",
        "            print(f\"âŒ {error_msg}\")\n",
        "            \n",
        "            tool_results.append({\n",
        "                \"tool\": tool_name,\n",
        "                \"parameters\": parameters,\n",
        "                \"result\": {\"success\": False, \"error\": str(e)},\n",
        "                \"success\": False\n",
        "            })\n",
        "    \n",
        "    print(f\"ğŸ“Š ì‹¤í–‰ ì™„ë£Œ: {len([r for r in tool_results if r['success']])}/{len(tool_results)} ì„±ê³µ\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"tool_results\": tool_results,\n",
        "        \"errors\": errors\n",
        "    }\n",
        "\n",
        "def aggregate_information(state: MCPState) -> MCPState:\n",
        "    \"\"\"ë„êµ¬ ê²°ê³¼ í†µí•©\"\"\"\n",
        "    user_query = state[\"user_query\"]\n",
        "    tool_results = state[\"tool_results\"]\n",
        "    \n",
        "    print(\"ğŸ“Š ì •ë³´ í†µí•© ì¤‘...\")\n",
        "    \n",
        "    # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ í†µí•©\n",
        "    successful_results = [r for r in tool_results if r[\"success\"]]\n",
        "    \n",
        "    if not successful_results:\n",
        "        aggregated_info = \"ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
        "        confidence = 0.1\n",
        "    else:\n",
        "        # ê²°ê³¼ ìš”ì•½ ìƒì„±\n",
        "        info_parts = []\n",
        "        \n",
        "        for result in successful_results:\n",
        "            tool_name = result[\"tool\"]\n",
        "            data = result[\"result\"]\n",
        "            \n",
        "            if tool_name == \"web_search\":\n",
        "                if data.get(\"results\"):\n",
        "                    info_parts.append(f\"ì›¹ ê²€ìƒ‰ ê²°ê³¼: {len(data['results'])}ê°œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
        "                    for i, res in enumerate(data[\"results\"][:2], 1):\n",
        "                        info_parts.append(f\"  {i}. {res['title']}: {res['snippet']}\")\n",
        "            \n",
        "            elif tool_name == \"wikipedia_search\":\n",
        "                if data.get(\"summary\"):\n",
        "                    info_parts.append(f\"ìœ„í‚¤í”¼ë””ì•„ ì •ë³´: {data['title']}\")\n",
        "                    info_parts.append(f\"  ìš”ì•½: {data['summary'][:200]}...\")\n",
        "            \n",
        "            elif tool_name == \"get_stock_info\":\n",
        "                info_parts.append(f\"ì£¼ì‹ ì •ë³´: {data['company_name']} ({data['symbol']})\")\n",
        "                info_parts.append(f\"  í˜„ì¬ê°€: ${data['current_price']}, ë³€ë™: {data['change']:+.2f} ({data['change_percent']:+.2f}%)\")\n",
        "                info_parts.append(f\"  ê±°ë˜ëŸ‰: {data['volume']:,}\")\n",
        "            \n",
        "            elif tool_name == \"get_weather\":\n",
        "                info_parts.append(f\"{data['city']} ë‚ ì”¨ ì •ë³´:\")\n",
        "                info_parts.append(f\"  ì˜¨ë„: {data['temperature']}Â°C, ìŠµë„: {data['humidity']}%\")\n",
        "                info_parts.append(f\"  ë‚ ì”¨: {data['description']}\")\n",
        "            \n",
        "            elif tool_name == \"calculate\":\n",
        "                info_parts.append(f\"ê³„ì‚° ê²°ê³¼: {data['expression']} = {data['result']}\")\n",
        "        \n",
        "        aggregated_info = \"\\n\".join(info_parts)\n",
        "        confidence = min(0.9, 0.6 + len(successful_results) * 0.1)\n",
        "    \n",
        "    print(f\"âœ… ì •ë³´ í†µí•© ì™„ë£Œ (ì‹ ë¢°ë„: {confidence:.3f})\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"aggregated_info\": aggregated_info,\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "def generate_response(state: MCPState) -> MCPState:\n",
        "    \"\"\"ìµœì¢… ì‘ë‹µ ìƒì„±\"\"\"\n",
        "    user_query = state[\"user_query\"]\n",
        "    aggregated_info = state[\"aggregated_info\"]\n",
        "    \n",
        "    print(\"ğŸ’¬ ìµœì¢… ì‘ë‹µ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
        "    prompt = f\"\"\"ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì™¸ë¶€ ë„êµ¬ë“¤ë¡œë¶€í„° ì–»ì€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œê·¼í•˜ê³  ìœ ìš©í•œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì‚¬ìš©ì ì§ˆë¬¸: {user_query}\n",
        "\n",
        "ìˆ˜ì§‘ëœ ì •ë³´:\n",
        "{aggregated_info}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. ì •ë³´ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”\n",
        "2. êµ¬ì²´ì ì¸ ë°ì´í„°ë‚˜ ìˆ˜ì¹˜ê°€ ìˆë‹¤ë©´ í¬í•¨í•˜ì„¸ìš”\n",
        "3. ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”\n",
        "4. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
        "5. ì •ë³´ì˜ ì¶œì²˜ë¥¼ ì–¸ê¸‰í•´ì£¼ì„¸ìš”\n",
        "\n",
        "ì‘ë‹µ:\"\"\"\n",
        "    \n",
        "    final_response = llm.generate(prompt, max_length=400, temperature=0.5)\n",
        "    \n",
        "    print(f\"ğŸ“ ì‘ë‹µ ìƒì„± ì™„ë£Œ: {len(final_response)} ê¸€ì\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"final_response\": final_response\n",
        "    }\n",
        "\n",
        "def evaluate_response(state: MCPState) -> MCPState:\n",
        "    \"\"\"ì‘ë‹µ í’ˆì§ˆ í‰ê°€\"\"\"\n",
        "    confidence = state[\"confidence\"]\n",
        "    errors = state[\"errors\"]\n",
        "    retry_count = state[\"retry_count\"]\n",
        "    tool_results = state[\"tool_results\"]\n",
        "    \n",
        "    # ì¬ì‹œë„ í•„ìš” ì¡°ê±´\n",
        "    successful_tools = len([r for r in tool_results if r[\"success\"]])\n",
        "    need_retry = (\n",
        "        successful_tools == 0 and      # ì„±ê³µí•œ ë„êµ¬ê°€ ì—†ê³ \n",
        "        retry_count < 1 and            # ì¬ì‹œë„ íšŸìˆ˜ê°€ ì ê³ \n",
        "        len(errors) > 0                # ì˜¤ë¥˜ê°€ ìˆìŒ\n",
        "    )\n",
        "    \n",
        "    print(f\"ğŸ“Š ì‘ë‹µ í‰ê°€: ì‹ ë¢°ë„={confidence:.3f}, ì„±ê³µë„êµ¬={successful_tools}, ì˜¤ë¥˜={len(errors)}, ì¬ì‹œë„í•„ìš”={need_retry}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"need_retry\": need_retry\n",
        "    }\n",
        "\n",
        "def retry_with_backup(state: MCPState) -> MCPState:\n",
        "    \"\"\"ë°±ì—… ì „ëµìœ¼ë¡œ ì¬ì‹œë„\"\"\"\n",
        "    print(\"ğŸ”„ ë°±ì—… ì „ëµìœ¼ë¡œ ì¬ì‹œë„...\")\n",
        "    \n",
        "    # ë°±ì—… ë„êµ¬ë¡œ ì›¹ ê²€ìƒ‰ ì‚¬ìš©\n",
        "    return {\n",
        "        **state,\n",
        "        \"selected_tools\": [\"web_search\"],  # ë°±ì—…ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ë§Œ\n",
        "        \"retry_count\": state[\"retry_count\"] + 1\n",
        "    }\n",
        "\n",
        "def should_retry(state: MCPState) -> str:\n",
        "    \"\"\"ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •\"\"\"\n",
        "    if state.get(\"need_retry\", False):\n",
        "        return \"retry\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "print(\"âœ… MCP ì›Œí¬í”Œë¡œ ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. LangGraph MCP ì›Œí¬í”Œë¡œ êµ¬ì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MCP ì›Œí¬í”Œë¡œ ìƒì„±\n",
        "workflow = StateGraph(MCPState)\n",
        "\n",
        "# ë…¸ë“œ ì¶”ê°€\n",
        "workflow.add_node(\"analyze\", analyze_intent)\n",
        "workflow.add_node(\"prepare\", prepare_tool_calls)\n",
        "workflow.add_node(\"execute\", execute_tools)\n",
        "workflow.add_node(\"aggregate\", aggregate_information)\n",
        "workflow.add_node(\"generate\", generate_response)\n",
        "workflow.add_node(\"evaluate\", evaluate_response)\n",
        "workflow.add_node(\"retry\", retry_with_backup)\n",
        "\n",
        "# ì—£ì§€ ì—°ê²°\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_edge(\"analyze\", \"prepare\")\n",
        "workflow.add_edge(\"prepare\", \"execute\")\n",
        "workflow.add_edge(\"execute\", \"aggregate\")\n",
        "workflow.add_edge(\"aggregate\", \"generate\")\n",
        "workflow.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "# ì¡°ê±´ë¶€ ì—£ì§€\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    should_retry,\n",
        "    {\n",
        "        \"retry\": \"retry\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# ì¬ì‹œë„ í›„ ë„êµ¬ ì¤€ë¹„ë¡œ\n",
        "workflow.add_edge(\"retry\", \"prepare\")\n",
        "\n",
        "# ì•± ì»´íŒŒì¼\n",
        "mcp_app = workflow.compile()\n",
        "\n",
        "print(\"âœ… MCP LangGraph ì›Œí¬í”Œë¡œ êµ¬ì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. MCP ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_mcp_system(query: str):\n",
        "    \"\"\"MCP í†µí•© ì‹œìŠ¤í…œ ì‹¤í–‰\"\"\"\n",
        "    print(f\"\\nğŸš€ MCP ì‹œìŠ¤í…œ ì‹œì‘\")\n",
        "    print(f\"â“ ì‚¬ìš©ì ì§ˆë¬¸: {query}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # ì´ˆê¸° ìƒíƒœ\n",
        "    initial_state = {\n",
        "        \"user_query\": query,\n",
        "        \"retry_count\": 0,\n",
        "        \"errors\": []\n",
        "    }\n",
        "    \n",
        "    # ì›Œí¬í”Œë¡œ ì‹¤í–‰\n",
        "    final_state = mcp_app.invoke(initial_state)\n",
        "    \n",
        "    print(\"\\nğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ” ì„ íƒëœ ë„êµ¬: {final_state['selected_tools']}\")\n",
        "    print(f\"âš¡ ì‹¤í–‰ëœ ë„êµ¬: {len(final_state['tool_results'])}ê°œ\")\n",
        "    print(f\"âœ… ì„±ê³µí•œ ë„êµ¬: {len([r for r in final_state['tool_results'] if r['success']])}ê°œ\")\n",
        "    print(f\"ğŸ’¬ ìµœì¢… ì‘ë‹µ: {final_state['final_response']}\")\n",
        "    print(f\"ğŸ“Š ì‹ ë¢°ë„: {final_state['confidence']:.3f}\")\n",
        "    print(f\"ğŸ”„ ì¬ì‹œë„ íšŸìˆ˜: {final_state['retry_count']}\")\n",
        "    \n",
        "    # ë„êµ¬ ê²°ê³¼ ìƒì„¸ ì •ë³´\n",
        "    if final_state['tool_results']:\n",
        "        print(\"\\nğŸ›  ë„êµ¬ ì‹¤í–‰ ìƒì„¸:\")\n",
        "        for i, result in enumerate(final_state['tool_results'], 1):\n",
        "            status = \"âœ…\" if result['success'] else \"âŒ\"\n",
        "            print(f\"  [{i}] {status} {result['tool']}\")\n",
        "            if result['success'] and 'result' in result:\n",
        "                data = result['result']\n",
        "                if isinstance(data, dict) and 'success' in data:\n",
        "                    print(f\"      ë°ì´í„°: {str(data)[:100]}...\")\n",
        "    \n",
        "    # ì˜¤ë¥˜ ì •ë³´\n",
        "    if final_state['errors']:\n",
        "        print(\"\\nâŒ ë°œìƒí•œ ì˜¤ë¥˜:\")\n",
        "        for error in final_state['errors']:\n",
        "            print(f\"  - {error}\")\n",
        "    \n",
        "    return final_state\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
        "test_queries = [\n",
        "    \"ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê²€ìƒ‰í•´ì¤˜\",\n",
        "    \"ì• í”Œ ì£¼ì‹ ê°€ê²©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "    \"ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "    \"123 ë”í•˜ê¸° 456ì€ ì–¼ë§ˆì¸ê°€ìš”?\",\n",
        "    \"ë¨¸ì‹ ëŸ¬ë‹ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”\"\n",
        "]\n",
        "\n",
        "# ì²« ë²ˆì§¸ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "result = run_mcp_system(test_queries[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ë‹¤ì–‘í•œ ì§ˆë¬¸ìœ¼ë¡œ ì¢…í•© í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰\n",
        "results = []\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n\\nğŸ§ª í…ŒìŠ¤íŠ¸ {i}/{len(test_queries)}\")\n",
        "    try:\n",
        "        result = run_mcp_system(query)\n",
        "        success_rate = len([r for r in result['tool_results'] if r['success']]) / max(len(result['tool_results']), 1) * 100\n",
        "        \n",
        "        results.append({\n",
        "            \"query\": query,\n",
        "            \"tools_used\": result['selected_tools'],\n",
        "            \"success_rate\": success_rate,\n",
        "            \"response\": result['final_response'],\n",
        "            \"confidence\": result['confidence'],\n",
        "            \"retries\": result['retry_count'],\n",
        "            \"errors\": len(result['errors'])\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        results.append({\n",
        "            \"query\": query,\n",
        "            \"tools_used\": [],\n",
        "            \"success_rate\": 0,\n",
        "            \"response\": f\"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {str(e)}\",\n",
        "            \"confidence\": 0.0,\n",
        "            \"retries\": 0,\n",
        "            \"errors\": 1\n",
        "        })\n",
        "\n",
        "# ê²°ê³¼ ìš”ì•½\n",
        "print(\"\\n\\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "avg_success_rate = sum(r[\"success_rate\"] for r in results) / len(results)\n",
        "avg_confidence = sum(r[\"confidence\"] for r in results) / len(results)\n",
        "total_retries = sum(r[\"retries\"] for r in results)\n",
        "total_errors = sum(r[\"errors\"] for r in results)\n",
        "\n",
        "print(f\"í‰ê·  ë„êµ¬ ì„±ê³µë¥ : {avg_success_rate:.1f}%\")\n",
        "print(f\"í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
        "print(f\"ì´ ì¬ì‹œë„ íšŸìˆ˜: {total_retries}\")\n",
        "print(f\"ì´ ì˜¤ë¥˜ ìˆ˜: {total_errors}\")\n",
        "\n",
        "# ë„êµ¬ ì‚¬ìš© í†µê³„\n",
        "tool_usage = {}\n",
        "for result in results:\n",
        "    for tool in result[\"tools_used\"]:\n",
        "        tool_usage[tool] = tool_usage.get(tool, 0) + 1\n",
        "\n",
        "print(\"\\nğŸ›  ë„êµ¬ ì‚¬ìš© í†µê³„:\")\n",
        "for tool, count in sorted(tool_usage.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {tool}: {count}íšŒ\")\n",
        "\n",
        "print(\"\\nğŸ“‹ ìƒì„¸ ê²°ê³¼:\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n[{i}] {result['query']}\")\n",
        "    print(f\"    ì‚¬ìš© ë„êµ¬: {result['tools_used']}\")\n",
        "    print(f\"    ì„±ê³µë¥ : {result['success_rate']:.1f}%, ì‹ ë¢°ë„: {result['confidence']:.3f}\")\n",
        "    print(f\"    ì‘ë‹µ: {result['response'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ê³ ê¸‰ ê¸°ëŠ¥: ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë³µí•© ì§ˆë¬¸ë“¤ (ì—¬ëŸ¬ ë„êµ¬ê°€ í•„ìš”í•œ ì§ˆë¬¸ë“¤)\n",
        "complex_queries = [\n",
        "    \"ì• í”Œ ì£¼ì‹ ì •ë³´ì™€ ì„œìš¸ ë‚ ì”¨ë¥¼ ë‘˜ ë‹¤ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "    \"ì¸ê³µì§€ëŠ¥ì— ëŒ€í•œ ìœ„í‚¤í”¼ë””ì•„ ì •ë³´ë¥¼ ì°¾ê³ , 100 ê³±í•˜ê¸° 50ë„ ê³„ì‚°í•´ì£¼ì„¸ìš”\",\n",
        "    \"í…ŒìŠ¬ë¼ ì£¼ì‹ ê°€ê²©ê³¼ ë¶€ì‚° ë‚ ì”¨ ê·¸ë¦¬ê³  ë”¥ëŸ¬ë‹ ì •ë³´ë¥¼ ëª¨ë‘ ì•Œë ¤ì£¼ì„¸ìš”\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ”¬ ë³µí•© ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, query in enumerate(complex_queries, 1):\n",
        "    print(f\"\\nğŸ§ª ë³µí•© ì§ˆë¬¸ {i}\")\n",
        "    try:\n",
        "        result = run_mcp_system(query)\n",
        "        tools_count = len(result['selected_tools'])\n",
        "        success_count = len([r for r in result['tool_results'] if r['success']])\n",
        "        print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ: {tools_count}ê°œ ë„êµ¬ ì„ íƒ, {success_count}ê°œ ì„±ê³µ\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ì„±ëŠ¥ ë¶„ì„ ë° ìµœì í™” ì œì•ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_mcp_performance():\n",
        "    \"\"\"MCP ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„\"\"\"\n",
        "    print(\"ğŸ”¬ MCP ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ì „ì²´ ì„±ëŠ¥ ì§€í‘œ\n",
        "    total_queries = len(results)\n",
        "    high_conf_queries = sum(1 for r in results if r[\"confidence\"] >= 0.7)\n",
        "    no_error_queries = sum(1 for r in results if r[\"errors\"] == 0)\n",
        "    \n",
        "    print(f\"ì „ì²´ ì§ˆë¬¸ ìˆ˜: {total_queries}\")\n",
        "    print(f\"ê³ ì‹ ë¢°ë„ ì‘ë‹µ: {high_conf_queries}ê°œ ({high_conf_queries/total_queries*100:.1f}%)\")\n",
        "    print(f\"ì˜¤ë¥˜ ì—†ëŠ” ì‘ë‹µ: {no_error_queries}ê°œ ({no_error_queries/total_queries*100:.1f}%)\")\n",
        "    \n",
        "    # ë„êµ¬ë³„ ì„±ëŠ¥ ë¶„ì„\n",
        "    print(\"\\nğŸ›  ë„êµ¬ë³„ ì„±ëŠ¥:\")\n",
        "    for tool_name in mcp_registry.list_tools():\n",
        "        usage_count = tool_usage.get(tool_name, 0)\n",
        "        if usage_count > 0:\n",
        "            print(f\"  {tool_name}: {usage_count}íšŒ ì‚¬ìš©\")\n",
        "    \n",
        "    # ì‹ ë¢°ë„ ë¶„í¬\n",
        "    confidences = [r[\"confidence\"] for r in results]\n",
        "    high_conf = sum(1 for c in confidences if c >= 0.8)\n",
        "    medium_conf = sum(1 for c in confidences if 0.5 <= c < 0.8)\n",
        "    low_conf = sum(1 for c in confidences if c < 0.5)\n",
        "    \n",
        "    print(\"\\nğŸ“Š ì‹ ë¢°ë„ ë¶„í¬:\")\n",
        "    print(f\"  ë†’ìŒ (â‰¥0.8): {high_conf}ê°œ\")\n",
        "    print(f\"  ë³´í†µ (0.5~0.8): {medium_conf}ê°œ\")\n",
        "    print(f\"  ë‚®ìŒ (<0.5): {low_conf}ê°œ\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ ì‹œìŠ¤í…œ ì¥ì :\")\n",
        "    print(\"  - ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ë“¤ì˜ ìë™ í†µí•©\")\n",
        "    print(\"  - ì§€ëŠ¥ì ì¸ ë„êµ¬ ì„ íƒ ë° ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\")\n",
        "    print(\"  - ë‹¤ì¤‘ ë„êµ¬ ê²°ê³¼ì˜ íš¨ê³¼ì ì¸ í†µí•©\")\n",
        "    print(\"  - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë°±ì—… ì „ëµ ì œê³µ\")\n",
        "    print(\"  - Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ ë¬¸ë§¥ ì´í•´ í™œìš©\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ ê°œì„  ì œì•ˆ:\")\n",
        "    if avg_confidence < 0.7:\n",
        "        print(\"  - ë” ì •êµí•œ ì˜ë„ ë¶„ì„ ë° ë„êµ¬ ì„ íƒ ë¡œì§\")\n",
        "        print(\"  - ë„êµ¬ ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€ ê°•í™”\")\n",
        "    if total_errors > 0:\n",
        "        print(\"  - ë” ê²¬ê³ í•œ ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜\")\n",
        "        print(\"  - ì‹¤ì œ API ì—°ë™ ì‹œ ì†ë„ ì œí•œ ë° ì¸ì¦ ì²˜ë¦¬\")\n",
        "    if total_retries > 0:\n",
        "        print(\"  - ì´ˆê¸° ë„êµ¬ ì„ íƒ ì •í™•ë„ í–¥ìƒ\")\n",
        "        print(\"  - ë” ë‚˜ì€ ë°±ì—… ì „ëµ ê°œë°œ\")\n",
        "    \n",
        "    print(\"\\nğŸš€ í™•ì¥ ê°€ëŠ¥ì„±:\")\n",
        "    print(\"  - ì‹¤ì‹œê°„ API ì—°ë™ (Google Search, OpenWeatherMap ë“±)\")\n",
        "    print(\"  - ë” ë§ì€ ë„ë©”ì¸ íŠ¹í™” ë„êµ¬ ì¶”ê°€\")\n",
        "    print(\"  - ì‚¬ìš©ì ë§ì¶¤í˜• ë„êµ¬ ì„ íƒ í•™ìŠµ\")\n",
        "    print(\"  - ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ìºì‹± ë° ìµœì í™”\")\n",
        "\n",
        "analyze_mcp_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. ì‹¤ìŠµ ê³¼ì œ\n",
        "\n",
        "### ê³¼ì œ 1: ìƒˆë¡œìš´ ë„êµ¬ ì¶”ê°€\n",
        "- í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë„êµ¬ë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "- ë‰´ìŠ¤ ê²€ìƒ‰ ë„êµ¬ë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”\n",
        "- ì´ë¯¸ì§€ ê²€ìƒ‰ API ì—°ë™ì„ ì‹œë„í•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 2: ì§€ëŠ¥ì  ë„êµ¬ ì„ íƒ\n",
        "- ë” ì •êµí•œ ìì—°ì–´ ì²˜ë¦¬ë¥¼ í†µí•œ ë„êµ¬ ì„ íƒ ë¡œì§ì„ ê°œì„ í•´ë³´ì„¸ìš”\n",
        "- ì‚¬ìš©ì ì§ˆë¬¸ì˜ ë§¥ë½ì„ ë” ì˜ ì´í•´í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 3: ê²°ê³¼ í†µí•© ê°œì„ \n",
        "- ì—¬ëŸ¬ ë„êµ¬ ê²°ê³¼ë¥¼ ë” íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ëŠ” ë°©ë²•ì„ ê°œë°œí•´ë³´ì„¸ìš”\n",
        "- ê²°ê³¼ ê°„ì˜ ì¼ê´€ì„± ê²€ì¦ ë©”ì»¤ë‹ˆì¦˜ì„ ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 4: ì‹¤ì œ API ì—°ë™\n",
        "- Google Search APIë‚˜ ë‹¤ë¥¸ ì‹¤ì œ APIì™€ ì—°ë™í•´ë³´ì„¸ìš”\n",
        "- API í‚¤ ê´€ë¦¬ ë° ì†ë„ ì œí•œ ì²˜ë¦¬ë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„\n",
        "print(\"ğŸ“ MCP í†µí•© ì‹¤ìŠµ ì™„ë£Œ!\")\n",
        "print(\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
        "print(\"1. 06-gradio-ui.ipynb - Gradio UI ë˜í•‘ (ìµœì¢…)\")\n",
        "\n",
        "print(\"\\nğŸ’¡ í•µì‹¬ í•™ìŠµ ë‚´ìš©:\")\n",
        "print(\"- MCP(Model Context Protocol) ê°œë…ê³¼ êµ¬í˜„\")\n",
        "print(\"- ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ë“¤ì˜ ìë™ í†µí•©\")\n",
        "print(\"- ì§€ëŠ¥ì  ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰ ì›Œí¬í”Œë¡œ\")\n",
        "print(\"- ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë°±ì—… ì „ëµ\")\n",
        "print(\"- Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì„ í†µí•œ ë§¥ë½ ì´í•´\")\n",
        "print(\"- ë³µí•© ì§ˆë¬¸ì˜ íš¨ê³¼ì ì¸ ì²˜ë¦¬\")\n",
        "\n",
        "print(\"\\nğŸŒŸ ì‹¤ì œ í™œìš© ì‚¬ë¡€:\")\n",
        "print(\"- AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ê¸°ëŠ¥ í™•ì¥\")\n",
        "print(\"- ë©€í‹°ëª¨ë‹¬ ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ\")\n",
        "print(\"- ë¹„ì¦ˆë‹ˆìŠ¤ ì¸í…”ë¦¬ì „ìŠ¤ ë„êµ¬ í†µí•©\")\n",
        "print(\"- ìë™í™”ëœ ì •ë³´ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸\")\n",
        "\n",
        "print(\"\\nâœ… MCP í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}