{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 3 - Text-to-SQL with LangGraph\n",
        "# ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì‹œìŠ¤í…œ\n",
        "\n",
        "ì´ ì‹¤ìŠµì—ì„œëŠ” LangGraphì™€ Day 1ì˜ íŒŒì¸íŠœë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬\n",
        "ìì—°ì–´ ì§ˆë¬¸ì„ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
        "\n",
        "## í•µì‹¬ ê°œë…\n",
        "- ìŠ¤í‚¤ë§ˆ ì´í•´ ë° ë¶„ì„\n",
        "- ìì—°ì–´ â†’ SQL ë³€í™˜\n",
        "- SQL ê²€ì¦ ë° ìˆ˜ì •\n",
        "- ê²°ê³¼ í•´ì„ ë° ìì—°ì–´ ìš”ì•½"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain langgraph sqlite3 pandas sqlalchemy transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "import re\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "from langchain.schema import Document\n",
        "from langgraph.graph import StateGraph, END\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Day1FinetunedLLM:\n",
        "    def __init__(self, model_name=\"ryanu/my-exaone-raft-model\"):\n",
        "        self.model_name = model_name\n",
        "        self.base_model = \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        print(f\"ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}\")\n",
        "        print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
        "        \n",
        "        # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.base_model,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # íŒŒì¸íŠœë‹ëœ ì–´ëŒ‘í„° ë¡œë“œ\n",
        "        try:\n",
        "            self.model = PeftModel.from_pretrained(self.model, model_name)\n",
        "            print(\"âœ… íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ íŒŒì¸íŠœë‹ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš©: {e}\")\n",
        "    \n",
        "    def generate(self, prompt: str, max_length: int = 512, temperature: float = 0.1) -> str:\n",
        "        \"\"\"í…ìŠ¤íŠ¸ ìƒì„± (SQL ìƒì„±ì—ëŠ” ë‚®ì€ temperature ì‚¬ìš©)\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            prompt, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=2048\n",
        "        ).to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=inputs['input_ids'].shape[1] + max_length,\n",
        "                temperature=temperature,\n",
        "                do_sample=True if temperature > 0 else False,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        generated_text = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:], \n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        \n",
        "        return generated_text.strip()\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "llm = Day1FinetunedLLM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ìƒ˜í”Œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sample_database():\n",
        "    \"\"\"ìƒ˜í”Œ ì „ììƒê±°ë˜ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±\"\"\"\n",
        "    # SQLite ì—°ê²°\n",
        "    conn = sqlite3.connect('ecommerce.db')\n",
        "    cursor = conn.cursor()\n",
        "    \n",
        "    # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ\n",
        "    cursor.execute('DROP TABLE IF EXISTS order_items')\n",
        "    cursor.execute('DROP TABLE IF EXISTS orders')\n",
        "    cursor.execute('DROP TABLE IF EXISTS products')\n",
        "    cursor.execute('DROP TABLE IF EXISTS customers')\n",
        "    cursor.execute('DROP TABLE IF EXISTS categories')\n",
        "    \n",
        "    # ì¹´í…Œê³ ë¦¬ í…Œì´ë¸”\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE categories (\n",
        "            category_id INTEGER PRIMARY KEY,\n",
        "            category_name TEXT NOT NULL,\n",
        "            description TEXT\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # ìƒí’ˆ í…Œì´ë¸”\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE products (\n",
        "            product_id INTEGER PRIMARY KEY,\n",
        "            product_name TEXT NOT NULL,\n",
        "            category_id INTEGER,\n",
        "            price DECIMAL(10, 2),\n",
        "            stock_quantity INTEGER,\n",
        "            created_date DATE,\n",
        "            FOREIGN KEY (category_id) REFERENCES categories (category_id)\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # ê³ ê° í…Œì´ë¸”\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE customers (\n",
        "            customer_id INTEGER PRIMARY KEY,\n",
        "            customer_name TEXT NOT NULL,\n",
        "            email TEXT,\n",
        "            city TEXT,\n",
        "            join_date DATE\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # ì£¼ë¬¸ í…Œì´ë¸”\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE orders (\n",
        "            order_id INTEGER PRIMARY KEY,\n",
        "            customer_id INTEGER,\n",
        "            order_date DATE,\n",
        "            total_amount DECIMAL(10, 2),\n",
        "            status TEXT,\n",
        "            FOREIGN KEY (customer_id) REFERENCES customers (customer_id)\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # ì£¼ë¬¸ ìƒí’ˆ í…Œì´ë¸”\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE order_items (\n",
        "            order_item_id INTEGER PRIMARY KEY,\n",
        "            order_id INTEGER,\n",
        "            product_id INTEGER,\n",
        "            quantity INTEGER,\n",
        "            unit_price DECIMAL(10, 2),\n",
        "            FOREIGN KEY (order_id) REFERENCES orders (order_id),\n",
        "            FOREIGN KEY (product_id) REFERENCES products (product_id)\n",
        "        )\n",
        "    ''')\n",
        "    \n",
        "    # ìƒ˜í”Œ ë°ì´í„° ì‚½ì…\n",
        "    # ì¹´í…Œê³ ë¦¬ ë°ì´í„°\n",
        "    categories_data = [\n",
        "        (1, 'ì „ìì œí’ˆ', 'ì»´í“¨í„°, ìŠ¤ë§ˆíŠ¸í° ë“±'),\n",
        "        (2, 'ì˜ë¥˜', 'ë‚¨ì„±ë³µ, ì—¬ì„±ë³µ, ì•„ë™ë³µ'),\n",
        "        (3, 'ë„ì„œ', 'ì†Œì„¤, ì „ë¬¸ì„œì , ë§Œí™”'),\n",
        "        (4, 'ê°€ì „ì œí’ˆ', 'ëƒ‰ì¥ê³ , ì„¸íƒê¸°, TV')\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO categories VALUES (?, ?, ?)', categories_data)\n",
        "    \n",
        "    # ìƒí’ˆ ë°ì´í„°\n",
        "    products_data = [\n",
        "        (1, 'ì•„ì´í° 15', 1, 1200000, 50, '2024-01-15'),\n",
        "        (2, 'ê°¤ëŸ­ì‹œ S24', 1, 1100000, 30, '2024-01-20'),\n",
        "        (3, 'ë§¥ë¶ í”„ë¡œ', 1, 2500000, 15, '2024-02-01'),\n",
        "        (4, 'ë‚˜ì´í‚¤ ìš´ë™í™”', 2, 150000, 100, '2024-01-10'),\n",
        "        (5, 'ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ êµê³¼ì„œ', 3, 45000, 200, '2024-01-05'),\n",
        "        (6, 'LG ëƒ‰ì¥ê³ ', 4, 800000, 20, '2024-02-10'),\n",
        "        (7, 'ì•„ë””ë‹¤ìŠ¤ í‹°ì…”ì¸ ', 2, 35000, 150, '2024-01-25'),\n",
        "        (8, 'íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°', 3, 38000, 80, '2024-01-30')\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO products VALUES (?, ?, ?, ?, ?, ?)', products_data)\n",
        "    \n",
        "    # ê³ ê° ë°ì´í„°\n",
        "    customers_data = [\n",
        "        (1, 'ê¹€ì² ìˆ˜', 'kim@email.com', 'ì„œìš¸', '2023-01-15'),\n",
        "        (2, 'ì´ì˜í¬', 'lee@email.com', 'ë¶€ì‚°', '2023-03-20'),\n",
        "        (3, 'ë°•ë¯¼ìˆ˜', 'park@email.com', 'ëŒ€êµ¬', '2023-05-10'),\n",
        "        (4, 'ìµœì§€ì€', 'choi@email.com', 'ì„œìš¸', '2023-07-25'),\n",
        "        (5, 'ì •ë‹¤ì˜', 'jung@email.com', 'ì¸ì²œ', '2023-09-15')\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO customers VALUES (?, ?, ?, ?, ?)', customers_data)\n",
        "    \n",
        "    # ì£¼ë¬¸ ë°ì´í„°\n",
        "    orders_data = [\n",
        "        (1, 1, '2024-01-20', 1200000, 'ë°°ì†¡ì™„ë£Œ'),\n",
        "        (2, 2, '2024-01-25', 185000, 'ë°°ì†¡ì¤‘'),\n",
        "        (3, 1, '2024-02-01', 83000, 'ë°°ì†¡ì™„ë£Œ'),\n",
        "        (4, 3, '2024-02-05', 2500000, 'ë°°ì†¡ì™„ë£Œ'),\n",
        "        (5, 4, '2024-02-10', 1150000, 'ë°°ì†¡ì¤€ë¹„ì¤‘'),\n",
        "        (6, 2, '2024-02-15', 800000, 'ì£¼ë¬¸ì ‘ìˆ˜'),\n",
        "        (7, 5, '2024-02-20', 70000, 'ë°°ì†¡ì™„ë£Œ')\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO orders VALUES (?, ?, ?, ?, ?)', orders_data)\n",
        "    \n",
        "    # ì£¼ë¬¸ ìƒí’ˆ ë°ì´í„°\n",
        "    order_items_data = [\n",
        "        (1, 1, 1, 1, 1200000),  # ê¹€ì² ìˆ˜ - ì•„ì´í°\n",
        "        (2, 2, 4, 1, 150000),   # ì´ì˜í¬ - ë‚˜ì´í‚¤ ìš´ë™í™”\n",
        "        (3, 2, 7, 1, 35000),    # ì´ì˜í¬ - ì•„ë””ë‹¤ìŠ¤ í‹°ì…”ì¸ \n",
        "        (4, 3, 5, 1, 45000),    # ê¹€ì² ìˆ˜ - ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ êµê³¼ì„œ\n",
        "        (5, 3, 8, 1, 38000),    # ê¹€ì² ìˆ˜ - íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°\n",
        "        (6, 4, 3, 1, 2500000),  # ë°•ë¯¼ìˆ˜ - ë§¥ë¶ í”„ë¡œ\n",
        "        (7, 5, 2, 1, 1100000),  # ìµœì§€ì€ - ê°¤ëŸ­ì‹œ\n",
        "        (8, 5, 4, 1, 150000),   # ìµœì§€ì€ - ë‚˜ì´í‚¤ ìš´ë™í™”\n",
        "        (9, 6, 6, 1, 800000),   # ì´ì˜í¬ - LG ëƒ‰ì¥ê³ \n",
        "        (10, 7, 7, 2, 35000)    # ì •ë‹¤ì˜ - ì•„ë””ë‹¤ìŠ¤ í‹°ì…”ì¸  2ê°œ\n",
        "    ]\n",
        "    cursor.executemany('INSERT INTO order_items VALUES (?, ?, ?, ?, ?)', order_items_data)\n",
        "    \n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    \n",
        "    print(\"âœ… ìƒ˜í”Œ ì „ììƒê±°ë˜ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
        "    return 'ecommerce.db'\n",
        "\n",
        "# ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±\n",
        "db_path = create_sample_database()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ì„ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DatabaseAnalyzer:\n",
        "    def __init__(self, db_path: str):\n",
        "        self.db_path = db_path\n",
        "        self.engine = create_engine(f'sqlite:///{db_path}')\n",
        "        self.schema_info = self._analyze_schema()\n",
        "    \n",
        "    def _analyze_schema(self) -> Dict[str, Any]:\n",
        "        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë¶„ì„\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "        tables = [row[0] for row in cursor.fetchall()]\n",
        "        \n",
        "        schema_info = {\n",
        "            'tables': {},\n",
        "            'relationships': [],\n",
        "            'sample_data': {}\n",
        "        }\n",
        "        \n",
        "        for table in tables:\n",
        "            # ì»¬ëŸ¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
        "            cursor.execute(f\"PRAGMA table_info({table})\")\n",
        "            columns = cursor.fetchall()\n",
        "            \n",
        "            schema_info['tables'][table] = {\n",
        "                'columns': [\n",
        "                    {\n",
        "                        'name': col[1],\n",
        "                        'type': col[2],\n",
        "                        'nullable': not col[3],\n",
        "                        'primary_key': bool(col[5])\n",
        "                    }\n",
        "                    for col in columns\n",
        "                ]\n",
        "            }\n",
        "            \n",
        "            # ì™¸ë˜ í‚¤ ì •ë³´\n",
        "            cursor.execute(f\"PRAGMA foreign_key_list({table})\")\n",
        "            foreign_keys = cursor.fetchall()\n",
        "            \n",
        "            for fk in foreign_keys:\n",
        "                schema_info['relationships'].append({\n",
        "                    'from_table': table,\n",
        "                    'from_column': fk[3],\n",
        "                    'to_table': fk[2],\n",
        "                    'to_column': fk[4]\n",
        "                })\n",
        "            \n",
        "            # ìƒ˜í”Œ ë°ì´í„°\n",
        "            cursor.execute(f\"SELECT * FROM {table} LIMIT 3\")\n",
        "            sample_rows = cursor.fetchall()\n",
        "            schema_info['sample_data'][table] = sample_rows\n",
        "        \n",
        "        conn.close()\n",
        "        return schema_info\n",
        "    \n",
        "    def get_schema_description(self) -> str:\n",
        "        \"\"\"ìŠ¤í‚¤ë§ˆ ì„¤ëª… í…ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
        "        description = \"ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´:\\n\\n\"\n",
        "        \n",
        "        for table_name, table_info in self.schema_info['tables'].items():\n",
        "            description += f\"í…Œì´ë¸”: {table_name}\\n\"\n",
        "            description += \"ì»¬ëŸ¼:\\n\"\n",
        "            \n",
        "            for col in table_info['columns']:\n",
        "                pk_marker = \" (PK)\" if col['primary_key'] else \"\"\n",
        "                nullable_marker = \" (NULL í—ˆìš©)\" if col['nullable'] else \"\"\n",
        "                description += f\"  - {col['name']}: {col['type']}{pk_marker}{nullable_marker}\\n\"\n",
        "            \n",
        "            description += \"\\n\"\n",
        "        \n",
        "        if self.schema_info['relationships']:\n",
        "            description += \"ê´€ê³„:\\n\"\n",
        "            for rel in self.schema_info['relationships']:\n",
        "                description += f\"  - {rel['from_table']}.{rel['from_column']} â†’ {rel['to_table']}.{rel['to_column']}\\n\"\n",
        "        \n",
        "        return description\n",
        "    \n",
        "    def execute_query(self, query: str) -> pd.DataFrame:\n",
        "        \"\"\"SQL ì¿¼ë¦¬ ì‹¤í–‰\"\"\"\n",
        "        try:\n",
        "            return pd.read_sql_query(query, self.engine)\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"SQL ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}\")\n",
        "\n",
        "# ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
        "db_analyzer = DatabaseAnalyzer(db_path)\n",
        "print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "print(\"\\nìŠ¤í‚¤ë§ˆ ì •ë³´:\")\n",
        "print(db_analyzer.get_schema_description())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Text2SQL ìƒíƒœ ì •ì˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Text2SQLState(TypedDict):\n",
        "    \"\"\"Text2SQL ì›Œí¬í”Œë¡œ ìƒíƒœ\"\"\"\n",
        "    question: str              # ìì—°ì–´ ì§ˆë¬¸\n",
        "    schema_context: str        # ìŠ¤í‚¤ë§ˆ ì •ë³´\n",
        "    generated_sql: str         # ìƒì„±ëœ SQL\n",
        "    sql_valid: bool           # SQL ìœ íš¨ì„±\n",
        "    sql_error: str            # SQL ì˜¤ë¥˜ ë©”ì‹œì§€\n",
        "    query_result: pd.DataFrame # ì¿¼ë¦¬ ê²°ê³¼\n",
        "    natural_answer: str        # ìì—°ì–´ ë‹µë³€\n",
        "    confidence: float          # ì‹ ë¢°ë„\n",
        "    need_revision: bool        # ìˆ˜ì • í•„ìš” ì—¬ë¶€\n",
        "    revision_count: int        # ìˆ˜ì • íšŸìˆ˜\n",
        "\n",
        "print(\"âœ… Text2SQL ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Text2SQL ì›Œí¬í”Œë¡œ ë…¸ë“œë“¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_question(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"ì§ˆë¬¸ ë¶„ì„ ë° ìŠ¤í‚¤ë§ˆ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    \n",
        "    print(f\"ğŸ“‹ ì§ˆë¬¸ ë¶„ì„: {question}\")\n",
        "    \n",
        "    # ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¤€ë¹„\n",
        "    schema_context = db_analyzer.get_schema_description()\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"schema_context\": schema_context,\n",
        "        \"revision_count\": state.get(\"revision_count\", 0)\n",
        "    }\n",
        "\n",
        "def generate_sql(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    schema_context = state[\"schema_context\"]\n",
        "    \n",
        "    print(\"ğŸ”„ SQL ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # SQL ìƒì„± í”„ë¡¬í”„íŠ¸\n",
        "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ SQL ê°œë°œìì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ì§ˆë¬¸ì„ ì •í™•í•œ SQL ì¿¼ë¦¬ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n",
        "{schema_context}\n",
        "\n",
        "ìì—°ì–´ ì§ˆë¬¸: {question}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. SQLite ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "2. ì •í™•í•œ í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "3. ì ì ˆí•œ JOINì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "4. ê°€ë…ì„± ìˆëŠ” SQLì„ ì‘ì„±í•˜ì„¸ìš”\n",
        "5. SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
        "\n",
        "SQL ì¿¼ë¦¬:\"\"\"\n",
        "    \n",
        "    generated_sql = llm.generate(prompt, max_length=300, temperature=0.1)\n",
        "    \n",
        "    # SQL ì¿¼ë¦¬ ì •ì œ (ì£¼ì„ì´ë‚˜ ì„¤ëª… ì œê±°)\n",
        "    sql_lines = []\n",
        "    for line in generated_sql.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line and not line.startswith('--') and not line.startswith('#'):\n",
        "            sql_lines.append(line)\n",
        "    \n",
        "    clean_sql = ' '.join(sql_lines).strip()\n",
        "    \n",
        "    print(f\"ğŸ” ìƒì„±ëœ SQL: {clean_sql}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"generated_sql\": clean_sql\n",
        "    }\n",
        "\n",
        "def validate_sql(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"ìƒì„±ëœ SQL ìœ íš¨ì„± ê²€ì¦\"\"\"\n",
        "    sql = state[\"generated_sql\"]\n",
        "    \n",
        "    print(\"âœ… SQL ìœ íš¨ì„± ê²€ì¦ ì¤‘...\")\n",
        "    \n",
        "    try:\n",
        "        # SQL ì‹¤í–‰ ì‹œë„\n",
        "        result = db_analyzer.execute_query(sql)\n",
        "        \n",
        "        # ê²°ê³¼ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸\n",
        "        is_valid = True\n",
        "        error_msg = \"\"\n",
        "        \n",
        "        if result.empty:\n",
        "            print(\"âš ï¸ ì¿¼ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤\")\n",
        "        \n",
        "        print(f\"âœ… SQL ê²€ì¦ ì„±ê³µ, {len(result)}ê°œ í–‰ ë°˜í™˜\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        is_valid = False\n",
        "        error_msg = str(e)\n",
        "        result = pd.DataFrame()\n",
        "        print(f\"âŒ SQL ê²€ì¦ ì‹¤íŒ¨: {error_msg}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"sql_valid\": is_valid,\n",
        "        \"sql_error\": error_msg,\n",
        "        \"query_result\": result\n",
        "    }\n",
        "\n",
        "def fix_sql(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"SQL ì˜¤ë¥˜ ìˆ˜ì •\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    schema_context = state[\"schema_context\"]\n",
        "    broken_sql = state[\"generated_sql\"]\n",
        "    error_msg = state[\"sql_error\"]\n",
        "    \n",
        "    print(\"ğŸ”§ SQL ì˜¤ë¥˜ ìˆ˜ì • ì¤‘...\")\n",
        "    \n",
        "    # ì˜¤ë¥˜ ìˆ˜ì • í”„ë¡¬í”„íŠ¸\n",
        "    prompt = f\"\"\"ë‹¤ìŒ SQL ì¿¼ë¦¬ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ê³  ì˜¬ë°”ë¥¸ SQLë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ:\n",
        "{schema_context}\n",
        "\n",
        "ì›ë˜ ì§ˆë¬¸: {question}\n",
        "ì˜¤ë¥˜ê°€ ìˆëŠ” SQL: {broken_sql}\n",
        "ì˜¤ë¥˜ ë©”ì‹œì§€: {error_msg}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. ì˜¤ë¥˜ë¥¼ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”\n",
        "2. ìŠ¤í‚¤ë§ˆì— ë§ëŠ” ì˜¬ë°”ë¥¸ í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
        "3. SQLite ë¬¸ë²•ì„ ì¤€ìˆ˜í•˜ì„¸ìš”\n",
        "4. ìˆ˜ì •ëœ SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ì„¸ìš”\n",
        "\n",
        "ìˆ˜ì •ëœ SQL:\"\"\"\n",
        "    \n",
        "    fixed_sql = llm.generate(prompt, max_length=300, temperature=0.1)\n",
        "    \n",
        "    # SQL ì •ì œ\n",
        "    sql_lines = []\n",
        "    for line in fixed_sql.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line and not line.startswith('--') and not line.startswith('#'):\n",
        "            sql_lines.append(line)\n",
        "    \n",
        "    clean_sql = ' '.join(sql_lines).strip()\n",
        "    \n",
        "    print(f\"ğŸ”§ ìˆ˜ì •ëœ SQL: {clean_sql}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"generated_sql\": clean_sql,\n",
        "        \"revision_count\": state[\"revision_count\"] + 1\n",
        "    }\n",
        "\n",
        "def interpret_results(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ìì—°ì–´ë¡œ í•´ì„\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    sql = state[\"generated_sql\"]\n",
        "    result = state[\"query_result\"]\n",
        "    \n",
        "    print(\"ğŸ“Š ê²°ê³¼ í•´ì„ ì¤‘...\")\n",
        "    \n",
        "    # ê²°ê³¼ ìš”ì•½ ìƒì„±\n",
        "    if result.empty:\n",
        "        natural_answer = \"ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "        confidence = 0.7\n",
        "    else:\n",
        "        # ê²°ê³¼ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "        result_text = result.to_string(index=False, max_rows=10)\n",
        "        \n",
        "        # ìì—°ì–´ ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸\n",
        "        prompt = f\"\"\"ë‹¤ìŒ SQL ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì›ë˜ ì§ˆë¬¸ì— ëŒ€í•œ ìì—°ì–´ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "ì›ë˜ ì§ˆë¬¸: {question}\n",
        "ì‹¤í–‰ëœ SQL: {sql}\n",
        "ì¿¼ë¦¬ ê²°ê³¼:\n",
        "{result_text}\n",
        "\n",
        "ìš”êµ¬ì‚¬í•­:\n",
        "1. ê²°ê³¼ë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”\n",
        "2. êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ ê°’ì„ í¬í•¨í•˜ì„¸ìš”\n",
        "3. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
        "4. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”\n",
        "\n",
        "ìì—°ì–´ ë‹µë³€:\"\"\"\n",
        "        \n",
        "        natural_answer = llm.generate(prompt, max_length=200, temperature=0.3)\n",
        "        \n",
        "        # ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)\n",
        "        if len(result) > 0:\n",
        "            confidence = min(0.9, 0.6 + len(result.columns) * 0.1)\n",
        "        else:\n",
        "            confidence = 0.5\n",
        "    \n",
        "    print(f\"ğŸ’¬ ìì—°ì–´ ë‹µë³€: {natural_answer}\")\n",
        "    print(f\"ğŸ“Š ì‹ ë¢°ë„: {confidence:.3f}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"natural_answer\": natural_answer,\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "def evaluate_response(state: Text2SQLState) -> Text2SQLState:\n",
        "    \"\"\"ì‘ë‹µ í’ˆì§ˆ í‰ê°€\"\"\"\n",
        "    confidence = state[\"confidence\"]\n",
        "    revision_count = state[\"revision_count\"]\n",
        "    sql_valid = state[\"sql_valid\"]\n",
        "    \n",
        "    # ìˆ˜ì •ì´ í•„ìš”í•œ ì¡°ê±´\n",
        "    need_revision = (\n",
        "        not sql_valid and           # SQLì´ ìœ íš¨í•˜ì§€ ì•Šê³ \n",
        "        revision_count < 2 and      # ìˆ˜ì • íšŸìˆ˜ê°€ 2íšŒ ë¯¸ë§Œì´ê³ \n",
        "        confidence < 0.6            # ì‹ ë¢°ë„ê°€ ë‚®ìŒ\n",
        "    )\n",
        "    \n",
        "    print(f\"ğŸ“Š ì‘ë‹µ í‰ê°€: ìœ íš¨={sql_valid}, ì‹ ë¢°ë„={confidence:.3f}, ìˆ˜ì •={revision_count}, ì¬ìˆ˜ì •í•„ìš”={need_revision}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"need_revision\": need_revision\n",
        "    }\n",
        "\n",
        "def should_revise(state: Text2SQLState) -> str:\n",
        "    \"\"\"ìˆ˜ì • ì—¬ë¶€ ê²°ì •\"\"\"\n",
        "    if state[\"need_revision\"]:\n",
        "        return \"fix\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "print(\"âœ… Text2SQL ì›Œí¬í”Œë¡œ ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LangGraph Text2SQL ì›Œí¬í”Œë¡œ êµ¬ì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text2SQL ì›Œí¬í”Œë¡œ ìƒì„±\n",
        "workflow = StateGraph(Text2SQLState)\n",
        "\n",
        "# ë…¸ë“œ ì¶”ê°€\n",
        "workflow.add_node(\"analyze\", analyze_question)\n",
        "workflow.add_node(\"generate\", generate_sql)\n",
        "workflow.add_node(\"validate\", validate_sql)\n",
        "workflow.add_node(\"fix\", fix_sql)\n",
        "workflow.add_node(\"interpret\", interpret_results)\n",
        "workflow.add_node(\"evaluate\", evaluate_response)\n",
        "\n",
        "# ì—£ì§€ ì—°ê²°\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_edge(\"analyze\", \"generate\")\n",
        "workflow.add_edge(\"generate\", \"validate\")\n",
        "workflow.add_edge(\"validate\", \"interpret\")\n",
        "workflow.add_edge(\"interpret\", \"evaluate\")\n",
        "\n",
        "# ì¡°ê±´ë¶€ ì—£ì§€\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    should_revise,\n",
        "    {\n",
        "        \"fix\": \"fix\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# ìˆ˜ì • í›„ ë‹¤ì‹œ ê²€ì¦ìœ¼ë¡œ\n",
        "workflow.add_edge(\"fix\", \"validate\")\n",
        "\n",
        "# ì•± ì»´íŒŒì¼\n",
        "text2sql_app = workflow.compile()\n",
        "\n",
        "print(\"âœ… Text2SQL LangGraph ì›Œí¬í”Œë¡œ êµ¬ì„± ì™„ë£Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Text2SQL ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_text2sql(question: str):\n",
        "    \"\"\"Text2SQL ì‹œìŠ¤í…œ ì‹¤í–‰\"\"\"\n",
        "    print(f\"\\nğŸš€ Text2SQL ì‹œìŠ¤í…œ ì‹œì‘\")\n",
        "    print(f\"â“ ì§ˆë¬¸: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # ì´ˆê¸° ìƒíƒœ\n",
        "    initial_state = {\n",
        "        \"question\": question,\n",
        "        \"revision_count\": 0\n",
        "    }\n",
        "    \n",
        "    # ì›Œí¬í”Œë¡œ ì‹¤í–‰\n",
        "    final_state = text2sql_app.invoke(initial_state)\n",
        "    \n",
        "    print(\"\\nğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ” ìƒì„±ëœ SQL: {final_state['generated_sql']}\")\n",
        "    print(f\"âœ… SQL ìœ íš¨ì„±: {final_state['sql_valid']}\")\n",
        "    print(f\"ğŸ’¬ ìì—°ì–´ ë‹µë³€: {final_state['natural_answer']}\")\n",
        "    print(f\"ğŸ“Š ì‹ ë¢°ë„: {final_state['confidence']:.3f}\")\n",
        "    print(f\"ğŸ”„ ìˆ˜ì • íšŸìˆ˜: {final_state['revision_count']}\")\n",
        "    \n",
        "    # ì¿¼ë¦¬ ê²°ê³¼ í‘œì‹œ\n",
        "    if not final_state['query_result'].empty:\n",
        "        print(\"\\nğŸ“‹ ì¿¼ë¦¬ ê²°ê³¼:\")\n",
        "        print(final_state['query_result'].to_string(index=False))\n",
        "    \n",
        "    # ì˜¤ë¥˜ ì •ë³´ í‘œì‹œ\n",
        "    if final_state.get('sql_error'):\n",
        "        print(f\"\\nâŒ SQL ì˜¤ë¥˜: {final_state['sql_error']}\")\n",
        "    \n",
        "    return final_state\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤\n",
        "test_questions = [\n",
        "    \"ê°€ì¥ ë¹„ì‹¼ ìƒí’ˆì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
        "    \"ì„œìš¸ì— ì‚¬ëŠ” ê³ ê°ë“¤ì˜ ì´ ì£¼ë¬¸ ê¸ˆì•¡ì€?\",\n",
        "    \"ì „ìì œí’ˆ ì¹´í…Œê³ ë¦¬ì˜ ìƒí’ˆë“¤ì„ ë³´ì—¬ì£¼ì„¸ìš”\",\n",
        "    \"ê° ê³ ê°ë³„ ì£¼ë¬¸ íšŸìˆ˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "    \"ë°°ì†¡ì™„ë£Œëœ ì£¼ë¬¸ì˜ í‰ê·  ê¸ˆì•¡ì€?\"\n",
        "]\n",
        "\n",
        "# ì²« ë²ˆì§¸ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
        "result = run_text2sql(test_questions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. ë‹¤ì–‘í•œ ì§ˆë¬¸ìœ¼ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì‹¤í–‰\n",
        "results = []\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n\\nğŸ§ª í…ŒìŠ¤íŠ¸ {i}/{len(test_questions)}\")\n",
        "    try:\n",
        "        result = run_text2sql(question)\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"sql\": result[\"generated_sql\"],\n",
        "            \"valid\": result[\"sql_valid\"],\n",
        "            \"answer\": result[\"natural_answer\"],\n",
        "            \"confidence\": result[\"confidence\"],\n",
        "            \"revisions\": result[\"revision_count\"]\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        results.append({\n",
        "            \"question\": question,\n",
        "            \"sql\": \"ì˜¤ë¥˜ ë°œìƒ\",\n",
        "            \"valid\": False,\n",
        "            \"answer\": f\"ì˜¤ë¥˜: {str(e)}\",\n",
        "            \"confidence\": 0.0,\n",
        "            \"revisions\": 0\n",
        "        })\n",
        "\n",
        "# ê²°ê³¼ ìš”ì•½\n",
        "print(\"\\n\\nğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "valid_results = [r for r in results if r[\"valid\"]]\n",
        "success_rate = len(valid_results) / len(results) * 100\n",
        "avg_confidence = sum(r[\"confidence\"] for r in valid_results) / max(len(valid_results), 1)\n",
        "avg_revisions = sum(r[\"revisions\"] for r in results) / len(results)\n",
        "\n",
        "print(f\"ì„±ê³µë¥ : {success_rate:.1f}% ({len(valid_results)}/{len(results)})\")\n",
        "print(f\"í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}\")\n",
        "print(f\"í‰ê·  ìˆ˜ì • íšŸìˆ˜: {avg_revisions:.1f}\")\n",
        "\n",
        "print(\"\\nğŸ“‹ ìƒì„¸ ê²°ê³¼:\")\n",
        "for i, result in enumerate(results, 1):\n",
        "    status = \"âœ…\" if result[\"valid\"] else \"âŒ\"\n",
        "    print(f\"\\n[{i}] {status} {result['question']}\")\n",
        "    print(f\"    SQL: {result['sql'][:60]}...\")\n",
        "    print(f\"    ë‹µë³€: {result['answer'][:80]}...\")\n",
        "    print(f\"    ì‹ ë¢°ë„: {result['confidence']:.3f}, ìˆ˜ì •: {result['revisions']}íšŒ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. ê³ ê¸‰ ê¸°ëŠ¥: ë³µì¡í•œ ì§ˆë¬¸ ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë” ë³µì¡í•œ ì§ˆë¬¸ë“¤ë¡œ í…ŒìŠ¤íŠ¸\n",
        "complex_questions = [\n",
        "    \"ê° ì¹´í…Œê³ ë¦¬ë³„ í‰ê·  ì£¼ë¬¸ ê¸ˆì•¡ê³¼ ì£¼ë¬¸ ê±´ìˆ˜ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”\",\n",
        "    \"2024ë…„ 2ì›”ì— ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆ top 3ëŠ”?\",\n",
        "    \"ê³ ê°ë³„ ì´ êµ¬ë§¤ ê¸ˆì•¡ê³¼ ì£¼ë¬¸ íšŸìˆ˜ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì£¼ì„¸ìš”\",\n",
        "    \"ë°°ì†¡ ìƒíƒœë³„ ì£¼ë¬¸ ê±´ìˆ˜ì™€ ì´ ê¸ˆì•¡ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
        "    \"ì „ìì œí’ˆì„ êµ¬ë§¤í•œ ê³ ê°ë“¤ì˜ í‰ê·  êµ¬ë§¤ ê¸ˆì•¡ì€?\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ”¬ ë³µì¡í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for i, question in enumerate(complex_questions[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ í…ŒìŠ¤íŠ¸\n",
        "    print(f\"\\nğŸ§ª ë³µì¡í•œ ì§ˆë¬¸ {i}\")\n",
        "    try:\n",
        "        result = run_text2sql(question)\n",
        "        print(f\"âœ… ì²˜ë¦¬ ì™„ë£Œ: ì‹ ë¢°ë„ {result['confidence']:.3f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. ì„±ëŠ¥ ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_text2sql_performance():\n",
        "    \"\"\"Text2SQL ì„±ëŠ¥ ë¶„ì„\"\"\"\n",
        "    print(\"ğŸ”¬ Text2SQL ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„\n",
        "    total_questions = len(results)\n",
        "    successful = sum(1 for r in results if r[\"valid\"])\n",
        "    failed = total_questions - successful\n",
        "    \n",
        "    print(f\"ì „ì²´ ì§ˆë¬¸: {total_questions}ê°œ\")\n",
        "    print(f\"ì„±ê³µ: {successful}ê°œ ({successful/total_questions*100:.1f}%)\")\n",
        "    print(f\"ì‹¤íŒ¨: {failed}ê°œ ({failed/total_questions*100:.1f}%)\")\n",
        "    \n",
        "    # ì‹ ë¢°ë„ ë¶„í¬\n",
        "    if successful > 0:\n",
        "        confidences = [r[\"confidence\"] for r in results if r[\"valid\"]]\n",
        "        high_conf = sum(1 for c in confidences if c >= 0.8)\n",
        "        medium_conf = sum(1 for c in confidences if 0.6 <= c < 0.8)\n",
        "        low_conf = sum(1 for c in confidences if c < 0.6)\n",
        "        \n",
        "        print(\"\\nì‹ ë¢°ë„ ë¶„í¬ (ì„±ê³µí•œ ê²½ìš°):\")\n",
        "        print(f\"  ë†’ìŒ (â‰¥0.8): {high_conf}ê°œ\")\n",
        "        print(f\"  ë³´í†µ (0.6~0.8): {medium_conf}ê°œ\")\n",
        "        print(f\"  ë‚®ìŒ (<0.6): {low_conf}ê°œ\")\n",
        "    \n",
        "    # ìˆ˜ì • íšŸìˆ˜ ë¶„ì„\n",
        "    revision_counts = [r[\"revisions\"] for r in results]\n",
        "    no_revision = sum(1 for r in revision_counts if r == 0)\n",
        "    one_revision = sum(1 for r in revision_counts if r == 1)\n",
        "    multi_revision = sum(1 for r in revision_counts if r >= 2)\n",
        "    \n",
        "    print(\"\\nìˆ˜ì • íšŸìˆ˜ ë¶„í¬:\")\n",
        "    print(f\"  ìˆ˜ì • ì—†ìŒ: {no_revision}ê°œ\")\n",
        "    print(f\"  1íšŒ ìˆ˜ì •: {one_revision}ê°œ\")\n",
        "    print(f\"  2íšŒ ì´ìƒ: {multi_revision}ê°œ\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ ì‹œìŠ¤í…œ ì¥ì :\")\n",
        "    print(\"  - Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ SQL ìƒì„± ëŠ¥ë ¥ í™œìš©\")\n",
        "    print(\"  - ìë™ ìŠ¤í‚¤ë§ˆ ë¶„ì„ ë° ì»¨í…ìŠ¤íŠ¸ ì œê³µ\")\n",
        "    print(\"  - SQL ê²€ì¦ ë° ìë™ ìˆ˜ì • ê¸°ëŠ¥\")\n",
        "    print(\"  - ì¿¼ë¦¬ ê²°ê³¼ì˜ ìì—°ì–´ í•´ì„\")\n",
        "    \n",
        "    print(\"\\nğŸ’¡ ê°œì„  ì œì•ˆ:\")\n",
        "    if success_rate < 80:\n",
        "        print(\"  - ë” ì •êµí•œ ìŠ¤í‚¤ë§ˆ ì„¤ëª… ë° ì˜ˆì‹œ ì¶”ê°€\")\n",
        "        print(\"  - SQL ìƒì„± í”„ë¡¬í”„íŠ¸ ê°œì„ \")\n",
        "    if avg_revisions > 0.5:\n",
        "        print(\"  - ì´ˆê¸° SQL ìƒì„± í’ˆì§ˆ í–¥ìƒ\")\n",
        "        print(\"  - ë” ë‚˜ì€ ì˜¤ë¥˜ ë¶„ì„ ë° ìˆ˜ì • ë¡œì§\")\n",
        "    if avg_confidence < 0.7:\n",
        "        print(\"  - ì‹ ë¢°ë„ ê³„ì‚° ë°©ì‹ ê°œì„ \")\n",
        "        print(\"  - ê²°ê³¼ ê²€ì¦ ë¡œì§ ê°•í™”\")\n",
        "\n",
        "analyze_text2sql_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. ì‹¤ìŠµ ê³¼ì œ\n",
        "\n",
        "### ê³¼ì œ 1: ìŠ¤í‚¤ë§ˆ ì„¤ëª… ê°œì„ \n",
        "- ê° í…Œì´ë¸”ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ì™€ ê´€ê³„ë¥¼ ë” ìì„¸íˆ ì„¤ëª…í•˜ëŠ” ê¸°ëŠ¥ì„ ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "- ìƒ˜í”Œ ë°ì´í„°ë¥¼ í¬í•¨í•œ ë” í’ë¶€í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 2: ì¿¼ë¦¬ ìµœì í™”\n",
        "- ìƒì„±ëœ SQLì˜ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ìµœì í™”í•˜ëŠ” ë…¸ë“œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”\n",
        "- ì¸ë±ìŠ¤ í™œìš© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 3: ë‹¤ì¤‘ ì¿¼ë¦¬ ì²˜ë¦¬\n",
        "- í•œ ë²ˆì˜ ì§ˆë¬¸ì— ì—¬ëŸ¬ ê°œì˜ SQLì´ í•„ìš”í•œ ê²½ìš°ë¥¼ ì²˜ë¦¬í•´ë³´ì„¸ìš”\n",
        "- ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•œ ë‹¨ê³„ë³„ ì¿¼ë¦¬ ì‹¤í–‰ì„ êµ¬í˜„í•´ë³´ì„¸ìš”\n",
        "\n",
        "### ê³¼ì œ 4: ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™\n",
        "- PostgreSQLì´ë‚˜ MySQL ê°™ì€ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—°ë™í•´ë³´ì„¸ìš”\n",
        "- ë” í° ìŠ¤í‚¤ë§ˆì™€ ë³µì¡í•œ ê´€ê³„ë¥¼ ë‹¤ë£¨ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì„¸ìš”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„\n",
        "print(\"ğŸ“ Text2SQL ì‹¤ìŠµ ì™„ë£Œ!\")\n",
        "print(\"\\në‹¤ìŒ ë‹¨ê³„:\")\n",
        "print(\"1. 05-mcp-integration.ipynb - MCP(Model Context Protocol) í†µí•©\")\n",
        "print(\"2. 06-gradio-ui.ipynb - Gradioë¥¼ í†µí•œ UI ë˜í•‘\")\n",
        "\n",
        "print(\"\\nğŸ’¡ í•µì‹¬ í•™ìŠµ ë‚´ìš©:\")\n",
        "print(\"- ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ì™„ì „í•œ ì›Œí¬í”Œë¡œ\")\n",
        "print(\"- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ìë™ ë¶„ì„ ë° í™œìš©\")\n",
        "print(\"- SQL ê²€ì¦ ë° ì˜¤ë¥˜ ìë™ ìˆ˜ì •\")\n",
        "print(\"- ì¿¼ë¦¬ ê²°ê³¼ì˜ ìì—°ì–´ í•´ì„\")\n",
        "print(\"- Day 1 íŒŒì¸íŠœë‹ ëª¨ë¸ì˜ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±\")\n",
        "\n",
        "# ë¦¬ì†ŒìŠ¤ ì •ë¦¬\n",
        "db_analyzer.engine.dispose()\n",
        "print(\"\\nâœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}