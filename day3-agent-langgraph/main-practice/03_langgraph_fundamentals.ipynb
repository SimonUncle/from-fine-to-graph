{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ 02: LangGraph ì‹¤ë¬´ íŒ¨í„´ (EXAONE ì‹¤ì „)\n",
    "\n",
    "## ğŸ’¡ 01ë²ˆê¹Œì§€ ë°°ìš´ ë©”ì»¤ë‹ˆì¦˜ì„ ì‹¤ì œ LLMìœ¼ë¡œ êµ¬í˜„í•˜ì!\n",
    "\n",
    "### ğŸ“š ì§€ê¸ˆê¹Œì§€ì˜ í•™ìŠµ ê²½ë¡œ\n",
    "```\n",
    "00ë²ˆ: State, Node, Graph ê¸°ë³¸ ê°œë…\n",
    "  â†“\n",
    "01ë²ˆ: LangGraph ë©”ì»¤ë‹ˆì¦˜ (Command, Annotated, interrupt ë„êµ¬)\n",
    "  â†“\n",
    "02ë²ˆ: ì‹¤ë¬´ ì ìš© (EXAONEìœ¼ë¡œ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°) â† ì§€ê¸ˆ ì—¬ê¸°!\n",
    "```\n",
    "\n",
    "### ğŸ” 01ë²ˆ vs 02ë²ˆ ì°¨ì´\n",
    "\n",
    "#### 01ë²ˆ (advanced-integration.ipynb)\n",
    "- ğŸ”§ **ë©”ì»¤ë‹ˆì¦˜ ì¤‘ì‹¬**: Command, Annotated, interruptê°€ **ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€**\n",
    "- ğŸ“ **êµ¬ì¡° ì´í•´**: LangGraph ë‚´ë¶€ ë™ì‘ ì›ë¦¬\n",
    "- ğŸ’¡ **ê°„ë‹¨í•œ ì˜ˆì œ**: ë¬¸ìì—´ ê¸°ë°˜, Mock ë°ì´í„°\n",
    "- ğŸ¯ **ëª©í‘œ**: \"LangGraph ë„êµ¬ë¥¼ ì–´ë–»ê²Œ ì“°ëŠ”ê°€\"\n",
    "\n",
    "#### 02ë²ˆ (ì§€ê¸ˆ ë…¸íŠ¸ë¶)\n",
    "- ğŸš€ **ì‹¤ë¬´ íŒ¨í„´ ì¤‘ì‹¬**: Routing, Summarization ë“± **ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œ í•´ê²°**\n",
    "- ğŸ¤– **ì‹¤ì œ LLM ì‚¬ìš©**: EXAONEì´ ì§„ì§œë¡œ ì¶”ë¡ í•˜ê³  ì‘ë‹µ ìƒì„±\n",
    "- ğŸ“Š **ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤**: ì´ë©”ì¼ ì‘ë‹µ, ê³ ê° ë¬¸ì˜, ëŒ€í™” ìš”ì•½\n",
    "- ğŸ¯ **ëª©í‘œ**: \"ì‹¤ë¬´ì—ì„œ ì–´ë–»ê²Œ ì ìš©í•˜ëŠ”ê°€\"\n",
    "\n",
    "## ğŸ¯ ì´ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš°ëŠ” ê²ƒë“¤\n",
    "\n",
    "### âœ… ì‹¤ë¬´ê¸‰ ì›Œí¬í”Œë¡œìš° íŒ¨í„´\n",
    "1. **Routing**: EXAONEì´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•´ì„œ ì ì ˆí•œ ê²½ë¡œë¡œ ë¼ìš°íŒ…\n",
    "2. **Fan-out/Fan-in**: ë³‘ë ¬ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± ê·¹ëŒ€í™”\n",
    "3. **ëŒ€í™” ê¸°ë¡ ìš”ì•½**: ê¸´ ëŒ€í™”ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ìš”ì•½\n",
    "4. **Human in the Loop**: AI ì²˜ë¦¬ì— ì¸ê°„ ê²€í†  ì¶”ê°€\n",
    "\n",
    "### ğŸ”„ íŒ¨í„´ë³„ 01ë²ˆ ì—°ê²°\n",
    "- **Routing** â† 01ë²ˆ Commandë¥¼ LLM íŒë‹¨ì— ì ìš©\n",
    "- **Fan-out/Fan-in** â† 01ë²ˆ Annotated Stateë¡œ ì•ˆì „í•œ ë³‘ë ¬ ì²˜ë¦¬\n",
    "- **Summarization** â† ìƒˆë¡œìš´ íŒ¨í„´! ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "- **Human in the Loop** â† 01ë²ˆ interruptë¥¼ ì´ë©”ì¼ ì‹œìŠ¤í…œì— ì ìš©\n",
    "\n",
    "### ğŸ’¼ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤\n",
    "- **ê³ ê° ë¬¸ì˜ ìë™ ì²˜ë¦¬**: LLMì´ ë¬¸ì˜ ìœ í˜• íŒë‹¨ â†’ ì „ë¬¸íŒ€ ìë™ ë¼ìš°íŒ…\n",
    "- **ë‹¤ê°ë„ ì •ë³´ ìˆ˜ì§‘**: 3ê°œ íŒ€ì´ ë™ì‹œì— ì¡°ì‚¬ â†’ EXAONEì´ í†µí•© ë¦¬í¬íŠ¸ ì‘ì„±\n",
    "- **ì±—ë´‡ ë©”ëª¨ë¦¬ ê´€ë¦¬**: ê¸´ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì„œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "- **ì´ë©”ì¼ ìë™ ì‘ë‹µ**: AI ì´ˆì•ˆ ìƒì„± â†’ ì¸ê°„ ê²€í†  â†’ ìµœì¢… ë°œì†¡\n",
    "\n",
    "### â±ï¸ ì˜ˆìƒ í•™ìŠµ ì‹œê°„: 30-40ë¶„\n",
    "ê° íŒ¨í„´ì„ EXAONEìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰í•´ë³´ë©´ì„œ ì‹¤ë¬´ ì ìš© ë°©ë²•ì„ ì²´ë“í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° import + EXAONE ëª¨ë¸ ë¡œë“œ\n",
    "!pip install -q langgraph langchain langchain-teddynote\n",
    "!pip install -q grandalf matplotlib networkx pyppeteer\n",
    "!pip install -q git+https://github.com/lgai-exaone/transformers@add-exaone4\n",
    "!pip install -q torch accelerate\n",
    "\n",
    "from typing import TypedDict, List, Dict, Any, Annotated\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "from langchain_teddynote.messages import stream_graph, random_uuid\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì™„ë£Œ!\")\n",
    "print(\"ğŸ”¥ ì‹¤ì œ Human in the Loopì„ ìœ„í•œ interrupt, Command ì¶”ê°€!\")\n",
    "\n",
    "# ğŸ¤– EXAONE ëª¨ë¸ ë¡œë“œ\n",
    "MODEL_NAME = \"LGAI-EXAONE/EXAONE-4.0-1.2B\"\n",
    "\n",
    "print(f\"ğŸš€ EXAONE-4.0-1.2B ëª¨ë¸ ë¡œë“œ ì‹œì‘: {MODEL_NAME}\")\n",
    "\n",
    "# EXAONE-4.0-1.2B ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (CPU í˜¸í™˜)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32,  # CPU í˜¸í™˜ì„ ìœ„í•´ float32 ì‚¬ìš©\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ… EXAONE-4.0-1.2B ëª¨ë¸ ë¡œë“œ ì„±ê³µ!\")\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def pure_exaone_inference(messages_or_prompt):\n",
    "    \"\"\"ğŸ”¥ EXAONE ëŒ€í™” ë§¥ë½ ì§€ì› í•¨ìˆ˜ - HuggingFace ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜\"\"\"\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    try:\n",
    "        # ğŸ¯ ì…ë ¥ì´ ë¬¸ìì—´ì´ë©´ ë‹¨ì¼ ë©”ì‹œì§€ë¡œ, ë¦¬ìŠ¤íŠ¸ë©´ ëŒ€í™” ë§¥ë½ìœ¼ë¡œ ì²˜ë¦¬\n",
    "        if isinstance(messages_or_prompt, str):\n",
    "            messages = [{\"role\": \"user\", \"content\": messages_or_prompt}]\n",
    "        else:\n",
    "            # ì´ë¯¸ EXAONE chat formatì¸ ê²½ìš°\n",
    "            messages = messages_or_prompt\n",
    "        \n",
    "        # ğŸ”¥ EXAONE í‘œì¤€ chat templateë¡œ ì „ì²´ ëŒ€í™” ë§¥ë½ ì²˜ë¦¬\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages,  # ì „ì²´ ëŒ€í™” history\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=80,     # ë” ì§§ê³  ì§‘ì¤‘ëœ ì‘ë‹µ\n",
    "                temperature=0.1,       # ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ ê°’\n",
    "                do_sample=True,        # HuggingFace ê°€ì´ë“œ ê¶Œì¥\n",
    "                top_p=0.9,            # ì ì ˆí•œ ì°½ì˜ì„± í—ˆìš©\n",
    "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # ì…ë ¥ ê¸¸ì´ë§Œí¼ ì œê±°í•˜ê³  ìƒˆë¡œ ìƒì„±ëœ ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "        generated_ids = outputs[0][input_ids.shape[-1]:]\n",
    "        ai_response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        \n",
    "        clear_gpu_memory()\n",
    "        \n",
    "        # ğŸ”¥ ê¹”ë”í•œ ì‘ë‹µë§Œ ë°˜í™˜\n",
    "        return ai_response if ai_response else \"ì•ˆë…•í•˜ì„¸ìš”!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        clear_gpu_memory()\n",
    "        print(f\"ğŸš¨ EXAONE ì¶”ë¡  ì˜¤ë¥˜: {e}\")\n",
    "        return \"ì£„ì†¡í•´ìš”, ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?\"\n",
    "\n",
    "print(\"âœ… EXAONE ëª¨ë¸ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"ğŸ”¥ ìµœì í™”ëœ EXAONE ì‹œìŠ¤í…œ:\")\n",
    "print(\"   ğŸ’¬ chat template: ì „ì²´ ëŒ€í™” history ì²˜ë¦¬\")\n",
    "print(\"   ğŸ¯ temperature=0.1 + do_sample=True: ì¼ê´€ì„± + ì°½ì˜ì„±\")\n",
    "print(\"   ğŸ§  max_new_tokens=80: ì§‘ì¤‘ëœ ì‘ë‹µ\")\n",
    "print(\"   ğŸª top_p=0.9: ì ì ˆí•œ ë‹¤ì–‘ì„±\")\n",
    "print(\"ğŸ’» CPU ìµœì í™” ëª¨ë“œ (êµìœ¡ìš© ì•ˆì •ì„± ìš°ì„ )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 1: Routing íŒ¨í„´ - LLMì´ íŒë‹¨í•˜ëŠ” ì§€ëŠ¥ì  ë¼ìš°íŒ…\n",
    "\n",
    "### ğŸ’¡ 01ë²ˆì—ì„œ ë°°ìš´ ê²ƒì„ ì‹¤ë¬´ì— ì ìš©!\n",
    "01ë²ˆì—ì„œ **Command**ë¡œ ë‹¤ìŒ ë…¸ë“œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒí•˜ëŠ” ë°©ë²•ì„ ë°°ì› ì–´ìš”.  \n",
    "ì´ì œ **EXAONE LLMì´ ë‚´ìš©ì„ ì´í•´**í•´ì„œ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¥¼ ê²°ì •í•˜ê²Œ ë§Œë“¤ì–´ë´…ì‹œë‹¤!\n",
    "\n",
    "### ğŸ¯ Routingì´ë€?\n",
    "00ë²ˆì—ì„œëŠ” **ê¸€ì ìˆ˜**ë‚˜ **ë‹¨ìˆœ ì¡°ê±´**ìœ¼ë¡œ ë¶„ê¸°í–ˆì§€ë§Œ,  \n",
    "ì´ì œëŠ” **LLMì´ ë‚´ìš©ì„ ì´í•´**í•´ì„œ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¥¼ ê²°ì •í•´ë³´ì!\n",
    "\n",
    "### ğŸ”„ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤\n",
    "- **ê³„ì‚° ë¬¸ì œ**: ê³„ì‚°ê¸°ë¡œ ë¼ìš°íŒ…\n",
    "- **ë²ˆì—­ ìš”ì²­**: ë²ˆì—­ ì—”ì§„ìœ¼ë¡œ ë¼ìš°íŒ…  \n",
    "- **ì¼ë°˜ ëŒ€í™”**: ëŒ€í™” ì‹œìŠ¤í…œìœ¼ë¡œ ë¼ìš°íŒ…\n",
    "- **ì½”ë”© ì§ˆë¬¸**: ì½”ë“œ ë¶„ì„ê¸°ë¡œ ë¼ìš°íŒ…\n",
    "\n",
    "**í•µì‹¬**: LLMì´ ì§ˆë¬¸ì˜ **ì˜ë„**ë¥¼ íŒŒì•…í•´ì„œ ìµœì ì˜ ì²˜ë¦¬ ë°©ë²• ì„ íƒ!\n",
    "\n",
    "### ğŸ”— 01ë²ˆ ë©”ì»¤ë‹ˆì¦˜ vs 02ë²ˆ ì‹¤ë¬´ ì ìš©\n",
    "```\n",
    "01ë²ˆ: Command(goto='next_node', update={...})\n",
    "      â†“ \"ë„êµ¬ ì‚¬ìš©ë²•\"\n",
    "02ë²ˆ: EXAONEì´ ì§ˆë¬¸ ë¶„ì„ â†’ intelligent_routerê°€ Command ë¦¬í„´\n",
    "      â†“ \"LLM ê¸°ë°˜ ì‹¤ë¬´ ë¼ìš°íŒ…\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤– Routingìš© State ì •ì˜\n",
    "class RoutingState(TypedDict):\n",
    "    user_query: str          # ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    query_type: str          # LLMì´ ë¶„ì„í•œ ì§ˆë¬¸ ìœ í˜•\n",
    "    processing_route: str    # ì„ íƒëœ ì²˜ë¦¬ ê²½ë¡œ\n",
    "    result: str             # ìµœì¢… ì²˜ë¦¬ ê²°ê³¼\n",
    "    confidence: float       # ë¼ìš°íŒ… ì‹ ë¢°ë„\n",
    "\n",
    "def intelligent_router(state: RoutingState) -> str:\n",
    "    \"\"\"ğŸ§  EXAONE LLMì´ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì ì ˆí•œ ê²½ë¡œ ê²°ì •\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    # ğŸ¤– EXAONEì—ê²Œ ì§ˆë¬¸ ë¶„ë¥˜ ìš”ì²­\n",
    "    routing_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ê°€ì¥ ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì§ˆë¬¸: {user_query}\n",
    "\n",
    "ì„ íƒ ê°€ëŠ¥í•œ ê²½ë¡œ:\n",
    "1. \"calculation\" - ìˆ˜í•™ ê³„ì‚°ì´ë‚˜ ì—°ì‚°ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "2. \"translation\" - ë²ˆì—­ì´ë‚˜ ì–¸ì–´ ë³€í™˜ì´ í•„ìš”í•œ ì§ˆë¬¸\n",
    "3. \"coding\" - í”„ë¡œê·¸ë˜ë°ì´ë‚˜ ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸\n",
    "4. \"general\" - ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ìƒì‹ ì§ˆë¬¸\n",
    "\n",
    "ê°€ì¥ ì ì ˆí•œ ê²½ë¡œë¥¼ í•˜ë‚˜ë§Œ ì„ íƒí•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”: \"\"\"\n",
    "\n",
    "    llm_response = pure_exaone_inference(routing_prompt)\n",
    "    \n",
    "    # ğŸ” LLM ì‘ë‹µì—ì„œ ë¼ìš°íŒ… ê²½ë¡œ ì¶”ì¶œ\n",
    "    if \"calculation\" in llm_response.lower():\n",
    "        return \"calculation\"\n",
    "    elif \"translation\" in llm_response.lower():\n",
    "        return \"translation\" \n",
    "    elif \"coding\" in llm_response.lower():\n",
    "        return \"coding\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "print(\"ğŸ§  ì§€ëŠ¥ì  ë¼ìš°í„° ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   - EXAONE LLMì´ ì§ˆë¬¸ ë‚´ìš©ì„ ë¶„ì„\")\n",
    "print(\"   - 4ê°€ì§€ ê²½ë¡œ ì¤‘ ìµœì  ê²½ë¡œ ì„ íƒ\")\n",
    "print(\"   - í•˜ë“œì½”ë”© ì—†ëŠ” ì™„ì „ ì§€ëŠ¥ì  íŒë‹¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ ê° ê²½ë¡œë³„ ì²˜ë¦¬ ë…¸ë“œë“¤ ì •ì˜\n",
    "def calculation_node(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"ğŸ§® ê³„ì‚° ì „ìš© ë…¸ë“œ - EXAONEì„ ê³„ì‚°ê¸°ë¡œ í™œìš©\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    # EXAONEì—ê²Œ ê³„ì‚° ìš”ì²­\n",
    "    calc_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ìˆ˜í•™ ê³„ì‚°ì„ ì •í™•íˆ ê³„ì‚°í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ê³„ì‚°: {user_query}\n",
    "\n",
    "ìˆ«ìì™€ ê¸°ë³¸ ì‚¬ì¹™ì—°ì‚°ë§Œ ì‚¬ìš©í•´ì„œ ì •í™•í•œ ë‹µì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "ì˜ˆ: 10 + 5 = 15\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(calc_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"query_type\": \"calculation\",\n",
    "        \"processing_route\": \"ê³„ì‚° ì²˜ë¦¬\",\n",
    "        \"result\": f\"ğŸ§® ê³„ì‚° ê²°ê³¼: {result}\",\n",
    "        \"confidence\": 0.95\n",
    "    }\n",
    "\n",
    "def translation_node(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"ğŸŒ ë²ˆì—­ ì „ìš© ë…¸ë“œ - EXAONEì„ ë²ˆì—­ê¸°ë¡œ í™œìš©\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    translation_prompt = f\"\"\"\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì›ë¬¸: {user_query}\n",
    "\n",
    "í•œêµ­ì–´ë©´ ì˜ì–´ë¡œ, ì˜ì–´ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\n",
    "ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë²ˆì—­ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(translation_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"query_type\": \"translation\", \n",
    "        \"processing_route\": \"ë²ˆì—­ ì²˜ë¦¬\",\n",
    "        \"result\": f\"ğŸŒ ë²ˆì—­ ê²°ê³¼: {result}\",\n",
    "        \"confidence\": 0.90\n",
    "    }\n",
    "\n",
    "def coding_node(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"ğŸ’» ì½”ë”© ì „ìš© ë…¸ë“œ - EXAONEì„ í”„ë¡œê·¸ë˜ë° ë„ìš°ë¯¸ë¡œ í™œìš©\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    coding_prompt = f\"\"\"\n",
    "ë‹¤ìŒ í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì§ˆë¬¸: {user_query}\n",
    "\n",
    "ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ëª…í™•í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "ì‹¤ìš©ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(coding_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"query_type\": \"coding\",\n",
    "        \"processing_route\": \"ì½”ë”© ì²˜ë¦¬\", \n",
    "        \"result\": f\"ğŸ’» ì½”ë”© ë‹µë³€: {result}\",\n",
    "        \"confidence\": 0.85\n",
    "    }\n",
    "\n",
    "def general_node(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"ğŸ’¬ ì¼ë°˜ ëŒ€í™” ë…¸ë“œ - EXAONEì„ ì¹œê·¼í•œ ëŒ€í™” ìƒëŒ€ë¡œ í™œìš©\"\"\"\n",
    "    user_query = state[\"user_query\"]\n",
    "    \n",
    "    general_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì§ˆë¬¸: {user_query}\n",
    "\n",
    "ìì—°ìŠ¤ëŸ½ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ í¬í•¨í•œ ë‹µë³€ì„ ë¶€íƒë“œë¦½ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(general_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"query_type\": \"general\",\n",
    "        \"processing_route\": \"ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬\",\n",
    "        \"result\": f\"ğŸ’¬ ì¼ë°˜ ë‹µë³€: {result}\",\n",
    "        \"confidence\": 0.80\n",
    "    }\n",
    "\n",
    "print(\"ğŸ”§ ëª¨ë“  ë¼ìš°íŒ… ì²˜ë¦¬ ë…¸ë“œ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   ğŸ§® calculation_node: ìˆ˜í•™ ê³„ì‚° ì „ë¬¸\")\n",
    "print(\"   ğŸŒ translation_node: ì–¸ì–´ ë²ˆì—­ ì „ë¬¸\")  \n",
    "print(\"   ğŸ’» coding_node: í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ ì „ë¬¸\")\n",
    "print(\"   ğŸ’¬ general_node: ì¼ë°˜ ëŒ€í™” ì „ë¬¸\")\n",
    "print(\"   ğŸ¯ ê° ë…¸ë“œê°€ íŠ¹í™”ëœ EXAONE í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”„ ì§€ëŠ¥ì  ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "routing_workflow = StateGraph(RoutingState)\n",
    "\n",
    "# ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œë“¤ ì¶”ê°€\n",
    "routing_workflow.add_node(\"calculation\", calculation_node)\n",
    "routing_workflow.add_node(\"translation\", translation_node) \n",
    "routing_workflow.add_node(\"coding\", coding_node)\n",
    "routing_workflow.add_node(\"general\", general_node)\n",
    "\n",
    "# ğŸ§  ì¡°ê±´ë¶€ ì‹œì‘ì : EXAONEì´ ë¶„ì„í•´ì„œ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…\n",
    "routing_workflow.set_conditional_entry_point(\n",
    "    intelligent_router,  # LLM ê¸°ë°˜ ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "    {\n",
    "        \"calculation\": \"calculation\",\n",
    "        \"translation\": \"translation\", \n",
    "        \"coding\": \"coding\",\n",
    "        \"general\": \"general\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œëŠ” ENDë¡œ ì—°ê²° (ë‹¨ì¼ ì²˜ë¦¬ í›„ ì¢…ë£Œ)\n",
    "routing_workflow.add_edge(\"calculation\", END)\n",
    "routing_workflow.add_edge(\"translation\", END)\n",
    "routing_workflow.add_edge(\"coding\", END)\n",
    "routing_workflow.add_edge(\"general\", END)\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼\n",
    "routing_app = routing_workflow.compile()\n",
    "\n",
    "print(\"ğŸ”„ ì§€ëŠ¥ì  ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° ì™„ì„±!\")\n",
    "print(\"   ğŸ§  EXAONE LLMì´ ì§ˆë¬¸ ë‚´ìš© ë¶„ì„\")\n",
    "print(\"   ğŸ¯ 4ê°œ ì „ë¬¸ ë…¸ë“œ ì¤‘ ìµœì  ê²½ë¡œ ìë™ ì„ íƒ\")  \n",
    "print(\"   âš¡ í•˜ë“œì½”ë”© ì—†ëŠ” ì™„ì „ ì§€ëŠ¥ì  ë¶„ê¸°\")\n",
    "print(\"   ğŸ’ ì‹¤ë¬´ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ íŒ¨í„´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° ì‹œê°í™”  \n",
    "print(\"ğŸ“Š ì§€ëŠ¥ì  ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:\")\n",
    "visualize_graph(routing_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª ì§€ëŠ¥ì  ë¼ìš°íŒ… ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª EXAONE ê¸°ë°˜ ì§€ëŠ¥ì  ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 4ê°€ì§€ ë‹¤ë¥¸ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸\n",
    "routing_test_queries = [\n",
    "    \"10 + 25ë¥¼ ê³„ì‚°í•´ì¤˜\",\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•´ì¤˜\", \n",
    "    \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì–´ë–»ê²Œ ë§Œë“œë‚˜ìš”?\",\n",
    "    \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”!\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(routing_test_queries, 1):\n",
    "    print(f\"\\nğŸ” í…ŒìŠ¤íŠ¸ {i}: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # ë¼ìš°íŒ… ì‹œìŠ¤í…œ ì‹¤í–‰\n",
    "    result = routing_app.invoke({\n",
    "        \"user_query\": query,\n",
    "        \"query_type\": \"\",\n",
    "        \"processing_route\": \"\",\n",
    "        \"result\": \"\",\n",
    "        \"confidence\": 0.0\n",
    "    })\n",
    "    \n",
    "    print(f\"ğŸ§  ì§ˆë¬¸ ìœ í˜• ë¶„ì„: {result['query_type']}\")\n",
    "    print(f\"ğŸ›£ï¸  ì„ íƒëœ ì²˜ë¦¬ ê²½ë¡œ: {result['processing_route']}\")\n",
    "    print(f\"ğŸ“Š ë¼ìš°íŒ… ì‹ ë¢°ë„: {result['confidence']*100:.0f}%\")\n",
    "    print(f\"âœ… ì²˜ë¦¬ ê²°ê³¼: {result['result']}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì§€ëŠ¥ì  ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ EXAONE LLMì´ ì§ˆë¬¸ ë‚´ìš©ì„ ì´í•´í•˜ê³  ì ì ˆí•œ ê²½ë¡œë¡œ ìë™ ë¶„ê¸°!\")\n",
    "print(\"ğŸ”¥ í•˜ë“œì½”ë”© ì—†ì´ ì™„ì „íˆ ì§€ëŠ¥ì ì¸ ì›Œí¬í”Œë¡œìš° êµ¬í˜„!\")\n",
    "\n",
    "# ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš°ì˜ í•µì‹¬ ì¥ì  ì„¤ëª…\n",
    "print(f\"\\n{'ğŸ¯' * 20} ë¼ìš°íŒ… íŒ¨í„´ì˜ í•µì‹¬ ì¥ì  {'ğŸ¯' * 20}\")\n",
    "print(\"âœ… ì™„ì „ ì§€ëŠ¥ì  ë¶„ê¸°: LLMì´ ë‚´ìš©ì„ ì´í•´í•´ì„œ íŒë‹¨\")\n",
    "print(\"âœ… í™•ì¥ì„±: ìƒˆë¡œìš´ ì²˜ë¦¬ ê²½ë¡œ ì¶”ê°€ ì‹œ ì½”ë“œ ìˆ˜ì • ìµœì†Œí™”\")\n",
    "print(\"âœ… ìœ ì§€ë³´ìˆ˜ì„±: ê° ì²˜ë¦¬ ë…¸ë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬\")\n",
    "print(\"âœ… ì‹¤ë¬´ ì ìš©ì„±: ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ êµ¬ì¡°\")\n",
    "print(\"âœ… ì„±ëŠ¥ ìµœì í™”: ê° ì‘ì—…ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ìµœì  ì„±ëŠ¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì‹¤ìŠµ 1: LLM ê¸°ë°˜ ë¼ìš°í„° ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸°\n",
    "\n",
    "ë°©ê¸ˆ ë³¸ `intelligent_router` í•¨ìˆ˜ë¥¼ ì°¸ê³ í•˜ì—¬, ë” ê°„ë‹¨í•œ ë²„ì „ì˜ ë¼ìš°í„°ë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”.\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "- ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…\n",
    "- \"ê³„ì‚°\" í‚¤ì›Œë“œ â†’ \"calc\" ë…¸ë“œ\n",
    "- \"ë²ˆì—­\" í‚¤ì›Œë“œ â†’ \"translate\" ë…¸ë“œ\n",
    "- ê·¸ ì™¸ â†’ \"general\" ë…¸ë“œ\n",
    "- LLM í˜¸ì¶œ ì—†ì´ ê°„ë‹¨í•œ ì¡°ê±´ë¬¸ìœ¼ë¡œ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "class SimpleState(TypedDict):\n",
    "    query: str\n",
    "    result: str\n",
    "\n",
    "def simple_keyword_router(state: SimpleState) -> Literal[\"calc\", \"translate\", \"general\"]:\n",
    "    '''\n",
    "    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•˜ëŠ” í•¨ìˆ˜\n",
    "    '''\n",
    "    query = state['query']\n",
    "    \n",
    "    # ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "    # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë¼ìš°íŒ… ë¡œì§ì„ ì‘ì„±í•˜ì„¸ìš”\n",
    "    pass  # ì´ ì¤„ì„ ì§€ìš°ê³  ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_state = {\"query\": \"10 ê³±í•˜ê¸° 5ë¥¼ ê³„ì‚°í•´ì¤˜\", \"result\": \"\"}\n",
    "print(f\"ë¼ìš°íŒ… ê²°ê³¼: {simple_keyword_router(test_state)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "```python\n",
    "def simple_keyword_router(state: SimpleState) -> Literal[\"calc\", \"translate\", \"general\"]:\n",
    "    '''\n",
    "    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…í•˜ëŠ” í•¨ìˆ˜\n",
    "    '''\n",
    "    query = state['query']\n",
    "    \n",
    "    if 'ê³„ì‚°' in query or 'ë”í•˜ê¸°' in query or 'ê³±í•˜ê¸°' in query:\n",
    "        return \"calc\"\n",
    "    elif 'ë²ˆì—­' in query or 'translate' in query:\n",
    "        return \"translate\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_state = {\"query\": \"10 ê³±í•˜ê¸° 5ë¥¼ ê³„ì‚°í•´ì¤˜\", \"result\": \"\"}\n",
    "print(f\"ë¼ìš°íŒ… ê²°ê³¼: {simple_keyword_router(test_state)}\")  # calc\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ê°œë…:**\n",
    "- Literal íƒ€ì…ìœ¼ë¡œ ê°€ëŠ¥í•œ ë¼ìš°íŒ… ëŒ€ìƒì„ ëª…ì‹œ\n",
    "- ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë¹ ë¥¸ ë¼ìš°íŒ… ê°€ëŠ¥\n",
    "- LLM í˜¸ì¶œ ì—†ì´ë„ ê¸°ë³¸ì ì¸ ì˜ë„ ë¶„ë¥˜ ê°€ëŠ¥\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Part 2: Fan-out/Fan-in íŒ¨í„´ - ë³‘ë ¬ ì²˜ë¦¬ë¡œ íš¨ìœ¨ ê·¹ëŒ€í™”\n",
    "\n",
    "### ğŸ’¡ 01ë²ˆì—ì„œ ë°°ìš´ ê²ƒì„ ì‹¤ë¬´ì— ì ìš©!\n",
    "01ë²ˆì—ì„œ **Annotated State**ë¡œ ì—¬ëŸ¬ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ ë³‘í•©í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ì–´ìš”.  \n",
    "ì´ì œ **ì‹¤ì œ 3ê°œ ì „ë¬¸íŒ€ì´ ë™ì‹œì— EXAONEìœ¼ë¡œ ì¡°ì‚¬**í•˜ê³  ê²°ê³¼ë¥¼ í†µí•©í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "### ğŸ¯ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤\n",
    "í•œ ì£¼ì œì— ëŒ€í•´ ë‹¤ê°ë„ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ë•Œ:\n",
    "- ğŸ›ï¸ **ì—­ì‚¬íŒ€**: ì—­ì‚¬ì  ë°°ê²½ê³¼ ì‚¬ê±´ ì¡°ì‚¬\n",
    "- ğŸ­ **ë¬¸í™”íŒ€**: ë¬¸í™”ì  íŠ¹ì§•ê³¼ ì „í†µ ì¡°ì‚¬\n",
    "- ğŸ—ºï¸ **ê´€ê´‘íŒ€**: ê´€ê´‘ì§€ì™€ ëª…ì†Œ ì¡°ì‚¬\n",
    "\n",
    "ëª¨ë“  íŒ€ì´ ë™ì‹œì— ì‘ì—…í•˜ê³  â†’ EXAONEì´ ìµœì¢… í†µí•© ë¦¬í¬íŠ¸ ì‘ì„±!\n",
    "\n",
    "### ğŸ”— 01ë²ˆ ë©”ì»¤ë‹ˆì¦˜ vs 02ë²ˆ ì‹¤ë¬´ ì ìš©\n",
    "```\n",
    "01ë²ˆ: Annotated[List[str], operator.add]ë¡œ ì•ˆì „í•œ ë³‘í•©\n",
    "      â†“ \"ë„êµ¬ ì‚¬ìš©ë²•\"\n",
    "02ë²ˆ: 3ê°œ EXAONE ë…¸ë“œê°€ ë³‘ë ¬ ì‹¤í–‰ â†’ results ìë™ ëˆ„ì \n",
    "      â†“ \"ì‹¤ë¬´ ë³‘ë ¬ ì²˜ë¦¬\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Annotated\n",
    "import operator\n",
    "\n",
    "class FanoutState(TypedDict):\n",
    "    user_topic: str              # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì£¼ì œ\n",
    "    results: Annotated[List[str], operator.add]  # ë³‘ë ¬ ê²°ê³¼ë“¤ì„ ë³‘í•©\n",
    "    final_summary: str           # ìµœì¢… í†µí•© ê²°ê³¼\n",
    "\n",
    "def distributor_node(state: FanoutState) -> FanoutState:\n",
    "    \"\"\"ğŸš€ ì‹œì‘ ë…¸ë“œ - ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¶„ë°°\"\"\"\n",
    "    return {\n",
    "        **state,\n",
    "        \"results\": []  # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "    }\n",
    "\n",
    "# ğŸ›ï¸ ì—­ì‚¬ ì „ë¬¸ ë…¸ë“œ\n",
    "def history_research_node(state: FanoutState) -> FanoutState:\n",
    "    \"\"\"ğŸ›ï¸ ì—­ì‚¬ ì •ë³´ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì¡°ì‚¬\"\"\"\n",
    "    topic = state[\"user_topic\"]\n",
    "    \n",
    "    history_prompt = f\"\"\"\n",
    "'{topic}'ì— ê´€ë ¨ëœ ì—­ì‚¬ì  ë°°ê²½ê³¼ ì¤‘ìš”í•œ ì—­ì‚¬ì  ì‚¬ê±´ë“¤ì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì£¼ì œ: {topic}\n",
    "\n",
    "ì—­ì‚¬ì  ê´€ì ì—ì„œ:\n",
    "- ì£¼ìš” ì—­ì‚¬ì  ì‚¬ê±´\n",
    "- ì‹œëŒ€ì  ë°°ê²½\n",
    "- ì—­ì‚¬ì  ì˜ë¯¸ì™€ ì˜í–¥\n",
    "\n",
    "ì „ë¬¸ì ì´ê³  ì •í™•í•œ ì—­ì‚¬ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(history_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"results\": [f\"ğŸ›ï¸ ì—­ì‚¬ ë¶„ì•¼: {result}\"]\n",
    "    }\n",
    "\n",
    "# ğŸ­ ë¬¸í™” ì „ë¬¸ ë…¸ë“œ\n",
    "def culture_research_node(state: FanoutState) -> FanoutState:\n",
    "    \"\"\"ğŸ­ ë¬¸í™” ì •ë³´ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì¡°ì‚¬\"\"\"\n",
    "    topic = state[\"user_topic\"]\n",
    "    \n",
    "    culture_prompt = f\"\"\"\n",
    "'{topic}'ì— ê´€ë ¨ëœ ë¬¸í™”ì  íŠ¹ì§•ê³¼ ì „í†µì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì£¼ì œ: {topic}\n",
    "\n",
    "ë¬¸í™”ì  ê´€ì ì—ì„œ:\n",
    "- ì „í†µ ë¬¸í™”ì™€ í’ìŠµ\n",
    "- ì˜ˆìˆ ê³¼ ë¬¸í•™\n",
    "- ìƒí™œ ë¬¸í™”ì™€ íŠ¹ì§•\n",
    "\n",
    "ë¬¸í™”ì  ê¹Šì´ê°€ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(culture_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"results\": [f\"ğŸ­ ë¬¸í™” ë¶„ì•¼: {result}\"]\n",
    "    }\n",
    "\n",
    "# ğŸ—ºï¸ ê´€ê´‘ì§€ ì „ë¬¸ ë…¸ë“œ  \n",
    "def tourism_research_node(state: FanoutState) -> FanoutState:\n",
    "    \"\"\"ğŸ—ºï¸ ê´€ê´‘ ì •ë³´ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì¡°ì‚¬\"\"\"\n",
    "    topic = state[\"user_topic\"]\n",
    "    \n",
    "    tourism_prompt = f\"\"\"\n",
    "'{topic}'ì— ê´€ë ¨ëœ ê´€ê´‘ì§€ì™€ ëª…ì†Œì— ëŒ€í•´ ì „ë¬¸ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì£¼ì œ: {topic}\n",
    "\n",
    "ê´€ê´‘ ê´€ì ì—ì„œ:\n",
    "- ëŒ€í‘œì ì¸ ëª…ì†Œì™€ ê´€ê´‘ì§€\n",
    "- íŠ¹ë³„í•œ ì²´í—˜ê³¼ í™œë™\n",
    "- ë°©ë¬¸í• ë§Œí•œ ê°€ì¹˜ê°€ ìˆëŠ” ê³³ë“¤\n",
    "\n",
    "ì‹¤ìš©ì ì¸ ê´€ê´‘ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    result = pure_exaone_inference(tourism_prompt)\n",
    "    \n",
    "    return {\n",
    "        \"results\": [f\"ğŸ—ºï¸ ê´€ê´‘ ë¶„ì•¼: {result}\"]\n",
    "    }\n",
    "\n",
    "print(\"ğŸ”„ Fan-out ë…¸ë“œë“¤ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   ğŸš€ distributor_node: ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ì \")\n",
    "print(\"   ğŸ›ï¸ history_research_node: ì—­ì‚¬ ì „ë¬¸ ì¡°ì‚¬\")\n",
    "print(\"   ğŸ­ culture_research_node: ë¬¸í™” ì „ë¬¸ ì¡°ì‚¬\")\n",
    "print(\"   ğŸ—ºï¸ tourism_research_node: ê´€ê´‘ ì „ë¬¸ ì¡°ì‚¬\")\n",
    "print(\"   âš¡ Annotated í‚¤ë¡œ ì•ˆì „í•œ ë³‘ë ¬ ê²°ê³¼ ë³‘í•©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”— Fan-in ë…¸ë“œ ë° ì˜¬ë°”ë¥¸ ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "def synthesis_node(state: FanoutState) -> FanoutState:\n",
    "    \"\"\"ğŸ”— 3ê°œ ì „ë¬¸ ë¶„ì•¼ ê²°ê³¼ë¥¼ ì¢…í•©í•´ì„œ ì™„ì „í•œ ë‹µë³€ ìƒì„±\"\"\"\n",
    "    topic = state[\"user_topic\"]\n",
    "    results = state.get(\"results\", [])\n",
    "    \n",
    "    # ê° ë¶„ì•¼ë³„ ê²°ê³¼ ì •ë¦¬\n",
    "    all_results = \"\\n\\n\".join(results)\n",
    "    \n",
    "    # ì „ì²´ ì •ë³´ë¥¼ ì¢…í•©í•˜ëŠ” EXAONE í”„ë¡¬í”„íŠ¸\n",
    "    synthesis_prompt = f\"\"\"\n",
    "ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ 3ê°œ ë¶„ì•¼ì˜ ì „ë¬¸ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ì¢…í•©í•´ì„œ ì™„ì „í•˜ê³  ì²´ê³„ì ì¸ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì£¼ì œ: {topic}\n",
    "\n",
    "ì¡°ì‚¬ ê²°ê³¼:\n",
    "{all_results}\n",
    "\n",
    "ìœ„ 3ê°œ ì „ë¬¸ ë¶„ì•¼ì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬:\n",
    "1. ì „ì²´ì ì¸ ê°œìš”ì™€ íŠ¹ì§•\n",
    "2. ê° ë¶„ì•¼ ê°„ì˜ ì—°ê´€ì„±ê³¼ í†µí•©ì  ê´€ì \n",
    "3. ì¢…í•©ì ì¸ ê²°ë¡ ê³¼ ê¶Œì¥ì‚¬í•­\n",
    "\n",
    "ì²´ê³„ì ì´ê³  ì™„ì„±ë„ ë†’ì€ í†µí•© ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    final_result = pure_exaone_inference(synthesis_prompt)\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"final_summary\": f\"ğŸ”— ì¢…í•© ê²°ê³¼: {final_result}\"\n",
    "    }\n",
    "\n",
    "# ğŸ”„ Fan-out/Fan-in ì›Œí¬í”Œë¡œìš° êµ¬ì¶• (LangGraph í‘œì¤€ êµ¬ì¡°)\n",
    "fanout_workflow = StateGraph(FanoutState)\n",
    "\n",
    "# 1ï¸âƒ£ ëª¨ë“  ë…¸ë“œ ì¶”ê°€\n",
    "fanout_workflow.add_node(\"distributor\", distributor_node)    # ì‹œì‘/ë¶„ë°° ë…¸ë“œ\n",
    "fanout_workflow.add_node(\"history\", history_research_node)   # ë³‘ë ¬ ë…¸ë“œ 1\n",
    "fanout_workflow.add_node(\"culture\", culture_research_node)   # ë³‘ë ¬ ë…¸ë“œ 2  \n",
    "fanout_workflow.add_node(\"tourism\", tourism_research_node)   # ë³‘ë ¬ ë…¸ë“œ 3\n",
    "fanout_workflow.add_node(\"synthesis\", synthesis_node)        # í†µí•© ë…¸ë“œ\n",
    "\n",
    "# 2ï¸âƒ£ ì›Œí¬í”Œë¡œìš° ì—°ê²° (ì‚¬ìš©ì ì˜ˆì‹œ íŒ¨í„´ ì ìš©)\n",
    "fanout_workflow.add_edge(START, \"distributor\")    # START â†’ distributor\n",
    "\n",
    "# 3ï¸âƒ£ Fan-out: distributorì—ì„œ 3ê°œ ë³‘ë ¬ ë…¸ë“œë¡œ ë¶„ê¸°\n",
    "fanout_workflow.add_edge(\"distributor\", \"history\")\n",
    "fanout_workflow.add_edge(\"distributor\", \"culture\") \n",
    "fanout_workflow.add_edge(\"distributor\", \"tourism\")\n",
    "\n",
    "# 4ï¸âƒ£ Fan-in: 3ê°œ ë³‘ë ¬ ë…¸ë“œì—ì„œ synthesisë¡œ í†µí•©\n",
    "fanout_workflow.add_edge(\"history\", \"synthesis\")\n",
    "fanout_workflow.add_edge(\"culture\", \"synthesis\")\n",
    "fanout_workflow.add_edge(\"tourism\", \"synthesis\")\n",
    "\n",
    "# 5ï¸âƒ£ ìµœì¢… ì¢…ë£Œ\n",
    "fanout_workflow.add_edge(\"synthesis\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "fanout_app = fanout_workflow.compile()\n",
    "\n",
    "print(\"ğŸ”„ Fan-out/Fan-in ì›Œí¬í”Œë¡œìš° ì™„ì„±!\")\n",
    "print(\"   ğŸš€ START â†’ distributor: ë‹¨ì¼ ì‹œì‘ì \")\n",
    "print(\"   ğŸ“¤ Fan-out: distributor â†’ {history, culture, tourism}\")\n",
    "print(\"   ğŸ“¥ Fan-in: {history, culture, tourism} â†’ synthesis\") \n",
    "print(\"   ğŸ synthesis â†’ END: ìµœì¢… ì™„ë£Œ\")\n",
    "print(\"   âš¡ LangGraph í‘œì¤€ êµ¬ì¡°ë¡œ ì•ˆì „í•œ ë³‘ë ¬ ì²˜ë¦¬!\")\n",
    "print(\"   ğŸ¯ InvalidUpdateError ì™„ì „ í•´ê²°!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Fan-out/Fan-in ì›Œí¬í”Œë¡œìš° ì‹œê°í™”\n",
    "print(\"ğŸ“Š ë³‘ë ¬ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:\")\n",
    "visualize_graph(fanout_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Fan-out/Fan-in ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ìˆ˜ì •ëœ êµ¬ì¡°)\n",
    "print(\"ğŸ§ª ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ë³µí•©ì ì¸ ì£¼ì œë¡œ í…ŒìŠ¤íŠ¸ (3ê°œ ë¶„ì•¼ ëª¨ë‘ì—ì„œ ì •ë³´ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ì£¼ì œ)\n",
    "test_topic = \"í•œêµ­\"\n",
    "\n",
    "print(f\"ğŸ” í…ŒìŠ¤íŠ¸ ì£¼ì œ: \\\"{test_topic}\\\"\")\n",
    "print(\"ğŸ“¤ Fan-out: ì—­ì‚¬, ë¬¸í™”, ê´€ê´‘ 3ê°œ ë¶„ì•¼ ë³‘ë ¬ ì¡°ì‚¬ ì‹œì‘...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Fan-out/Fan-in ì‹œìŠ¤í…œ ì‹¤í–‰ (ìƒˆë¡œìš´ State êµ¬ì¡°)\n",
    "result = fanout_app.invoke({\n",
    "    \"user_topic\": test_topic,\n",
    "    \"results\": [],\n",
    "    \"final_summary\": \"\"\n",
    "})\n",
    "\n",
    "print(\"ğŸ“¥ ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"\\nğŸ”— ìˆ˜ì§‘ëœ ì „ë¬¸ ë¶„ì•¼ ê²°ê³¼ ({len(result['results'])}ê°œ):\")\n",
    "for i, res in enumerate(result['results'], 1):\n",
    "    print(f\"   {i}. {res}\")\n",
    "\n",
    "print(f\"\\nğŸ”— ìµœì¢… í†µí•© ê²°ê³¼:\")\n",
    "print(f\"   {result['final_summary']}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Fan-out/Fan-in í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ”¥ LangGraph í‘œì¤€ êµ¬ì¡°ë¡œ ì™„ë²½í•œ Fan-out/Fan-in êµ¬í˜„!\")\n",
    "\n",
    "# Fan-out/Fan-in íŒ¨í„´ì˜ í•µì‹¬ ì¥ì  ì„¤ëª…\n",
    "print(f\"\\n{'ğŸ”„' * 20} Fan-out/Fan-in íŒ¨í„´ì˜ í•µì‹¬ ì¥ì  {'ğŸ”„' * 20}\")\n",
    "print(\"âš¡ ì„±ëŠ¥ í–¥ìƒ: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•\")\n",
    "print(\"ğŸ¯ í’ˆì§ˆ í–¥ìƒ: ë‹¤ê°ë„ ì „ë¬¸ ë¶„ì„ìœ¼ë¡œ ì™„ì„±ë„ ë†’ì€ ë‹µë³€\")\n",
    "print(\"ğŸ”§ ì•ˆì „ì„±: Annotated í‚¤ë¡œ ìƒíƒœ ì¶©ëŒ ì™„ì „ ë°©ì§€\")\n",
    "print(\"ğŸ“ˆ í™•ì¥ì„±: ìƒˆë¡œìš´ ì „ë¬¸ ë¶„ì•¼ ì¶”ê°€ ìš©ì´\")\n",
    "print(\"ğŸª ì‹¤ë¬´ ì ìš©: LangGraph í‘œì¤€ì„ ë”°ë¥´ëŠ” ì•ˆì •ì  êµ¬ì¡°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì‹¤ìŠµ 2: Fan-out/Fan-in ì´í•´í•˜ê¸°\n",
    "\n",
    "ë°©ê¸ˆ ë³¸ ë³‘ë ¬ ì²˜ë¦¬ ì˜ˆì‹œì—ì„œ 3ê°œì˜ ë…¸ë“œê°€ ë™ì‹œì— ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ì§ˆë¬¸:** Fan-out/Fan-in íŒ¨í„´ì˜ ì¥ì ìœ¼ë¡œ ì˜³ì§€ ì•Šì€ ê²ƒì€?\n",
    "\n",
    "A) ì—¬ëŸ¬ ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ì—¬ ì „ì²´ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆë‹¤  \n",
    "B) ê° ë…¸ë“œëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë¯€ë¡œ í•œ ë…¸ë“œì˜ ì‹¤íŒ¨ê°€ ë‹¤ë¥¸ ë…¸ë“œì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤  \n",
    "C) LangGraphê°€ ìë™ìœ¼ë¡œ ìƒíƒœë¥¼ ë³‘í•©í•˜ë¯€ë¡œ ê°œë°œìê°€ ë³‘í•© ë¡œì§ì„ ì‘ì„±í•  í•„ìš”ê°€ ì—†ë‹¤  \n",
    "D) ëª¨ë“  ë…¸ë“œê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ë¯€ë¡œ ê°€ì¥ ëŠë¦° ë…¸ë“œì˜ ì²˜ë¦¬ ì‹œê°„ì´ ì „ì²´ ì‹œê°„ì„ ê²°ì •í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ë‹µì„ ì…ë ¥í•˜ì„¸ìš”\n",
    "my_answer = \"\"  # \"A\", \"B\", \"C\", \"D\" ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
    "\n",
    "# ì œì¶œ\n",
    "print(f\"ì„ íƒí•œ ë‹µ: {my_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "**ì •ë‹µ: C**\n",
    "\n",
    "**í•´ì„¤:**\n",
    "\n",
    "A) âœ… ë§ìŠµë‹ˆë‹¤. ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "B) âœ… ë§ìŠµë‹ˆë‹¤. ê° ë…¸ë“œëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "\n",
    "C) âŒ **í‹€ë ¸ìŠµë‹ˆë‹¤.** LangGraphëŠ” ìë™ìœ¼ë¡œ Fan-inì„ ì²˜ë¦¬í•˜ì§€ë§Œ, **ê°œë°œìê°€ Annotatedë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘í•© ê·œì¹™ì„ ëª…ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.**\n",
    "\n",
    "```python\n",
    "# ê°œë°œìê°€ ë³‘í•© ê·œì¹™ì„ ì§€ì •í•´ì•¼ í•¨\n",
    "class State(TypedDict):\n",
    "    results: Annotated[List[str], operator.add]  # â† ë¦¬ìŠ¤íŠ¸ ëˆ„ì \n",
    "    query: str  # â† ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ë¡œ ë®ì–´ì“°ê¸°\n",
    "```\n",
    "\n",
    "D) âœ… ë§ìŠµë‹ˆë‹¤. ëª¨ë“  ë³‘ë ¬ ë…¸ë“œê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.\n",
    "\n",
    "**í•µì‹¬:**\n",
    "- Fan-inì—ì„œ Annotated ì—†ëŠ” í•„ë“œëŠ” ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ë¡œ ë®ì–´ì”€\n",
    "- Annotated[List, operator.add]ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ëˆ„ì \n",
    "- ê°œë°œìê°€ ëª…ì‹œì ìœ¼ë¡œ ë³‘í•© ì „ëµì„ ì§€ì •í•´ì•¼ í•¨\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Part 3: ë©€í‹°í„´ ëŒ€í™” & ìš”ì•½ íŒ¨í„´ - ì§€ëŠ¥ì  ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "\n",
    "### ğŸ¯ ë©€í‹°í„´ ëŒ€í™”ì—ì„œ ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ ì™œ ì¤‘ìš”í•œê°€?\n",
    "ì—¬ëŸ¬ í„´ì— ê±¸ì¹œ ê¸´ ëŒ€í™”ê°€ ê³„ì†ë˜ë©´ **í† í° í•œê³„**ì— ë„ë‹¬í•˜ê³  **ì„±ëŠ¥ì´ ì €í•˜**ë©ë‹ˆë‹¤.  \n",
    "í•˜ì§€ë§Œ ë‹¨ìˆœíˆ ì˜¤ë˜ëœ ëŒ€í™”ë¥¼ ë²„ë¦¬ë©´ **ì¤‘ìš”í•œ ë§¥ë½ì„ ìƒê²Œ** ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ’¡ ì§€ëŠ¥ì  í•´ê²°ì±…: EXAONE ê¸°ë°˜ ìš”ì•½\n",
    "- **ì¤‘ìš”í•œ ì •ë³´ ë³´ì¡´**: ì‚¬ìš©ì ì´ë¦„, ì„ í˜¸ë„, í•µì‹¬ ëŒ€í™” ë‚´ìš©\n",
    "- **ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°**: ì¸ì‚¬ë§, ë°˜ë³µì ì¸ ë‚´ìš©, ì„ì‹œ ì •ë³´  \n",
    "- **ë§¥ë½ ìœ ì§€**: ìš”ì•½ í›„ì—ë„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ ë³´ì¥\n",
    "\n",
    "### ğŸ”„ ì‹¤ë¬´ ì‹œë‚˜ë¦¬ì˜¤: ì±—ë´‡ ë©€í‹°í„´ ëŒ€í™”\n",
    "1. ê³ ê°ê³¼ ì—¬ëŸ¬ í„´ ëŒ€í™” ì§„í–‰ (20í„´ ì´ìƒ)\n",
    "2. ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ ìš”ì•½ íŠ¸ë¦¬ê±°\n",
    "3. EXAONEì´ í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•´ì„œ ê°„ë‹¨íˆ ìš”ì•½\n",
    "4. ìš”ì•½ëœ ë‚´ìš© + ìµœê·¼ 5í„´ìœ¼ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "5. ì„±ëŠ¥ ìœ ì§€í•˜ë©´ì„œ ë§¥ë½ë„ ë³´ì¡´í•˜ëŠ” ì™„ë²½í•œ ê· í˜•!\n",
    "\n",
    "### ğŸ”— ìƒˆë¡œìš´ íŒ¨í„´!\n",
    "01ë²ˆì—ì„œëŠ” ë‹¤ë£¨ì§€ ì•Šì€ ì‹¤ë¬´ ì „ìš© íŒ¨í„´ì…ë‹ˆë‹¤.\n",
    "- **ë©€í‹°í„´ ëŒ€í™” ê´€ë¦¬**: ì—¬ëŸ¬ í„´ì— ê±¸ì¹œ ëŒ€í™” ì¶”ì \n",
    "- **ì¡°ê±´ë¶€ ì‹¤í–‰**: ëŒ€í™” ê¸¸ì´ì— ë”°ë¼ ìš”ì•½ ë…¸ë“œ í™œì„±í™”\n",
    "- **ë©”ëª¨ë¦¬ ìµœì í™”**: LLM ì»¨í…ìŠ¤íŠ¸ ì°½ ê´€ë¦¬\n",
    "- **ë§¥ë½ ë³´ì¡´**: ìš”ì•½ + ìµœê·¼ ëŒ€í™”ë¡œ ê· í˜•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š ëŒ€í™” ìš”ì•½ìš© State ì •ì˜\n",
    "class SummarizationState(TypedDict):\n",
    "    conversation_history: List[str]  # ì „ì²´ ëŒ€í™” ê¸°ë¡\n",
    "    summary: str                     # ìš”ì•½ëœ í•µì‹¬ ë‚´ìš©  \n",
    "    recent_turns: List[str]         # ìµœê·¼ ëª‡ í„´ì˜ ëŒ€í™”\n",
    "    user_input: str                 # í˜„ì¬ ì‚¬ìš©ì ì…ë ¥\n",
    "    response: str                   # AI ì‘ë‹µ\n",
    "    should_summarize: bool          # ìš”ì•½ í•„ìš” ì—¬ë¶€\n",
    "\n",
    "def should_summarize_check(state: SummarizationState) -> str:\n",
    "    \"\"\"ğŸ” ìš”ì•½ì´ í•„ìš”í•œì§€ íŒë‹¨ (3í„´ = 6ê°œ í•­ëª© ê¸°ì¤€)\"\"\"\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    current_count = len(history)\n",
    "    \n",
    "    if current_count >= 6:  # 3í„´ ì´ìƒì´ë©´ ìš”ì•½\n",
    "        return \"summarize\"\n",
    "    else:\n",
    "        return \"normal_chat\"\n",
    "\n",
    "def summarization_node(state: SummarizationState) -> SummarizationState:\n",
    "    \"\"\"ğŸ“š EXAONEì„ ì‚¬ìš©í•´ì„œ ëŒ€í™” ê¸°ë¡ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ìš”ì•½\"\"\"\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    \n",
    "    # ê¸°ì¡´ ìš”ì•½ì´ ìˆë‹¤ë©´ í¬í•¨\n",
    "    existing_summary = state.get(\"summary\", \"\")\n",
    "    summary_prefix = f\"ì´ì „ ìš”ì•½: {existing_summary}\\n\\n\" if existing_summary else \"\"\n",
    "    \n",
    "    # ì „ì²´ ëŒ€í™” ë‚´ìš© ìš”ì•½\n",
    "    conversation_text = \"\\n\".join(history)\n",
    "    \n",
    "    summarization_prompt = f\"\"\"\n",
    "{summary_prefix}ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ëŒ€í™” ë‚´ìš©:\n",
    "{conversation_text}\n",
    "\n",
    "ìš”ì•½ ì‹œ í¬í•¨í•´ì•¼ í•  ì •ë³´:\n",
    "1. ì‚¬ìš©ìì˜ ì´ë¦„, ì„ í˜¸ë„ ë“± ê°œì¸ ì •ë³´\n",
    "2. ì¤‘ìš”í•œ ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ í•µì‹¬ ë‚´ìš©\n",
    "3. ì§„í–‰ ì¤‘ì¸ ì£¼ì œë‚˜ ì‘ì—…\n",
    "4. í–¥í›„ ëŒ€í™”ì— í•„ìš”í•œ ë§¥ë½ ì •ë³´\n",
    "\n",
    "ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ë°˜ë³µì ì¸ ë‚´ìš©ì€ ì œì™¸í•˜ê³ , í•µì‹¬ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    new_summary = pure_exaone_inference(summarization_prompt)\n",
    "    \n",
    "    # ìµœê·¼ 5ê°œ í•­ëª©ë§Œ ìœ ì§€ (ë‚˜ë¨¸ì§€ëŠ” ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´)\n",
    "    recent_turns = history[-5:] if len(history) >= 5 else history\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"summary\": new_summary,\n",
    "        \"recent_turns\": recent_turns,\n",
    "        \"conversation_history\": recent_turns,  # ë©”ëª¨ë¦¬ ìµœì í™”\n",
    "        \"should_summarize\": False\n",
    "    }\n",
    "\n",
    "def normal_chat_node(state: SummarizationState) -> SummarizationState:\n",
    "    \"\"\"ğŸ’¬ ì¼ë°˜ì ì¸ ëŒ€í™” ì²˜ë¦¬ (ìš”ì•½ ì—†ì´)\"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    \n",
    "    # ê¸°ì¡´ ìš”ì•½ + ìµœê·¼ ëŒ€í™” ë§¥ë½ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    context = \"\"\n",
    "    if summary:\n",
    "        context += f\"ì´ì „ ëŒ€í™” ìš”ì•½: {summary}\\n\\n\"\n",
    "        \n",
    "    if history:\n",
    "        recent_context = \"\\n\".join(history[-5:])  # ìµœê·¼ 5ê°œ í•­ëª©\n",
    "        context += f\"ìµœê·¼ ëŒ€í™”:\\n{recent_context}\\n\\n\"\n",
    "        \n",
    "    chat_prompt = f\"{context}ì‚¬ìš©ì: {user_input}\\n\\nìœ„ ë§¥ë½ì„ ê³ ë ¤í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”.\"\n",
    "    \n",
    "    response = pure_exaone_inference(chat_prompt)\n",
    "    \n",
    "    # ëŒ€í™” ê¸°ë¡ì— í˜„ì¬ í„´ ì¶”ê°€\n",
    "    updated_history = history + [f\"ì‚¬ìš©ì: {user_input}\", f\"AI: {response}\"]\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"conversation_history\": updated_history,\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "print(\"ğŸ“š ë©€í‹°í„´ ëŒ€í™” & ìš”ì•½ ì‹œìŠ¤í…œ ë…¸ë“œ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"   ğŸ” should_summarize_check: 6ê°œ í•­ëª© ì´ìƒì´ë©´ ìš”ì•½\")  \n",
    "print(\"   ğŸ“š summarization_node: ì „ì²´ ëŒ€í™” â†’ ìš”ì•½ + ìµœê·¼ 5ê°œë§Œ ìœ ì§€\")\n",
    "print(\"   ğŸ’¬ normal_chat_node: ìš”ì•½ + ìµœê·¼ ëŒ€í™”ë¡œ ë§¥ë½ ìœ ì§€\")\n",
    "print(\"   ğŸ¯ ê°„ë‹¨ëª…ë£Œí•œ ìš”ì•½ ë¡œì§!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“š ëŒ€í™” ìš”ì•½ ì›Œí¬í”Œë¡œìš° êµ¬ì¶•\n",
    "summarization_workflow = StateGraph(SummarizationState)\n",
    "\n",
    "# ë…¸ë“œë“¤ ì¶”ê°€\n",
    "summarization_workflow.add_node(\"normal_chat\", normal_chat_node)\n",
    "summarization_workflow.add_node(\"summarize\", summarization_node)\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì‹œì‘: ìš”ì•½ í•„ìš”ì„± ì²´í¬ í›„ ì ì ˆí•œ ë…¸ë“œë¡œ ë¼ìš°íŒ…\n",
    "summarization_workflow.set_conditional_entry_point(\n",
    "    should_summarize_check,\n",
    "    {\n",
    "        \"normal_chat\": \"normal_chat\",\n",
    "        \"summarize\": \"summarize\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# ìš”ì•½ í›„ì—ëŠ” ì¼ë°˜ ëŒ€í™”ë¡œ ì´ì–´ì§\n",
    "summarization_workflow.add_edge(\"summarize\", \"normal_chat\")\n",
    "summarization_workflow.add_edge(\"normal_chat\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "summarization_app = summarization_workflow.compile()\n",
    "\n",
    "print(\"ğŸ“š ëŒ€í™” ìš”ì•½ ì›Œí¬í”Œë¡œìš° ì™„ì„±!\")\n",
    "print(\"   ğŸ” ìë™ ê¸¸ì´ ì²´í¬: 3í„´ ì´ìƒì´ë©´ ìë™ ìš”ì•½ (ê°•ì˜ìš©)\")\n",
    "print(\"   ğŸ“š ì§€ëŠ¥ì  ìš”ì•½: EXAONEì´ í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ\")\n",
    "print(\"   ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™”: ìš”ì•½ + ìµœê·¼ 5í„´ë§Œ ìœ ì§€\")\n",
    "print(\"   ğŸ¯ ì„±ëŠ¥ê³¼ ë§¥ë½ì˜ ì™„ë²½í•œ ê· í˜•!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª 4í„´ ëŒ€í™” ìš”ì•½ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ§ª EXAONE ê¸°ë°˜ ëŒ€í™” ìš”ì•½ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 4í„´ ëŒ€í™”ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ìš”ì•½ ê¸°ëŠ¥ í™•ì‹¤íˆ í…ŒìŠ¤íŠ¸\n",
    "print(\"ğŸ“ 4í„´ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ìš”ì•½ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"ğŸ’¡ 3í„´ í›„(6ê°œ í•­ëª© í›„)ì— ìš”ì•½ì´ íŠ¸ë¦¬ê±°ë˜ë„ë¡ ì„¤ì •!\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ì´ˆê¸° ìƒíƒœ ì„¤ì •\n",
    "test_state = {\n",
    "    \"conversation_history\": [],\n",
    "    \"summary\": \"\",\n",
    "    \"recent_turns\": [],\n",
    "    \"user_input\": \"\",\n",
    "    \"response\": \"\",\n",
    "    \"should_summarize\": False\n",
    "}\n",
    "\n",
    "# 4í„´ì˜ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ (ìš”ì•½ì´ í™•ì‹¤íˆ ë°œìƒí•˜ë„ë¡)\n",
    "conversation_turns = [\n",
    "    \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ê¹€ë¯¼ìˆ˜ë¼ê³  í•©ë‹ˆë‹¤.\",\n",
    "    \"íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ ë°°ìš°ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ ì‹œì‘í•˜ë©´ ì¢‹ì„ê¹Œìš”?\",\n",
    "    \"ë°ì´í„° ë¶„ì„ ë¶„ì•¼ì— ê´€ì‹¬ì´ ìˆì–´ì„œ íŒë‹¤ìŠ¤ë„ ë°°ìš°ê³  ì‹¶ìŠµë‹ˆë‹¤.\",\n",
    "    \"ë¨¸ì‹ ëŸ¬ë‹ë„ í•¨ê»˜ ë°°ìš¸ ìˆ˜ ìˆì„ê¹Œìš”?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ”„ í„´ë³„ ëŒ€í™” ì§„í–‰ ë° ìƒíƒœ ë³€í™” ê´€ì°°:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for turn_num, user_input in enumerate(conversation_turns, 1):\n",
    "    print(f\"\\n{'='*20} {turn_num}í„´ ì‹œì‘ {'='*20}\")\n",
    "    print(f\"ğŸ“¢ ì‚¬ìš©ì ì…ë ¥: \\\"{user_input}\\\"\")\n",
    "    \n",
    "    before_history = test_state.get(\"conversation_history\", [])\n",
    "    \n",
    "    # í˜„ì¬ í„´ì˜ ì‚¬ìš©ì ì…ë ¥ ì„¤ì •\n",
    "    test_state[\"user_input\"] = user_input\n",
    "    \n",
    "    # ğŸ”¥ ëŒ€í™” ì‹œìŠ¤í…œ ì‹¤í–‰ (ë””ë²„ê·¸ ì¶œë ¥ í¬í•¨)\n",
    "    result = summarization_app.invoke(test_state)\n",
    "    \n",
    "    # ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "    test_state = result\n",
    "    \n",
    "    after_history = result.get(\"conversation_history\", [])\n",
    "    print(f\"ğŸ¤– AI ì‘ë‹µ: \\\"{result.get('response', 'N/A')[:80]}...\\\"\")\n",
    "    \n",
    "    # ìš”ì•½ ì—¬ë¶€ ìƒì„¸ í™•ì¸\n",
    "    summary_content = result.get(\"summary\", \"\")\n",
    "    if summary_content:\n",
    "        print(f\"ğŸ“š âœ… ìš”ì•½ ìƒì„± ì„±ê³µ!\")\n",
    "        print(f\"   ğŸ“ ìš”ì•½ ë‚´ìš©: \\\"{summary_content[:100]}...\\\"\")\n",
    "        print(f\"   ğŸ’¾ ìµœê·¼ ëŒ€í™” ìœ ì§€: {len(result.get('recent_turns', []))}ê°œ í•­ëª©\")\n",
    "        print(f\"   ğŸ”¥ ë©”ëª¨ë¦¬ ìµœì í™”: {len(before_history)} â†’ {len(after_history)}ê°œë¡œ ì••ì¶•!\")\n",
    "        print(\"   âœ… ìš”ì•½ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™!\")\n",
    "    else:\n",
    "        print(\"   â³ ìš”ì•½ ì—†ìŒ - ì•„ì§ ì¡°ê±´ ë¯¸ë‹¬\")\n",
    "    \n",
    "    # ë‹¤ìŒ í„´ ì˜ˆìƒ\n",
    "    expected_next = \"ìš”ì•½ í›„ ëŒ€í™”\" if len(after_history) >= 6 else \"ì¼ë°˜ ëŒ€í™”\"\n",
    "    print(f\"   ğŸ”® ë‹¤ìŒ í„´ ì˜ˆìƒ: {expected_next}\")\n",
    "    \n",
    "\n",
    "print(f\"\\n{'ğŸ¯' * 25} ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„ {'ğŸ¯' * 25}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ê²€ì¦\n",
    "final_history = test_state.get(\"conversation_history\", [])\n",
    "final_summary = test_state.get(\"summary\", \"\")\n",
    "\n",
    "if final_summary:\n",
    "    print(\"ğŸ‰ ìš”ì•½ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!\")\n",
    "    print(f\"   ğŸ“Š ìµœì¢… ëŒ€í™” ê¸°ë¡: {len(final_history)}ê°œ\")\n",
    "    print(f\"   ğŸ“ ìš”ì•½ ê¸¸ì´: {len(final_summary)}ê¸€ì\")\n",
    "    print(f\"   ğŸ’¾ ë©”ëª¨ë¦¬ ì ˆì•½ë¥ : {((8-len(final_history))/8*100):.1f}% ì ˆì•½\")\n",
    "    print(f\"   ğŸ¯ ë§¥ë½ ë³´ì¡´: ìš”ì•½ìœ¼ë¡œ í•µì‹¬ ì •ë³´ ìœ ì§€\")\n",
    "else:\n",
    "    print(\"âŒ ìš”ì•½ ì‹œìŠ¤í…œ ë¬¸ì œ ë°œê²¬!\")\n",
    "    print(\"   ğŸ”§ ì¶”ê°€ ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\n{'ğŸš€' * 25} ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ {'ğŸš€' * 25}\")\n",
    "print(\"ğŸ“ˆ í™•ì¥ì„±: ê¸´ ê³ ê° ìƒë‹´ì—ì„œ í† í° í•œê³„ ë°©ì§€\")\n",
    "print(\"ğŸ§  ì§€ëŠ¥ì„±: EXAONEì´ í•µì‹¬ ë‚´ìš©ë§Œ ì„ ë³„í•˜ì—¬ ìš”ì•½\")\n",
    "print(\"âš–ï¸  ê· í˜•ì„±: ì„±ëŠ¥ ìµœì í™”ì™€ ë§¥ë½ ë³´ì¡´ì„ ë™ì‹œì— ë‹¬ì„±\")\n",
    "print(\"ğŸ”§ ì‹¤ìš©ì„±: should_summarize_checkì—ì„œ í„´ ìˆ˜ ì‰½ê²Œ ì¡°ì •\")\n",
    "print(\"ğŸ’¡ ê°•ì˜ íš¨ê³¼: í•™ìƒë“¤ì´ ìš”ì•½ ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ ê´€ì°° ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š ëŒ€í™” ìš”ì•½ ì›Œí¬í”Œë¡œìš° ì‹œê°í™”\n",
    "print(\"ğŸ“Š ëŒ€í™” ìš”ì•½ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:\")\n",
    "visualize_graph(summarization_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘¥ Part 4: Human in the Loop íŒ¨í„´ - ì¸ê°„ì˜ ì§€í˜œê°€ í•„ìš”í•œ ìˆœê°„\n",
    "\n",
    "### ğŸ’¡ 01ë²ˆì—ì„œ ë°°ìš´ ê²ƒì„ ì‹¤ë¬´ì— ì ìš©!\n",
    "01ë²ˆì—ì„œ **interrupt()**ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ì‹œì •ì§€í•˜ê³  **Command(resume)**ìœ¼ë¡œ ì¬ê°œí•˜ëŠ” ë°©ë²•ì„ ë°°ì› ì–´ìš”.  \n",
    "ì´ì œ **ì‹¤ì œ ì´ë©”ì¼ ìë™ ì‘ë‹µ ì‹œìŠ¤í…œ**ì— ì ìš©í•´ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤!\n",
    "\n",
    "### ğŸ¯ Human in the Loopê°€ í•„ìš”í•œ ì´ìœ \n",
    "AIê°€ ì•„ë¬´ë¦¬ ë˜‘ë˜‘í•´ë„ **ì¤‘ìš”í•œ ê³ ê° ì‘ëŒ€**ë‚˜ **ë¯¼ê°í•œ ì´ë©”ì¼**ì—ëŠ” ì¸ê°„ì˜ ê²€í† ê°€ í•„ìˆ˜!\n",
    "\n",
    "### ğŸ“§ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤: ì´ë©”ì¼ ìë™ ì‘ë‹µ ì‹œìŠ¤í…œ\n",
    "í˜„ëŒ€ ê¸°ì—…ì˜ ê³ ê° ì„œë¹„ìŠ¤íŒ€ì´ ë§¤ì¼ ìˆ˜ë°± í†µì˜ ê³ ê° ì´ë©”ì¼ì„ ì²˜ë¦¬í•˜ëŠ” ìƒí™©ì„ ìƒê°í•´ë³´ì„¸ìš”:\n",
    "\n",
    "**ğŸ”„ Human in the Loop ì›Œí¬í”Œë¡œìš°:**\n",
    "1. **ê³ ê° ì´ë©”ì¼ ì ‘ìˆ˜**: ë°°ì†¡ ì§€ì—°, í™˜ë¶ˆ ìš”ì²­, ê¸°ìˆ  ë¬¸ì˜ ë“±\n",
    "2. **AI ì´ˆì•ˆ ìƒì„±**: EXAONEì´ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì‘ë‹µ ì´ˆì•ˆ ìë™ ì‘ì„±\n",
    "3. **ì¸ê°„ ê²€í†  ë‹¨ê³„**: ê³ ê°ì„œë¹„ìŠ¤íŒ€ì´ AI ì´ˆì•ˆì„ ê²€í† í•˜ê³  í”¼ë“œë°± ì œê³µ\n",
    "4. **ìµœì¢… ì‘ë‹µ í™•ì •**: í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ì™„ì„±ëœ ì‘ë‹µì„ ê³ ê°ì—ê²Œ ë°œì†¡\n",
    "\n",
    "### ğŸ’¡ í•µì‹¬ ê°€ì¹˜\n",
    "- **íš¨ìœ¨ì„±**: AIê°€ 80% ì‘ì—…ì„ ìë™í™”í•˜ì—¬ ì²˜ë¦¬ ì‹œê°„ ëŒ€í­ ë‹¨ì¶•\n",
    "- **í’ˆì§ˆ ë³´ì¥**: ì¸ê°„ ì „ë¬¸ê°€ì˜ ê²€í† ë¡œ ê³ ê° ë§Œì¡±ë„ í–¥ìƒ\n",
    "- **ìœ„í—˜ ê´€ë¦¬**: ë¯¼ê°í•œ ë‚´ìš©ì´ë‚˜ ë³µì¡í•œ ìƒí™©ì—ì„œ ì‹¤ìˆ˜ ë°©ì§€\n",
    "- **ì¼ê´€ì„±**: íšŒì‚¬ ì •ì±…ê³¼ í†¤ì•¤ë§¤ë„ˆë¥¼ ì¼ê´€ë˜ê²Œ ìœ ì§€\n",
    "\n",
    "### ğŸš€ ì‹¤ë¬´ ì ìš© íš¨ê³¼\n",
    "- **ì²˜ë¦¬ëŸ‰ 300% ì¦ê°€**: í•˜ë£¨ 100í†µ â†’ 300í†µ ì²˜ë¦¬ ê°€ëŠ¥\n",
    "- **ì‘ë‹µ í’ˆì§ˆ í–¥ìƒ**: ì¸ê°„ ê²€í† ë¡œ ê³ ê° ë§Œì¡±ë„ 95% ë‹¬ì„±\n",
    "- **ë¹„ìš© ì ˆê°**: ì¸ë ¥ íˆ¬ì…ì€ ì¤„ì´ê³  ì„œë¹„ìŠ¤ í’ˆì§ˆì€ í–¥ìƒ\n",
    "\n",
    "### ğŸ”— 01ë²ˆ ë©”ì»¤ë‹ˆì¦˜ vs 02ë²ˆ ì‹¤ë¬´ ì ìš©\n",
    "```\n",
    "01ë²ˆ: interrupt() â†’ Command(resume) ê¸°ë³¸ ë™ì‘\n",
    "      â†“ \"ë„êµ¬ ì‚¬ìš©ë²•\"\n",
    "02ë²ˆ: ì´ë©”ì¼ ì´ˆì•ˆ â†’ ê²€í† ì í”¼ë“œë°± â†’ ìµœì¢… ë°œì†¡\n",
    "      â†“ \"ì‹¤ë¬´ ì´ë©”ì¼ ì‹œìŠ¤í…œ\"\n",
    "```\n",
    "\n",
    "ì•„ë˜ì—ì„œ ì‹¤ì œ ì‘ë™í•˜ëŠ” Human in the Loop ì‹œìŠ¤í…œì„ ì²´í—˜í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph, add_messages\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# ğŸ“§ ì´ë©”ì¼ ìë™ ì‘ë‹µ ì‹œìŠ¤í…œìš© State\n",
    "class EmailState(TypedDict):\n",
    "    customer_email: str      # ê³ ê° ì´ë©”ì¼ ë‚´ìš©\n",
    "    ai_draft: str           # AIê°€ ìƒì„±í•œ ì‘ë‹µ ì´ˆì•ˆ\n",
    "    human_feedback: str     # ì¸ê°„ ê²€í† ì í”¼ë“œë°±\n",
    "    final_response: str     # ìµœì¢… ì´ë©”ì¼ ì‘ë‹µ\n",
    "\n",
    "def ai_draft_node(state: EmailState):\n",
    "    \"\"\"ğŸ¤– AIê°€ ê³ ê° ì´ë©”ì¼ì— ëŒ€í•œ ì‘ë‹µ ì´ˆì•ˆ ìƒì„±\"\"\"\n",
    "    customer_email = state[\"customer_email\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "ë‹¤ìŒ ê³ ê° ì´ë©”ì¼ì— ëŒ€í•œ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ê³ ê° ì´ë©”ì¼: {customer_email}\n",
    "\n",
    "íšŒì‚¬ ì •ì±…ì— ë§ëŠ” ì •ì¤‘í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "    \n",
    "    ai_draft = pure_exaone_inference(prompt)\n",
    "    print(f\"ğŸ¤– AI ì‘ë‹µ ì´ˆì•ˆ ìƒì„± ì™„ë£Œ\")\n",
    "    return {\"ai_draft\": ai_draft}\n",
    "\n",
    "def human_review_node(state: EmailState):\n",
    "    \"\"\"ğŸ‘¤ ì¸ê°„ ê²€í† ìê°€ AI ì´ˆì•ˆì„ ê²€í† \"\"\"\n",
    "    ai_draft = state[\"ai_draft\"]\n",
    "    \n",
    "    print(f\"ğŸ“§ AI ì‘ë‹µ ì´ˆì•ˆ: {ai_draft}\")\n",
    "    \n",
    "    # ğŸ›‘ ì—¬ê¸°ì„œ ì¸ê°„ ê²€í† ìì˜ ìŠ¹ì¸/í”¼ë“œë°± ëŒ€ê¸°\n",
    "    feedback = interrupt({\n",
    "        \"message\": \"AIê°€ ì´ë©”ì¼ ì‘ë‹µ ì´ˆì•ˆì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ê²€í†  í›„ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”:\",\n",
    "        \"draft\": ai_draft\n",
    "    })\n",
    "    \n",
    "    return {\"human_feedback\": feedback}\n",
    "\n",
    "def finalize_node(state: EmailState):\n",
    "    \"\"\"âœ… ìµœì¢… ì´ë©”ì¼ ì‘ë‹µ í™•ì •\"\"\"\n",
    "    ai_draft = state[\"ai_draft\"]\n",
    "    feedback = state[\"human_feedback\"]\n",
    "    \n",
    "    if \"ìŠ¹ì¸\" in feedback:\n",
    "        final_response = ai_draft\n",
    "    else:\n",
    "        # í”¼ë“œë°± ë°˜ì˜í•´ì„œ ìˆ˜ì •\n",
    "        prompt = f\"\"\"\n",
    "ë‹¤ìŒ AI ì´ˆì•ˆì„ ê²€í† ì í”¼ë“œë°±ì— ë”°ë¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì›ë³¸ ì´ˆì•ˆ: {ai_draft}\n",
    "ê²€í† ì í”¼ë“œë°±: {feedback}\n",
    "\n",
    "í”¼ë“œë°±ì„ ë°˜ì˜í•œ ê°œì„ ëœ ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "        final_response = pure_exaone_inference(prompt)\n",
    "    \n",
    "    print(f\"âœ… ìµœì¢… ì´ë©”ì¼ ì‘ë‹µ í™•ì •!\")\n",
    "    return {\"final_response\": final_response}\n",
    "\n",
    "print(\"ğŸ“§ ì´ë©”ì¼ ìë™ ì‘ë‹µ Human in the Loop ì‹œìŠ¤í…œ êµ¬ì„± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“§ ì´ë©”ì¼ ìë™ ì‘ë‹µ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
    "workflow = StateGraph(EmailState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"ai_draft\", ai_draft_node)\n",
    "workflow.add_node(\"human_review\", human_review_node)\n",
    "workflow.add_node(\"finalize\", finalize_node)\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì—°ê²°\n",
    "workflow.add_edge(START, \"ai_draft\")\n",
    "workflow.add_edge(\"ai_draft\", \"human_review\")\n",
    "workflow.add_edge(\"human_review\", \"finalize\")\n",
    "workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "# ì²´í¬í¬ì¸í„° ì„¤ì • (Human in the Loopì— í•„ìˆ˜)\n",
    "checkpointer = MemorySaver()\n",
    "email_app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"âœ… ì´ë©”ì¼ ìë™ ì‘ë‹µ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“§ 1ë‹¨ê³„: ê³ ê° ì´ë©”ì¼ ì²˜ë¦¬ (interrupt ì§€ì ê¹Œì§€)\n",
    "import uuid\n",
    "\n",
    "# ê³ ê° ì´ë©”ì¼ ì˜ˆì‹œ\n",
    "customer_email = \"\"\"\n",
    "ì•ˆë…•í•˜ì„¸ìš”,\n",
    "\n",
    "ì§€ë‚œì£¼ì— ì£¼ë¬¸í•œ ë…¸íŠ¸ë¶ì´ ì•„ì§ ë„ì°©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. \n",
    "ì£¼ë¬¸ë²ˆí˜¸ëŠ” ORD-2024-1234ì´ê³ , ë°°ì†¡ ì˜ˆì •ì¼ì´ 3ì¼ ì „ì´ì—ˆëŠ”ë°\n",
    "ì•„ì§ ë°°ì†¡ ì¶”ì ì—ì„œ í™•ì¸ì´ ì•ˆ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì–¸ì œì¯¤ ë°›ì„ ìˆ˜ ìˆì„ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê¹€ê³ ê° ë“œë¦¼\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“§ ê³ ê° ì´ë©”ì¼:\")\n",
    "print(customer_email)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "result = email_app.invoke(\n",
    "    {\"customer_email\": customer_email}, \n",
    "    config=config\n",
    ")\n",
    "\n",
    "# interrupt í™•ì¸\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"âœ… Human in the Loop í™œì„±í™”!\")\n",
    "    print(\"ğŸ‘¤ ê²€í† ìì˜ í”¼ë“œë°±ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "    print(\"\\nğŸ“‹ AI ì´ˆì•ˆ:\")\n",
    "    print(result[\"ai_draft\"])\n",
    "    print(f\"\\nğŸ” Thread ID: {thread_id}\")\n",
    "    print(\"ğŸ“Œ ë‹¤ìŒ ì…€ì—ì„œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"âŒ interruptê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ê²°ê³¼:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“§ 2ë‹¨ê³„: ê²€í† ì í”¼ë“œë°± í›„ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
    "\n",
    "# ê²€í† ì í”¼ë“œë°± (ì‹¤ì œë¡œëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ë°›ìŒ)\n",
    "reviewer_feedback = \"\"\"\n",
    "AI ì´ˆì•ˆì´ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”:\n",
    "1. ì‚¬ê³¼ ì¸ì‚¬ë¥¼ ë” ëª…í™•íˆ\n",
    "2. êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆ ì œì‹œ\n",
    "3. ê³ ê° ë§Œì¡±ì„ ìœ„í•œ ì¶”ê°€ í˜œíƒ ì–¸ê¸‰\n",
    "\n",
    "ìŠ¹ì¸ì€ ìˆ˜ì • í›„ì— í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ‘¤ ê²€í† ì í”¼ë“œë°±:\")\n",
    "print(reviewer_feedback)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Command(resume)ìœ¼ë¡œ ì›Œí¬í”Œë¡œìš° ì¬ì‹œì‘\n",
    "final_result = email_app.invoke(\n",
    "    Command(resume=reviewer_feedback),\n",
    "    config  # ì´ì „ê³¼ ë™ì¼í•œ config ì‚¬ìš©\n",
    ")\n",
    "\n",
    "print(\"âœ… ìµœì¢… ì´ë©”ì¼ ì‘ë‹µ ì™„ì„±!\")\n",
    "print(\"\\nğŸ“§ ìµœì¢… ê³ ê° ì‘ë‹µ:\")\n",
    "print(\"=\"*60)\n",
    "print(final_result[\"final_response\"])\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nğŸ‰ Human in the Loop í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¼ ì‹¤ë¬´ì—ì„œëŠ” ì´ ì‘ë‹µì´ ê³ ê°ì—ê²Œ ìë™ ë°œì†¡ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“§ Human in the Loop ì›Œí¬í”Œë¡œìš° ì •ë¦¬\n",
    "\n",
    "print(\"ğŸ“‹ ì´ë©”ì¼ ìë™ ì‘ë‹µ Human in the Loop ì‹œìŠ¤í…œ:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "ğŸ¯ ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤:\n",
    "   ê³ ê° â†’ ë°°ì†¡ ì§€ì—° ë¬¸ì˜ ì´ë©”ì¼ ë°œì†¡\n",
    "   \n",
    "ğŸ“ 1ë‹¨ê³„ (AI ì´ˆì•ˆ ìƒì„±):\n",
    "   ğŸ¤– EXAONEì´ ê³ ê° ì´ë©”ì¼ ë¶„ì„\n",
    "   ğŸ“ ì „ë¬¸ì ì¸ ì‘ë‹µ ì´ˆì•ˆ ìë™ ìƒì„±\n",
    "   \n",
    "ğŸ“ 2ë‹¨ê³„ (Human ê²€í† ):\n",
    "   ğŸ›‘ interrupt() ë°œìƒ â†’ ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨\n",
    "   ğŸ‘¤ ê³ ê°ì„œë¹„ìŠ¤íŒ€ ê²€í† ìê°€ ì´ˆì•ˆ í™•ì¸\n",
    "   ğŸ’¬ í”¼ë“œë°±: \"ì‚¬ê³¼ ì¸ì‚¬ ì¶”ê°€, êµ¬ì²´ì  í•´ê²°ì±… ì œì‹œ\"\n",
    "   \n",
    "ğŸ“ 3ë‹¨ê³„ (ìµœì¢… ì‘ë‹µ):\n",
    "   ğŸ”„ AIê°€ í”¼ë“œë°± ë°˜ì˜í•˜ì—¬ ì‘ë‹µ ìˆ˜ì •\n",
    "   âœ… ìµœì¢… ìŠ¹ì¸ëœ ì´ë©”ì¼ ê³ ê°ì—ê²Œ ë°œì†¡\n",
    "\n",
    "ğŸ’¡ í•µì‹¬ ê°€ì¹˜:\n",
    "   - ìë™í™”ë¡œ íš¨ìœ¨ì„± ì¦ëŒ€\n",
    "   - ì¸ê°„ ê²€í† ë¡œ í’ˆì§ˆ ë³´ì¥\n",
    "   - ê³ ê° ë§Œì¡±ë„ í–¥ìƒ\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nğŸ”§ ì›Œí¬í”Œë¡œìš° êµ¬ì¡°:\")\n",
    "visualize_graph(email_app)\n",
    "\n",
    "print(\"\\nğŸ“ í•™ìŠµ í¬ì¸íŠ¸:\")\n",
    "print(\"- interrupt()ë¡œ ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨\")\n",
    "print(\"- Command(resume)ë¡œ ì¬ì‹œì‘\")\n",
    "print(\"- ì²´í¬í¬ì¸í„°ë¡œ ìƒíƒœ ì €ì¥\")\n",
    "print(\"- ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ íŒ¨í„´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì‹¤ìŠµ 3: Human-in-the-Loop êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "ë°©ê¸ˆ ë³¸ ì´ë©”ì¼ ê²€í†  ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬, ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”.\n",
    "\n",
    "**ì‹œë‚˜ë¦¬ì˜¤:**\n",
    "- ì‚¬ìš©ìê°€ ë¬¸ì„œë¥¼ ì œì¶œí•˜ë©´ AIê°€ ìë™ ê²€í† \n",
    "- ìœ„í—˜ë„ê°€ ë†’ìœ¼ë©´(risk_level > 7) ì‚¬ëŒì˜ ìŠ¹ì¸ í•„ìš”\n",
    "- interrupt()ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì¼ì‹œ ì¤‘ì§€í•˜ê³  ì‚¬ëŒì˜ í”¼ë“œë°± ëŒ€ê¸°\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "- ApprovalStateì— risk_level, document, human_decision í•„ë“œ ì‚¬ìš©\n",
    "- check_risk_node: ìœ„í—˜ë„ê°€ 7 ì´ˆê³¼ë©´ needs_approval=True\n",
    "- approval_node: needs_approvalì´ë©´ interruptë¡œ ì¤‘ë‹¨í•˜ê³  í”¼ë“œë°± ëŒ€ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "class ApprovalState(TypedDict):\n",
    "    document: str\n",
    "    risk_level: int\n",
    "    needs_approval: bool\n",
    "    human_decision: str\n",
    "\n",
    "def check_risk_node(state: ApprovalState):\n",
    "    '''ë¬¸ì„œì˜ ìœ„í—˜ë„ë¥¼ í™•ì¸'''\n",
    "    risk = state['risk_level']\n",
    "    needs_approval = risk > 7\n",
    "    return {\"needs_approval\": needs_approval}\n",
    "\n",
    "def approval_node(state: ApprovalState):\n",
    "    '''ì‚¬ëŒì˜ ìŠ¹ì¸ì´ í•„ìš”í•˜ë©´ interruptë¡œ ì¤‘ë‹¨'''\n",
    "    # ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "    # needs_approvalì´ Trueë©´ interrupt() í˜¸ì¶œí•˜ì—¬ í”¼ë“œë°± ëŒ€ê¸°\n",
    "    # interrupt ë©”ì‹œì§€ì— ë¬¸ì„œ ì •ë³´ì™€ ìœ„í—˜ë„ í¬í•¨\n",
    "    pass  # ì´ ì¤„ì„ ì§€ìš°ê³  ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "# âš ï¸ ì°¸ê³ : interrupt()ëŠ” ê·¸ë˜í”„ ì•ˆì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤!\n",
    "# ì§ì ‘ í˜¸ì¶œí•˜ë©´ ì—ëŸ¬ê°€ ë‚˜ìš”. ì •ë‹µ ë³´ê¸°ì—ì„œ ì „ì²´ ê·¸ë˜í”„ ì˜ˆì‹œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "print(\"âœ… approval_node í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"ğŸ’¡ interrupt()ëŠ” ê·¸ë˜í”„ë¡œ ì»´íŒŒì¼í•œ í›„ì—ë§Œ ì‘ë™í•©ë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "```python\n",
    "def approval_node(state: ApprovalState):\n",
    "    '''ì‚¬ëŒì˜ ìŠ¹ì¸ì´ í•„ìš”í•˜ë©´ interruptë¡œ ì¤‘ë‹¨'''\n",
    "    if state['needs_approval']:\n",
    "        # ì›Œí¬í”Œë¡œìš°ë¥¼ ì¤‘ë‹¨í•˜ê³  ì‚¬ëŒì˜ í”¼ë“œë°± ëŒ€ê¸°\n",
    "        feedback = interrupt({\n",
    "            \"message\": \"ìœ„í—˜ë„ê°€ ë†’ì€ ë¬¸ì„œì…ë‹ˆë‹¤. ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\",\n",
    "            \"document\": state[\"document\"],\n",
    "            \"risk_level\": state[\"risk_level\"]\n",
    "        })\n",
    "        return {\"human_decision\": feedback}\n",
    "    else:\n",
    "        return {\"human_decision\": \"ìë™ ìŠ¹ì¸\"}\n",
    "```\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”: interrupt()ëŠ” ê·¸ë˜í”„ ì•ˆì—ì„œë§Œ ì‘ë™!**\n",
    "\n",
    "ìœ„ í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ë©´ `RuntimeError: Called get_config outside of a runnable context` ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²• (ì „ì²´ ê·¸ë˜í”„):**\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# 1. ê·¸ë˜í”„ êµ¬ì„±\n",
    "workflow = StateGraph(ApprovalState)\n",
    "workflow.add_node(\"check_risk\", check_risk_node)\n",
    "workflow.add_node(\"approval\", approval_node)\n",
    "\n",
    "workflow.set_entry_point(\"check_risk\")\n",
    "workflow.add_edge(\"check_risk\", \"approval\")\n",
    "workflow.add_edge(\"approval\", END)\n",
    "\n",
    "# 2. MemorySaverë¡œ ì»´íŒŒì¼ (interrupt ì‚¬ìš© ì‹œ í•„ìˆ˜!)\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 3. ì‹¤í–‰\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-1\"}}\n",
    "result = app.invoke({\n",
    "    \"document\": \"ê¸°ë°€ ë¬¸ì„œ A\",\n",
    "    \"risk_level\": 9,\n",
    "    \"needs_approval\": False,  # ì´ê±´ check_risk_nodeê°€ ì„¤ì •í•¨\n",
    "    \"human_decision\": \"\"\n",
    "}, config=config)\n",
    "\n",
    "print(result)\n",
    "# interrupt()ê°€ í˜¸ì¶œë˜ë©´ ì›Œí¬í”Œë¡œìš°ê°€ ì¤‘ë‹¨ë¨!\n",
    "\n",
    "# 4. ì¬ê°œ (ì‚¬ëŒì´ ê²€í†  í›„)\n",
    "from langgraph.types import Command\n",
    "final = app.invoke(Command(resume=\"ìŠ¹ì¸í•¨\"), config=config)\n",
    "print(final)\n",
    "```\n",
    "\n",
    "**í•µì‹¬ ê°œë…:**\n",
    "\n",
    "1. **interrupt()ëŠ” ê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸ í•„ìˆ˜**: \n",
    "   - ë…¸ë“œë¥¼ ì§ì ‘ í˜¸ì¶œ âŒ â†’ `approval_node(state)` ì—ëŸ¬!\n",
    "   - ê·¸ë˜í”„ë¡œ ì‹¤í–‰ âœ… â†’ `app.invoke(...)` ì •ìƒ ì‘ë™\n",
    "\n",
    "2. **MemorySaver í•„ìˆ˜**:\n",
    "   - interrupt()ë¡œ ì¤‘ë‹¨ëœ ìƒíƒœë¥¼ ì €ì¥í•˜ë ¤ë©´ checkpointer í•„ìš”\n",
    "   - `compile(checkpointer=MemorySaver())`\n",
    "\n",
    "3. **ì¬ê°œ ë°©ë²•**:\n",
    "   - `app.invoke(Command(resume=\"ì‚¬ëŒì˜ ì‘ë‹µ\"), config=config)`\n",
    "   - ê°™ì€ thread_id ì‚¬ìš©í•´ì•¼ ì´ì–´ì„œ ì‹¤í–‰ë¨\n",
    "\n",
    "4. **ì‚¬ìš© ì‚¬ë¡€**:\n",
    "   - ì¤‘ìš”í•œ ê²°ì •ì— ì‚¬ëŒì˜ ê°œì… í•„ìš”\n",
    "   - ì™¸ë¶€ ì‹œìŠ¤í…œ ëŒ€ê¸° (ê²°ì œ ìŠ¹ì¸, API ì‘ë‹µ ë“±)\n",
    "   - ë‹¨ê³„ë³„ ê²€í†  ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ LangGraph ê¸°ë³¸ íŒ¨í„´ í•™ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### âœ… ì„±ê³µì ìœ¼ë¡œ ë§ˆìŠ¤í„°í•œ 4ê°€ì§€ í•µì‹¬ íŒ¨í„´:\n",
    "\n",
    "#### 1ï¸âƒ£ **Routing íŒ¨í„´** ğŸ§ \n",
    "- **ëª©ì **: ì‚¬ìš©ì ì…ë ¥ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ê²½ë¡œë¡œ ë¼ìš°íŒ…\n",
    "- **ì‹¤ë¬´ í™œìš©**: ê³ ê° ë¬¸ì˜ ìœ í˜•ë³„ ìë™ ë¶„ë¥˜, ìš°ì„ ìˆœìœ„ ì„¤ì •\n",
    "- **í•µì‹¬ ê¸°ìˆ **: ì¡°ê±´ë¶€ ì—£ì§€, LLM ê¸°ë°˜ ë¶„ë¥˜\n",
    "\n",
    "#### 2ï¸âƒ£ **Fan-out/Fan-in íŒ¨í„´** ğŸ”„  \n",
    "- **ëª©ì **: ë³µì¡í•œ ì‘ì—…ì„ ì—¬ëŸ¬ ì „ë¬¸ ì˜ì—­ìœ¼ë¡œ ë³‘ë ¬ ë¶„ì‚° í›„ ê²°ê³¼ í†µí•©\n",
    "- **ì‹¤ë¬´ í™œìš©**: ë‹¤ê°ë„ ë¶„ì„, ì „ë¬¸íŒ€ í˜‘ì—…, ì„±ëŠ¥ ìµœì í™”\n",
    "- **í•µì‹¬ ê¸°ìˆ **: ë³‘ë ¬ ë…¸ë“œ ì‹¤í–‰, ê²°ê³¼ ì§‘ê³„\n",
    "\n",
    "#### 3ï¸âƒ£ **Summarization íŒ¨í„´** ğŸ“š\n",
    "- **ëª©ì **: ê¸´ ëŒ€í™”ë‚˜ ë¬¸ì„œë¥¼ í•µì‹¬ ì •ë³´ë§Œ ì••ì¶•í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ\n",
    "- **ì‹¤ë¬´ í™œìš©**: ì±„íŒ…ë´‡ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬, íšŒì˜ë¡ ìš”ì•½, ë¬¸ì„œ ì••ì¶•\n",
    "- **í•µì‹¬ ê¸°ìˆ **: ì¡°ê±´ë¶€ ìš”ì•½, ìƒíƒœ ê´€ë¦¬\n",
    "\n",
    "#### 4ï¸âƒ£ **Human in the Loop íŒ¨í„´** ğŸ‘¥\n",
    "- **ëª©ì **: ì¤‘ìš”í•œ ê²°ì •ì´ë‚˜ ë¯¼ê°í•œ ì‘ì—…ì— ì¸ê°„ì˜ ê²€í† ì™€ ìŠ¹ì¸ ê³¼ì • ì¶”ê°€\n",
    "- **ì‹¤ë¬´ í™œìš©**: ì´ë©”ì¼ ìë™ ì‘ë‹µ, ê³ ê° ì„œë¹„ìŠ¤, ì½˜í…ì¸  ê²€í† \n",
    "- **í•µì‹¬ ê¸°ìˆ **: interrupt() í•¨ìˆ˜, ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨/ì¬ì‹œì‘\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„: ê³ ê¸‰ í†µí•© íŒ¨í„´\n",
    "ê¸°ë³¸ íŒ¨í„´ì„ ì™„ì „íˆ ì´í•´í–ˆë‹¤ë©´, `01-advanced-integration.ipynb`ì—ì„œ ëª¨ë“  íŒ¨í„´ì„ ì¡°í•©í•œ ì‹¤ë¬´ê¸‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì„¸ìš”!\n",
    "\n",
    "### ğŸ’¡ ì‹¤ë¬´ ì ìš© ê°€ì´ë“œ\n",
    "ê° íŒ¨í„´ì€ ë…ë¦½ì ìœ¼ë¡œë„ ê°•ë ¥í•˜ì§€ë§Œ, ì¡°í•©í•  ë•Œ ì§„ì •í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë°œíœ˜í•©ë‹ˆë‹¤:\n",
    "- **ë‹¨ì¼ íŒ¨í„´**: íŠ¹ì • ë¬¸ì œ í•´ê²°\n",
    "- **íŒ¨í„´ ì¡°í•©**: ì™„ì „í•œ ì—”í„°í”„ë¼ì´ì¦ˆ ì†”ë£¨ì…˜\n",
    "\n",
    "ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤! ì´ì œ LangGraphë¡œ ì‹¤ë¬´ê¸‰ AI ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}