{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 3 - Advanced RAG with LangGraph\n",
        "# 고급 RAG 체인 구현\n",
        "\n",
        "이 실습에서는 LangGraph를 사용하여 고급 RAG 시스템을 구현합니다.\n",
        "Day 1에서 파인튜닝한 모델을 활용하여 더욱 정교한 검색-생성 파이프라인을 구축합니다.\n",
        "\n",
        "## 핵심 개념\n",
        "- 다단계 검색 전략 (Multi-step Retrieval)\n",
        "- 검색 결과 재순위화 (Reranking)\n",
        "- 컨텍스트 압축 및 요약\n",
        "- 동적 검색 전략 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain langgraph chromadb sentence-transformers rank-bm25 transformers torch datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional, TypedDict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.prebuilt import ToolExecutor\n",
        "\n",
        "print(\"라이브러리 import 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Day 1 파인튜닝 모델 로드\n",
        "\n",
        "먼저 Day 1에서 파인튜닝한 EXAONE 모델을 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Day1FinetunedLLM:\n",
        "    def __init__(self, model_name=\"ryanu/my-exaone-raft-model\"):\n",
        "        self.model_name = model_name\n",
        "        self.base_model = \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        print(f\"모델 로딩 중: {model_name}\")\n",
        "        print(f\"사용 디바이스: {self.device}\")\n",
        "        \n",
        "        # 토크나이저 로드\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.base_model,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # 베이스 모델 로드\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            self.base_model,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        # 파인튜닝된 어댑터 로드\n",
        "        try:\n",
        "            self.model = PeftModel.from_pretrained(self.model, model_name)\n",
        "            print(\"✅ 파인튜닝 모델 로드 완료\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 파인튜닝 모델 로드 실패, 베이스 모델 사용: {e}\")\n",
        "    \n",
        "    def generate(self, prompt: str, max_length: int = 512, temperature: float = 0.7) -> str:\n",
        "        \"\"\"텍스트 생성\"\"\"\n",
        "        inputs = self.tokenizer(\n",
        "            prompt, \n",
        "            return_tensors=\"pt\", \n",
        "            truncation=True, \n",
        "            max_length=2048\n",
        "        ).to(self.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=inputs['input_ids'].shape[1] + max_length,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "        \n",
        "        # 입력 부분 제거하고 생성된 텍스트만 반환\n",
        "        generated_text = self.tokenizer.decode(\n",
        "            outputs[0][inputs['input_ids'].shape[1]:], \n",
        "            skip_special_tokens=True\n",
        "        )\n",
        "        \n",
        "        return generated_text.strip()\n",
        "\n",
        "# 모델 초기화\n",
        "llm = Day1FinetunedLLM()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 고급 검색 시스템 구성\n",
        "\n",
        "여러 검색 전략을 결합한 하이브리드 검색 시스템을 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdvancedRetriever:\n",
        "    def __init__(self):\n",
        "        # 벡터 검색을 위한 임베딩 모델\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        \n",
        "        # 재순위화를 위한 크로스 인코더\n",
        "        self.reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "        \n",
        "        # ChromaDB 클라이언트\n",
        "        self.chroma_client = chromadb.Client()\n",
        "        self.collection_name = \"advanced_rag_docs\"\n",
        "        \n",
        "        # 컬렉션 초기화\n",
        "        try:\n",
        "            self.collection = self.chroma_client.get_collection(self.collection_name)\n",
        "        except:\n",
        "            self.collection = self.chroma_client.create_collection(\n",
        "                name=self.collection_name,\n",
        "                metadata={\"hnsw:space\": \"cosine\"}\n",
        "            )\n",
        "        \n",
        "        # BM25 검색을 위한 변수들\n",
        "        self.bm25 = None\n",
        "        self.documents = []\n",
        "        self.doc_metadata = []\n",
        "    \n",
        "    def add_documents(self, documents: List[Document]):\n",
        "        \"\"\"문서 추가 및 인덱싱\"\"\"\n",
        "        print(f\"문서 {len(documents)}개 인덱싱 중...\")\n",
        "        \n",
        "        # 텍스트와 메타데이터 분리\n",
        "        texts = [doc.page_content for doc in documents]\n",
        "        metadatas = [doc.metadata for doc in documents]\n",
        "        \n",
        "        # 벡터 임베딩 생성\n",
        "        embeddings = self.embedding_model.encode(texts)\n",
        "        \n",
        "        # ChromaDB에 저장\n",
        "        ids = [f\"doc_{i}\" for i in range(len(texts))]\n",
        "        self.collection.add(\n",
        "            embeddings=embeddings.tolist(),\n",
        "            documents=texts,\n",
        "            metadatas=metadatas,\n",
        "            ids=ids\n",
        "        )\n",
        "        \n",
        "        # BM25 인덱스 구축\n",
        "        self.documents = texts\n",
        "        self.doc_metadata = metadatas\n",
        "        tokenized_docs = [doc.lower().split() for doc in texts]\n",
        "        self.bm25 = BM25Okapi(tokenized_docs)\n",
        "        \n",
        "        print(\"✅ 문서 인덱싱 완료\")\n",
        "    \n",
        "    def semantic_search(self, query: str, k: int = 10) -> List[Dict]:\n",
        "        \"\"\"의미적 벡터 검색\"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query])\n",
        "        \n",
        "        results = self.collection.query(\n",
        "            query_embeddings=query_embedding.tolist(),\n",
        "            n_results=k\n",
        "        )\n",
        "        \n",
        "        return [\n",
        "            {\n",
        "                \"content\": doc,\n",
        "                \"score\": 1 - distance,  # 유사도로 변환\n",
        "                \"metadata\": meta,\n",
        "                \"method\": \"semantic\"\n",
        "            }\n",
        "            for doc, distance, meta in zip(\n",
        "                results['documents'][0],\n",
        "                results['distances'][0], \n",
        "                results['metadatas'][0]\n",
        "            )\n",
        "        ]\n",
        "    \n",
        "    def keyword_search(self, query: str, k: int = 10) -> List[Dict]:\n",
        "        \"\"\"키워드 기반 BM25 검색\"\"\"\n",
        "        if self.bm25 is None:\n",
        "            return []\n",
        "        \n",
        "        query_tokens = query.lower().split()\n",
        "        scores = self.bm25.get_scores(query_tokens)\n",
        "        \n",
        "        # 상위 k개 결과 선택\n",
        "        top_indices = scores.argsort()[-k:][::-1]\n",
        "        \n",
        "        return [\n",
        "            {\n",
        "                \"content\": self.documents[idx],\n",
        "                \"score\": float(scores[idx]),\n",
        "                \"metadata\": self.doc_metadata[idx],\n",
        "                \"method\": \"keyword\"\n",
        "            }\n",
        "            for idx in top_indices if scores[idx] > 0\n",
        "        ]\n",
        "    \n",
        "    def hybrid_search(self, query: str, k: int = 10, alpha: float = 0.7) -> List[Dict]:\n",
        "        \"\"\"하이브리드 검색 (의미적 + 키워드)\"\"\"\n",
        "        # 각각의 검색 결과 가져오기\n",
        "        semantic_results = self.semantic_search(query, k * 2)\n",
        "        keyword_results = self.keyword_search(query, k * 2)\n",
        "        \n",
        "        # 점수 정규화\n",
        "        if semantic_results:\n",
        "            max_semantic = max(r['score'] for r in semantic_results)\n",
        "            for r in semantic_results:\n",
        "                r['norm_score'] = r['score'] / max_semantic if max_semantic > 0 else 0\n",
        "        \n",
        "        if keyword_results:\n",
        "            max_keyword = max(r['score'] for r in keyword_results)\n",
        "            for r in keyword_results:\n",
        "                r['norm_score'] = r['score'] / max_keyword if max_keyword > 0 else 0\n",
        "        \n",
        "        # 결과 합치기 및 재점수화\n",
        "        combined_results = {}\n",
        "        \n",
        "        for result in semantic_results:\n",
        "            content = result['content']\n",
        "            if content not in combined_results:\n",
        "                combined_results[content] = result.copy()\n",
        "                combined_results[content]['hybrid_score'] = alpha * result['norm_score']\n",
        "                combined_results[content]['methods'] = ['semantic']\n",
        "            else:\n",
        "                combined_results[content]['hybrid_score'] += alpha * result['norm_score']\n",
        "                combined_results[content]['methods'].append('semantic')\n",
        "        \n",
        "        for result in keyword_results:\n",
        "            content = result['content']\n",
        "            if content not in combined_results:\n",
        "                combined_results[content] = result.copy()\n",
        "                combined_results[content]['hybrid_score'] = (1 - alpha) * result['norm_score']\n",
        "                combined_results[content]['methods'] = ['keyword']\n",
        "            else:\n",
        "                combined_results[content]['hybrid_score'] += (1 - alpha) * result['norm_score']\n",
        "                if 'keyword' not in combined_results[content]['methods']:\n",
        "                    combined_results[content]['methods'].append('keyword')\n",
        "        \n",
        "        # 점수 기준 정렬 후 상위 k개 반환\n",
        "        sorted_results = sorted(\n",
        "            combined_results.values(),\n",
        "            key=lambda x: x['hybrid_score'],\n",
        "            reverse=True\n",
        "        )[:k]\n",
        "        \n",
        "        return sorted_results\n",
        "    \n",
        "    def rerank_results(self, query: str, results: List[Dict], top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"크로스 인코더를 사용한 재순위화\"\"\"\n",
        "        if not results:\n",
        "            return []\n",
        "        \n",
        "        # 쿼리-문서 쌍 생성\n",
        "        pairs = [[query, result['content']] for result in results]\n",
        "        \n",
        "        # 재순위화 점수 계산\n",
        "        rerank_scores = self.reranker.predict(pairs)\n",
        "        \n",
        "        # 결과에 재순위화 점수 추가\n",
        "        for i, result in enumerate(results):\n",
        "            result['rerank_score'] = float(rerank_scores[i])\n",
        "        \n",
        "        # 재순위화 점수 기준으로 정렬\n",
        "        reranked_results = sorted(\n",
        "            results,\n",
        "            key=lambda x: x['rerank_score'],\n",
        "            reverse=True\n",
        "        )[:top_k]\n",
        "        \n",
        "        return reranked_results\n",
        "\n",
        "# 검색 시스템 초기화\n",
        "retriever = AdvancedRetriever()\n",
        "print(\"✅ 고급 검색 시스템 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 샘플 문서 생성 및 인덱싱"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 문서 생성\n",
        "sample_docs = [\n",
        "    Document(\n",
        "        page_content=\"머신러닝은 인공지능의 하위 분야로, 컴퓨터가 명시적으로 프로그래밍되지 않고도 학습할 수 있게 하는 기술입니다. 지도 학습, 비지도 학습, 강화 학습의 세 가지 주요 유형이 있습니다.\",\n",
        "        metadata={\"topic\": \"machine_learning\", \"difficulty\": \"beginner\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"딥러닝은 인공 신경망을 사용하는 머신러닝의 특별한 형태입니다. 다층 퍼셉트론, 합성곱 신경망(CNN), 순환 신경망(RNN), 트랜스포머 등 다양한 아키텍처가 있습니다.\",\n",
        "        metadata={\"topic\": \"deep_learning\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성할 수 있게 하는 AI 분야입니다. 토크나이제이션, 형태소 분석, 구문 분석, 의미 분석 등의 단계를 포함합니다.\",\n",
        "        metadata={\"topic\": \"nlp\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"트랜스포머는 어텐션 메커니즘만을 사용하는 신경망 아키텍처입니다. BERT, GPT, T5 등 많은 현대 언어 모델의 기초가 되었으며, '어텐션이 전부다'라는 논문에서 처음 소개되었습니다.\",\n",
        "        metadata={\"topic\": \"transformers\", \"difficulty\": \"advanced\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"파인튜닝은 사전 훈련된 모델을 특정 작업에 맞게 추가로 훈련시키는 기법입니다. 전체 파라미터를 업데이트하는 풀 파인튜닝과 일부만 업데이트하는 LoRA, 어댑터 등의 효율적 방법이 있습니다.\",\n",
        "        metadata={\"topic\": \"fine_tuning\", \"difficulty\": \"advanced\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"RAG(Retrieval-Augmented Generation)는 외부 지식을 검색하여 생성 모델에 제공하는 기법입니다. 벡터 데이터베이스를 통한 의미적 검색과 언어 모델의 생성 능력을 결합합니다.\",\n",
        "        metadata={\"topic\": \"rag\", \"difficulty\": \"advanced\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"LangChain은 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다. 체인, 에이전트, 메모리 등의 개념을 통해 복잡한 AI 워크플로를 구성할 수 있습니다.\",\n",
        "        metadata={\"topic\": \"langchain\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"벡터 데이터베이스는 고차원 벡터를 효율적으로 저장하고 검색하는 데이터베이스입니다. Chroma, Pinecone, Weaviate, FAISS 등이 대표적이며, 의미적 검색에 필수적입니다.\",\n",
        "        metadata={\"topic\": \"vector_database\", \"difficulty\": \"intermediate\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "# 문서 인덱싱\n",
        "retriever.add_documents(sample_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LangGraph 상태 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RAGState(TypedDict):\n",
        "    \"\"\"RAG 워크플로 상태\"\"\"\n",
        "    query: str                    # 사용자 질문\n",
        "    search_strategy: str          # 검색 전략 (semantic, keyword, hybrid)\n",
        "    raw_results: List[Dict]       # 초기 검색 결과\n",
        "    reranked_results: List[Dict]  # 재순위화된 결과\n",
        "    context: str                  # 최종 컨텍스트\n",
        "    answer: str                   # 생성된 답변\n",
        "    confidence: float             # 신뢰도 점수\n",
        "    need_refinement: bool         # 개선 필요 여부\n",
        "    iteration: int                # 반복 횟수\n",
        "\n",
        "print(\"✅ 상태 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 워크플로 노드 함수들"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_query(state: RAGState) -> RAGState:\n",
        "    \"\"\"질문 분석 및 검색 전략 결정\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    \n",
        "    # 간단한 휴리스틱으로 검색 전략 결정\n",
        "    if any(word in query.lower() for word in [\"개념\", \"정의\", \"설명\", \"무엇\", \"what\", \"define\"]):\n",
        "        strategy = \"semantic\"  # 개념적 질문은 의미적 검색\n",
        "    elif any(word in query.lower() for word in [\"방법\", \"어떻게\", \"how\", \"단계\", \"절차\"]):\n",
        "        strategy = \"hybrid\"    # 방법론적 질문은 하이브리드 검색\n",
        "    else:\n",
        "        strategy = \"hybrid\"    # 기본은 하이브리드\n",
        "    \n",
        "    print(f\"📊 질문 분석: '{query}' -> 전략: {strategy}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"search_strategy\": strategy,\n",
        "        \"iteration\": state.get(\"iteration\", 0)\n",
        "    }\n",
        "\n",
        "def retrieve_documents(state: RAGState) -> RAGState:\n",
        "    \"\"\"문서 검색\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    strategy = state[\"search_strategy\"]\n",
        "    \n",
        "    print(f\"🔍 문서 검색 중: {strategy} 전략 사용\")\n",
        "    \n",
        "    if strategy == \"semantic\":\n",
        "        results = retriever.semantic_search(query, k=15)\n",
        "    elif strategy == \"keyword\":\n",
        "        results = retriever.keyword_search(query, k=15)\n",
        "    else:  # hybrid\n",
        "        results = retriever.hybrid_search(query, k=15)\n",
        "    \n",
        "    print(f\"📋 검색 결과: {len(results)}개 문서\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"raw_results\": results\n",
        "    }\n",
        "\n",
        "def rerank_results(state: RAGState) -> RAGState:\n",
        "    \"\"\"검색 결과 재순위화\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    raw_results = state[\"raw_results\"]\n",
        "    \n",
        "    print(\"📊 검색 결과 재순위화 중...\")\n",
        "    \n",
        "    reranked = retriever.rerank_results(query, raw_results, top_k=8)\n",
        "    \n",
        "    print(f\"✅ 재순위화 완료: 상위 {len(reranked)}개 선택\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"reranked_results\": reranked\n",
        "    }\n",
        "\n",
        "def prepare_context(state: RAGState) -> RAGState:\n",
        "    \"\"\"컨텍스트 준비 및 압축\"\"\"\n",
        "    results = state[\"reranked_results\"]\n",
        "    \n",
        "    # 컨텍스트 구성\n",
        "    context_parts = []\n",
        "    for i, result in enumerate(results[:5], 1):  # 상위 5개만 사용\n",
        "        context_parts.append(\n",
        "            f\"[참고자료 {i}] (관련도: {result.get('rerank_score', 0):.3f})\\n\"\n",
        "            f\"{result['content']}\\n\"\n",
        "        )\n",
        "    \n",
        "    context = \"\\n\".join(context_parts)\n",
        "    \n",
        "    print(f\"📝 컨텍스트 준비 완료: {len(context)} 글자\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"context\": context\n",
        "    }\n",
        "\n",
        "def generate_answer(state: RAGState) -> RAGState:\n",
        "    \"\"\"답변 생성\"\"\"\n",
        "    query = state[\"query\"]\n",
        "    context = state[\"context\"]\n",
        "    \n",
        "    print(\"🤖 답변 생성 중...\")\n",
        "    \n",
        "    # 프롬프트 구성\n",
        "    prompt = f\"\"\"다음 참고자료를 바탕으로 질문에 답변해주세요.\n",
        "\n",
        "참고자료:\n",
        "{context}\n",
        "\n",
        "질문: {query}\n",
        "\n",
        "답변:\n",
        "- 참고자료의 내용을 바탕으로 정확하고 구체적으로 답변해주세요\n",
        "- 참고자료에 없는 내용은 추측하지 마세요\n",
        "- 답변 근거를 명시해주세요\n",
        "\n",
        "답변:\"\"\"\n",
        "    \n",
        "    # 답변 생성\n",
        "    answer = llm.generate(prompt, max_length=400, temperature=0.3)\n",
        "    \n",
        "    # 간단한 신뢰도 계산 (실제로는 더 정교한 방법 사용)\n",
        "    avg_rerank_score = sum(r.get('rerank_score', 0) for r in state[\"reranked_results\"][:3]) / min(3, len(state[\"reranked_results\"]))\n",
        "    confidence = min(avg_rerank_score * 2, 1.0)  # 정규화\n",
        "    \n",
        "    print(f\"✅ 답변 생성 완료 (신뢰도: {confidence:.3f})\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"answer\": answer,\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "def evaluate_answer(state: RAGState) -> RAGState:\n",
        "    \"\"\"답변 품질 평가\"\"\"\n",
        "    confidence = state[\"confidence\"]\n",
        "    iteration = state[\"iteration\"]\n",
        "    \n",
        "    # 개선 필요 여부 판단\n",
        "    need_refinement = (\n",
        "        confidence < 0.6 and  # 신뢰도가 낮고\n",
        "        iteration < 2 and     # 반복 횟수가 적고\n",
        "        len(state[\"answer\"]) < 50  # 답변이 너무 짧음\n",
        "    )\n",
        "    \n",
        "    print(f\"📊 답변 평가: 신뢰도={confidence:.3f}, 반복={iteration}, 개선필요={need_refinement}\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"need_refinement\": need_refinement\n",
        "    }\n",
        "\n",
        "def refine_query(state: RAGState) -> RAGState:\n",
        "    \"\"\"질문 개선 및 재검색\"\"\"\n",
        "    original_query = state[\"query\"]\n",
        "    \n",
        "    # 질문 확장 (실제로는 더 정교한 방법 사용)\n",
        "    expanded_query = f\"{original_query} 자세한 설명 예시\"\n",
        "    \n",
        "    print(f\"🔄 질문 개선: '{original_query}' -> '{expanded_query}'\")\n",
        "    \n",
        "    return {\n",
        "        **state,\n",
        "        \"query\": expanded_query,\n",
        "        \"iteration\": state[\"iteration\"] + 1,\n",
        "        \"search_strategy\": \"hybrid\"  # 재검색은 하이브리드로\n",
        "    }\n",
        "\n",
        "def should_refine(state: RAGState) -> str:\n",
        "    \"\"\"개선 여부 결정\"\"\"\n",
        "    if state[\"need_refinement\"]:\n",
        "        return \"refine\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "print(\"✅ 워크플로 노드 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. LangGraph 워크플로 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 그래프 생성\n",
        "workflow = StateGraph(RAGState)\n",
        "\n",
        "# 노드 추가\n",
        "workflow.add_node(\"analyze\", analyze_query)\n",
        "workflow.add_node(\"retrieve\", retrieve_documents)\n",
        "workflow.add_node(\"rerank\", rerank_results)\n",
        "workflow.add_node(\"context\", prepare_context)\n",
        "workflow.add_node(\"generate\", generate_answer)\n",
        "workflow.add_node(\"evaluate\", evaluate_answer)\n",
        "workflow.add_node(\"refine\", refine_query)\n",
        "\n",
        "# 엣지 연결\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_edge(\"analyze\", \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"rerank\")\n",
        "workflow.add_edge(\"rerank\", \"context\")\n",
        "workflow.add_edge(\"context\", \"generate\")\n",
        "workflow.add_edge(\"generate\", \"evaluate\")\n",
        "\n",
        "# 조건부 엣지\n",
        "workflow.add_conditional_edges(\n",
        "    \"evaluate\",\n",
        "    should_refine,\n",
        "    {\n",
        "        \"refine\": \"refine\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "# 개선 후 다시 분석으로\n",
        "workflow.add_edge(\"refine\", \"analyze\")\n",
        "\n",
        "# 앱 컴파일\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"✅ LangGraph 워크플로 구성 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 고급 RAG 시스템 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_advanced_rag(question: str):\n",
        "    \"\"\"고급 RAG 시스템 실행\"\"\"\n",
        "    print(f\"\\n🚀 고급 RAG 시스템 시작\")\n",
        "    print(f\"❓ 질문: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # 초기 상태\n",
        "    initial_state = {\n",
        "        \"query\": question,\n",
        "        \"iteration\": 0\n",
        "    }\n",
        "    \n",
        "    # 워크플로 실행\n",
        "    final_state = app.invoke(initial_state)\n",
        "    \n",
        "    print(\"\\n📊 최종 결과\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"🎯 답변: {final_state['answer']}\")\n",
        "    print(f\"📊 신뢰도: {final_state['confidence']:.3f}\")\n",
        "    print(f\"🔄 반복 횟수: {final_state['iteration']}\")\n",
        "    print(f\"🔍 최종 검색 전략: {final_state['search_strategy']}\")\n",
        "    \n",
        "    # 상위 검색 결과 표시\n",
        "    print(\"\\n🔍 주요 참고자료:\")\n",
        "    for i, result in enumerate(final_state['reranked_results'][:3], 1):\n",
        "        print(f\"\\n[{i}] 점수: {result.get('rerank_score', 0):.3f}\")\n",
        "        print(f\"내용: {result['content'][:100]}...\")\n",
        "        print(f\"방법: {result.get('methods', [result.get('method', 'unknown')])}\")\n",
        "    \n",
        "    return final_state\n",
        "\n",
        "# 테스트 질문들\n",
        "test_questions = [\n",
        "    \"머신러닝이 무엇인가요?\",\n",
        "    \"파인튜닝을 어떻게 하나요?\",\n",
        "    \"RAG 시스템의 장점은?\"\n",
        "]\n",
        "\n",
        "# 첫 번째 질문으로 테스트\n",
        "result = run_advanced_rag(test_questions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 다양한 질문으로 성능 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모든 테스트 질문 실행\n",
        "results = []\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n\\n🧪 테스트 {i}/{len(test_questions)}\")\n",
        "    result = run_advanced_rag(question)\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"answer\": result[\"answer\"],\n",
        "        \"confidence\": result[\"confidence\"],\n",
        "        \"iterations\": result[\"iteration\"],\n",
        "        \"strategy\": result[\"search_strategy\"]\n",
        "    })\n",
        "\n",
        "# 결과 요약\n",
        "print(\"\\n\\n📊 전체 테스트 결과 요약\")\n",
        "print(\"=\" * 100)\n",
        "avg_confidence = sum(r[\"confidence\"] for r in results) / len(results)\n",
        "avg_iterations = sum(r[\"iterations\"] for r in results) / len(results)\n",
        "\n",
        "print(f\"평균 신뢰도: {avg_confidence:.3f}\")\n",
        "print(f\"평균 반복 횟수: {avg_iterations:.1f}\")\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n[{i}] {result['question']}\")\n",
        "    print(f\"    신뢰도: {result['confidence']:.3f}, 반복: {result['iterations']}, 전략: {result['strategy']}\")\n",
        "    print(f\"    답변: {result['answer'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 워크플로 시각화 및 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_workflow_performance():\n",
        "    \"\"\"워크플로 성능 분석\"\"\"\n",
        "    print(\"🔬 고급 RAG 워크플로 성능 분석\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # 검색 전략별 성능\n",
        "    strategies = [r[\"strategy\"] for r in results]\n",
        "    strategy_counts = {}\n",
        "    for strategy in strategies:\n",
        "        strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1\n",
        "    \n",
        "    print(\"검색 전략 사용 빈도:\")\n",
        "    for strategy, count in strategy_counts.items():\n",
        "        print(f\"  {strategy}: {count}회\")\n",
        "    \n",
        "    # 신뢰도 분포\n",
        "    confidences = [r[\"confidence\"] for r in results]\n",
        "    high_conf = sum(1 for c in confidences if c >= 0.7)\n",
        "    medium_conf = sum(1 for c in confidences if 0.4 <= c < 0.7)\n",
        "    low_conf = sum(1 for c in confidences if c < 0.4)\n",
        "    \n",
        "    print(\"\\n신뢰도 분포:\")\n",
        "    print(f\"  높음 (≥0.7): {high_conf}개\")\n",
        "    print(f\"  보통 (0.4~0.7): {medium_conf}개\")\n",
        "    print(f\"  낮음 (<0.4): {low_conf}개\")\n",
        "    \n",
        "    # 개선 사항 제안\n",
        "    print(\"\\n💡 개선 제안:\")\n",
        "    if avg_confidence < 0.6:\n",
        "        print(\"  - 더 많은 문서를 추가하여 검색 품질 향상\")\n",
        "        print(\"  - 더 정교한 재순위화 모델 사용\")\n",
        "    if avg_iterations > 0.5:\n",
        "        print(\"  - 초기 질문 분석 로직 개선\")\n",
        "        print(\"  - 더 나은 검색 전략 선택 알고리즘\")\n",
        "    \n",
        "    print(\"\\n🎯 워크플로 장점:\")\n",
        "    print(\"  - 다단계 검색으로 정확도 향상\")\n",
        "    print(\"  - 동적 전략 선택으로 적응성 확보\")\n",
        "    print(\"  - 재순위화를 통한 관련성 개선\")\n",
        "    print(\"  - 반복 개선을 통한 품질 향상\")\n",
        "\n",
        "analyze_workflow_performance()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 실습 과제\n",
        "\n",
        "### 과제 1: 새로운 검색 전략 추가\n",
        "- BM25와 TF-IDF를 결합한 새로운 검색 전략을 구현해보세요\n",
        "- 질문 유형에 따라 더 세분화된 전략 선택 로직을 만들어보세요\n",
        "\n",
        "### 과제 2: 컨텍스트 압축 개선\n",
        "- 검색된 문서에서 중요한 문장만 추출하는 요약 기능을 추가해보세요\n",
        "- 중복 정보를 제거하는 로직을 구현해보세요\n",
        "\n",
        "### 과제 3: 답변 품질 평가 고도화\n",
        "- 더 정교한 신뢰도 계산 방법을 구현해보세요\n",
        "- 답변의 완전성과 정확성을 평가하는 메트릭을 추가해보세요\n",
        "\n",
        "### 과제 4: 실제 문서로 확장\n",
        "- PDF나 웹 문서를 로드하여 더 큰 문서 컬렉션을 구축해보세요\n",
        "- 청킹 전략을 개선하여 더 나은 검색 성능을 달성해보세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 과제 해결을 위한 시작점\n",
        "print(\"🎓 고급 RAG 실습 완료!\")\n",
        "print(\"\\n다음 단계:\")\n",
        "print(\"1. 04-text2sql.ipynb - Text-to-SQL 시스템\")\n",
        "print(\"2. 05-mcp-integration.ipynb - MCP 통합\")\n",
        "print(\"3. 06-gradio-ui.ipynb - UI 래핑\")\n",
        "\n",
        "print(\"\\n💡 핵심 학습 내용:\")\n",
        "print(\"- 하이브리드 검색 전략 (의미적 + 키워드)\")\n",
        "print(\"- 크로스 인코더를 통한 재순위화\")\n",
        "print(\"- LangGraph를 활용한 복잡한 워크플로 구성\")\n",
        "print(\"- 동적 품질 평가 및 반복 개선\")\n",
        "print(\"- Day 1 파인튜닝 모델의 실전 활용\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}