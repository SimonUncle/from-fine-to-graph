{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Memory & Persistence - Agentì˜ ê¸°ì–µ ì‹œìŠ¤í…œ\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "LangGraph Agentê°€ **ëŒ€í™”ë¥¼ ê¸°ì–µ**í•˜ê³  **ì§€ì‹ì„ ì¶•ì **í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "### Part 1: Short-term Memory (í•œ ì„¸ì…˜ ë‚´)\n",
    "1. **add_messages ë©”ëª¨ë¦¬ ëˆ„ìˆ˜**: ë¬´í•œ ëˆ„ì ì˜ ìœ„í—˜ì„±\n",
    "2. **Window Memory**: ìµœê·¼ Nê°œë§Œ ìœ ì§€í•˜ëŠ” í•´ê²°ì±…\n",
    "3. **MemorySaver**: thread_idë¡œ ì‚¬ìš©ìë³„ ëŒ€í™” ë¶„ë¦¬\n",
    "\n",
    "### Part 2: Long-term Memory (ì„¸ì…˜ ë„˜ì–´ì„œ)\n",
    "1. **Semantic Memory**: ì‚¬ìš©ì ì‚¬ì‹¤/ì§€ì‹ ì €ì¥\n",
    "2. **Episodic Memory**: ì„±ê³µí•œ ì‘ì—… ì‚¬ë¡€ ìë™ ì €ì¥\n",
    "3. **Procedural Memory**: ì‹¤íŒ¨ í•™ìŠµìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„ \n",
    "\n",
    "### Part 3: Production ë°°í¬\n",
    "- InMemoryStore í•œê³„ì™€ ì™¸ë¶€ DB ì†”ë£¨ì…˜\n",
    "- MongoDB, PostgreSQL, Redis ì—°ë™\n",
    "- TTL, í¬ê¸° ì œí•œ ë“± ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ë²•\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ“š **ì°¸ê³  ìë£Œ**:\n",
    "- DeepLearning.AI \"Long-Term Agentic Memory with LangGraph\" (Harrison Chase)\n",
    "- LangGraph ê³µì‹ ë¬¸ì„œ: Memory Management\n",
    "- GitHub Issue #3898: add_messages ë©”ëª¨ë¦¬ ëˆ„ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q langgraph langchain-core langchain-huggingface transformers torch\n\nprint(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "print(\"ğŸ”„ EXAONE 3.5 ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100, temperature=0.7, return_full_text=False)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "def to_prompt(messages):\n",
    "    \"\"\"ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ LLM í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜\"\"\"\n",
    "    return \"\\n\".join([f\"{'User' if isinstance(m, HumanMessage) else 'Assistant'}: {m.content}\" for m in messages]) + \"\\nAssistant:\"\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({'GPU' if torch.cuda.is_available() else 'CPU'} ì‚¬ìš©)\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Short-term Memory\n",
    "\n",
    "## 1ï¸âƒ£ add_messages ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë¬¸ì œ âš ï¸\n",
    "\n",
    "### ë¬¸ì œ ìƒí™©\n",
    "\n",
    "LangGraphì—ì„œ `add_messages` reducerë¥¼ ì‚¬ìš©í•˜ë©´ ë©”ì‹œì§€ê°€ **ë¬´í•œ ëˆ„ì **ë©ë‹ˆë‹¤!\n",
    "\n",
    "```python\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]  # â† ë¬¸ì œ!\n",
    "```\n",
    "\n",
    "### ì™œ ë¬¸ì œì¸ê°€?\n",
    "\n",
    "| ë¬¸ì œ | ì„¤ëª… | ì˜ˆì‹œ |\n",
    "|------|------|------|\n",
    "| **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** | ëŒ€í™”ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë©”ëª¨ë¦¬ í­ë°œ | 1000í„´ â†’ 2000ê°œ ë©”ì‹œì§€ â†’ ì„œë²„ ë‹¤ìš´ |\n",
    "| **ë¹„ìš© ì¦ê°€** | LLMì— ëª¨ë“  ë©”ì‹œì§€ ì „ì†¡ | 10ë§Œ í† í° Ã— $0.03/1K = $3 (í•œ ëŒ€í™”!) |\n",
    "| **ì»¨í…ìŠ¤íŠ¸ ì´ˆê³¼** | LLM context window ì œí•œ | GPT-4: 128K, Claude: 200K |\n",
    "\n",
    "### ì‹¤ì œ ì‚¬ë¡€\n",
    "\n",
    "- **GitHub Issue #3898**: \"RAM usage increases with every message\"\n",
    "- Production í™˜ê²½ì—ì„œ 24ì‹œê°„ ìš´ì˜ ì‹œ ì„œë²„ ë©”ëª¨ë¦¬ í­ë°œ ë³´ê³ \n",
    "- ê³ ê° ì„œë¹„ìŠ¤ ì±—ë´‡: 100í„´ ëŒ€í™” í›„ ì‘ë‹µ ì†ë„ ì €í•˜\n",
    "\n",
    "**ë‹¤ìŒ ì…€ì—ì„œ ì§ì ‘ ì¬í˜„í•´ë´…ì‹œë‹¤!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# âŒ ìœ„í—˜í•œ íŒ¨í„´: add_messages ì‚¬ìš©\n",
    "class BadState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]  # ë©”ì‹œì§€ê°€ ê³„ì† ëˆ„ì ë¨!\n",
    "\n",
    "def bad_agent(state: BadState):\n",
    "    \"\"\"ê°„ë‹¨í•œ echo agent\"\"\"\n",
    "    prompt = to_prompt(state[\"messages\"])\n",
    "    response = AIMessage(content=llm.invoke(prompt).strip())\n",
    "    return {\"messages\": [response]}  # add_messagesê°€ ìë™ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ì— ì¶”ê°€\n",
    "\n",
    "# Graph êµ¬ì„±\n",
    "graph = StateGraph(BadState)\n",
    "graph.add_node(\"agent\", bad_agent)\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_edge(\"agent\", END)\n",
    "bad_app = graph.compile()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: 5í„´ ëŒ€í™”\n",
    "state = {\"messages\": []}\n",
    "turns = [\"ì•ˆë…•\", \"ë‚ ì”¨ ì–´ë•Œ?\", \"ì¢‹ì•„\", \"ê³ ë§ˆì›Œ\", \"ë˜ ë´\"]\n",
    "\n",
    "print(\"ğŸ“Š ë©”ì‹œì§€ ëˆ„ì  í˜„í™©:\")\n",
    "for i, msg in enumerate(turns, 1):\n",
    "    state[\"messages\"].append(HumanMessage(content=msg))\n",
    "    result = bad_app.invoke(state)\n",
    "    state = result  # ì—…ë°ì´íŠ¸ëœ state (ë©”ì‹œì§€ ê³„ì† ëˆ„ì )\n",
    "    \n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {msg}\")\n",
    "    print(f\"Assistant: {state['messages'][-1].content[:60]}...\")\n",
    "    print(f\"ğŸ’¬ ëˆ„ì  ë©”ì‹œì§€: {len(state['messages'])}ê°œ\")\n",
    "\n",
    "print(f\"\\nâš ï¸  ë¬¸ì œ: {len(state['messages'])}ê°œë¡œ ê³„ì† ì¦ê°€!\")\n",
    "print(f\"   100í„´ì´ë©´? 200ê°œ!\")\n",
    "print(f\"   1000í„´ì´ë©´? 2000ê°œ! â†’ ğŸ’¥ ë©”ëª¨ë¦¬ í­ë°œ\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ¯ ì‹¤ìŠµ 1: Window Memory ì§ì ‘ êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ëŠ” Window Memoryë¥¼ ë§Œë“œì„¸ìš”!\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "- ì „ì²´ ë©”ì‹œì§€ì—ì„œ ìµœê·¼ window_sizeê°œë§Œ ìŠ¬ë¼ì´ì‹±\n",
    "- ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¼ (ë©”ëª¨ë¦¬ ì ˆì•½!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "# TODO: apply_window í•¨ìˆ˜ë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    "def apply_window(messages: List, window_size: int) -> List:\n",
    "    '''ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€'''\n",
    "    # ì—¬ê¸°ì— ìŠ¬ë¼ì´ì‹±! ğŸ‘‡\n",
    "    pass  # ì´ ì¤„ì„ ì§€ìš°ê³  ì‘ì„±í•˜ì„¸ìš”\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_msgs = [\"M1\", \"M2\", \"M3\", \"M4\", \"M5\"]\n",
    "result = apply_window(test_msgs, window_size=3)\n",
    "\n",
    "print(f\"ì „ì²´: {test_msgs}\")\n",
    "print(f\"Window 3ê°œ: {result}\")\n",
    "\n",
    "if result == [\"M3\", \"M4\", \"M5\"]:\n",
    "    print(\"âœ… ì •ë‹µ! ìµœê·¼ 3ê°œë§Œ ìœ ì§€!\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ íŒíŠ¸: return messages[-window_size:]\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "```python\n",
    "def apply_window(messages: List, window_size: int) -> List:\n",
    "    '''ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€'''\n",
    "    if len(messages) <= window_size:\n",
    "        return messages\n",
    "    return messages[-window_size:]\n",
    "```\n",
    "\n",
    "**Window Memory íŒ¨í„´:**\n",
    "```python\n",
    "# Agent ë‚´ë¶€\n",
    "def agent(state):\n",
    "    all_msgs = state[\"messages\"]\n",
    "    recent = all_msgs[-window_size:]  # ìµœê·¼ Nê°œë§Œ\n",
    "    \n",
    "    response = llm.invoke(recent)\n",
    "    return {\"messages\": recent + [response]}\n",
    "```\n",
    "\n",
    "**í•µì‹¬:** ì˜¤ë˜ëœ ë©”ì‹œì§€ëŠ” ë²„ë ¤ì„œ ë©”ëª¨ë¦¬ ì ˆì•½!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### ğŸ¯ í€´ì¦ˆ: add_messagesì˜ ë¬¸ì œì ì€?\n\n`add_messages` reducerë¥¼ ì‚¬ìš©í•˜ë©´ ì–´ë–¤ ë¬¸ì œê°€ ë°œìƒí•˜ë‚˜ìš”?\n\n**A)** ë©”ì‹œì§€ê°€ ë®ì–´ì”Œì›Œì§\n**B)** ë©”ì‹œì§€ê°€ ë¬´í•œ ëˆ„ì ë˜ì–´ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜\n**C)** ë©”ì‹œì§€ê°€ ì‚­ì œë¨\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n# TODO: ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”\n\nmy_answer = \"\"  # \"A\", \"B\", \"C\"\n\nif my_answer == \"B\":\n    print(\"âœ… ì •ë‹µ!\")\nelif my_answer:\n    print(\"âŒ ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!\")\nelse:\n    print(\"ğŸ’¡ íŒíŠ¸ë¥¼ ë³´ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n\n**ì •ë‹µ: B**\n\n**í•´ì„¤:**\n- A) âŒ ì˜¤íˆë ¤ ë°˜ëŒ€ (ë®ì–´ì“°ê¸°ê°€ ì•ˆ ë¨!)\n- **B) âœ… ë¬´í•œ ëˆ„ì  â†’ ë©”ëª¨ë¦¬ í­ë°œ, ë¹„ìš© ì¦ê°€, ì»¨í…ìŠ¤íŠ¸ ì´ˆê³¼**\n- C) âŒ ì‚­ì œë˜ì§€ ì•Šê³  ê³„ì† ìŒ“ì„\n\n**ë¬¸ì œ:**\n```python\nmessages: Annotated[List, add_messages]\n# 100í„´ ëŒ€í™” â†’ 200ê°œ ë©”ì‹œì§€!\n# 1000í„´ â†’ 2000ê°œ! â†’ ğŸ’¥\n```\n\n**í•´ê²°:** Window Memory, trim_messages ë“±\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Window Memory - í•´ê²°ì±… âœ…\n",
    "\n",
    "### í•µì‹¬ ì•„ì´ë””ì–´\n",
    "\n",
    "**ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€**í•˜ë©´ ë©”ëª¨ë¦¬ê°€ ì œí•œë©ë‹ˆë‹¤!\n",
    "\n",
    "```python\n",
    "# add_messages ì œê±°!\n",
    "messages: List  # ë‹¨ìˆœ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# ìˆ˜ë™ìœ¼ë¡œ ìµœê·¼ Nê°œë§Œ ìœ ì§€\n",
    "recent = messages[-N:]\n",
    "```\n",
    "\n",
    "### ì¥ì \n",
    "\n",
    "| í•­ëª© | add_messages | Window Memory |\n",
    "|------|--------------|---------------|\n",
    "| ë©”ëª¨ë¦¬ | âŒ ë¬´í•œ ì¦ê°€ | âœ… ê³ ì • (2Nê°œ) |\n",
    "| ë¹„ìš© | âŒ ê³„ì† ì¦ê°€ | âœ… ê³ ì • |\n",
    "| ì†ë„ | âŒ ì ì  ëŠë¦¼ | âœ… ì¼ì • |\n",
    "\n",
    "### LangChain ê³µì‹ ë°©ë²•\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# í† í° ê¸°ë°˜ ì œí•œ\n",
    "trimmed = trim_messages(\n",
    "    messages,\n",
    "    max_tokens=1000,\n",
    "    strategy=\"last\"  # ìµœê·¼ ë©”ì‹œì§€ ìš°ì„ \n",
    ")\n",
    "```\n",
    "\n",
    "**ë‹¤ìŒ ì…€ì—ì„œ ì§ì ‘ êµ¬í˜„í•´ë´…ì‹œë‹¤!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# âœ… ì•ˆì „í•œ íŒ¨í„´: Window Memory\n",
    "class WindowState(TypedDict):\n",
    "    messages: List  # add_messages ì œê±°!\n",
    "    window_size: int  # ìµœê·¼ ëª‡ ê°œë¥¼ ìœ ì§€í• ì§€\n",
    "\n",
    "def window_agent(state: WindowState):\n",
    "    \"\"\"ìµœê·¼ Nê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€í•˜ëŠ” Agent\"\"\"\n",
    "    all_msgs = state.get(\"messages\", [])\n",
    "    window_size = state.get(\"window_size\", 5)\n",
    "    \n",
    "    # í•µì‹¬: ìµœê·¼ Nê°œë§Œ ìœ ì§€!\n",
    "    recent = all_msgs[-window_size:] if len(all_msgs) > window_size else all_msgs\n",
    "    \n",
    "    # LLM í˜¸ì¶œ (ìµœê·¼ ë©”ì‹œì§€ë§Œ ì‚¬ìš©)\n",
    "    prompt = to_prompt(recent)\n",
    "    response = AIMessage(content=llm.invoke(prompt).strip())\n",
    "    \n",
    "    # ìµœê·¼ Nê°œ + ìƒˆ ì‘ë‹µë§Œ ë°˜í™˜\n",
    "    return {\"messages\": recent + [response]}\n",
    "\n",
    "# Graph\n",
    "graph = StateGraph(WindowState)\n",
    "graph.add_node(\"agent\", window_agent)\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_edge(\"agent\", END)\n",
    "window_app = graph.compile()\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: window_size=3ìœ¼ë¡œ ê¸´ ëŒ€í™”\n",
    "state = {\"messages\": [], \"window_size\": 3}\n",
    "turns = [\"ë‚´ ì´ë¦„ì€ ì² ìˆ˜\", \"ë‚˜ëŠ” ì„œìš¸ ì‚°ë‹¤\", \"ë‚˜ëŠ” ê°œë°œì\", \"íŒŒì´ì¬ ì¢‹ì•„í•´\", \"ë‚´ ì´ë¦„ ë­ì˜€ì§€?\"]\n",
    "\n",
    "print(\"ğŸ“Š Window Memory í…ŒìŠ¤íŠ¸:\")\n",
    "for i, msg in enumerate(turns, 1):\n",
    "    state[\"messages\"].append(HumanMessage(content=msg))\n",
    "    result = window_app.invoke(state)\n",
    "    state = {\"messages\": result[\"messages\"], \"window_size\": 3}\n",
    "    \n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"User: {msg}\")\n",
    "    print(f\"Assistant: {result['messages'][-1].content[:80]}...\")\n",
    "    print(f\"ğŸ’¬ í˜„ì¬ ë©”ì‹œì§€ ìˆ˜: {len(state['messages'])}ê°œ\")\n",
    "\n",
    "print(f\"\\nâŒ ê²°ê³¼: 'ì² ìˆ˜'ë¥¼ ê¸°ì–µ ëª»í•¨!\")\n",
    "print(f\"   ì´ìœ : window_size=3ì´ë¼ Turn 1ì´ ì´ë¯¸ ì‚­ì œë¨\")\n",
    "print(f\"   ì´ê²ƒì´ Window Memoryì˜ íŠ¸ë ˆì´ë“œì˜¤í”„!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ MemorySaver - ì„¸ì…˜ ê´€ë¦¬ ğŸ’¾\n",
    "\n",
    "### ë¬¸ì œ: ì‚¬ìš©ìë³„ë¡œ ëŒ€í™”ë¥¼ ì–´ë–»ê²Œ ë¶„ë¦¬í•˜ë‚˜?\n",
    "\n",
    "ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— Agentë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€í™”ê°€ ì„ì…ë‹ˆë‹¤!\n",
    "\n",
    "```python\n",
    "# Alice: \"ë‚´ ì´ë¦„ì€ Alice\"\n",
    "# Bob: \"ë‚´ ì´ë¦„ì€ Bob\"\n",
    "# Alice: \"ë‚´ ì´ë¦„ ë­ì˜€ì§€?\" â†’ Bob? Alice? ğŸ¤”\n",
    "```\n",
    "\n",
    "### í•´ê²°ì±…: thread_id + Checkpointer\n",
    "\n",
    "**Checkpointer**ëŠ” ê° `thread_id`ë³„ë¡œ ëŒ€í™”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# ì‚¬ìš©ìë³„ ì„¤ì •\n",
    "config_alice = {\"configurable\": {\"thread_id\": \"alice\"}}\n",
    "config_bob = {\"configurable\": {\"thread_id\": \"bob\"}}\n",
    "\n",
    "app.invoke({...}, config=config_alice)  # Alice ëŒ€í™”\n",
    "app.invoke({...}, config=config_bob)    # Bob ëŒ€í™” (ë¶„ë¦¬ë¨!)\n",
    "```\n",
    "\n",
    "### âš ï¸ add_messagesë¥¼ ë‹¤ì‹œ ì“°ëŠ” ì´ìœ \n",
    "\n",
    "**Window Memoryì—ì„œëŠ” ì œê±°í–ˆëŠ”ë° ì™œ?**\n",
    "\n",
    "| í•­ëª© | Window Memory | MemorySaver |\n",
    "|------|---------------|-------------|\n",
    "| **ëª©ì ** | ë©”ëª¨ë¦¬ ì œí•œ | ì„¸ì…˜ ë¶„ë¦¬ |\n",
    "| **ê´€ë¦¬ ë°©ì‹** | ìˆ˜ë™ ìŠ¬ë¼ì´ì‹± | Checkpointer ìë™ |\n",
    "| **add_messages** | âŒ ì œê±° (ë¬´í•œ ëˆ„ì  ë°©ì§€) | âœ… ì‚¬ìš© (ìë™ merge) |\n",
    "| **ì•ˆì „ì„±** | ì§ì ‘ ê´€ë¦¬ | threadë³„ ê²©ë¦¬ |\n",
    "\n",
    "**í•µì‹¬ ì°¨ì´**:\n",
    "- Window Memory: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ ìœ„í•´ **ì§ì ‘ ê´€ë¦¬**\n",
    "- MemorySaver: **threadë³„ë¡œ ë¶„ë¦¬**ë˜ë‹ˆê¹Œ add_messages ì¨ë„ ì•ˆì „!\n",
    "\n",
    "### MemorySaver vs Production\n",
    "\n",
    "| í•­ëª© | MemorySaver | Production (PostgreSQL ë“±) |\n",
    "|------|-------------|---------------------------|\n",
    "| ì €ì¥ ìœ„ì¹˜ | ë©”ëª¨ë¦¬ | DB |\n",
    "| ì˜êµ¬ì„± | âŒ ì¬ì‹œì‘ ì‹œ ì‚­ì œ | âœ… ì˜êµ¬ ì €ì¥ |\n",
    "| ìš©ë„ | ê°œë°œ/í…ŒìŠ¤íŠ¸ | Production |\n",
    "\n",
    "**âš ï¸ ì¤‘ìš”**: `MemorySaver`ëŠ” ë…¸íŠ¸ë¶ ì¬ì‹œì‘ ì‹œ ëª¨ë“  ëŒ€í™”ê°€ ì‚¬ë¼ì§‘ë‹ˆë‹¤!\n",
    "\n",
    "**ë‹¤ìŒ ì…€ì—ì„œ ì‚¬ìš©ìë³„ ì„¸ì…˜ ê´€ë¦¬ë¥¼ í…ŒìŠ¤íŠ¸í•´ë´…ì‹œë‹¤!**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# MemorySaverìš© State (add_messages ë‹¤ì‹œ ì¶”ê°€!)\n",
    "class PersistentState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]  # âœ… Checkpointerì™€ í•¨ê»˜ ì‚¬ìš©\n",
    "\n",
    "def persistent_agent(state: PersistentState):\n",
    "    \"\"\"Checkpointerê°€ ì´ì „ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•´ì¤Œ\"\"\"\n",
    "    # state[\"messages\"]ì—ëŠ” checkpointerê°€ ë¡œë“œí•œ ì „ì²´ íˆìŠ¤í† ë¦¬ + ìƒˆ ë©”ì‹œì§€ê°€ ì´ë¯¸ í•©ì³ì ¸ ìˆìŒ!\n",
    "    prompt = to_prompt(state[\"messages\"])\n",
    "    response = AIMessage(content=llm.invoke(prompt).strip())\n",
    "    \n",
    "    return {\"messages\": [response]}  # add_messagesê°€ ìë™ìœ¼ë¡œ ê¸°ì¡´ ë©”ì‹œì§€ì— ì¶”ê°€\n",
    "\n",
    "# Checkpointerì™€ í•¨ê»˜ Graph ìƒì„±\n",
    "checkpointer = MemorySaver()\n",
    "persistent_graph = StateGraph(PersistentState)\n",
    "persistent_graph.add_node(\"agent\", persistent_agent)\n",
    "persistent_graph.add_edge(START, \"agent\")\n",
    "persistent_graph.add_edge(\"agent\", END)\n",
    "persistent_app = persistent_graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Alice ì„¸ì…˜ ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Alice Turn 1\n",
    "config_alice = {\"configurable\": {\"thread_id\": \"alice\"}}\n",
    "result1 = persistent_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë‚´ ì´ë¦„ì€ Aliceì•¼\")]},\n",
    "    config=config_alice\n",
    ")\n",
    "print(f\"\\n[Turn 1]\")\n",
    "print(f\"User: ë‚´ ì´ë¦„ì€ Aliceì•¼\")\n",
    "print(f\"Assistant: {result1['messages'][-1].content}\")\n",
    "\n",
    "# Alice Turn 2\n",
    "result2 = persistent_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë‚˜ëŠ” ê°œë°œìì•¼\")]},\n",
    "    config=config_alice\n",
    ")\n",
    "print(f\"\\n[Turn 2]\")\n",
    "print(f\"User: ë‚˜ëŠ” ê°œë°œìì•¼\")\n",
    "print(f\"Assistant: {result2['messages'][-1].content}\")\n",
    "\n",
    "# Alice Turn 3 - ê¸°ì–µ í…ŒìŠ¤íŠ¸!\n",
    "result3 = persistent_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë‚´ ì´ë¦„ ë­ì˜€ì§€?\")]},\n",
    "    config=config_alice\n",
    ")\n",
    "print(f\"\\n[Turn 3] - ê¸°ì–µ í…ŒìŠ¤íŠ¸!\")\n",
    "print(f\"User: ë‚´ ì´ë¦„ ë­ì˜€ì§€?\")\n",
    "print(f\"Assistant: {result3['messages'][-1].content}\")\n",
    "print(f\"âœ… Alice ì„¸ì…˜ ì´ {len(result3['messages'])}ê°œ ë©”ì‹œì§€ ìœ ì§€\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Bob ì„¸ì…˜ ì‹œì‘ (Aliceì™€ ì™„ì „íˆ ë¶„ë¦¬!)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Bob Turn 1\n",
    "config_bob = {\"configurable\": {\"thread_id\": \"bob\"}}\n",
    "result_bob1 = persistent_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë‚´ ì´ë¦„ì€ Bobì´ì•¼\")]},\n",
    "    config=config_bob\n",
    ")\n",
    "print(f\"\\n[Turn 1]\")\n",
    "print(f\"User: ë‚´ ì´ë¦„ì€ Bobì´ì•¼\")\n",
    "print(f\"Assistant: {result_bob1['messages'][-1].content}\")\n",
    "\n",
    "# Bob Turn 2 - ê¸°ì–µ í…ŒìŠ¤íŠ¸\n",
    "result_bob2 = persistent_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë‚´ ì´ë¦„ ë­ì§€?\")]},\n",
    "    config=config_bob\n",
    ")\n",
    "print(f\"\\n[Turn 2] - Bob ê¸°ì–µ í…ŒìŠ¤íŠ¸\")\n",
    "print(f\"User: ë‚´ ì´ë¦„ ë­ì§€?\")\n",
    "print(f\"Assistant: {result_bob2['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ê²€ì¦: thread_idë¡œ ì™„ì „ ë¶„ë¦¬!\")\n",
    "print(\"   - Alice ì„¸ì…˜: 'Alice' ê¸°ì–µ ({}ê°œ ë©”ì‹œì§€)\".format(len(result3['messages'])))\n",
    "print(\"   - Bob ì„¸ì…˜: 'Bob' ê¸°ì–µ ({}ê°œ ë©”ì‹œì§€)\".format(len(result_bob2['messages'])))\n",
    "print(\"   - ì„œë¡œ ì„ì´ì§€ ì•ŠìŒ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ’¡ í•µì‹¬:\")\n",
    "print(\"   Window Memory: add_messages ì œê±° + ìˆ˜ë™ ìŠ¬ë¼ì´ì‹±\")\n",
    "print(\"   MemorySaver: add_messages ì‚¬ìš© + Checkpointer ìë™ ê´€ë¦¬\")\n",
    "print(\"   â†’ threadë³„ë¡œ ê²©ë¦¬ë˜ë‹ˆê¹Œ add_messages ì¨ë„ ì•ˆì „!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ¯ ì‹¤ìŠµ 3: MemorySaver config ì‘ì„±í•˜ê¸°\n",
    "\n",
    "ì‚¬ìš©ì \"bob\"ì˜ ëŒ€í™”ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ configë¥¼ ì‘ì„±í•˜ì„¸ìš”!\n",
    "\n",
    "**ìš”êµ¬ì‚¬í•­:**\n",
    "- thread_idë¥¼ \"bob\"ìœ¼ë¡œ ì„¤ì •\n",
    "- configurable ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "# TODO: bobì˜ configë¥¼ ì™„ì„±í•˜ì„¸ìš”\n",
    "\n",
    "config_bob = {\n",
    "    # ì—¬ê¸°ì— ì‘ì„±! ğŸ‘‡\n",
    "}\n",
    "\n",
    "# ê²€ì¦\n",
    "try:\n",
    "    assert \"configurable\" in config_bob\n",
    "    assert config_bob[\"configurable\"][\"thread_id\"] == \"bob\"\n",
    "    print(\"âœ… ì •ë‹µ!\")\n",
    "    print(f\"   config: {config_bob}\")\n",
    "except:\n",
    "    print(\"ğŸ’¡ íŒíŠ¸:\")\n",
    "    print('   {\"configurable\": {\"thread_id\": \"bob\"}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "```python\n",
    "config_bob = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"bob\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**ì‚¬ìš© ì˜ˆì‹œ:**\n",
    "```python\n",
    "app = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "# Bobì˜ ëŒ€í™”\n",
    "app.invoke({\"messages\": [...]}, config=config_bob)\n",
    "\n",
    "# Aliceì˜ ëŒ€í™” (ë¶„ë¦¬ë¨!)\n",
    "config_alice = {\"configurable\": {\"thread_id\": \"alice\"}}\n",
    "app.invoke({\"messages\": [...]}, config=config_alice)\n",
    "```\n",
    "\n",
    "**í•µì‹¬:** thread_idë¡œ ì‚¬ìš©ìë³„ ëŒ€í™” ì™„ì „ ë¶„ë¦¬!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ¯ í€´ì¦ˆ: Long-term Memory 3ê°€ì§€ íƒ€ì…\n",
    "\n",
    "**Semantic, Episodic, Procedural** ë©”ëª¨ë¦¬ê°€ ì €ì¥í•˜ëŠ” ê²ƒì€?\n",
    "\n",
    "**A)**  \n",
    "- Semantic: ì‚¬ìš©ì í”„ë¡œí•„  \n",
    "- Episodic: ì„±ê³µ ì‚¬ë¡€  \n",
    "- Procedural: ì‹¤íŒ¨ í•™ìŠµ ê·œì¹™\n",
    "\n",
    "**B)**  \n",
    "- Semantic: ëŒ€í™” ë‚´ì—­  \n",
    "- Episodic: ê²€ìƒ‰ ê²°ê³¼  \n",
    "- Procedural: ê³„ì‚° ê²°ê³¼\n",
    "\n",
    "**C)**  \n",
    "- Semantic: ì„ì‹œ ë°ì´í„°  \n",
    "- Episodic: ìºì‹œ  \n",
    "- Procedural: ë¡œê·¸"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "my_answer = \"\"  # \"A\", \"B\", \"C\"\n",
    "\n",
    "if my_answer == \"A\":\n",
    "    print(\"âœ… ì •ë‹µ!\")\n",
    "    print(\"   Semantic: ì‚¬ì‹¤/ì§€ì‹ (ì‚¬ìš©ì ì´ë¦„, ì„ í˜¸ë„)\")\n",
    "    print(\"   Episodic: ê²½í—˜/ì‚¬ë¡€ (ì„±ê³µí•œ ì‘ì—… â†’ Few-shot)\")\n",
    "    print(\"   Procedural: ê·œì¹™/ì ˆì°¨ (ì‹¤íŒ¨ â†’ Reflection â†’ ê°œì„ )\")\n",
    "elif my_answer:\n",
    "    print(\"âŒ ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ íŒíŠ¸: DeepLearning.AI ê³µì‹ íŒ¨í„´\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "**ì •ë‹µ: A**\n",
    "\n",
    "**3ê°€ì§€ Long-term Memory:**\n",
    "\n",
    "1. **Semantic Memory (ì‚¬ì‹¤/ì§€ì‹)**\n",
    "   - ì‚¬ìš©ì í”„ë¡œí•„, ë„ë©”ì¸ ì§€ì‹\n",
    "   - ì˜ˆ: `{\"name\": \"Alice\", \"job\": \"developer\"}`\n",
    "\n",
    "2. **Episodic Memory (ê²½í—˜/ì‚¬ë¡€)**\n",
    "   - ì„±ê³µí•œ ì‘ì—… ì €ì¥ â†’ Few-shot í™œìš©\n",
    "   - ì˜ˆ: ê³¼ê±° ì´ë©”ì¼ ìš”ì•½ ì‚¬ë¡€\n",
    "\n",
    "3. **Procedural Memory (ê·œì¹™/ì ˆì°¨)**\n",
    "   - ì‹¤íŒ¨ í•™ìŠµ â†’ Reflection â†’ í”„ë¡¬í”„íŠ¸ ê°œì„ \n",
    "   - ì˜ˆ: \"ì´ëª¨ì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”\" (v2 ê·œì¹™)\n",
    "\n",
    "**í•µì‹¬:** Agentê°€ **ìë™ìœ¼ë¡œ** ì €ì¥í•˜ê³  í•™ìŠµ!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Long-term Memory (3ê°€ì§€ íƒ€ì…)\n",
    "\n",
    "**ì„¸ì…˜ì„ ë„˜ì–´ì„œ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” ë°©ë²•!**\n",
    "\n",
    "## ğŸ—„ï¸ Store APIë€?\n",
    "\n",
    "LangGraphëŠ” **Store API**ë¡œ ì¥ê¸° ë©”ëª¨ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "### â“ \"ì´ê±° ìºì‹œ ì•„ë‹˜?\"\n",
    "\n",
    "**ì•„ë‹™ë‹ˆë‹¤!** ìºì‹œì™€ StoreëŠ” ì™„ì „íˆ ë‹¤ë¥¸ ëª©ì ì…ë‹ˆë‹¤:\n",
    "\n",
    "| í•­ëª© | ìºì‹œ (Redis ë“±) | Store (LangGraph) |\n",
    "|------|----------------|-------------------|\n",
    "| **ëª©ì ** | ì„±ëŠ¥ í–¥ìƒ (ì„ì‹œ ì €ì¥) | ì§€ì‹ ê´€ë¦¬ (ì˜êµ¬ ì €ì¥) |\n",
    "| **ìˆ˜ëª…** | ì§§ìŒ (TTL ìë™ ë§Œë£Œ) | ì˜êµ¬ (ëª…ì‹œì  ì‚­ì œ í•„ìš”) |\n",
    "| **êµ¬ì¡°** | Key-Value | **Namespace + Key + Value** |\n",
    "| **ì¡°íšŒ** | Keyë¡œë§Œ | **Namespace ì „ì²´ ê²€ìƒ‰ ê°€ëŠ¥** |\n",
    "| **ì˜ˆì‹œ** | API ì‘ë‹µ ìºì‹± | ì‚¬ìš©ì í”„ë¡œí•„ DB |\n",
    "\n",
    "### Store API 3ê°€ì§€ í•µì‹¬ ê°œë…\n",
    "\n",
    "```python\n",
    "# 1. Namespace: ë°ì´í„° ë²”ì£¼ (Tuple)\n",
    "namespace = (\"user\", \"alice\")  # Alice ì‚¬ìš©ì ì „ìš© ê³µê°„\n",
    "namespace = (\"episodes\", \"email_task\")  # ì´ë©”ì¼ ì‘ì—… ì‚¬ë¡€\n",
    "\n",
    "# 2. Key: í•­ëª© ì‹ë³„ì (String)\n",
    "key = \"name\"  # ì‚¬ìš©ì ì´ë¦„\n",
    "key = \"example_1\"  # ì²« ë²ˆì§¸ ì˜ˆì œ\n",
    "\n",
    "# 3. Value: êµ¬ì¡°í™”ëœ ë°ì´í„° (Dict)\n",
    "value = {\"value\": \"Alice\", \"verified\": True, \"updated_at\": \"2025-01-15\"}\n",
    "\n",
    "# ì €ì¥\n",
    "store.put(namespace, key, value)\n",
    "\n",
    "# ì¡°íšŒ: namespace ë‚´ ëª¨ë“  í•­ëª©\n",
    "for item in store.search(namespace):\n",
    "    print(f\"{item.key}: {item.value}\")\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Namespaceê°€ ì™œ ì¤‘ìš”í•œê°€?\n",
    "\n",
    "**ì‚¬ìš©ìë³„ ë°ì´í„° ê²©ë¦¬!**\n",
    "\n",
    "```python\n",
    "# Aliceì™€ Bobì˜ ë°ì´í„°ê°€ ì™„ì „íˆ ë¶„ë¦¬ë¨\n",
    "store.put((\"user\", \"alice\"), \"name\", {\"value\": \"Alice\"})\n",
    "store.put((\"user\", \"bob\"), \"name\", {\"value\": \"Bob\"})\n",
    "\n",
    "# Alice ë°ì´í„°ë§Œ ì¡°íšŒ (Bob ë°ì´í„°ëŠ” ì•ˆ ë‚˜ì˜´!)\n",
    "alice_data = store.search((\"user\", \"alice\"))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š 3ê°€ì§€ ë©”ëª¨ë¦¬ íƒ€ì… (ê³µì‹ íŒ¨í„´)\n",
    "\n",
    "DeepLearning.AI \"Long-Term Agentic Memory\" ê°•ì˜ì—ì„œ ì†Œê°œëœ íŒ¨í„´:\n",
    "\n",
    "| íƒ€ì… | ì €ì¥ ë‚´ìš© | **ì–¸ì œ ì €ì¥?** | Namespace ì˜ˆì‹œ |\n",
    "|------|----------|---------------|----------------|\n",
    "| **Semantic** | ì‚¬ì‹¤/ì§€ì‹ | ëŒ€í™” ì¤‘ ì‚¬ì‹¤ ë°œê²¬ ì‹œ | (\"user\", user_id) |\n",
    "| **Episodic** | ê²½í—˜/ì‚¬ë¡€ | **Task ì„±ê³µ ì‹œ ìë™!** | (\"episodes\", task_type) |\n",
    "| **Procedural** | ê·œì¹™/ì ˆì°¨ | **ì‹¤íŒ¨ ì‹œ Reflection!** | (\"procedures\", task_type) |\n",
    "\n",
    "**í•µì‹¬**: Agentê°€ **ìë™ìœ¼ë¡œ** ì €ì¥í•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n### ğŸ¯ í€´ì¦ˆ: Long-term Memory 3ê°€ì§€ íƒ€ì…ì€?\n\nLangGraphì—ì„œ ì‚¬ìš©í•˜ëŠ” ì¥ê¸° ë©”ëª¨ë¦¬ 3ê°€ì§€ íƒ€ì…ì€?\n\n**A)** Semantic, Episodic, Procedural\n**B)** Short, Medium, Long\n**C)** Cache, Store, Database\n"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n# TODO: ì •ë‹µì„ ì„ íƒí•˜ì„¸ìš”\n\nmy_answer = \"\"  # \"A\", \"B\", \"C\"\n\nif my_answer == \"A\":\n    print(\"âœ… ì •ë‹µ!\")\nelif my_answer:\n    print(\"âŒ ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!\")\nelse:\n    print(\"ğŸ’¡ íŒíŠ¸ë¥¼ ë³´ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<details>\n<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n\n**ì •ë‹µ: A**\n\n**í•´ì„¤:**\n- **A) âœ… Semantic (ì‚¬ì‹¤), Episodic (ê²½í—˜), Procedural (ê·œì¹™)**\n- B) âŒ ê¸°ê°„ì´ ì•„ë‹ˆë¼ ì¢…ë¥˜ë¡œ êµ¬ë¶„\n- C) âŒ ì €ì¥ ë°©ì‹ (ë©”ëª¨ë¦¬ íƒ€ì…ì´ ì•„ë‹˜)\n\n**3ê°€ì§€ íƒ€ì…:**\n1. **Semantic**: ì‚¬ìš©ì í”„ë¡œí•„, ë„ë©”ì¸ ì§€ì‹\n2. **Episodic**: ì„±ê³µí•œ ì‘ì—… ì‚¬ë¡€ (Few-shot)\n3. **Procedural**: ì‹¤íŒ¨ í•™ìŠµ â†’ í”„ë¡¬í”„íŠ¸ ê°œì„ \n\n**í•µì‹¬:** DeepLearning.AI ê³µì‹ íŒ¨í„´!\n\n</details>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Semantic Memory - ì‚¬ì‹¤/ì§€ì‹ ì €ì¥ ğŸ“\n",
    "\n",
    "### ì •ì˜\n",
    "\n",
    "**Semantic Memory**ëŠ” ì‚¬ìš©ìë‚˜ ë„ë©”ì¸ì— ëŒ€í•œ **ì‚¬ì‹¤(facts)**ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì˜ˆì‹œ\n",
    "\n",
    "- ì‚¬ìš©ì í”„ë¡œí•„: ì´ë¦„, ì§ì—…, ì„ í˜¸ë„\n",
    "- ë„ë©”ì¸ ì§€ì‹: ì œí’ˆ ì •ë³´, íšŒì‚¬ ê·œì •\n",
    "- í™˜ê²½ ì„¤ì •: ì–¸ì–´, íƒ€ì„ì¡´, ì•Œë¦¼ ì„¤ì •\n",
    "\n",
    "### ì‚¬ìš© íŒ¨í„´\n",
    "\n",
    "```python\n",
    "# ì‚¬ìš©ì ì •ë³´ ì €ì¥\n",
    "store.put(\n",
    "    (\"user\", \"alice\"),\n",
    "    \"name\",\n",
    "    {\"value\": \"Alice\", \"verified\": True}\n",
    ")\n",
    "\n",
    "store.put(\n",
    "    (\"user\", \"alice\"),\n",
    "    \"preferences\",\n",
    "    {\n",
    "        \"language\": \"ko\",\n",
    "        \"timezone\": \"Asia/Seoul\",\n",
    "        \"likes_spicy_food\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Agentì—ì„œ í™œìš©\n",
    "user_facts = store.search((\"user\", \"alice\"))\n",
    "context = \"ì‚¬ìš©ì ì •ë³´: \" + \", \".join([f\"{item.key}={item.value}\" for item in user_facts])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ¯ ì‹¤ìŠµ 4: Store API namespace ì´í•´\n",
    "\n",
    "Store APIì—ì„œ ì‚¬ìš©ì aliceì˜ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì˜¬ë°”ë¥¸ namespaceëŠ”?\n",
    "\n",
    "**A)** `\"user_alice\"`  \n",
    "**B)** `(\"user\", \"alice\")`  \n",
    "**C)** `{\"user\": \"alice\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! ğŸ‘‡\n",
    "my_answer = \"\"  # \"A\", \"B\", \"C\"\n",
    "\n",
    "if my_answer == \"B\":\n",
    "    print(\"âœ… ì •ë‹µ!\")\n",
    "    print(\"   NamespaceëŠ” Tuple í˜•íƒœ!\")\n",
    "    print('   ì˜ˆ: (\"user\", \"alice\"), (\"episodes\", \"email\")')\n",
    "elif my_answer:\n",
    "    print(\"âŒ ë‹¤ì‹œ ìƒê°í•´ë³´ì„¸ìš”!\")\n",
    "else:\n",
    "    print(\"ğŸ’¡ íŒíŠ¸: Tuple (ê´„í˜¸) ì‚¬ìš©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ“ ì •ë‹µ ë³´ê¸° (í´ë¦­)</summary>\n",
    "\n",
    "**ì •ë‹µ: B** `(\"user\", \"alice\")`\n",
    "\n",
    "**Store API êµ¬ì¡°:**\n",
    "```python\n",
    "# Namespace: Tuple\n",
    "namespace = (\"user\", \"alice\")\n",
    "\n",
    "# Key: String\n",
    "key = \"name\"\n",
    "\n",
    "# Value: Dict\n",
    "value = {\"value\": \"Alice\", \"verified\": True}\n",
    "\n",
    "# ì €ì¥\n",
    "store.put(namespace, key, value)\n",
    "\n",
    "# ì¡°íšŒ\n",
    "for item in store.search(namespace):\n",
    "    print(f\"{item.key}: {item.value}\")\n",
    "```\n",
    "\n",
    "**ì™œ Tuple?**\n",
    "- ê³„ì¸µ êµ¬ì¡° í‘œí˜„ (category, subcategory)\n",
    "- ì‚¬ìš©ìë³„ ë°ì´í„° ê²©ë¦¬\n",
    "- ë¹ ë¥¸ ê²€ìƒ‰\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "- `(\"user\", \"alice\")` - Alice ì‚¬ìš©ì ë°ì´í„°\n",
    "- `(\"episodes\", \"email_task\")` - ì´ë©”ì¼ ì‘ì—… ì‚¬ë¡€\n",
    "- `(\"procedures\", \"summary\")` - ìš”ì•½ ê·œì¹™\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Semantic Memory: ì‚¬ìš©ì ì‚¬ì‹¤ ì €ì¥\n",
    "user_id = \"alice\"\n",
    "namespace = (\"user\", user_id)\n",
    "\n",
    "store.put(namespace, \"name\", {\"value\": \"Alice\", \"verified\": True})\n",
    "store.put(namespace, \"job\", {\"value\": \"developer\", \"years\": 5})\n",
    "store.put(namespace, \"preferences\", {\"food\": \"spicy\", \"language\": \"ko\"})\n",
    "\n",
    "print(\"ğŸ“‹ Aliceì˜ Semantic Memory:\")\n",
    "for item in store.search(namespace):\n",
    "    print(f\"  {item.key}: {item.value}\")\n",
    "\n",
    "# Agentì—ì„œ í™œìš© ì˜ˆì‹œ\n",
    "facts = [f\"{item.key}: {item.value['value'] if 'value' in item.value else item.value}\" \n",
    "         for item in store.search(namespace)]\n",
    "context = \"[ì‚¬ìš©ì ì •ë³´]\\n\" + \"\\n\".join(facts)\n",
    "\n",
    "prompt = f\"{context}\\n\\nUser: ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ìŒì‹ ìŠ¤íƒ€ì¼ì€?\\nAssistant:\"\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f\"\\nâœ… Agent ë‹µë³€ (Semantic Memory í™œìš©):\")\n",
    "print(f\"   {response.strip()[:80]}...\")\n",
    "print(f\"\\nğŸ’¡ Agentê°€ ì €ì¥ëœ ì‚¬ìš©ì ì •ë³´ë¥¼ í™œìš©í•´ì„œ ë‹µë³€!\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Episodic Memory - ê²½í—˜/ì‚¬ë¡€ ì €ì¥ ğŸ¬\n",
    "\n",
    "### ì •ì˜\n",
    "\n",
    "**Episodic Memory**ëŠ” Agentê°€ **ì„±ê³µí•œ ì‘ì—…ì˜ ì‚¬ë¡€**ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€?\n",
    "\n",
    "- **Few-shot Learning**: ê³¼ê±° ì„±ê³µ ì‚¬ë¡€ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ â†’ ì •í™•ë„ í–¥ìƒ\n",
    "- **ì¼ê´€ì„±**: ê°™ì€ ì‘ì—…ì„ ë°˜ë³µí•  ë•Œ ê°™ì€ íŒ¨í„´ ì‚¬ìš©\n",
    "- **í•™ìŠµ**: ì‹œê°„ì´ ì§€ë‚ ìˆ˜ë¡ ì ì  ì˜í•¨\n",
    "\n",
    "### ë™ì‘ ë°©ì‹\n",
    "\n",
    "```python\n",
    "def agent_with_episodic(state):\n",
    "    # 1. ê³¼ê±° ì‚¬ë¡€ ê²€ìƒ‰\n",
    "    examples = store.search((\"episodes\", \"email_summary\"))\n",
    "    \n",
    "    # 2. Few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "    few_shot = \"\\n\".join([f\"Q: {ex.value['input']}\\nA: {ex.value['output']}\" \n",
    "                          for ex in examples])\n",
    "    \n",
    "    # 3. LLM í˜¸ì¶œ\n",
    "    result = llm.invoke(f\"{few_shot}\\n\\nQ: {state['input']}\\nA:\")\n",
    "    \n",
    "    # 4. ì„±ê³µ ì‹œ ìë™ ì €ì¥!\n",
    "    if success:\n",
    "        store.put(\n",
    "            (\"episodes\", \"email_summary\"),\n",
    "            f\"example_{timestamp}\",\n",
    "            {\"input\": state['input'], \"output\": result, \"success\": True}\n",
    "        )\n",
    "```\n",
    "\n",
    "### ì›ë¦¬\n",
    "\n",
    "**CoALA ë…¼ë¬¸**: \"Facts â†’ Semantic, Experiences â†’ Episodic\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def episodic_agent(state):\n",
    "    \"\"\"ì„±ê³µí•œ ì‘ì—…ì„ ìë™ìœ¼ë¡œ Episodic Memoryì— ì €ì¥\"\"\"\n",
    "    \n",
    "    user_input = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Task ì‹¤í–‰ (ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜)\n",
    "    if \"íšŒì˜\" in user_input:\n",
    "        result = \"ğŸ“… íšŒì˜ ì¼ì • ì •ë¦¬ë¨\"\n",
    "        success = True\n",
    "    elif \"ë³´ê³ ì„œ\" in user_input:\n",
    "        result = \"ğŸ“ ë³´ê³ ì„œ ë§ˆê°ì¼ í™•ì¸ë¨\"\n",
    "        success = True\n",
    "    else:\n",
    "        result = \"â“ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"\n",
    "        success = False\n",
    "    \n",
    "    # ì„±ê³µ ì‹œ ìë™ ì €ì¥!\n",
    "    if success:\n",
    "        episode_key = f\"auto_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        store.put(\n",
    "            (\"episodes\", \"email_summary\"),\n",
    "            episode_key,\n",
    "            {\n",
    "                \"input\": user_input,\n",
    "                \"output\": result,\n",
    "                \"success\": True,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        print(f\"âœ… ìë™ ì €ì¥: {episode_key} â†’ {result}\")\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=result)]}\n",
    "\n",
    "# Graph\n",
    "class EpisodicState(TypedDict):\n",
    "    messages: List\n",
    "\n",
    "epi_graph = StateGraph(EpisodicState)\n",
    "epi_graph.add_node(\"agent\", episodic_agent)\n",
    "epi_graph.add_edge(START, \"agent\")\n",
    "epi_graph.add_edge(\"agent\", END)\n",
    "epi_app = epi_graph.compile()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: ì„±ê³µ ì‚¬ë¡€ ì €ì¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "epi_app.invoke({\"messages\": [HumanMessage(content=\"íšŒì˜ ì¼ì • ì •ë¦¬í•´ì¤˜\")]})\n",
    "epi_app.invoke({\"messages\": [HumanMessage(content=\"ë³´ê³ ì„œ ë§ˆê°ì¼ í™•ì¸\")]})\n",
    "\n",
    "print(\"\\nğŸ“¦ ì €ì¥ëœ Episodic Memory:\")\n",
    "episodes = list(store.search((\"episodes\", \"email_summary\")))\n",
    "for item in episodes:\n",
    "    print(f\"  {item.key}: {item.value['input']} â†’ {item.value['output']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 2: ì €ì¥ëœ ì‚¬ë¡€ë¥¼ Few-shotìœ¼ë¡œ í™œìš©!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Few-shot í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "examples = [f\"Q: {item.value['input']}\\nA: {item.value['output']}\" \n",
    "            for item in store.search((\"episodes\", \"email_summary\"))]\n",
    "few_shot_prompt = \"\\n\\n\".join(examples)\n",
    "\n",
    "# ìƒˆë¡œìš´ ì§ˆë¬¸ (ë¹„ìŠ·í•œ íŒ¨í„´)\n",
    "new_query = \"í”„ë¡œì íŠ¸ í‚¥ì˜¤í”„ ë¯¸íŒ… ë‹¤ìŒì£¼ ì›”ìš”ì¼\"\n",
    "full_prompt = f\"{few_shot_prompt}\\n\\nQ: {new_query}\\nA:\"\n",
    "\n",
    "print(f\"\\nìƒˆë¡œìš´ ì§ˆë¬¸: {new_query}\")\n",
    "print(f\"\\nFew-shot í”„ë¡¬í”„íŠ¸ (ê³¼ê±° ì‚¬ë¡€):\")\n",
    "for ex in examples:\n",
    "    print(f\"  {ex.split(chr(10))[0][:50]}...\")\n",
    "\n",
    "result_with_fewshot = llm.invoke(full_prompt)\n",
    "\n",
    "print(f\"\\nLLM ì¶œë ¥ (Few-shot í™œìš©): {result_with_fewshot.strip()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¡ Episodic Memory íš¨ê³¼:\")\n",
    "print(\"   1. ì„±ê³µí•œ ì‘ì—… ìë™ ì €ì¥\")\n",
    "print(\"   2. ê³¼ê±° ì‚¬ë¡€ë¥¼ Few-shotìœ¼ë¡œ í™œìš©\")\n",
    "print(\"   3. ë¹„ìŠ·í•œ ì‘ì—… ì‹œ ì¼ê´€ëœ íŒ¨í„´ ìœ ì§€\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Procedural Memory - ê·œì¹™/ì ˆì°¨ ì €ì¥ ğŸ”§\n",
    "\n",
    "### ì •ì˜\n",
    "\n",
    "**Procedural Memory**ëŠ” Agentê°€ **ì‹¤íŒ¨ë¥¼ í•™ìŠµ**í•´ì„œ **í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê°œì„ **í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë™ì‘ ì›ë¦¬ (Reflection)\n",
    "\n",
    "```\n",
    "1. Agent ì‹¤í–‰ â†’ ì‹¤íŒ¨ ê°ì§€\n",
    "2. Reflection: \"ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€\" LLMì—ê²Œ ë¶„ì„ ìš”ì²­\n",
    "3. ê°œì„ ëœ ê·œì¹™ ìƒì„±\n",
    "4. Procedural Memoryì— ì €ì¥ (version up)\n",
    "5. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ê°œì„ ëœ ê·œì¹™ ì‚¬ìš©\n",
    "```\n",
    "\n",
    "### ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤\n",
    "\n",
    "**1ì°¨ ì‹œë„**:\n",
    "- ê·œì¹™: \"ì´ë©”ì¼ ìš”ì•½ ì‹œ ê°„ê²°í•˜ê²Œ\"\n",
    "- ê²°ê³¼: \"íšŒì˜ ë‚´ì¼\" (ì´ëª¨ì§€ ì—†ìŒ)\n",
    "- ì‹¤íŒ¨! (ì‚¬ìš©ìê°€ ë‚ ì§œë¥¼ ë†“ì¹¨)\n",
    "\n",
    "**Reflection**:\n",
    "- LLM: \"ë‚ ì§œì™€ ì‘ì—…ì„ êµ¬ë¶„í•˜ëŠ” ì‹œê°ì  í‘œì‹œê°€ í•„ìš”í•©ë‹ˆë‹¤. ğŸ“…, ğŸ“ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\"\n",
    "\n",
    "**2ì°¨ ì‹œë„** (ê°œì„ ëœ ê·œì¹™):\n",
    "- ê·œì¹™: \"ì´ë©”ì¼ ìš”ì•½ ì‹œ ë‚ ì§œëŠ” ğŸ“…, ì‘ì—…ì€ ğŸ“ ì´ëª¨ì§€ ì‚¬ìš©\"\n",
    "- ê²°ê³¼: \"ğŸ“… íšŒì˜: ë‚´ì¼ 3ì‹œ\"\n",
    "- ì„±ê³µ!\n",
    "\n",
    "### Meta-Prompting\n",
    "\n",
    "Agentê°€ ìì‹ ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìŠ¤ìŠ¤ë¡œ ê°œì„ í•˜ëŠ” **Self-refinement** íŒ¨í„´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def procedural_agent(state):\n",
    "    \"\"\"ì‹¤íŒ¨ ì‹œ Reflectionìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„ \"\"\"\n",
    "    \n",
    "    user_input = state[\"messages\"][-1].content\n",
    "    \n",
    "    # í˜„ì¬ ê·œì¹™ ê°€ì ¸ì˜¤ê¸°\n",
    "    proc_ns = (\"procedures\", \"email_task\")\n",
    "    items = list(store.search(proc_ns))\n",
    "    current_rule = items[0].value[\"rule\"] if items else \"ê¸°ë³¸ ê·œì¹™ ì—†ìŒ\"\n",
    "    current_version = items[0].value.get(\"version\", 0) if items else 0\n",
    "    \n",
    "    # Task ì‹¤í–‰\n",
    "    prompt = f\"[ê·œì¹™] {current_rule}\\n\\nì…ë ¥: {user_input}\\nì¶œë ¥:\"\n",
    "    result = llm.invoke(prompt).strip()\n",
    "    \n",
    "    # ì„±ê³µ/ì‹¤íŒ¨ íŒë‹¨ (ê°„ë‹¨í•œ ê·œì¹™: ì´ëª¨ì§€ í¬í•¨ ì—¬ë¶€)\n",
    "    has_emoji = any(c in result for c in [\"ğŸ“…\", \"ğŸ“\", \"ğŸ¯\"])\n",
    "    is_concise = len(result) < 100\n",
    "    success = has_emoji and is_concise\n",
    "    \n",
    "    # ì‹¤íŒ¨ ì‹œ Reflection!\n",
    "    if not success:\n",
    "        print(f\"âŒ ì‹¤íŒ¨ ê°ì§€: ì´ëª¨ì§€ ëˆ„ë½ ë˜ëŠ” ë„ˆë¬´ ì¥í™©í•¨\")\n",
    "        print(f\"   ì¶œë ¥: {result[:50]}...\")\n",
    "        \n",
    "        # Reflection í”„ë¡¬í”„íŠ¸\n",
    "        reflection_prompt = f\"\"\"\n",
    "í˜„ì¬ ê·œì¹™: {current_rule}\n",
    "ì…ë ¥: {user_input}\n",
    "ì¶œë ¥: {result}\n",
    "ë¬¸ì œì : ì´ëª¨ì§€ê°€ ì—†ê±°ë‚˜ ë„ˆë¬´ ê¹€\n",
    "\n",
    "ê°œì„ ëœ ê·œì¹™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:\n",
    "\"\"\"\n",
    "        improved_rule = llm.invoke(reflection_prompt).strip()[:100]\n",
    "        \n",
    "        # ìë™ ì €ì¥\n",
    "        store.put(\n",
    "            proc_ns,\n",
    "            \"instruction\",\n",
    "            {\n",
    "                \"rule\": improved_rule,\n",
    "                \"version\": current_version + 1,\n",
    "                \"reason\": \"Reflection: ì´ëª¨ì§€ ëˆ„ë½ ë˜ëŠ” ì¥í™©í•¨\",\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        print(f\"âœ… ìë™ ê°œì„ : v{current_version} â†’ v{current_version + 1}\")\n",
    "        print(f\"   ìƒˆ ê·œì¹™: {improved_rule[:60]}...\")\n",
    "    else:\n",
    "        print(f\"âœ… ì„±ê³µ: {result[:40]}...\")\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=result)]}\n",
    "\n",
    "# ì´ˆê¸° ê·œì¹™ ì„¤ì •\n",
    "store.put((\"procedures\", \"email_task\"), \"instruction\", {\n",
    "    \"rule\": \"ì´ë©”ì¼ ìš”ì•½ ì‹œ ê°„ê²°í•˜ê²Œ ì‘ì„±\",\n",
    "    \"version\": 1\n",
    "})\n",
    "\n",
    "# Graph\n",
    "class ProceduralState(TypedDict):\n",
    "    messages: List\n",
    "\n",
    "proc_graph = StateGraph(ProceduralState)\n",
    "proc_graph.add_node(\"agent\", procedural_agent)\n",
    "proc_graph.add_edge(START, \"agent\")\n",
    "proc_graph.add_edge(\"agent\", END)\n",
    "proc_app = proc_graph.compile()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: v1 ê·œì¹™ìœ¼ë¡œ ì‹¤í–‰ (ì‹¤íŒ¨ ì˜ˆìƒ)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result_v1 = proc_app.invoke({\"messages\": [HumanMessage(content=\"íšŒì˜ ì¼ì • ì•Œë ¤ì¤˜\")]})\n",
    "v1_output = result_v1['messages'][-1].content\n",
    "\n",
    "print(\"\\nğŸ“¦ Procedural Memory:\")\n",
    "for item in store.search((\"procedures\", \"email_task\")):\n",
    "    print(f\"  v{item.value['version']}: {item.value['rule'][:60]}...\")\n",
    "    if 'reason' in item.value:\n",
    "        print(f\"    ì´ìœ : {item.value['reason']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Step 2: v2 ê·œì¹™ìœ¼ë¡œ ê°™ì€ ì§ˆë¬¸ ì¬ì‹¤í–‰!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# v2 ê·œì¹™ìœ¼ë¡œ ì¬ì‹¤í–‰\n",
    "result_v2 = proc_app.invoke({\"messages\": [HumanMessage(content=\"íšŒì˜ ì¼ì • ì•Œë ¤ì¤˜\")]})\n",
    "v2_output = result_v2['messages'][-1].content\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Before/After ë¹„êµ:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nv1 ì¶œë ¥: {v1_output[:60]}...\")\n",
    "print(f\"v1 ìƒíƒœ: âŒ ì‹¤íŒ¨ (ì´ëª¨ì§€ ì—†ìŒ)\\n\")\n",
    "print(f\"v2 ì¶œë ¥: {v2_output[:60]}...\")\n",
    "print(f\"v2 ìƒíƒœ: âœ… ì„±ê³µ (ì´ëª¨ì§€ í¬í•¨!)\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ’¡ Procedural Memory íš¨ê³¼:\")\n",
    "print(\"   1. ì‹¤íŒ¨ ê°ì§€ â†’ Reflection\")\n",
    "print(\"   2. í”„ë¡¬í”„íŠ¸ ìë™ ê°œì„  (v1 â†’ v2)\")\n",
    "print(\"   3. ê°™ì€ ì‹¤ìˆ˜ ë°˜ë³µ ì•ˆ í•¨!\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Production ë°°í¬ ğŸš€\n",
    "\n",
    "## âš ï¸  InMemoryStoreì˜ í•œê³„\n",
    "\n",
    "**í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ `InMemoryStore`ëŠ” ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©ë§Œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤!**\n",
    "\n",
    "| ë¬¸ì œ | ì„¤ëª… | ì˜í–¥ |\n",
    "|------|------|------|\n",
    "| **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜** | ê³„ì† ìŒ“ì´ë©´ ë©”ëª¨ë¦¬ í­ë°œ | ì„œë²„ ë‹¤ìš´ |\n",
    "| **ì¬ì‹œì‘ ì‹œ ì‚­ì œ** | ë…¸íŠ¸ë¶/ì„œë²„ ì¬ì‹œì‘ â†’ ëª¨ë“  ë°ì´í„° ì‚¬ë¼ì§ | ì‚¬ìš©ì ê²½í—˜ íŒŒê´´ |\n",
    "| **ë‹¨ì¼ ë¨¸ì‹ ** | í•œ ì„œë²„ì—ë§Œ ì €ì¥ | í™•ì¥ ë¶ˆê°€ëŠ¥ |\n",
    "| **í¬ê¸° ì œí•œ ì—†ìŒ** | ìë™ ì •ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ì—†ìŒ | ë¬´í•œ ì¦ê°€ |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… í•´ê²°ì±…: ì™¸ë¶€ DB ì—°ë™\n",
    "\n",
    "### 1. MongoDB Store (2025ë…„ ê³µì‹ ì§€ì›!)\n",
    "\n",
    "```python\n",
    "from langgraph.store.mongodb import MongoDBStore\n",
    "\n",
    "# MongoDB Atlas (ë¬´ë£Œ: 512MB)\n",
    "store = MongoDBStore(\n",
    "    connection_string=\"mongodb+srv://user:pass@cluster.mongodb.net/\",\n",
    "    database=\"agent_memory\"\n",
    ")\n",
    "```\n",
    "\n",
    "**ì¥ì **:\n",
    "- âœ… ì˜êµ¬ ì €ì¥\n",
    "- âœ… ë¬´ë£Œ í˜¸ìŠ¤íŒ… (Atlas 512MB)\n",
    "- âœ… TTL ì§€ì› (ìë™ ë§Œë£Œ)\n",
    "- âœ… í™•ì¥ ê°€ëŠ¥\n",
    "\n",
    "### 2. PostgreSQL Store (pgvector)\n",
    "\n",
    "```python\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "# Supabase (ë¬´ë£Œ: 500MB)\n",
    "store = PostgresStore(\n",
    "    connection_string=\"postgresql://user:pass@db.supabase.co:5432/postgres\"\n",
    ")\n",
    "```\n",
    "\n",
    "**ì¥ì **:\n",
    "- âœ… Semantic Search (pgvector)\n",
    "- âœ… íŠ¸ëœì­ì…˜\n",
    "- âœ… ë¬´ë£Œ (Supabase, Neon)\n",
    "\n",
    "### 3. Redis Store (ì´ˆê³ ì†)\n",
    "\n",
    "```python\n",
    "from langgraph.store.redis import RedisStore\n",
    "\n",
    "# Upstash Redis (ë¬´ë£Œ: 10GB)\n",
    "store = RedisStore(\n",
    "    url=\"redis://default:pass@us1-xxx.upstash.io:6379\"\n",
    ")\n",
    "\n",
    "# TTL ìë™ ì„¤ì •\n",
    "store.put(namespace, key, value, ttl=86400)  # 24ì‹œê°„\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”§ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë°©ë²•\n",
    "\n",
    "### 1. TTL (Time-To-Live)\n",
    "\n",
    "```python\n",
    "# Episodic: 30ì¼ í›„ ìë™ ì‚­ì œ\n",
    "store.put(\n",
    "    (\"episodes\", \"task\"),\n",
    "    key,\n",
    "    value,\n",
    "    ttl=30*24*3600  # 30ì¼ (ì´ˆ)\n",
    ")\n",
    "\n",
    "# Semantic: ì˜êµ¬ ë³´ê´€\n",
    "store.put((\"user\", user_id), \"name\", value)  # TTL ì—†ìŒ\n",
    "```\n",
    "\n",
    "### 2. í¬ê¸° ì œí•œ\n",
    "\n",
    "```python\n",
    "# ìµœì‹  100ê°œë§Œ ìœ ì§€\n",
    "episodes = list(store.search((\"episodes\", \"task\")))\n",
    "if len(episodes) > 100:\n",
    "    # ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ\n",
    "    oldest = sorted(episodes, key=lambda x: x.value['timestamp'])[:10]\n",
    "    for item in oldest:\n",
    "        store.delete((\"episodes\", \"task\"), item.key)\n",
    "```\n",
    "\n",
    "### 3. ì£¼ê¸°ì  ì •ë¦¬ (Cron)\n",
    "\n",
    "```python\n",
    "# ë§¤ì¼ ìì •ì— ì •ë¦¬\n",
    "def cleanup_old_memories():\n",
    "    cutoff = datetime.now() - timedelta(days=30)\n",
    "    \n",
    "    for item in store.search((\"episodes\", \"*\")):\n",
    "        if datetime.fromisoformat(item.value['timestamp']) < cutoff:\n",
    "            store.delete(item.namespace, item.key)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’° ë¬´ë£Œ í˜¸ìŠ¤íŒ… ì˜µì…˜\n",
    "\n",
    "| ì„œë¹„ìŠ¤ | íƒ€ì… | ë¬´ë£Œ í•œë„ | ìš©ë„ |\n",
    "|--------|------|----------|------|\n",
    "| **MongoDB Atlas** | NoSQL | 512MB | Long-term Store |\n",
    "| **Supabase** | PostgreSQL | 500MB | Short-term + Long-term |\n",
    "| **Upstash Redis** | Redis | 10GB | TTL ê´€ë¦¬ |\n",
    "| **Neon** | PostgreSQL | 3GB | Long-term Store |\n",
    "\n",
    "**ê¶Œì¥ êµ¬ì„±** (ë¬´ë£Œ!):\n",
    "```\n",
    "Short-term: Supabase PostgreSQL (MemorySaver)\n",
    "Long-term: MongoDB Atlas (Store API)\n",
    "TTL ê´€ë¦¬: Upstash Redis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š ìš”ì•½\n",
    "\n",
    "### âœ… Part 1: Short-term Memory\n",
    "\n",
    "```python\n",
    "# âŒ ìœ„í—˜\n",
    "messages: Annotated[List, add_messages]  # ë¬´í•œ ëˆ„ì !\n",
    "\n",
    "# âœ… í•´ê²°\n",
    "messages: List  # ìˆ˜ë™ ê´€ë¦¬\n",
    "recent = messages[-N:]  # Window Memory\n",
    "\n",
    "# ğŸ’¾ ì„¸ì…˜ ê´€ë¦¬\n",
    "checkpointer = MemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": user_id}}\n",
    "```\n",
    "\n",
    "### âœ… Part 2: Long-term Memory\n",
    "\n",
    "```python\n",
    "# Semantic: ì‚¬ì‹¤ ì €ì¥\n",
    "store.put((\"user\", id), \"name\", {\"value\": \"Alice\"})\n",
    "\n",
    "# Episodic: ì„±ê³µ ì‹œ ìë™ ì €ì¥\n",
    "if success:\n",
    "    store.put((\"episodes\", task), key, {\n",
    "        \"input\": ..., \"output\": ...\n",
    "    })\n",
    "\n",
    "# Procedural: ì‹¤íŒ¨ ì‹œ Reflection\n",
    "if failed:\n",
    "    improved = llm.invoke(reflection_prompt)\n",
    "    store.put((\"procedures\", task), \"rule\", {\n",
    "        \"rule\": improved, \"version\": v+1\n",
    "    })\n",
    "```\n",
    "\n",
    "### âœ… Part 3: Production\n",
    "\n",
    "- InMemoryStore (ê°œë°œ) â†’ MongoDB/PostgreSQL/Redis (Production)\n",
    "- TTL, í¬ê¸° ì œí•œìœ¼ë¡œ ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "- ë¬´ë£Œ í˜¸ìŠ¤íŒ… ì˜µì…˜ í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "**ë‹¤ìŒ**: 07-ultimate-rag-agent.ipynbì—ì„œ ëª¨ë“  ê²ƒì„ í†µí•©!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}