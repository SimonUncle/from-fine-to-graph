{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Day 3 - Gradio UI Integration with LangGraph\n",
        "# Gradio를 통한 사용자 인터페이스 래핑\n",
        "\n",
        "이 실습에서는 앞서 구축한 LangGraph 시스템들을 Gradio를 사용하여\n",
        "사용자 친화적인 웹 인터페이스로 래핑합니다.\n",
        "\n",
        "## 핵심 개념\n",
        "- Gradio 기본 사용법\n",
        "- 다중 탭 인터페이스 구성\n",
        "- 실시간 스트리밍 출력\n",
        "- 파일 업로드/다운로드\n",
        "- 사용자 세션 관리\n",
        "\n",
        "## 통합할 시스템들\n",
        "- 고급 RAG 시스템\n",
        "- Text2SQL 시스템\n",
        "- MCP 통합 시스템"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gradio langchain langgraph transformers torch chromadb sentence-transformers sqlite3 pandas yfinance wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sqlite3\n",
        "import json\n",
        "import tempfile\n",
        "import time\n",
        "from typing import List, Dict, Any, Optional, Tuple, Iterator\n",
        "from datetime import datetime\n",
        "import threading\n",
        "import queue\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# LangGraph 관련 임포트\n",
        "from langchain.schema import Document\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "print(\"라이브러리 import 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Day 1 파인튜닝 모델 및 시스템 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Day1FinetunedLLM:\n",
        "    def __init__(self, model_name=\"ryanu/my-exaone-raft-model\"):\n",
        "        self.model_name = model_name\n",
        "        self.base_model = \"LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct\"\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        \n",
        "        print(f\"모델 로딩 중: {model_name}\")\n",
        "        print(f\"사용 디바이스: {self.device}\")\n",
        "        \n",
        "        try:\n",
        "            # 토크나이저 로드\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.base_model,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            \n",
        "            # 베이스 모델 로드\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                self.base_model,\n",
        "                torch_dtype=torch.float16,\n",
        "                device_map=\"auto\",\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            \n",
        "            # 파인튜닝된 어댑터 로드\n",
        "            try:\n",
        "                self.model = PeftModel.from_pretrained(self.model, model_name)\n",
        "                print(\"✅ 파인튜닝 모델 로드 완료\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 파인튜닝 모델 로드 실패, 베이스 모델 사용: {e}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 모델 로드 실패: {e}\")\n",
        "            # 데모용으로 더미 모델 사용\n",
        "            self.model = None\n",
        "            self.tokenizer = None\n",
        "    \n",
        "    def generate(self, prompt: str, max_length: int = 512, temperature: float = 0.7) -> str:\n",
        "        \"\"\"텍스트 생성\"\"\"\n",
        "        if self.model is None:\n",
        "            # 데모용 더미 응답\n",
        "            return f\"[데모 모드] 질문 '{prompt[:50]}...'에 대한 응답입니다.\"\n",
        "        \n",
        "        try:\n",
        "            inputs = self.tokenizer(\n",
        "                prompt, \n",
        "                return_tensors=\"pt\", \n",
        "                truncation=True, \n",
        "                max_length=2048\n",
        "            ).to(self.device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_length=inputs['input_ids'].shape[1] + max_length,\n",
        "                    temperature=temperature,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "            \n",
        "            generated_text = self.tokenizer.decode(\n",
        "                outputs[0][inputs['input_ids'].shape[1]:], \n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "            \n",
        "            return generated_text.strip()\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"생성 오류: {str(e)}\"\n",
        "\n",
        "# 글로벌 모델 인스턴스\n",
        "llm = Day1FinetunedLLM()\n",
        "print(\"✅ LLM 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 간소화된 RAG 시스템"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleRAGSystem:\n",
        "    \"\"\"Gradio UI용 간소화된 RAG 시스템\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self._create_sample_documents()\n",
        "    \n",
        "    def _create_sample_documents(self):\n",
        "        \"\"\"샘플 문서 생성\"\"\"\n",
        "        sample_docs = [\n",
        "            \"머신러닝은 인공지능의 하위 분야로, 컴퓨터가 명시적으로 프로그래밍되지 않고도 학습할 수 있게 하는 기술입니다.\",\n",
        "            \"딥러닝은 인공 신경망을 사용하는 머신러닝의 특별한 형태입니다. CNN, RNN, 트랜스포머 등 다양한 아키텍처가 있습니다.\",\n",
        "            \"자연어 처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 생성할 수 있게 하는 AI 분야입니다.\",\n",
        "            \"트랜스포머는 어텐션 메커니즘만을 사용하는 신경망 아키텍처로, BERT, GPT 등의 기초가 되었습니다.\",\n",
        "            \"파인튜닝은 사전 훈련된 모델을 특정 작업에 맞게 추가로 훈련시키는 기법입니다.\",\n",
        "            \"RAG(Retrieval-Augmented Generation)는 외부 지식을 검색하여 생성 모델에 제공하는 기법입니다.\",\n",
        "            \"LangChain은 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다.\",\n",
        "            \"벡터 데이터베이스는 고차원 벡터를 효율적으로 저장하고 검색하는 데이터베이스입니다.\"\n",
        "        ]\n",
        "        \n",
        "        for i, doc in enumerate(sample_docs):\n",
        "            self.documents.append({\n",
        "                \"id\": i,\n",
        "                \"content\": doc,\n",
        "                \"metadata\": {\"topic\": \"AI\", \"source\": \"sample\"}\n",
        "            })\n",
        "    \n",
        "    def add_document(self, content: str, metadata: Dict = None):\n",
        "        \"\"\"문서 추가\"\"\"\n",
        "        doc_id = len(self.documents)\n",
        "        self.documents.append({\n",
        "            \"id\": doc_id,\n",
        "            \"content\": content,\n",
        "            \"metadata\": metadata or {}\n",
        "        })\n",
        "        return doc_id\n",
        "    \n",
        "    def search_documents(self, query: str, top_k: int = 3) -> List[Dict]:\n",
        "        \"\"\"간단한 키워드 기반 문서 검색\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        results = []\n",
        "        \n",
        "        for doc in self.documents:\n",
        "            content_lower = doc[\"content\"].lower()\n",
        "            # 간단한 키워드 매칭 점수\n",
        "            score = 0\n",
        "            for word in query_lower.split():\n",
        "                if word in content_lower:\n",
        "                    score += content_lower.count(word)\n",
        "            \n",
        "            if score > 0:\n",
        "                results.append({\n",
        "                    \"document\": doc,\n",
        "                    \"score\": score\n",
        "                })\n",
        "        \n",
        "        # 점수 기준 정렬 후 상위 k개 반환\n",
        "        results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "        return results[:top_k]\n",
        "    \n",
        "    def generate_answer(self, query: str, progress_callback=None) -> Tuple[str, List[Dict]]:\n",
        "        \"\"\"RAG 답변 생성\"\"\"\n",
        "        if progress_callback:\n",
        "            progress_callback(\"🔍 문서 검색 중...\")\n",
        "        \n",
        "        # 관련 문서 검색\n",
        "        search_results = self.search_documents(query)\n",
        "        \n",
        "        if not search_results:\n",
        "            return \"관련 문서를 찾을 수 없습니다.\", []\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(f\"📚 {len(search_results)}개 문서 발견\")\n",
        "        \n",
        "        # 컨텍스트 구성\n",
        "        context_parts = []\n",
        "        for i, result in enumerate(search_results, 1):\n",
        "            doc = result[\"document\"]\n",
        "            context_parts.append(f\"[참고자료 {i}] {doc['content']}\")\n",
        "        \n",
        "        context = \"\\n\\n\".join(context_parts)\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"🤖 답변 생성 중...\")\n",
        "        \n",
        "        # 답변 생성 프롬프트\n",
        "        prompt = f\"\"\"다음 참고자료를 바탕으로 질문에 답변해주세요.\n",
        "\n",
        "참고자료:\n",
        "{context}\n",
        "\n",
        "질문: {query}\n",
        "\n",
        "답변:\n",
        "- 참고자료의 내용을 바탕으로 정확하고 구체적으로 답변해주세요\n",
        "- 참고자료에 없는 내용은 추측하지 마세요\n",
        "\n",
        "답변:\"\"\"\n",
        "        \n",
        "        answer = llm.generate(prompt, max_length=400, temperature=0.3)\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"✅ 답변 생성 완료\")\n",
        "        \n",
        "        return answer, [r[\"document\"] for r in search_results]\n",
        "\n",
        "# RAG 시스템 초기화\n",
        "rag_system = SimpleRAGSystem()\n",
        "print(\"✅ RAG 시스템 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 간소화된 Text2SQL 시스템"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleText2SQLSystem:\n",
        "    \"\"\"Gradio UI용 간소화된 Text2SQL 시스템\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.db_path = self._create_sample_database()\n",
        "        self.schema_info = self._get_schema_info()\n",
        "    \n",
        "    def _create_sample_database(self) -> str:\n",
        "        \"\"\"샘플 데이터베이스 생성\"\"\"\n",
        "        # 임시 데이터베이스 파일 생성\n",
        "        db_path = tempfile.mktemp(suffix=\".db\")\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        # 간단한 테이블 생성\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE products (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                name TEXT,\n",
        "                price REAL,\n",
        "                category TEXT\n",
        "            )\n",
        "        ''')\n",
        "        \n",
        "        cursor.execute('''\n",
        "            CREATE TABLE orders (\n",
        "                id INTEGER PRIMARY KEY,\n",
        "                product_id INTEGER,\n",
        "                quantity INTEGER,\n",
        "                order_date TEXT,\n",
        "                FOREIGN KEY (product_id) REFERENCES products (id)\n",
        "            )\n",
        "        ''')\n",
        "        \n",
        "        # 샘플 데이터 삽입\n",
        "        products = [\n",
        "            (1, '노트북', 1200000, '전자제품'),\n",
        "            (2, '마우스', 30000, '전자제품'),\n",
        "            (3, '키보드', 80000, '전자제품'),\n",
        "            (4, '모니터', 400000, '전자제품'),\n",
        "            (5, '의자', 200000, '가구')\n",
        "        ]\n",
        "        cursor.executemany('INSERT INTO products VALUES (?, ?, ?, ?)', products)\n",
        "        \n",
        "        orders = [\n",
        "            (1, 1, 2, '2024-01-15'),\n",
        "            (2, 2, 5, '2024-01-16'),\n",
        "            (3, 3, 3, '2024-01-17'),\n",
        "            (4, 1, 1, '2024-01-18'),\n",
        "            (5, 4, 2, '2024-01-19')\n",
        "        ]\n",
        "        cursor.executemany('INSERT INTO orders VALUES (?, ?, ?, ?)', orders)\n",
        "        \n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        \n",
        "        return db_path\n",
        "    \n",
        "    def _get_schema_info(self) -> str:\n",
        "        \"\"\"스키마 정보 가져오기\"\"\"\n",
        "        return \"\"\"데이터베이스 스키마:\n",
        "\n",
        "테이블: products\n",
        "- id: INTEGER (기본키)\n",
        "- name: TEXT (상품명)\n",
        "- price: REAL (가격)\n",
        "- category: TEXT (카테고리)\n",
        "\n",
        "테이블: orders\n",
        "- id: INTEGER (기본키)\n",
        "- product_id: INTEGER (상품 ID, products.id 참조)\n",
        "- quantity: INTEGER (수량)\n",
        "- order_date: TEXT (주문 날짜)\n",
        "\n",
        "관계: orders.product_id → products.id\"\"\"\n",
        "    \n",
        "    def generate_sql(self, question: str, progress_callback=None) -> Tuple[str, pd.DataFrame, str]:\n",
        "        \"\"\"자연어 질문을 SQL로 변환하고 실행\"\"\"\n",
        "        if progress_callback:\n",
        "            progress_callback(\"🧠 질문 분석 중...\")\n",
        "        \n",
        "        # SQL 생성 프롬프트\n",
        "        prompt = f\"\"\"다음 데이터베이스 스키마를 바탕으로 자연어 질문을 SQL 쿼리로 변환해주세요.\n",
        "\n",
        "{self.schema_info}\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "SQLite 문법을 사용하여 SQL 쿼리만 생성해주세요.\n",
        "\n",
        "SQL:\"\"\"\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"🔄 SQL 생성 중...\")\n",
        "        \n",
        "        sql_query = llm.generate(prompt, max_length=200, temperature=0.1)\n",
        "        \n",
        "        # SQL 정제\n",
        "        sql_query = sql_query.split('\\n')[0].strip()\n",
        "        if sql_query.endswith(';'):\n",
        "            sql_query = sql_query[:-1]\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"⚡ SQL 실행 중...\")\n",
        "        \n",
        "        # SQL 실행\n",
        "        try:\n",
        "            conn = sqlite3.connect(self.db_path)\n",
        "            result_df = pd.read_sql_query(sql_query, conn)\n",
        "            conn.close()\n",
        "            \n",
        "            if progress_callback:\n",
        "                progress_callback(f\"✅ 완료: {len(result_df)}개 행 반환\")\n",
        "            \n",
        "            return sql_query, result_df, \"성공\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"SQL 실행 오류: {str(e)}\"\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"❌ 오류: {error_msg}\")\n",
        "            \n",
        "            return sql_query, pd.DataFrame(), error_msg\n",
        "\n",
        "# Text2SQL 시스템 초기화\n",
        "text2sql_system = SimpleText2SQLSystem()\n",
        "print(\"✅ Text2SQL 시스템 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 간소화된 MCP 시스템"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleMCPSystem:\n",
        "    \"\"\"Gradio UI용 간소화된 MCP 시스템\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.tools = {\n",
        "            \"calculator\": self._calculator,\n",
        "            \"weather\": self._weather,\n",
        "            \"search\": self._search\n",
        "        }\n",
        "    \n",
        "    def _calculator(self, expression: str) -> Dict[str, Any]:\n",
        "        \"\"\"계산기 도구\"\"\"\n",
        "        try:\n",
        "            # 안전한 계산을 위해 허용된 문자만 사용\n",
        "            allowed_chars = set('0123456789+-*/.() ')\n",
        "            if not all(c in allowed_chars for c in expression):\n",
        "                return {\"success\": False, \"error\": \"허용되지 않은 문자\"}\n",
        "            \n",
        "            result = eval(expression)\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"expression\": expression,\n",
        "                \"result\": result\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": str(e)}\n",
        "    \n",
        "    def _weather(self, city: str) -> Dict[str, Any]:\n",
        "        \"\"\"날씨 도구 (시뮬레이션)\"\"\"\n",
        "        weather_data = {\n",
        "            \"서울\": {\"temp\": 15, \"desc\": \"맑음\"},\n",
        "            \"부산\": {\"temp\": 18, \"desc\": \"구름많음\"},\n",
        "            \"제주\": {\"temp\": 20, \"desc\": \"비\"}\n",
        "        }\n",
        "        \n",
        "        if city in weather_data:\n",
        "            data = weather_data[city]\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"city\": city,\n",
        "                \"temperature\": data[\"temp\"],\n",
        "                \"description\": data[\"desc\"]\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"city\": city,\n",
        "                \"temperature\": 22,\n",
        "                \"description\": \"맑음\"\n",
        "            }\n",
        "    \n",
        "    def _search(self, query: str) -> Dict[str, Any]:\n",
        "        \"\"\"검색 도구 (시뮬레이션)\"\"\"\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"query\": query,\n",
        "            \"results\": [\n",
        "                f\"{query}에 대한 검색 결과 1\",\n",
        "                f\"{query}에 대한 검색 결과 2\",\n",
        "                f\"{query}에 대한 검색 결과 3\"\n",
        "            ]\n",
        "        }\n",
        "    \n",
        "    def process_query(self, query: str, progress_callback=None) -> str:\n",
        "        \"\"\"쿼리 처리\"\"\"\n",
        "        if progress_callback:\n",
        "            progress_callback(\"🧠 쿼리 분석 중...\")\n",
        "        \n",
        "        query_lower = query.lower()\n",
        "        results = []\n",
        "        \n",
        "        # 간단한 키워드 기반 도구 선택\n",
        "        if any(word in query_lower for word in ['계산', '+', '-', '*', '/', '더하기', '빼기']):\n",
        "            if progress_callback:\n",
        "                progress_callback(\"🧮 계산기 실행 중...\")\n",
        "            \n",
        "            # 수식 추출 (간단한 방식)\n",
        "            import re\n",
        "            math_pattern = r'[0-9+\\-*/().\\s]+'\n",
        "            matches = re.findall(math_pattern, query)\n",
        "            \n",
        "            expression = None\n",
        "            for match in matches:\n",
        "                if any(op in match for op in ['+', '-', '*', '/']):\n",
        "                    expression = match.strip()\n",
        "                    break\n",
        "            \n",
        "            if expression:\n",
        "                result = self._calculator(expression)\n",
        "                if result[\"success\"]:\n",
        "                    results.append(f\"계산 결과: {expression} = {result['result']}\")\n",
        "                else:\n",
        "                    results.append(f\"계산 오류: {result['error']}\")\n",
        "        \n",
        "        if any(word in query_lower for word in ['날씨', 'weather']):\n",
        "            if progress_callback:\n",
        "                progress_callback(\"🌤 날씨 정보 조회 중...\")\n",
        "            \n",
        "            cities = ['서울', '부산', '대구', '인천', '제주']\n",
        "            city = \"서울\"  # 기본값\n",
        "            \n",
        "            for c in cities:\n",
        "                if c in query:\n",
        "                    city = c\n",
        "                    break\n",
        "            \n",
        "            result = self._weather(city)\n",
        "            if result[\"success\"]:\n",
        "                results.append(f\"{city} 날씨: {result['temperature']}°C, {result['description']}\")\n",
        "        \n",
        "        if any(word in query_lower for word in ['검색', '찾아', '알려']):\n",
        "            if progress_callback:\n",
        "                progress_callback(\"🔍 검색 중...\")\n",
        "            \n",
        "            result = self._search(query)\n",
        "            if result[\"success\"]:\n",
        "                results.append(f\"검색 결과: {', '.join(result['results'])}\")\n",
        "        \n",
        "        if not results:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"💬 기본 응답 생성 중...\")\n",
        "            \n",
        "            # 기본 응답 생성\n",
        "            prompt = f\"다음 질문에 간단히 답변해주세요: {query}\"\n",
        "            response = llm.generate(prompt, max_length=200, temperature=0.5)\n",
        "            results.append(response)\n",
        "        \n",
        "        if progress_callback:\n",
        "            progress_callback(\"✅ 처리 완료\")\n",
        "        \n",
        "        return \"\\n\\n\".join(results)\n",
        "\n",
        "# MCP 시스템 초기화\n",
        "mcp_system = SimpleMCPSystem()\n",
        "print(\"✅ MCP 시스템 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 채팅 기록 관리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChatHistory:\n",
        "    \"\"\"채팅 기록 관리 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.histories = {\n",
        "            \"rag\": [],\n",
        "            \"text2sql\": [],\n",
        "            \"mcp\": []\n",
        "        }\n",
        "    \n",
        "    def add_message(self, system: str, user_msg: str, bot_msg: str):\n",
        "        \"\"\"메시지 추가\"\"\"\n",
        "        if system in self.histories:\n",
        "            self.histories[system].append([user_msg, bot_msg])\n",
        "    \n",
        "    def get_history(self, system: str) -> List[List[str]]:\n",
        "        \"\"\"특정 시스템의 채팅 기록 반환\"\"\"\n",
        "        return self.histories.get(system, [])\n",
        "    \n",
        "    def clear_history(self, system: str):\n",
        "        \"\"\"특정 시스템의 채팅 기록 삭제\"\"\"\n",
        "        if system in self.histories:\n",
        "            self.histories[system] = []\n",
        "    \n",
        "    def export_history(self, system: str) -> str:\n",
        "        \"\"\"채팅 기록을 텍스트로 내보내기\"\"\"\n",
        "        history = self.get_history(system)\n",
        "        if not history:\n",
        "            return f\"{system} 시스템의 채팅 기록이 없습니다.\"\n",
        "        \n",
        "        export_text = f\"{system.upper()} 시스템 채팅 기록\\n\"\n",
        "        export_text += f\"내보낸 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
        "        export_text += \"=\" * 50 + \"\\n\\n\"\n",
        "        \n",
        "        for i, (user_msg, bot_msg) in enumerate(history, 1):\n",
        "            export_text += f\"[{i}] 사용자: {user_msg}\\n\"\n",
        "            export_text += f\"[{i}] 시스템: {bot_msg}\\n\\n\"\n",
        "        \n",
        "        return export_text\n",
        "\n",
        "# 글로벌 채팅 기록 관리자\n",
        "chat_history = ChatHistory()\n",
        "print(\"✅ 채팅 기록 관리자 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Gradio 인터페이스 함수들"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rag_chat_fn(message: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:\n",
        "    \"\"\"RAG 채팅 함수\"\"\"\n",
        "    if not message.strip():\n",
        "        return \"\", history\n",
        "    \n",
        "    try:\n",
        "        # 진행 상황을 위한 임시 응답\n",
        "        temp_response = \"🔍 문서를 검색하고 답변을 생성 중입니다...\"\n",
        "        \n",
        "        # RAG 시스템으로 답변 생성\n",
        "        answer, documents = rag_system.generate_answer(message)\n",
        "        \n",
        "        # 참고 문서 정보 추가\n",
        "        if documents:\n",
        "            doc_info = \"\\n\\n📚 참고 문서:\\n\"\n",
        "            for i, doc in enumerate(documents, 1):\n",
        "                doc_info += f\"{i}. {doc['content'][:100]}...\\n\"\n",
        "            answer += doc_info\n",
        "        \n",
        "        # 채팅 기록에 추가\n",
        "        chat_history.add_message(\"rag\", message, answer)\n",
        "        \n",
        "        # 히스토리 업데이트\n",
        "        new_history = history + [[message, answer]]\n",
        "        \n",
        "        return \"\", new_history\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"오류가 발생했습니다: {str(e)}\"\n",
        "        new_history = history + [[message, error_msg]]\n",
        "        return \"\", new_history\n",
        "\n",
        "def text2sql_chat_fn(message: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:\n",
        "    \"\"\"Text2SQL 채팅 함수\"\"\"\n",
        "    if not message.strip():\n",
        "        return \"\", history\n",
        "    \n",
        "    try:\n",
        "        # SQL 생성 및 실행\n",
        "        sql_query, result_df, status = text2sql_system.generate_sql(message)\n",
        "        \n",
        "        # 응답 구성\n",
        "        response = f\"🔍 생성된 SQL:\\n```sql\\n{sql_query}\\n```\\n\\n\"\n",
        "        \n",
        "        if status == \"성공\":\n",
        "            if not result_df.empty:\n",
        "                response += f\"📊 결과 ({len(result_df)}개 행):\\n{result_df.to_string(index=False)}\\n\\n\"\n",
        "                \n",
        "                # 결과 해석\n",
        "                interpretation_prompt = f\"\"\"다음 SQL 쿼리와 결과를 바탕으로 사용자 질문에 대한 자연어 답변을 생성해주세요.\n",
        "                \n",
        "질문: {message}\n",
        "SQL: {sql_query}\n",
        "결과: {result_df.to_string()}\n",
        "\n",
        "자연어 답변:\"\"\"\n",
        "                \n",
        "                interpretation = llm.generate(interpretation_prompt, max_length=200)\n",
        "                response += f\"💬 해석: {interpretation}\"\n",
        "            else:\n",
        "                response += \"📊 결과: 데이터가 없습니다.\"\n",
        "        else:\n",
        "            response += f\"❌ 오류: {status}\"\n",
        "        \n",
        "        # 채팅 기록에 추가\n",
        "        chat_history.add_message(\"text2sql\", message, response)\n",
        "        \n",
        "        # 히스토리 업데이트\n",
        "        new_history = history + [[message, response]]\n",
        "        \n",
        "        return \"\", new_history\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"오류가 발생했습니다: {str(e)}\"\n",
        "        new_history = history + [[message, error_msg]]\n",
        "        return \"\", new_history\n",
        "\n",
        "def mcp_chat_fn(message: str, history: List[List[str]]) -> Tuple[str, List[List[str]]]:\n",
        "    \"\"\"MCP 채팅 함수\"\"\"\n",
        "    if not message.strip():\n",
        "        return \"\", history\n",
        "    \n",
        "    try:\n",
        "        # MCP 시스템으로 처리\n",
        "        response = mcp_system.process_query(message)\n",
        "        \n",
        "        # 채팅 기록에 추가\n",
        "        chat_history.add_message(\"mcp\", message, response)\n",
        "        \n",
        "        # 히스토리 업데이트\n",
        "        new_history = history + [[message, response]]\n",
        "        \n",
        "        return \"\", new_history\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_msg = f\"오류가 발생했습니다: {str(e)}\"\n",
        "        new_history = history + [[message, error_msg]]\n",
        "        return \"\", new_history\n",
        "\n",
        "def add_document_fn(content: str) -> str:\n",
        "    \"\"\"RAG 시스템에 문서 추가\"\"\"\n",
        "    if not content.strip():\n",
        "        return \"❌ 빈 문서는 추가할 수 없습니다.\"\n",
        "    \n",
        "    try:\n",
        "        doc_id = rag_system.add_document(content)\n",
        "        return f\"✅ 문서가 성공적으로 추가되었습니다. (ID: {doc_id})\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ 문서 추가 중 오류가 발생했습니다: {str(e)}\"\n",
        "\n",
        "def export_chat_history_fn(system: str) -> str:\n",
        "    \"\"\"채팅 기록 내보내기\"\"\"\n",
        "    return chat_history.export_history(system)\n",
        "\n",
        "def clear_chat_history_fn(system: str) -> str:\n",
        "    \"\"\"채팅 기록 삭제\"\"\"\n",
        "    chat_history.clear_history(system)\n",
        "    return f\"{system} 시스템의 채팅 기록이 삭제되었습니다.\"\n",
        "\n",
        "print(\"✅ Gradio 인터페이스 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Gradio 인터페이스 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_gradio_interface():\n",
        "    \"\"\"Gradio 인터페이스 생성\"\"\"\n",
        "    \n",
        "    # 커스텀 CSS\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Arial', sans-serif !important;\n",
        "    }\n",
        "    \n",
        "    .chat-message {\n",
        "        padding: 10px;\n",
        "        margin: 5px 0;\n",
        "        border-radius: 10px;\n",
        "    }\n",
        "    \n",
        "    .user-message {\n",
        "        background-color: #e3f2fd;\n",
        "        text-align: right;\n",
        "    }\n",
        "    \n",
        "    .bot-message {\n",
        "        background-color: #f5f5f5;\n",
        "        text-align: left;\n",
        "    }\n",
        "    \"\"\"\n",
        "    \n",
        "    # 메인 인터페이스\n",
        "    with gr.Blocks(\n",
        "        title=\"🚀 Day 3: LangGraph + Gradio 통합 시스템\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        css=custom_css\n",
        "    ) as demo:\n",
        "        \n",
        "        # 헤더\n",
        "        gr.Markdown(\"\"\"\n",
        "        # 🚀 Day 3: LangGraph + Gradio 통합 시스템\n",
        "        \n",
        "        Day 1에서 파인튜닝한 EXAONE 모델과 LangGraph를 활용한 통합 AI 시스템입니다.\n",
        "        \n",
        "        ## 🔧 시스템 구성\n",
        "        - **RAG 시스템**: 문서 검색 기반 질의응답\n",
        "        - **Text2SQL 시스템**: 자연어를 SQL로 변환하여 데이터베이스 조회\n",
        "        - **MCP 통합 시스템**: 다양한 외부 도구를 활용한 멀티태스킹\n",
        "        \"\"\")\n",
        "        \n",
        "        # 탭 구성\n",
        "        with gr.Tabs() as tabs:\n",
        "            \n",
        "            # RAG 시스템 탭\n",
        "            with gr.TabItem(\"📚 RAG 시스템\", id=\"rag_tab\"):\n",
        "                gr.Markdown(\"### 📚 고급 RAG (Retrieval-Augmented Generation) 시스템\")\n",
        "                gr.Markdown(\n",
        "                    \"문서를 검색하여 컨텍스트를 제공하고, Day 1 파인튜닝 모델로 답변을 생성합니다.\"\n",
        "                )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=3):\n",
        "                        rag_chatbot = gr.Chatbot(\n",
        "                            label=\"RAG 대화\",\n",
        "                            height=400,\n",
        "                            show_copy_button=True\n",
        "                        )\n",
        "                        rag_msg = gr.Textbox(\n",
        "                            label=\"메시지\",\n",
        "                            placeholder=\"AI나 머신러닝에 대해 질문해보세요...\",\n",
        "                            lines=2\n",
        "                        )\n",
        "                        \n",
        "                        with gr.Row():\n",
        "                            rag_send_btn = gr.Button(\"📤 전송\", variant=\"primary\")\n",
        "                            rag_clear_btn = gr.Button(\"🗑 대화 지우기\", variant=\"secondary\")\n",
        "                    \n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"#### 📄 문서 관리\")\n",
        "                        doc_input = gr.Textbox(\n",
        "                            label=\"새 문서 추가\",\n",
        "                            placeholder=\"새로운 문서 내용을 입력하세요...\",\n",
        "                            lines=5\n",
        "                        )\n",
        "                        add_doc_btn = gr.Button(\"➕ 문서 추가\", variant=\"secondary\")\n",
        "                        doc_status = gr.Textbox(\n",
        "                            label=\"상태\",\n",
        "                            interactive=False,\n",
        "                            lines=2\n",
        "                        )\n",
        "                        \n",
        "                        gr.Markdown(\"#### 💾 기록 관리\")\n",
        "                        rag_export_btn = gr.Button(\"📥 대화 내보내기\")\n",
        "                        rag_export_output = gr.Textbox(\n",
        "                            label=\"내보낸 대화\",\n",
        "                            lines=5,\n",
        "                            max_lines=10\n",
        "                        )\n",
        "            \n",
        "            # Text2SQL 시스템 탭\n",
        "            with gr.TabItem(\"🗄 Text2SQL 시스템\", id=\"sql_tab\"):\n",
        "                gr.Markdown(\"### 🗄 Text-to-SQL 시스템\")\n",
        "                gr.Markdown(\n",
        "                    \"자연어 질문을 SQL 쿼리로 변환하고 데이터베이스에서 정보를 조회합니다.\"\n",
        "                )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=3):\n",
        "                        sql_chatbot = gr.Chatbot(\n",
        "                            label=\"Text2SQL 대화\",\n",
        "                            height=400,\n",
        "                            show_copy_button=True\n",
        "                        )\n",
        "                        sql_msg = gr.Textbox(\n",
        "                            label=\"데이터 질문\",\n",
        "                            placeholder=\"예: 가장 비싼 상품은 무엇인가요? 전자제품 카테고리의 총 주문 수량은?\",\n",
        "                            lines=2\n",
        "                        )\n",
        "                        \n",
        "                        with gr.Row():\n",
        "                            sql_send_btn = gr.Button(\"📤 질문하기\", variant=\"primary\")\n",
        "                            sql_clear_btn = gr.Button(\"🗑 대화 지우기\", variant=\"secondary\")\n",
        "                    \n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"#### 🏗 데이터베이스 스키마\")\n",
        "                        schema_display = gr.Textbox(\n",
        "                            value=text2sql_system.schema_info,\n",
        "                            label=\"스키마 정보\",\n",
        "                            interactive=False,\n",
        "                            lines=12,\n",
        "                            max_lines=15\n",
        "                        )\n",
        "                        \n",
        "                        gr.Markdown(\"#### 💾 기록 관리\")\n",
        "                        sql_export_btn = gr.Button(\"📥 대화 내보내기\")\n",
        "                        sql_export_output = gr.Textbox(\n",
        "                            label=\"내보낸 대화\",\n",
        "                            lines=5,\n",
        "                            max_lines=10\n",
        "                        )\n",
        "            \n",
        "            # MCP 시스템 탭\n",
        "            with gr.TabItem(\"🔧 MCP 통합 시스템\", id=\"mcp_tab\"):\n",
        "                gr.Markdown(\"### 🔧 MCP (Model Context Protocol) 통합 시스템\")\n",
        "                gr.Markdown(\n",
        "                    \"계산기, 날씨, 검색 등 다양한 외부 도구를 자동으로 선택하여 활용합니다.\"\n",
        "                )\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=3):\n",
        "                        mcp_chatbot = gr.Chatbot(\n",
        "                            label=\"MCP 대화\",\n",
        "                            height=400,\n",
        "                            show_copy_button=True\n",
        "                        )\n",
        "                        mcp_msg = gr.Textbox(\n",
        "                            label=\"멀티 태스크 요청\",\n",
        "                            placeholder=\"예: 123 + 456을 계산해주고, 서울 날씨도 알려주세요\",\n",
        "                            lines=2\n",
        "                        )\n",
        "                        \n",
        "                        with gr.Row():\n",
        "                            mcp_send_btn = gr.Button(\"📤 실행하기\", variant=\"primary\")\n",
        "                            mcp_clear_btn = gr.Button(\"🗑 대화 지우기\", variant=\"secondary\")\n",
        "                    \n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"#### 🛠 사용 가능한 도구들\")\n",
        "                        tools_info = gr.Markdown(\n",
        "                            \"\"\"\n",
        "                            **🧮 계산기**\n",
        "                            - 기본 수학 연산 (+, -, *, /)\n",
        "                            - 예: \"123 + 456 계산해줘\"\n",
        "                            \n",
        "                            **🌤 날씨 정보**\n",
        "                            - 한국 주요 도시 날씨\n",
        "                            - 예: \"서울 날씨 어때?\"\n",
        "                            \n",
        "                            **🔍 웹 검색**\n",
        "                            - 키워드 기반 정보 검색\n",
        "                            - 예: \"인공지능 정보 검색해줘\"\n",
        "                            \"\"\"\n",
        "                        )\n",
        "                        \n",
        "                        gr.Markdown(\"#### 💾 기록 관리\")\n",
        "                        mcp_export_btn = gr.Button(\"📥 대화 내보내기\")\n",
        "                        mcp_export_output = gr.Textbox(\n",
        "                            label=\"내보낸 대화\",\n",
        "                            lines=5,\n",
        "                            max_lines=10\n",
        "                        )\n",
        "            \n",
        "            # 시스템 정보 탭\n",
        "            with gr.TabItem(\"ℹ️ 시스템 정보\", id=\"info_tab\"):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ### 🔧 시스템 아키텍처\n",
        "                \n",
        "                #### 🧠 핵심 기술 스택\n",
        "                - **Day 1 파인튜닝 모델**: `ryanu/my-exaone-raft-model`\n",
        "                - **LangGraph**: 복잡한 워크플로 구성\n",
        "                - **Gradio**: 사용자 인터페이스\n",
        "                - **ChromaDB**: 벡터 데이터베이스 (RAG)\n",
        "                - **SQLite**: 관계형 데이터베이스 (Text2SQL)\n",
        "                \n",
        "                #### 📊 성능 특징\n",
        "                - **다중 시스템 통합**: 3개의 AI 시스템을 하나의 인터페이스로\n",
        "                - **실시간 처리**: 사용자 요청에 즉시 응답\n",
        "                - **확장 가능성**: 새로운 도구와 기능 추가 용이\n",
        "                - **사용자 친화적**: 직관적인 웹 인터페이스\n",
        "                \n",
        "                #### 🚀 활용 사례\n",
        "                1. **교육 도구**: AI 개념 학습 및 실습\n",
        "                2. **데이터 분석**: 자연어로 데이터베이스 조회\n",
        "                3. **업무 자동화**: 다양한 도구를 통합한 작업 처리\n",
        "                4. **연구 도구**: 정보 검색 및 문서 분석\n",
        "                \n",
        "                #### 🛠 기술적 구현\n",
        "                - **모듈화된 설계**: 각 시스템이 독립적으로 동작\n",
        "                - **오류 처리**: 견고한 예외 처리 및 복구\n",
        "                - **메모리 최적화**: 효율적인 리소스 관리\n",
        "                - **확장성**: 새로운 기능 추가 용이\n",
        "                \n",
        "                ---\n",
        "                \n",
        "                **💡 개발자 정보**\n",
        "                - 이 시스템은 Day 1-3 통합 실습 프로젝트입니다.\n",
        "                - 파인튜닝 → RAG → 고급 LangGraph 워크플로 → UI 래핑 과정을 완성했습니다.\n",
        "                \"\"\")\n",
        "                \n",
        "                gr.Markdown(\"\"\"\n",
        "                ### 📈 사용 통계\n",
        "                \"\"\")\n",
        "                \n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"#### RAG 시스템\")\n",
        "                        rag_docs_count = gr.Number(\n",
        "                            value=len(rag_system.documents),\n",
        "                            label=\"등록된 문서 수\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "                    \n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"#### Text2SQL 시스템\")\n",
        "                        sql_tables_count = gr.Number(\n",
        "                            value=2,  # products, orders\n",
        "                            label=\"데이터베이스 테이블 수\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "                    \n",
        "                    with gr.Column():\n",
        "                        gr.Markdown(\"#### MCP 시스템\")\n",
        "                        mcp_tools_count = gr.Number(\n",
        "                            value=len(mcp_system.tools),\n",
        "                            label=\"사용 가능한 도구 수\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "        \n",
        "        # 이벤트 핸들러 연결\n",
        "        \n",
        "        # RAG 시스템 이벤트\n",
        "        rag_msg.submit(\n",
        "            rag_chat_fn,\n",
        "            inputs=[rag_msg, rag_chatbot],\n",
        "            outputs=[rag_msg, rag_chatbot]\n",
        "        )\n",
        "        rag_send_btn.click(\n",
        "            rag_chat_fn,\n",
        "            inputs=[rag_msg, rag_chatbot],\n",
        "            outputs=[rag_msg, rag_chatbot]\n",
        "        )\n",
        "        rag_clear_btn.click(\n",
        "            lambda: ([], \"RAG 대화 기록이 지워졌습니다.\"),\n",
        "            outputs=[rag_chatbot, doc_status]\n",
        "        )\n",
        "        add_doc_btn.click(\n",
        "            add_document_fn,\n",
        "            inputs=[doc_input],\n",
        "            outputs=[doc_status]\n",
        "        )\n",
        "        rag_export_btn.click(\n",
        "            lambda: export_chat_history_fn(\"rag\"),\n",
        "            outputs=[rag_export_output]\n",
        "        )\n",
        "        \n",
        "        # Text2SQL 시스템 이벤트\n",
        "        sql_msg.submit(\n",
        "            text2sql_chat_fn,\n",
        "            inputs=[sql_msg, sql_chatbot],\n",
        "            outputs=[sql_msg, sql_chatbot]\n",
        "        )\n",
        "        sql_send_btn.click(\n",
        "            text2sql_chat_fn,\n",
        "            inputs=[sql_msg, sql_chatbot],\n",
        "            outputs=[sql_msg, sql_chatbot]\n",
        "        )\n",
        "        sql_clear_btn.click(\n",
        "            lambda: [],\n",
        "            outputs=[sql_chatbot]\n",
        "        )\n",
        "        sql_export_btn.click(\n",
        "            lambda: export_chat_history_fn(\"text2sql\"),\n",
        "            outputs=[sql_export_output]\n",
        "        )\n",
        "        \n",
        "        # MCP 시스템 이벤트\n",
        "        mcp_msg.submit(\n",
        "            mcp_chat_fn,\n",
        "            inputs=[mcp_msg, mcp_chatbot],\n",
        "            outputs=[mcp_msg, mcp_chatbot]\n",
        "        )\n",
        "        mcp_send_btn.click(\n",
        "            mcp_chat_fn,\n",
        "            inputs=[mcp_msg, mcp_chatbot],\n",
        "            outputs=[mcp_msg, mcp_chatbot]\n",
        "        )\n",
        "        mcp_clear_btn.click(\n",
        "            lambda: [],\n",
        "            outputs=[mcp_chatbot]\n",
        "        )\n",
        "        mcp_export_btn.click(\n",
        "            lambda: export_chat_history_fn(\"mcp\"),\n",
        "            outputs=[mcp_export_output]\n",
        "        )\n",
        "    \n",
        "    return demo\n",
        "\n",
        "print(\"✅ Gradio 인터페이스 구성 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 시스템 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 Day 3: LangGraph + Gradio 통합 시스템 시작\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 시스템 상태 확인\n",
        "    print(f\"📚 RAG 시스템: {len(rag_system.documents)}개 문서 로드됨\")\n",
        "    print(f\"🗄 Text2SQL 시스템: 데이터베이스 연결됨\")\n",
        "    print(f\"🔧 MCP 시스템: {len(mcp_system.tools)}개 도구 사용 가능\")\n",
        "    print(f\"🧠 LLM 모델: {llm.model_name}\")\n",
        "    \n",
        "    # Gradio 인터페이스 생성 및 실행\n",
        "    demo = create_gradio_interface()\n",
        "    \n",
        "    print(\"\\n🌐 웹 인터페이스를 실행합니다...\")\n",
        "    print(\"브라우저에서 자동으로 열립니다.\")\n",
        "    print(\"\\n💡 사용 방법:\")\n",
        "    print(\"1. 📚 RAG 탭: AI 관련 질문을 하고 문서를 추가해보세요\")\n",
        "    print(\"2. 🗄 Text2SQL 탭: 자연어로 데이터베이스를 조회해보세요\")\n",
        "    print(\"3. 🔧 MCP 탭: 계산, 날씨, 검색 등을 요청해보세요\")\n",
        "    print(\"4. ℹ️ 시스템 정보 탭: 시스템 구조와 통계를 확인하세요\")\n",
        "    \n",
        "    # 인터페이스 실행\n",
        "    demo.launch(\n",
        "        server_name=\"0.0.0.0\",  # 모든 IP에서 접근 가능\n",
        "        server_port=7860,       # 포트 설정\n",
        "        share=False,            # 공개 링크 생성하지 않음 (로컬 사용)\n",
        "        inbrowser=True,         # 브라우저에서 자동으로 열기\n",
        "        show_tips=True,         # 팁 표시\n",
        "        enable_queue=True       # 큐 시스템 활성화\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 고급 기능: 파일 업로드 및 내보내기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 파일 처리 함수들\n",
        "def process_uploaded_file(file_path: str) -> str:\n",
        "    \"\"\"업로드된 파일 처리\"\"\"\n",
        "    if not file_path:\n",
        "        return \"파일이 선택되지 않았습니다.\"\n",
        "    \n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "        \n",
        "        # 문서를 RAG 시스템에 추가\n",
        "        doc_id = rag_system.add_document(content, {\"source\": \"uploaded_file\"})\n",
        "        \n",
        "        return f\"✅ 파일이 성공적으로 처리되었습니다. (문서 ID: {doc_id})\\n내용 길이: {len(content)} 글자\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"❌ 파일 처리 중 오류가 발생했습니다: {str(e)}\"\n",
        "\n",
        "def download_chat_history(system: str):\n",
        "    \"\"\"채팅 기록을 파일로 다운로드\"\"\"\n",
        "    history_text = chat_history.export_history(system)\n",
        "    \n",
        "    # 임시 파일 생성\n",
        "    temp_file = tempfile.NamedTemporaryFile(\n",
        "        mode='w',\n",
        "        encoding='utf-8',\n",
        "        suffix=f'_{system}_history.txt',\n",
        "        delete=False\n",
        "    )\n",
        "    \n",
        "    temp_file.write(history_text)\n",
        "    temp_file.close()\n",
        "    \n",
        "    return temp_file.name\n",
        "\n",
        "print(\"✅ 파일 처리 함수 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 시스템 모니터링 및 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SystemMonitor:\n",
        "    \"\"\"시스템 모니터링 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.start_time = datetime.now()\n",
        "        self.stats = {\n",
        "            \"rag_queries\": 0,\n",
        "            \"sql_queries\": 0,\n",
        "            \"mcp_queries\": 0,\n",
        "            \"total_errors\": 0,\n",
        "            \"documents_added\": 0\n",
        "        }\n",
        "    \n",
        "    def log_query(self, system: str, success: bool = True):\n",
        "        \"\"\"쿼리 로깅\"\"\"\n",
        "        if system in [\"rag\", \"sql\", \"mcp\"]:\n",
        "            self.stats[f\"{system}_queries\"] += 1\n",
        "        \n",
        "        if not success:\n",
        "            self.stats[\"total_errors\"] += 1\n",
        "    \n",
        "    def log_document_added(self):\n",
        "        \"\"\"문서 추가 로깅\"\"\"\n",
        "        self.stats[\"documents_added\"] += 1\n",
        "    \n",
        "    def get_stats(self) -> Dict[str, Any]:\n",
        "        \"\"\"통계 반환\"\"\"\n",
        "        runtime = datetime.now() - self.start_time\n",
        "        \n",
        "        return {\n",
        "            **self.stats,\n",
        "            \"runtime_minutes\": runtime.total_seconds() / 60,\n",
        "            \"total_queries\": sum([\n",
        "                self.stats[\"rag_queries\"],\n",
        "                self.stats[\"sql_queries\"],\n",
        "                self.stats[\"mcp_queries\"]\n",
        "            ])\n",
        "        }\n",
        "    \n",
        "    def get_performance_report(self) -> str:\n",
        "        \"\"\"성능 리포트 생성\"\"\"\n",
        "        stats = self.get_stats()\n",
        "        \n",
        "        report = f\"\"\"🔍 시스템 성능 리포트\n",
        "==========================================\n",
        "\n",
        "⏱️ 실행 시간: {stats['runtime_minutes']:.1f}분\n",
        "📊 총 쿼리 수: {stats['total_queries']}개\n",
        "\n",
        "📚 RAG 시스템: {stats['rag_queries']}개 쿼리\n",
        "🗄️ Text2SQL 시스템: {stats['sql_queries']}개 쿼리  \n",
        "🔧 MCP 시스템: {stats['mcp_queries']}개 쿼리\n",
        "\n",
        "📄 추가된 문서: {stats['documents_added']}개\n",
        "❌ 총 오류: {stats['total_errors']}개\n",
        "\n",
        "💡 성공률: {(stats['total_queries'] - stats['total_errors']) / max(stats['total_queries'], 1) * 100:.1f}%\n",
        "\"\"\"\n",
        "        \n",
        "        return report\n",
        "\n",
        "# 글로벌 모니터링 인스턴스\n",
        "system_monitor = SystemMonitor()\n",
        "print(\"✅ 시스템 모니터링 초기화 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 실습 완료 및 다음 단계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\"\"🎓 Day 3 - Gradio UI 통합 실습 완료!\n",
        "\n",
        "🏆 달성한 목표:\n",
        "✅ Day 1 파인튜닝 모델을 모든 시스템에 통합\n",
        "✅ 고급 RAG 시스템 구현 및 UI 연동\n",
        "✅ Text2SQL 시스템 구현 및 UI 연동  \n",
        "✅ MCP 통합 시스템 구현 및 UI 연동\n",
        "✅ 사용자 친화적인 웹 인터페이스 구축\n",
        "✅ 실시간 채팅 및 기록 관리 기능\n",
        "✅ 시스템 모니터링 및 성능 분석\n",
        "\n",
        "🌟 핵심 학습 내용:\n",
        "1. **모델 통합**: 파인튜닝 모델의 실제 활용\n",
        "2. **워크플로 설계**: LangGraph를 통한 복잡한 AI 워크플로\n",
        "3. **UI 설계**: Gradio를 통한 전문적인 웹 인터페이스\n",
        "4. **시스템 통합**: 여러 AI 시스템의 효과적인 통합\n",
        "5. **사용자 경험**: 직관적이고 실용적인 UX 설계\n",
        "\n",
        "🚀 실제 활용 가능성:\n",
        "- 기업용 AI 어시스턴트 시스템\n",
        "- 교육용 AI 플랫폼\n",
        "- 데이터 분석 도구\n",
        "- 연구용 정보 검색 시스템\n",
        "- 업무 자동화 플랫폼\n",
        "\n",
        "💡 확장 아이디어:\n",
        "- 음성 입력/출력 추가\n",
        "- 다국어 지원\n",
        "- 더 많은 외부 API 통합\n",
        "- 사용자 인증 및 개인화\n",
        "- 클라우드 배포 및 스케일링\n",
        "\n",
        "🎯 3일차 여정 완료:\n",
        "Day 1: 파인튜닝 → Day 2: RAG → Day 3: LangGraph + UI\n",
        "완전한 AI 시스템 구축 여정을 마쳤습니다!\n",
        "\"\"\")\n",
        "\n",
        "# 최종 시스템 상태 체크\n",
        "print(\"\\n📊 최종 시스템 상태:\")\n",
        "print(f\"- RAG 문서: {len(rag_system.documents)}개\")\n",
        "print(f\"- SQL 테이블: 2개 (products, orders)\")\n",
        "print(f\"- MCP 도구: {len(mcp_system.tools)}개\")\n",
        "print(f\"- LLM 모델: {llm.model_name}\")\n",
        "print(\"\\n🎉 모든 시스템이 정상 작동 중입니다!\")\n",
        "\n",
        "print(\"\\n🚀 이제 위의 셀을 실행하여 웹 인터페이스를 시작하세요!\")\n",
        "print(\"   실행 후 브라우저에서 http://localhost:7860 으로 접속할 수 있습니다.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}