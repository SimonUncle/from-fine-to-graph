{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Multi-Agent Patterns - LangGraph ì™„ì „ ì •ë³µ\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "**LangGraphì˜ Multi-Agent íŒ¨í„´ì„ Manual Graph ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤:**\n",
    "\n",
    "### ì‹¤ì œ êµ¬í˜„ (Manual Graph ë°©ì‹) âœ…\n",
    "1. ğŸ•¸ï¸ **Network** - Agentë¼ë¦¬ ì§ì ‘ í†µì‹ \n",
    "2. ğŸ¯ **Supervisor (Manual)** - LLMì´ Agent ì„ íƒ\n",
    "3. ğŸ¢ **Hierarchical** - 2-level ê³„ì¸µ êµ¬ì¡°\n",
    "\n",
    "### ì°¸ê³ ìš© ì„¤ëª… ğŸ“š\n",
    "4. ğŸ¤– **create_react_agent** - Tool calling í•„ìš”\n",
    "5. ğŸ—ï¸ **LangGraph Supervisor** - ìƒˆë¡œìš´ prebuilt ë¼ì´ë¸ŒëŸ¬ë¦¬ (2025.2.26 ì¶œì‹œ)\n",
    "6. ğŸ **Swarm** - Agent ììœ¨ í˜‘ì—…\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ ì™œ Manual Graph?\n",
    "\n",
    "**Tool Callingì˜ ë²½:**\n",
    "- âŒ ì‘ì€ ëª¨ë¸ (EXAONE-1.2B, Granite-micro): Tool call ìƒì„± ë¶ˆì•ˆì •\n",
    "- âœ… Manual Graph: ëª¨ë“  ëª¨ë¸ í˜¸í™˜ + ì•ˆì •ì \n",
    "\n",
    "**Tool Calling ì§€ì› ëª¨ë¸ (OpenAI, Anthropic ë“±)ì„ ì‚¬ìš©í•œë‹¤ë©´:**\n",
    "- create_react_agent, LangGraph Supervisor ë“± prebuilt ì‚¬ìš© ê°€ëŠ¥\n",
    "- í•˜ì§€ë§Œ ë¡œì»¬ ë¬´ë£Œ ëª¨ë¸ë¡œëŠ” Manual Graphê°€ ìµœì„ !\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š íŒ¨í„´ ë¹„êµ\n",
    "\n",
    "| íŒ¨í„´ | êµ¬í˜„ ë°©ì‹ | Tool Calling | ì¶”ì²œ |\n",
    "|------|----------|--------------|------|\n",
    "| Network | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ |\n",
    "| Supervisor Manual | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ |\n",
    "| Hierarchical | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ |\n",
    "| create_react_agent | Prebuilt | í•„ìˆ˜ | OpenAIë§Œ |\n",
    "| LangGraph Supervisor | Prebuilt | í•„ìˆ˜ | OpenAIë§Œ |\n",
    "| Swarm | Prebuilt | í•„ìˆ˜ | OpenAIë§Œ |\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ í™˜ê²½ ì„¤ì •\n",
    "\n",
    "**EXAONE-4.0-1.2B ì‚¬ìš© (ì™„ì „ ë¬´ë£Œ!):**\n",
    "\n",
    "âœ… **ë¡œì»¬ ëª¨ë¸ ì‹¤í–‰**\n",
    "  - EXAONE-4.0-1.2B (LG AI í•œêµ­ ëª¨ë¸)\n",
    "  - Colab GPU ì‚¬ìš©\n",
    "  - ì™„ì „ ë¬´ë£Œ, í•œë„ ì—†ìŒ!\n",
    "  \n",
    "âœ… **Tool Calling ë„¤ì´í‹°ë¸Œ ì§€ì›** â­\n",
    "  - apply_chat_templateì— tools íŒŒë¼ë¯¸í„°\n",
    "  - ë³€í™˜ ë¶ˆí•„ìš”!\n",
    "\n",
    "âœ… **ì‘ê³  ë¹ ë¦„**\n",
    "  - 1.2B íŒŒë¼ë¯¸í„° (~2.5GB)\n",
    "  - ë¹ ë¥¸ ë‹¤ìš´ë¡œë“œ & ì‹¤í–‰\n",
    "\n",
    "**ì¤€ë¹„ë¬¼:**\n",
    "- Colab GPU (T4 ì´ìƒ)\n",
    "- í† í° ë¶ˆí•„ìš” (Public ëª¨ë¸)\n",
    "\n",
    "**Prebuilt íŒ¨í‚¤ì§€:**\n",
    "- `langgraph-supervisor`\n",
    "- `langgraph-swarm`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip uninstall -y torch torchvision torchaudio\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "!pip install -q -U langgraph langchain-core transformers accelerate\n",
    "\n",
    "# ì‹¤ì œ ë„êµ¬ìš© íŒ¨í‚¤ì§€\n",
    "!pip install -q wikipedia  # Wikipedia API\n",
    "\n",
    "# Prebuilt íŒ¨í„´ìš© íŒ¨í‚¤ì§€\n",
    "!pip install -q -U langgraph-supervisor\n",
    "!pip install -q -U langgraph-swarm\n",
    "\n",
    "print(\"\\nâœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\")\n",
    "\n",
    "# GPU í™•ì¸\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"   âš ï¸  CPU ì‚¬ìš© (ëŠë¦¼)\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EXAONEì€ Public ëª¨ë¸ - í† í° ë¶ˆí•„ìš”!\n",
    "print(\"âœ… EXAONE-4.0-1.2B (Public ëª¨ë¸, í† í° ë¶ˆí•„ìš”)\")\n",
    "print(\"   - Manual Graph ë°©ì‹ ì‚¬ìš©\")\n",
    "print(\"   - Tool calling ì—†ì´ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, Annotated, List, Literal, Any, Optional\n",
    "import operator\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import Field\n",
    "from IPython.display import Image\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "print(\"ğŸ”„ EXAONE ëª¨ë¸ ë¡œë”© ì¤‘... (~1ë¶„)\")\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-4.0-1.2B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "# ===== ê°„ë‹¨í•œ LLM Wrapper =====\n",
    "class SimpleLLM:\n",
    "    \"\"\"ê°„ë‹¨í•œ LLM í˜¸ì¶œ ë˜í¼ (Tool calling ì—†ìŒ)\"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def invoke(self, prompt: str) -> str:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ ì…ë ¥ â†’ í…ìŠ¤íŠ¸ ì¶œë ¥\"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        \n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        output = self.model.generate(\n",
    "            input_ids.to(self.model.device),\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        response = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ assistant ì‘ë‹µë§Œ ì¶”ì¶œ\n",
    "        if \"assistant\" in response:\n",
    "            response = response.split(\"assistant\")[-1].strip()\n",
    "        \n",
    "        return response\n",
    "\n",
    "# LLM ìƒì„±\n",
    "llm = SimpleLLM(model=model, tokenizer=tokenizer)\n",
    "\n",
    "print(\"âœ… Simple LLM ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ëª¨ë¸: EXAONE-4.0-1.2B (LG AI)\")\n",
    "print(f\"   - Tool calling: ì‚¬ìš© ì•ˆ í•¨ (Manual Graph ë°©ì‹)\")\n",
    "print(f\"   - í…ìŠ¤íŠ¸ ì…ë ¥ â†’ í…ìŠ¤íŠ¸ ì¶œë ¥\")\n",
    "print(f\"   - GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ ì‹¤ì œ ë„êµ¬ ë° ë°ì´í„°\n",
    "\n",
    "**ì´ì œë¶€í„°ëŠ” í•˜ë“œì½”ë”©ì´ ì•„ë‹Œ ì‹¤ì œ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤!**\n",
    "\n",
    "### ì‚¬ìš©í•˜ëŠ” ì‹¤ì œ ë„êµ¬ë“¤:\n",
    "\n",
    "1. **Wikipedia API** - ì‹¤ì œ ê²€ìƒ‰\n",
    "2. **File I/O** - ë§ˆí¬ë‹¤ìš´/JSON íŒŒì¼ ì‹¤ì œ ì €ì¥\n",
    "3. **JSON DB** - ì£¼ë¬¸/ì¬ê³  ë°ì´í„° ì‹¤ì œ ì¡°íšŒ\n",
    "4. **ì‹œë®¬ë ˆì´ì…˜** - í™˜ë¶ˆ/ì¬ê³  ë“± ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§\n",
    "\n",
    "### ìƒì„±ë˜ëŠ” ì‹¤ì œ ê²°ê³¼ë¬¼:\n",
    "\n",
    "- `outputs/*.md` - ë¦¬ì„œì¹˜ ë³´ê³ ì„œ, ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸\n",
    "- `outputs/*.json` - í”„ë¡œì íŠ¸ ê¸°íšì„œ\n",
    "- `data/orders.json` - ì£¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ (ìë™ ìƒì„±)\n",
    "\n",
    "**í•™ìƒë“¤ì´ ê²°ê³¼ë¥¼ ì§ì ‘ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!** ğŸ‰"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"ê° íŒ¨í„´ë³„ ë„êµ¬ëŠ” í•´ë‹¹ ì„¹ì…˜ì—ì„œ ì •ì˜ë©ë‹ˆë‹¤.\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1ï¸âƒ£ Network Architecture\n",
    "\n",
    "## ğŸ¯ ìœ ì¦ˆì¼€ì´ìŠ¤: Wikipedia ë¦¬ì„œì¹˜ íŒ€\n",
    "\n",
    "**ì‹œë‚˜ë¦¬ì˜¤:**\n",
    "```\n",
    "ì‚¬ìš©ì: \"Rust í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì¡°ì‚¬í•´ì¤˜\"\n",
    "\n",
    "â†’ Research Agent: Wikipedia ì‹¤ì œ ê²€ìƒ‰ ğŸ”\n",
    "â†’ LLM íŒë‹¨: ì •ë³´ê°€ ì¶©ë¶„í•œê°€?\n",
    "  â†’ ì¶©ë¶„í•˜ë©´: Writerë¡œ â†’ íŒŒì¼ ì €ì¥ ğŸ’¾\n",
    "  â†’ ë¶€ì¡±í•˜ë©´: ì¶”ê°€ ê²€ìƒ‰\n",
    "```\n",
    "\n",
    "**í•µì‹¬:** LLMì´ ì‹¤ì œë¡œ íŒë‹¨! (í•˜ë“œì½”ë”© âŒ)\n",
    "\n",
    "## ì¥ì \n",
    "\n",
    "âœ… **ë™ì  í˜‘ì—…** - LLMì´ ìƒí™© íŒë‹¨  \n",
    "âœ… **ìœ ì—°í•¨** - í•„ìš”ì‹œ ì¶”ê°€ ê²€ìƒ‰  \n",
    "âœ… **ì‹¤ì œ ë„êµ¬** - Wikipedia API + File I/O\n",
    "\n",
    "## ì‘ë™ ë°©ì‹\n",
    "\n",
    "```python\n",
    "def research_agent(state):\n",
    "    result = wikipedia_search.invoke(...)  # ì‹¤ì œ ê²€ìƒ‰!\n",
    "    \n",
    "    # LLMì—ê²Œ íŒë‹¨ ì‹œí‚´\n",
    "    decision = llm.invoke(\"ì •ë³´ê°€ ì¶©ë¶„í•œê°€?\")\n",
    "    \n",
    "    if \"ì¶©ë¶„\" in decision:\n",
    "        return Command(goto=\"writer\")\n",
    "    else:\n",
    "        return Command(goto=\"research\")  # ì¶”ê°€ ê²€ìƒ‰\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 1. Network: Wikipedia ë¦¬ì„œì¹˜ ====================\n",
    "\n",
    "# ğŸ“Œ Network ì „ìš© ë„êµ¬ (ì—¬ê¸°!)\n",
    "@tool\n",
    "def wikipedia_search(query: str, lang: str = \"ko\", sentences: int = 3) -> str:\n",
    "    \"\"\"Wikipediaì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤ (í•œêµ­ì–´/ì˜ì–´ ì§€ì›)\n",
    "    \n",
    "    Args:\n",
    "        query: ê²€ìƒ‰í•  ì£¼ì œ\n",
    "        lang: ì–¸ì–´ (ko/en)\n",
    "        sentences: ë°˜í™˜í•  ë¬¸ì¥ ìˆ˜\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import wikipedia\n",
    "        wikipedia.set_lang(lang)\n",
    "        result = wikipedia.summary(query, sentences=sentences)\n",
    "        return f\"ğŸ“š Wikipedia ê²€ìƒ‰ ê²°ê³¼:\\n{result}\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"ğŸ” ì—¬ëŸ¬ ê²°ê³¼ ë°œê²¬. ì²« ë²ˆì§¸ í•­ëª© ë°˜í™˜:\\n{wikipedia.summary(e.options[0], sentences=sentences)}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"âŒ '{query}' í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def save_markdown(filename: str, content: str) -> str:\n",
    "    \"\"\"ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì‹¤ì œë¡œ ì €ì¥í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        filename: íŒŒì¼ëª… (ì˜ˆ: report.md)\n",
    "        content: ë§ˆí¬ë‹¤ìš´ ë‚´ìš©\n",
    "    \"\"\"\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    filepath = f\"outputs/{filename}\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    return f\"âœ… {filename} ì €ì¥ ì™„ë£Œ! ğŸ“„\\nê²½ë¡œ: {filepath}\"\n",
    "\n",
    "# ===== LLM ì‘ë‹µ í´ë¦¬ë‹ í•¨ìˆ˜ =====\n",
    "def clean_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM ì‘ë‹µì—ì„œ ì‹¤ì œ ë‹µë³€ë§Œ ì¶”ì¶œ (EXAONE íŠ¹ì„± ê³ ë ¤)\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # <think> íƒœê·¸ ì œê±°\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ ì¤„ì´ ë³´í†µ ì‹¤ì œ ë‹µë³€ (EXAONE íŠ¹ì„±)\n",
    "    if lines:\n",
    "        # .mdë‚˜ .jsonìœ¼ë¡œ ëë‚˜ëŠ” ì¤„ ì°¾ê¸°\n",
    "        for line in reversed(lines):\n",
    "            if line.endswith('.md') or line.endswith('.json') or (len(line) < 50 and not '?' in line):\n",
    "                return line\n",
    "        # ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì¤„\n",
    "        return lines[-1]\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Research Agent (ì–‘ë°©í–¥!)\n",
    "def research_agent_network(state: MessagesState) -> Command[Literal[\"writer\", \"research\"]]:\n",
    "    \"\"\"Wikipedia ê²€ìƒ‰ â†’ LLMì´ ë‹¤ìŒ agent ê²°ì •\"\"\"\n",
    "    print(\"\\nğŸ” [Research] Wikipedia ê²€ìƒ‰ ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_query = messages[0].content\n",
    "    \n",
    "    # ì´ë¯¸ ê²€ìƒ‰í•œ íšŸìˆ˜ í™•ì¸\n",
    "    research_count = sum(1 for m in messages if hasattr(m, 'name') and m.name == \"research\")\n",
    "    print(f\"   (ê²€ìƒ‰ íšŸìˆ˜: {research_count + 1})\")\n",
    "    \n",
    "    # âœ… LLMì´ ì£¼ì œ ì¶”ì¶œ!\n",
    "    extraction_prompt = f\"\"\"ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì—ì„œ Wikipediaì—ì„œ ê²€ìƒ‰í•  ì£¼ì œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "ì£¼ì œë§Œ ê°„ê²°í•˜ê²Œ 1-3ë‹¨ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ì£¼ì œë§Œ!\n",
    "\n",
    "ì‚¬ìš©ì ìš”ì²­: {user_query}\n",
    "\n",
    "ì£¼ì œ:\"\"\"\n",
    "    \n",
    "    topic_raw = llm.invoke(extraction_prompt)\n",
    "    topic = clean_llm_response(topic_raw)\n",
    "    print(f\"   ğŸ“ ì¶”ì¶œëœ ì£¼ì œ: {topic}\")\n",
    "    \n",
    "    # Wikipedia ê²€ìƒ‰\n",
    "    result = wikipedia_search.invoke({\"query\": topic, \"lang\": \"ko\", \"sentences\": 3})\n",
    "    \n",
    "    # âœ… LLMì´ ë‹¤ìŒ agent ê²°ì •! (writer ë˜ëŠ” research ì¬ì‹¤í–‰)\n",
    "    routing_prompt = f\"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš©ì ìš”ì²­: {user_query}\n",
    "ê²€ìƒ‰ ê²°ê³¼: {result}\n",
    "ê²€ìƒ‰ íšŸìˆ˜: {research_count + 1}\n",
    "\n",
    "ë‹¤ìŒ agentë¥¼ ì„ íƒí•˜ì„¸ìš”:\n",
    "- writer: ì¶©ë¶„í•œ ì •ë³´ê°€ ìˆìŒ â†’ ë³´ê³ ì„œ ì‘ì„±\n",
    "- research: ë” ë§ì€ ê²€ìƒ‰ í•„ìš” (ìµœëŒ€ 2íšŒê¹Œì§€ë§Œ)\n",
    "\n",
    "í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (writer ë˜ëŠ” research):\"\"\"\n",
    "    \n",
    "    decision_raw = llm.invoke(routing_prompt)\n",
    "    decision = clean_llm_response(decision_raw).lower()\n",
    "    \n",
    "    # íŒŒì‹± (ê¸°ë³¸ê°’: writer)\n",
    "    if \"research\" in decision and research_count < 2:\n",
    "        next_agent = \"research\"\n",
    "        print(\"   ğŸ”„ ë” í•„ìš” â†’ Research ì¬ì‹¤í–‰\")\n",
    "    else:\n",
    "        next_agent = \"writer\"\n",
    "        print(\"   âœ… ì¶©ë¶„í•¨ â†’ Writerë¡œ ì „ë‹¬\")\n",
    "    \n",
    "    new_message = HumanMessage(content=result, name=\"research\")\n",
    "    \n",
    "    # âœ… í•­ìƒ goto ëª…ì‹œ!\n",
    "    return Command(update={\"messages\": [new_message]}, goto=next_agent)\n",
    "\n",
    "# Writer Agent (ì–‘ë°©í–¥!)\n",
    "def writer_agent_network(state: MessagesState) -> Command[Literal[\"research\", \"writer\", \"__end__\"]]:\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¡œ ë³´ê³ ì„œ ì‘ì„± â†’ LLMì´ ë‹¤ìŒ agent ê²°ì •\"\"\"\n",
    "    print(\"\\nâœï¸ [Writer] ë³´ê³ ì„œ ì‘ì„± ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_query = messages[0].content\n",
    "    research_results = [m.content for m in messages if hasattr(m, 'name') and m.name == \"research\"]\n",
    "    \n",
    "    writer_count = sum(1 for m in messages if hasattr(m, 'name') and m.name == \"writer\")\n",
    "    print(f\"   (ì‘ì„± íšŸìˆ˜: {writer_count + 1})\")\n",
    "    \n",
    "    # LLMì´ ë³´ê³ ì„œ ì‘ì„±\n",
    "    writer_prompt = f\"\"\"ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê°„ë‹¨í•œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ìš”ì²­: {user_query}\n",
    "ì¡°ì‚¬ ìë£Œ:\n",
    "{''.join(research_results)}\n",
    "\n",
    "ë³´ê³ ì„œ í˜•ì‹:\n",
    "# ì œëª©\n",
    "## ê°œìš”\n",
    "ë‚´ìš©...\n",
    "\n",
    "## ê²°ë¡ \n",
    "ë‚´ìš©...\n",
    "\n",
    "ë³´ê³ ì„œë§Œ ì‘ì„±í•˜ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):\"\"\"\n",
    "    \n",
    "    report = llm.invoke(writer_prompt)\n",
    "    \n",
    "    # âœ… LLMì´ ë‹¤ìŒ agent ê²°ì •!\n",
    "    routing_prompt = f\"\"\"ë³´ê³ ì„œë¥¼ ê²€í† í•˜ê³  ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ìš”ì²­: {user_query}\n",
    "ë³´ê³ ì„œ ì´ˆì•ˆ:\n",
    "{report[:300]}...\n",
    "\n",
    "ë‹¤ìŒ agentë¥¼ ì„ íƒí•˜ì„¸ìš”:\n",
    "- __end__: ë³´ê³ ì„œ ì™„ì„±ë¨ â†’ ì €ì¥í•˜ê³  ì¢…ë£Œ (ê¸°ë³¸ê°’)\n",
    "- research: ì¤‘ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•¨ â†’ ì¶”ê°€ ì¡°ì‚¬\n",
    "- writer: ë‚´ìš© ìˆ˜ì • í•„ìš” â†’ ë‹¤ì‹œ ì‘ì„± (ìµœëŒ€ 1íšŒ)\n",
    "\n",
    "í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (__end__ / research / writer):\"\"\"\n",
    "    \n",
    "    decision_raw = llm.invoke(routing_prompt)\n",
    "    decision = clean_llm_response(decision_raw).lower()\n",
    "    \n",
    "    # íŒŒì‹±\n",
    "    if \"research\" in decision and writer_count < 1:\n",
    "        next_agent = \"research\"\n",
    "        print(\"   ğŸ”„ ì •ë³´ ë¶€ì¡± â†’ Researchë¡œ ëŒì•„ê°\")\n",
    "        new_message = AIMessage(content=f\"[Writer í”¼ë“œë°±] ë” ë§ì€ ì •ë³´ í•„ìš”\", name=\"writer\")\n",
    "        return Command(update={\"messages\": [new_message]}, goto=next_agent)\n",
    "    elif \"writer\" in decision and writer_count < 1:\n",
    "        next_agent = \"writer\"\n",
    "        print(\"   ğŸ”„ ë‚´ìš© ìˆ˜ì • â†’ Writer ì¬ì‹¤í–‰\")\n",
    "        new_message = AIMessage(content=report, name=\"writer\")\n",
    "        return Command(update={\"messages\": [new_message]}, goto=next_agent)\n",
    "    else:\n",
    "        # ì™„ì„± â†’ ì €ì¥í•˜ê³  ì¢…ë£Œ\n",
    "        next_agent = \"__end__\"\n",
    "        print(\"   âœ… ì™„ì„± â†’ ì €ì¥í•˜ê³  ì¢…ë£Œ\")\n",
    "        \n",
    "        # âœ… LLMì´ íŒŒì¼ëª… ìƒì„±!\n",
    "        filename_prompt = f\"\"\"ë‹¤ìŒ ì£¼ì œì— ì í•©í•œ íŒŒì¼ëª…ì„ ìƒì„±í•˜ì„¸ìš”.\n",
    "ì¡°ê±´: ì˜ì–´, ì†Œë¬¸ì, ì–¸ë”ìŠ¤ì½”ì–´ ì‚¬ìš©, .md í™•ì¥ì\n",
    "ì˜ˆì‹œ: quantum_computing_report.md\n",
    "\n",
    "ì£¼ì œ: {user_query}\n",
    "\n",
    "íŒŒì¼ëª…ë§Œ ë‹µë³€í•˜ì„¸ìš” (ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):\"\"\"\n",
    "        \n",
    "        filename_raw = llm.invoke(filename_prompt)\n",
    "        filename = clean_llm_response(filename_raw)\n",
    "        \n",
    "        # .md í™•ì¥ì í™•ì¸\n",
    "        if not filename.endswith('.md'):\n",
    "            filename += '.md'\n",
    "        \n",
    "        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ˆì „í•˜ê²Œ)\n",
    "        import re\n",
    "        filename = re.sub(r'[^a-zA-Z0-9_.]', '_', filename)\n",
    "        \n",
    "        print(f\"   ğŸ“ ìƒì„±ëœ íŒŒì¼ëª…: {filename}\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        save_result = save_markdown.invoke({\"filename\": filename, \"content\": report})\n",
    "        print(f\"   {save_result}\")\n",
    "        \n",
    "        final_message = AIMessage(content=f\"ğŸ“„ ë³´ê³ ì„œ ì™„ì„±!\\n\\n{report[:200]}...\\n\\n{save_result}\")\n",
    "        return Command(update={\"messages\": [final_message]}, goto=next_agent)\n",
    "\n",
    "# Graph êµ¬ì„±\n",
    "network_graph = StateGraph(MessagesState)\n",
    "network_graph.add_node(\"research\", research_agent_network)\n",
    "network_graph.add_node(\"writer\", writer_agent_network)\n",
    "\n",
    "# âœ… STARTë§Œ ì—°ê²°! Commandì˜ gotoê°€ ì–‘ë°©í–¥ ì²˜ë¦¬\n",
    "network_graph.add_edge(START, \"research\")\n",
    "\n",
    "network_app = network_graph.compile()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "display(Image(network_app.get_graph().draw_mermaid_png()))\n",
    "\n",
    "print(\"\\nâœ… Network Pattern ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(\"   - Research â†” Writer (ì–‘ë°©í–¥!)\")\n",
    "print(\"   - LLM ì‘ë‹µ í´ë¦¬ë‹ ì¶”ê°€ (<think> íƒœê·¸ ì²˜ë¦¬)\")\n",
    "print(\"   - íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ìƒì„±\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ì‹¤ìŠµ ë¯¸ì…˜\n",
    "\n",
    "### ë¯¸ì…˜ A: Rust ì–¸ì–´ ì¡°ì‚¬ â­â­\n",
    "```\n",
    "\"Rust í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì¡°ì‚¬í•´ì¤˜\"\n",
    "```\n",
    "â†’ `rust_í”„ë¡œê·¸ë˜ë°_ì–¸ì–´_report.md` ìƒì„± í™•ì¸\n",
    "\n",
    "### ë¯¸ì…˜ B: AI ê¸°ìˆ  ì¡°ì‚¬ â­â­â­\n",
    "```\n",
    "\"GPT-4ì— ëŒ€í•´ ì¡°ì‚¬í•´ì¤˜\"\n",
    "```\n",
    "â†’ Wikipedia ê²€ìƒ‰ ê²°ê³¼ í™•ì¸  \n",
    "â†’ LLM íŒë‹¨ ë©”ì‹œì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network ì‹¤í–‰\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ•¸ï¸ Network: Wikipedia ë¦¬ì„œì¹˜\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "result = network_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Rust í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ëŒ€í•´ ì¡°ì‚¬í•´ì¤˜\")]},\n",
    "    config={\"recursion_limit\": 50}\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… ì™„ë£Œ!\")\n",
    "print(\"\\nğŸ“Š ê²°ê³¼:\")\n",
    "print(result['messages'][-1].content)\n",
    "\n",
    "# íŒŒì¼ í™•ì¸\n",
    "import os\n",
    "if os.path.exists(\"outputs\"):\n",
    "    print(\"\\nğŸ“ ìƒì„±ëœ íŒŒì¼:\")\n",
    "    for f in os.listdir(\"outputs\"):\n",
    "        if \"report\" in f:\n",
    "            print(f\"   âœ… {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2ï¸âƒ£ Supervisor - 3ê°€ì§€ êµ¬í˜„ ë°©ë²•\n",
    "\n",
    "## ğŸ¯ ìœ ì¦ˆì¼€ì´ìŠ¤: E-ì»¤ë¨¸ìŠ¤ ê³ ê° ì§€ì›\n",
    "\n",
    "**ì‹œë‚˜ë¦¬ì˜¤:**\n",
    "```\n",
    "ì‚¬ìš©ì: \"ì£¼ë¬¸ 12345 ì–´ë””ê¹Œì§€ ì™”ì–´?\"\n",
    "â†’ Supervisor (LLM): ì£¼ë¬¸ ê´€ë ¨ â†’ order_agent ì„ íƒ\n",
    "â†’ Order Agent: data/orders.json ì¡°íšŒ\n",
    "â†’ ê²°ê³¼: \"ë°°ì†¡ì¤‘ (ì„œìš¸ í—ˆë¸Œ)\"\n",
    "```\n",
    "\n",
    "**í•µì‹¬:** LLMì´ ì ì ˆí•œ agent ì„ íƒ!\n",
    "\n",
    "## 3ê°€ì§€ ë°©ë²•\n",
    "\n",
    "| ë°©ë²• | ë ˆë²¨ | íŠ¹ì§• | ì‚¬ìš©ë¥  |\n",
    "|------|------|------|--------|\n",
    "| 1. Graph ì§ì ‘ | Low | ì™„ì „ ì œì–´ | 5% |\n",
    "| 2. create_react_agent | Mid | Tool ë˜í•‘ | **80%** â­ |\n",
    "| 3. create_supervisor | High | í•œ ì¤„ | 15% |\n",
    "\n",
    "**ê°™ì€ ê¸°ëŠ¥, ë‹¤ë¥¸ êµ¬í˜„!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 2. Supervisor ì „ìš© ë„êµ¬ ====================\n",
    "\n",
    "# ë°ì´í„° ì´ˆê¸°í™” (í•œë²ˆë§Œ!)\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# orders.json ì´ˆê¸°í™”\n",
    "if not os.path.exists(\"data/orders.json\"):\n",
    "    orders = {\n",
    "        \"12345\": {\"status\": \"ë°°ì†¡ì¤‘\", \"location\": \"ì„œìš¸ í—ˆë¸Œ\", \"expected\": \"2025-10-17\", \"product\": \"ë…¸íŠ¸ë¶\"},\n",
    "        \"67890\": {\"status\": \"ë°°ì†¡ì™„ë£Œ\", \"location\": \"ê³ ê° ìˆ˜ë ¹\", \"expected\": \"2025-10-16\", \"product\": \"ë§ˆìš°ìŠ¤\"},\n",
    "        \"11111\": {\"status\": \"ì¤€ë¹„ì¤‘\", \"location\": \"ì°½ê³ \", \"expected\": \"2025-10-18\", \"product\": \"í‚¤ë³´ë“œ\"}\n",
    "    }\n",
    "    with open(\"data/orders.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(orders, f, ensure_ascii=False, indent=2)\n",
    "    print(\"âœ… data/orders.json ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# ===== LLM ì‘ë‹µ í´ë¦¬ë‹ =====\n",
    "def clean_llm_response(text: str) -> str:\n",
    "    \"\"\"LLM ì‘ë‹µì—ì„œ ì‹¤ì œ ë‹µë³€ë§Œ ì¶”ì¶œ\"\"\"\n",
    "    import re\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    if lines:\n",
    "        return lines[-1]\n",
    "    return text.strip()\n",
    "\n",
    "# ğŸ“Œ Supervisor ë„êµ¬ (ì—¬ê¸°!)\n",
    "@tool\n",
    "def search_order(order_id: str) -> str:\n",
    "    \"\"\"ì£¼ë¬¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        order_id: ì£¼ë¬¸ ë²ˆí˜¸\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(\"data/orders.json\", 'r', encoding='utf-8') as f:\n",
    "            orders = json.load(f)\n",
    "        \n",
    "        if order_id in orders:\n",
    "            order = orders[order_id]\n",
    "            return f\"ğŸ“¦ ì£¼ë¬¸ {order_id}\\nìƒí’ˆ: {order['product']}\\nìƒíƒœ: {order['status']}\\nìœ„ì¹˜: {order['location']}\\në°°ì†¡ ì˜ˆì •: {order['expected']}\"\n",
    "        else:\n",
    "            return f\"âŒ ì£¼ë¬¸ {order_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def process_refund(order_id: str, reason: str) -> str:\n",
    "    \"\"\"ì£¼ë¬¸ í™˜ë¶ˆì„ ì²˜ë¦¬í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        order_id: ì£¼ë¬¸ ë²ˆí˜¸\n",
    "        reason: í™˜ë¶ˆ ì‚¬ìœ \n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(\"data/orders.json\", 'r', encoding='utf-8') as f:\n",
    "            orders = json.load(f)\n",
    "        \n",
    "        if order_id not in orders:\n",
    "            return f\"âŒ ì£¼ë¬¸ {order_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # í™˜ë¶ˆ ì²˜ë¦¬\n",
    "        orders[order_id]['status'] = 'í™˜ë¶ˆì™„ë£Œ'\n",
    "        orders[order_id]['refund_reason'] = reason\n",
    "        orders[order_id]['refund_date'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        with open(\"data/orders.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(orders, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        return f\"âœ… ì£¼ë¬¸ {order_id} í™˜ë¶ˆ ì™„ë£Œ!\\nìƒí’ˆ: {orders[order_id]['product']}\\nì‚¬ìœ : {reason}\\nì²˜ë¦¬ì¼: {orders[order_id]['refund_date']}\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ í™˜ë¶ˆ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def check_inventory(product: str) -> str:\n",
    "    \"\"\"ìƒí’ˆ ì¬ê³ ë¥¼ í™•ì¸í•©ë‹ˆë‹¤\n",
    "    \n",
    "    Args:\n",
    "        product: ìƒí’ˆëª…\n",
    "    \"\"\"\n",
    "    inventory = {\n",
    "        \"ë…¸íŠ¸ë¶\": {\"stock\": 15, \"price\": 1500000, \"category\": \"ì „ìì œí’ˆ\"},\n",
    "        \"ë§ˆìš°ìŠ¤\": {\"stock\": 50, \"price\": 30000, \"category\": \"ì£¼ë³€ê¸°ê¸°\"},\n",
    "        \"í‚¤ë³´ë“œ\": {\"stock\": 0, \"price\": 80000, \"category\": \"ì£¼ë³€ê¸°ê¸°\"},\n",
    "        \"ëª¨ë‹ˆí„°\": {\"stock\": 8, \"price\": 400000, \"category\": \"ì „ìì œí’ˆ\"}\n",
    "    }\n",
    "    \n",
    "    if product in inventory:\n",
    "        item = inventory[product]\n",
    "        if item['stock'] > 0:\n",
    "            return f\"âœ… {product}\\nì¬ê³ : {item['stock']}ê°œ\\nê°€ê²©: {item['price']:,}ì›\\në¶„ë¥˜: {item['category']}\"\n",
    "        else:\n",
    "            return f\"âŒ {product}: í’ˆì ˆ (ê°€ê²©: {item['price']:,}ì›)\"\n",
    "    else:\n",
    "        return f\"âŒ {product}: ìƒí’ˆ ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "print(\"âœ… Supervisor ë„êµ¬ ì¤€ë¹„ ì™„ë£Œ:\")\n",
    "print(\"   - search_order: ì£¼ë¬¸ ì¡°íšŒ\")\n",
    "print(\"   - process_refund: í™˜ë¶ˆ ì²˜ë¦¬\")\n",
    "print(\"   - check_inventory: ì¬ê³  í™•ì¸\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ë°©ë²• 1: Graph ì§ì ‘ (Command)\n",
    "\n",
    "**Low-level ì™„ì „ ì œì–´!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Supervisor (Graph) ====================\n",
    "\n",
    "# Worker Agents (LLMì´ íŒŒë¼ë¯¸í„° ì¶”ì¶œ!)\n",
    "def order_agent_sup(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "    \"\"\"ì£¼ë¬¸ ì¡°íšŒ\"\"\"\n",
    "    print(\"\\nğŸ“¦ [Order] ì¡°íšŒ ì¤‘...\")\n",
    "    \n",
    "    user_msg = state[\"messages\"][0]\n",
    "    \n",
    "    # âœ… LLMì´ ì£¼ë¬¸ë²ˆí˜¸ ì¶”ì¶œ!\n",
    "    extraction_prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë©”ì‹œì§€ì—ì„œ ì£¼ë¬¸ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "ìˆ«ìë§Œ ë°˜í™˜í•˜ì„¸ìš” (5ìë¦¬). ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ìˆ«ìë§Œ!\n",
    "\n",
    "ê³ ê°: {user_msg}\n",
    "\n",
    "ì£¼ë¬¸ë²ˆí˜¸:\"\"\"\n",
    "    \n",
    "    order_id_raw = llm.invoke(extraction_prompt)\n",
    "    order_id = clean_llm_response(order_id_raw).strip()\n",
    "    print(f\"   ğŸ“ ì¶”ì¶œëœ ì£¼ë¬¸ë²ˆí˜¸: {order_id}\")\n",
    "    \n",
    "    result = search_order.invoke({\"order_id\": order_id})\n",
    "    print(f\"   âœ… ì™„ë£Œ\")\n",
    "    \n",
    "    # âœ… Supervisorë¡œ ëŒì•„ê°!\n",
    "    return Command(goto=\"supervisor\", update={\"messages\": [AIMessage(content=result)]})\n",
    "\n",
    "def refund_agent_sup(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "    \"\"\"í™˜ë¶ˆ ì²˜ë¦¬\"\"\"\n",
    "    print(\"\\nğŸ’° [Refund] ì²˜ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    user_msg = state[\"messages\"][0]\n",
    "    \n",
    "    # âœ… LLMì´ ì£¼ë¬¸ë²ˆí˜¸ + ì‚¬ìœ  ì¶”ì¶œ!\n",
    "    extraction_prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë©”ì‹œì§€ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "\n",
    "ê³ ê°: {user_msg}\n",
    "\n",
    "JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€:\n",
    "{{\"order_id\": \"ìˆ«ì\", \"reason\": \"í™˜ë¶ˆ ì‚¬ìœ \"}}\"\"\"\n",
    "    \n",
    "    extracted_raw = llm.invoke(extraction_prompt)\n",
    "    extracted = clean_llm_response(extracted_raw)\n",
    "    \n",
    "    # ê°„ë‹¨í•œ íŒŒì‹±\n",
    "    import re\n",
    "    order_match = re.search(r'\"order_id\":\\s*\"([^\"]+)\"', extracted)\n",
    "    reason_match = re.search(r'\"reason\":\\s*\"([^\"]+)\"', extracted)\n",
    "    \n",
    "    order_id = order_match.group(1) if order_match else \"12345\"\n",
    "    reason = reason_match.group(1) if reason_match else \"ê³ ê° ìš”ì²­\"\n",
    "    \n",
    "    print(f\"   ğŸ“ ì¶”ì¶œ: ì£¼ë¬¸={order_id}, ì‚¬ìœ ={reason}\")\n",
    "    \n",
    "    result = process_refund.invoke({\"order_id\": order_id, \"reason\": reason})\n",
    "    print(f\"   âœ… ì™„ë£Œ\")\n",
    "    \n",
    "    # âœ… Supervisorë¡œ ëŒì•„ê°!\n",
    "    return Command(goto=\"supervisor\", update={\"messages\": [AIMessage(content=result)]})\n",
    "\n",
    "def inventory_agent_sup(state: MessagesState) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "    \"\"\"ì¬ê³  í™•ì¸\"\"\"\n",
    "    print(\"\\nğŸ“Š [Inventory] í™•ì¸ ì¤‘...\")\n",
    "    \n",
    "    user_msg = state[\"messages\"][0]\n",
    "    \n",
    "    # âœ… LLMì´ ìƒí’ˆëª… ì¶”ì¶œ!\n",
    "    extraction_prompt = f\"\"\"ë‹¤ìŒ ê³ ê° ë©”ì‹œì§€ì—ì„œ ìƒí’ˆëª…ì„ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "ìƒí’ˆëª…ë§Œ í•œê¸€ë¡œ ë°˜í™˜í•˜ì„¸ìš” (ë…¸íŠ¸ë¶/ë§ˆìš°ìŠ¤/í‚¤ë³´ë“œ/ëª¨ë‹ˆí„° ì¤‘ í•˜ë‚˜). ë‹¤ë¥¸ ì„¤ëª… ì—†ì´!\n",
    "\n",
    "ê³ ê°: {user_msg}\n",
    "\n",
    "ìƒí’ˆëª…:\"\"\"\n",
    "    \n",
    "    product_raw = llm.invoke(extraction_prompt)\n",
    "    product = clean_llm_response(product_raw).strip()\n",
    "    print(f\"   ğŸ“ ì¶”ì¶œëœ ìƒí’ˆ: {product}\")\n",
    "    \n",
    "    result = check_inventory.invoke({\"product\": product})\n",
    "    print(f\"   âœ… ì™„ë£Œ\")\n",
    "    \n",
    "    # âœ… Supervisorë¡œ ëŒì•„ê°!\n",
    "    return Command(goto=\"supervisor\", update={\"messages\": [AIMessage(content=result)]})\n",
    "\n",
    "# Supervisor (LLMì´ ë¼ìš°íŒ…!)\n",
    "def supervisor_graph(state: MessagesState) -> Command[Literal[\"order_agent\", \"refund_agent\", \"inventory_agent\", \"__end__\"]]:\n",
    "    \"\"\"LLMì´ agent ì„ íƒ\"\"\"\n",
    "    print(\"\\nğŸ‘” [Supervisor] LLM íŒë‹¨ ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # ì´ë¯¸ ì²˜ë¦¬ë¨? (Workerì—ì„œ ëŒì•„ì˜¨ ê²½ìš°)\n",
    "    if len(messages) > 1:\n",
    "        print(\"   âœ… Worker ì²˜ë¦¬ ì™„ë£Œ â†’ ì¢…ë£Œ\")\n",
    "        # âœ… ENDë¡œ ê°!\n",
    "        return Command(goto=\"__end__\")\n",
    "    \n",
    "    user_msg = messages[0]\n",
    "    \n",
    "    # âœ… LLMì—ê²Œ ë¼ìš°íŒ… íŒë‹¨ ì‹œí‚´!\n",
    "    routing_prompt = f\"\"\"ê³ ê° ì§€ì› ë¼ìš°í„°. ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "agents:\n",
    "- order_agent: ì£¼ë¬¸ ì¡°íšŒ, ë°°ì†¡ ìœ„ì¹˜ í™•ì¸\n",
    "- refund_agent: í™˜ë¶ˆ ì²˜ë¦¬, ì·¨ì†Œ\n",
    "- inventory_agent: ì¬ê³  í™•ì¸, ê°€ê²© ë¬¸ì˜\n",
    "\n",
    "ê³ ê°: {user_msg}\n",
    "\n",
    "í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (order_agent / refund_agent / inventory_agent):\"\"\"\n",
    "    \n",
    "    decision_raw = llm.invoke(routing_prompt)\n",
    "    decision_text = decision_raw if hasattr(decision_raw, 'content') else str(decision_raw)\n",
    "    decision_clean = clean_llm_response(decision_text)\n",
    "    \n",
    "    print(f\"   ğŸ¤– LLM ê²°ì •: {decision_clean}\")\n",
    "    \n",
    "    # íŒŒì‹±\n",
    "    text = decision_clean.lower()\n",
    "    if \"refund\" in text or \"í™˜ë¶ˆ\" in text:\n",
    "        next_agent = \"refund_agent\"\n",
    "    elif \"inventory\" in text or \"ì¬ê³ \" in text:\n",
    "        next_agent = \"inventory_agent\"\n",
    "    else:\n",
    "        next_agent = \"order_agent\"\n",
    "    \n",
    "    print(f\"   â†’ {next_agent}\")\n",
    "    \n",
    "    # âœ… Workerë¡œ ì´ë™!\n",
    "    return Command(goto=next_agent)\n",
    "\n",
    "# Graph\n",
    "sup_graph = StateGraph(MessagesState)\n",
    "sup_graph.add_node(\"supervisor\", supervisor_graph)\n",
    "sup_graph.add_node(\"order_agent\", order_agent_sup)\n",
    "sup_graph.add_node(\"refund_agent\", refund_agent_sup)\n",
    "sup_graph.add_node(\"inventory_agent\", inventory_agent_sup)\n",
    "\n",
    "# âœ… STARTë§Œ ì—°ê²°! ë‚˜ë¨¸ì§€ëŠ” Commandì˜ gotoê°€ ì²˜ë¦¬\n",
    "sup_graph.add_edge(START, \"supervisor\")\n",
    "\n",
    "sup_graph_app = sup_graph.compile()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "display(Image(sup_graph_app.get_graph().draw_mermaid_png()))\n",
    "\n",
    "print(\"\\nâœ… Supervisor (Graph) ì™„ì„±!\")\n",
    "print(\"   íë¦„: START â†’ Supervisor â†’ Worker â†’ Supervisor â†’ END\")\n",
    "print(\"   - Supervisor: LLMì´ agent ë¼ìš°íŒ…\")\n",
    "print(\"   - Workers: LLMì´ íŒŒë¼ë¯¸í„° ì¶”ì¶œ â†’ Supervisorë¡œ ë³µê·€\")\n",
    "print(\"   - Supervisor: Worker ê²°ê³¼ í™•ì¸ â†’ END\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervisor (Graph) ì‹¤í–‰\n",
    "\n",
    "tests = [\n",
    "    \"ì£¼ë¬¸ 12345 ì–´ë””ê¹Œì§€ ì™”ì–´?\",\n",
    "    \"ì£¼ë¬¸ 67890 í™˜ë¶ˆí•´ì¤˜\",\n",
    "    \"ë…¸íŠ¸ë¶ ì¬ê³  ìˆì–´?\"\n",
    "]\n",
    "\n",
    "for user_msg in tests:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"ğŸ“‹ í…ŒìŠ¤íŠ¸: {user_msg}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    result = sup_graph_app.invoke(\n",
    "        {\"messages\": [HumanMessage(content=user_msg)]},\n",
    "        config={\"recursion_limit\": 50}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… ê²°ê³¼: {result['messages'][-1].content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ï¸âƒ£-B. Supervisor (create_react_agent ë°©ì‹)\n",
    "\n",
    "## ğŸ“š ì°¸ê³ ìš©: create_react_agent íŒ¨í„´\n",
    "\n",
    "`create_react_agent`ëŠ” LangGraphì˜ prebuilt í•¨ìˆ˜ë¡œ, ReAct íŒ¨í„´ì„ ìë™ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent = create_react_agent(\n",
    "    llm,  # Tool calling ì§€ì› LLM\n",
    "    tools=[handle_order, handle_refund, handle_inventory]\n",
    ")\n",
    "```\n",
    "\n",
    "### ì™œ Manual Graphë¥¼ ì„ íƒí–ˆë‚˜ìš”?\n",
    "\n",
    "**Tool calling ìì²´ëŠ” EXAONEë„ ì§€ì›í•©ë‹ˆë‹¤!** ë¬¸ì œëŠ”:\n",
    "\n",
    "1. **ë³µì¡í•œ ë˜í¼ êµ¬í˜„ í•„ìš”**\n",
    "   - AIMessage.tool_calls íŒŒì‹±\n",
    "   - ì´ì¤‘ JSON ì¸ì½”ë”© ì²˜ë¦¬\n",
    "   - ì—ëŸ¬ í•¸ë“¤ë§\n",
    "\n",
    "2. **ì‘ì€ ëª¨ë¸ì˜ ë¶ˆì•ˆì •ì„±**\n",
    "   - Tool call ìƒì„±ë¥  ë‚®ìŒ\n",
    "   - í˜•ì‹ ì˜¤ë¥˜ ë¹ˆë²ˆ\n",
    "\n",
    "3. **Manual Graphê°€ ë” ê°„ë‹¨**\n",
    "   - LLM â†’ í…ìŠ¤íŠ¸ â†’ ì •ê·œì‹ â†’ Tool ì‹¤í–‰\n",
    "   - ëª…í™•í•œ íë¦„\n",
    "   - ë””ë²„ê¹… ì‰¬ì›€\n",
    "\n",
    "**â†’ Cell 14ì˜ Manual Graph ë°©ì‹ ì‚¬ìš©!**\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2ï¸âƒ£-C. LangGraph Supervisor (Prebuilt)\n",
    "\n",
    "## ğŸ“š 2025.2.26 ì¶œì‹œ!\n",
    "\n",
    "```bash\n",
    "pip install langgraph-supervisor\n",
    "```\n",
    "\n",
    "```python\n",
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "supervisor_app = create_supervisor(\n",
    "    agents=[order_agent, refund_agent, inventory_agent],\n",
    "    supervisor_llm=llm\n",
    ")\n",
    "```\n",
    "\n",
    "**â†’ Manual Graph (Cell 14)ê°€ ë” ê°„ë‹¨í•˜ê³  ì•ˆì •ì !**\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3ï¸âƒ£ Hierarchical\n",
    "\n",
    "## ğŸ¯ ìœ ì¦ˆì¼€ì´ìŠ¤: ì½˜í…ì¸  ì œì‘ íšŒì‚¬\n",
    "\n",
    "**ì§„ì§œ 2-Level êµ¬ì¡°:**\n",
    "\n",
    "```\n",
    "Top Supervisor (ì „ì²´ ì œì–´ + ìµœì¢… ìŠ¹ì¸)\n",
    "  â”œâ”€ Research Team\n",
    "  â”‚   â”œâ”€ Wikipedia Agent (ê²€ìƒ‰ ì‹¤í–‰)\n",
    "  â”‚   â””â”€ Research Supervisor (ì¬ê²€ìƒ‰ or ìŠ¹ì¸ íŒë‹¨)\n",
    "  â”‚\n",
    "  â””â”€ Content Team\n",
    "      â”œâ”€ Writer Agent (ì½˜í…ì¸  ì‘ì„±)\n",
    "      â””â”€ Content Supervisor (ì¬ì‘ì„± or ìŠ¹ì¸ íŒë‹¨)\n",
    "```\n",
    "\n",
    "## ğŸ”„ ì‘ë™ íë¦„\n",
    "\n",
    "**1ë‹¨ê³„: Research Team**\n",
    "```\n",
    "Top Supervisor â†’ Wikipedia Agent â†’ Research Supervisor\n",
    "                                    â”œâ”€ ì¬ê²€ìƒ‰ â†’ Wikipedia Agent (ë£¨í”„)\n",
    "                                    â””â”€ ìŠ¹ì¸ â†’ Top Supervisor\n",
    "```\n",
    "\n",
    "**2ë‹¨ê³„: Content Team**\n",
    "```\n",
    "Top Supervisor â†’ Writer Agent â†’ Content Supervisor\n",
    "                                â”œâ”€ ì¬ì‘ì„± â†’ Writer Agent (ë£¨í”„)\n",
    "                                â””â”€ ìŠ¹ì¸ â†’ Top Supervisor\n",
    "```\n",
    "\n",
    "**3ë‹¨ê³„: ìµœì¢… ìŠ¹ì¸**\n",
    "```\n",
    "Top Supervisor â†’ íŒŒì¼ ì €ì¥ â†’ END\n",
    "```\n",
    "\n",
    "## ğŸ’¡ í•µì‹¬ íŠ¹ì§•\n",
    "\n",
    "âœ… **ê° íŒ€ì— Supervisor ìˆìŒ**\n",
    "- Research Supervisor: ê²€ìƒ‰ ê²°ê³¼ ê²€í† \n",
    "- Content Supervisor: ì‘ì„± ê²°ê³¼ ê²€í† \n",
    "\n",
    "âœ… **íŒ€ ë‚´ë¶€ í”¼ë“œë°± ë£¨í”„**\n",
    "- í’ˆì§ˆ ë¯¸ë‹¬ â†’ ì¬ì‘ì—…\n",
    "- ë§Œì¡± â†’ ìƒìœ„ Supervisorì—ê²Œ ì „ë‹¬\n",
    "\n",
    "âœ… **Top Supervisorì˜ ì—­í• **\n",
    "- ì „ì²´ íë¦„ ì œì–´\n",
    "- íŒ€ ê°„ ë¼ìš°íŒ…\n",
    "- ìµœì¢… ìŠ¹ì¸ ë° ì €ì¥\n",
    "\n",
    "âœ… **Commandë§Œ ì‚¬ìš©**\n",
    "- `add_edge` ì—†ìŒ!\n",
    "- ëª¨ë“  ë¼ìš°íŒ…ì´ `Command(goto=...)`ë¡œ ë™ì  ì²˜ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 3. Hierarchical ====================\n",
    "\n",
    "# ğŸ“Œ Hierarchical ë„êµ¬\n",
    "@tool\n",
    "def wikipedia_search(query: str, lang: str = \"ko\", sentences: int = 3) -> str:\n",
    "    \"\"\"Wikipediaì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤\"\"\"\n",
    "    try:\n",
    "        import wikipedia\n",
    "        wikipedia.set_lang(lang)\n",
    "        result = wikipedia.summary(query, sentences=sentences)\n",
    "        return f\"ğŸ“š Wikipedia ê²€ìƒ‰ ê²°ê³¼:\\n{result}\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"ğŸ” ì—¬ëŸ¬ ê²°ê³¼ ë°œê²¬. ì²« ë²ˆì§¸ í•­ëª©:\\n{wikipedia.summary(e.options[0], sentences=sentences)}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"âŒ '{query}' í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def save_project(filename: str, title: str, content: str) -> str:\n",
    "    \"\"\"í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤\"\"\"\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    filepath = f\"outputs/{filename}\"\n",
    "    \n",
    "    data = {\n",
    "        \"title\": title,\n",
    "        \"content\": content,\n",
    "        \"created\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return f\"âœ… {filename} ì €ì¥ ì™„ë£Œ! ğŸ“‹\\nì œëª©: {title}\\nê²½ë¡œ: {filepath}\"\n",
    "\n",
    "# ===== LLM ì‘ë‹µ í´ë¦¬ë‹ =====\n",
    "def clean_llm_response_hier(text: str) -> str:\n",
    "    \"\"\"LLM ì‘ë‹µì—ì„œ <think> íƒœê·¸ ì œê±°\"\"\"\n",
    "    import re\n",
    "    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    if lines:\n",
    "        # ì§§ê³  ê¹¨ë—í•œ ë¼ì¸ ì°¾ê¸°\n",
    "        clean_lines = [l for l in lines if len(l) < 100 and not any(c in l for c in ['?', '!', ':', 'ìƒì„±', 'ë‹µë³€', 'ì£¼ì œ', 'íŒŒì¼ëª…', 'ì œëª©'])]\n",
    "        if clean_lines:\n",
    "            return clean_lines[0]\n",
    "        return lines[-1]\n",
    "    return text.strip()\n",
    "\n",
    "# ===== ì§„ì§œ 2-Level Hierarchical =====\n",
    "\n",
    "# ========== Research Team (2ê°œ ë…¸ë“œ) ==========\n",
    "\n",
    "def research_wikipedia_agent(state: MessagesState) -> Command[Literal[\"research_supervisor\"]]:\n",
    "    \"\"\"Research Team - Wikipedia Agent (ê²€ìƒ‰)\"\"\"\n",
    "    print(\"\\nğŸ” [Research > Wikipedia Agent] ê²€ìƒ‰ ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_request = messages[0].content\n",
    "    \n",
    "    # LLMì´ ì£¼ì œ ì¶”ì¶œ\n",
    "    prompt = f\"\"\"ë‹¤ìŒ ìš”ì²­ì—ì„œ Wikipedia ê²€ìƒ‰í•  ì£¼ì œë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "ì£¼ì œë§Œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "ìš”ì²­: {user_request}\n",
    "\n",
    "ì£¼ì œ:\"\"\"\n",
    "    \n",
    "    topic_raw = llm.invoke(prompt)\n",
    "    topic = clean_llm_response_hier(topic_raw)\n",
    "    print(f\"   ğŸ“ ì£¼ì œ: {topic}\")\n",
    "    \n",
    "    # Wikipedia ê²€ìƒ‰\n",
    "    result = wikipedia_search.invoke({\"query\": topic, \"lang\": \"ko\", \"sentences\": 3})\n",
    "    print(\"   âœ… ê²€ìƒ‰ ì™„ë£Œ â†’ Research Supervisorë¡œ ì „ë‹¬\")\n",
    "    \n",
    "    return Command(\n",
    "        goto=\"research_supervisor\",\n",
    "        update={\"messages\": [AIMessage(content=f\"[Wikipedia] {result}\", name=\"wikipedia\")]}\n",
    "    )\n",
    "\n",
    "def research_supervisor_node(state: MessagesState) -> Command[Literal[\"research_wikipedia_agent\", \"top_supervisor\"]]:\n",
    "    \"\"\"Research Team - Supervisor (ê²€í†  í›„ ì¬ê²€ìƒ‰ or ìŠ¹ì¸)\"\"\"\n",
    "    print(\"\\nğŸ‘” [Research > Supervisor] ê²€í†  ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_request = messages[0].content\n",
    "    \n",
    "    # Wikipedia ê²°ê³¼ ì°¾ê¸°\n",
    "    wiki_result = \"\"\n",
    "    for m in messages:\n",
    "        if hasattr(m, 'name') and m.name == \"wikipedia\":\n",
    "            wiki_result = m.content\n",
    "            break\n",
    "    \n",
    "    # ì¬ê²€ìƒ‰ íšŸìˆ˜ í™•ì¸\n",
    "    research_count = sum(1 for m in messages if hasattr(m, 'name') and m.name == \"wikipedia\")\n",
    "    print(f\"   ğŸ“Š ê²€ìƒ‰ íšŸìˆ˜: {research_count}\")\n",
    "    \n",
    "    # LLMì´ íŒë‹¨\n",
    "    prompt = f\"\"\"Wikipedia ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ìš”ì²­: {user_request}\n",
    "ê²€ìƒ‰ ê²°ê³¼: {wiki_result[:300]}...\n",
    "ê²€ìƒ‰ íšŸìˆ˜: {research_count}\n",
    "\n",
    "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ:\n",
    "- ì¬ê²€ìƒ‰: ì •ë³´ê°€ ë¶€ì¡±í•¨ (ìµœëŒ€ 2íšŒê¹Œì§€ë§Œ)\n",
    "- ìŠ¹ì¸: ì¶©ë¶„í•œ ì •ë³´ â†’ Content Teamìœ¼ë¡œ ì „ë‹¬\n",
    "\n",
    "í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (ì¬ê²€ìƒ‰ / ìŠ¹ì¸):\"\"\"\n",
    "    \n",
    "    decision_raw = llm.invoke(prompt)\n",
    "    decision = clean_llm_response_hier(decision_raw).lower()\n",
    "    \n",
    "    if \"ì¬ê²€ìƒ‰\" in decision and research_count < 2:\n",
    "        print(\"   âŒ ì¬ê²€ìƒ‰ í•„ìš” â†’ Wikipedia Agentë¡œ ë³µê·€\")\n",
    "        return Command(goto=\"research_wikipedia_agent\")\n",
    "    else:\n",
    "        print(\"   âœ… ìŠ¹ì¸ â†’ Top Supervisorë¡œ ì „ë‹¬\")\n",
    "        return Command(goto=\"top_supervisor\")\n",
    "\n",
    "# ========== Content Team (2ê°œ ë…¸ë“œ) ==========\n",
    "\n",
    "def content_writer_agent(state: MessagesState) -> Command[Literal[\"content_supervisor\"]]:\n",
    "    \"\"\"Content Team - Writer Agent (ì‘ì„±)\"\"\"\n",
    "    print(\"\\nâœï¸ [Content > Writer Agent] ì‘ì„± ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_request = messages[0].content\n",
    "    \n",
    "    # Research ê²°ê³¼ ì°¾ê¸°\n",
    "    research_results = [m.content for m in messages if hasattr(m, 'name') and m.name == \"wikipedia\"]\n",
    "    \n",
    "    # LLMì´ ì½˜í…ì¸  ì‘ì„±\n",
    "    prompt = f\"\"\"ë‹¤ìŒ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ì˜ í”„ë¡œì íŠ¸ ê¸°íšì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ìš”ì²­: {user_request}\n",
    "ì¡°ì‚¬ ìë£Œ:\n",
    "{''.join(research_results)}\n",
    "\n",
    "JSON í˜•ì‹:\n",
    "{{\n",
    "  \"title\": \"ì œëª© (í•œê¸€, 2-5ë‹¨ì–´)\",\n",
    "  \"summary\": \"ìš”ì•½ (2-3ë¬¸ì¥)\",\n",
    "  \"details\": \"ìƒì„¸ ë‚´ìš© (3-5ë¬¸ì¥)\"\n",
    "}}\n",
    "\n",
    "JSONë§Œ ì‘ì„±í•˜ì„¸ìš”:\"\"\"\n",
    "    \n",
    "    content_raw = llm.invoke(prompt)\n",
    "    print(\"   âœ… ì‘ì„± ì™„ë£Œ â†’ Content Supervisorë¡œ ì „ë‹¬\")\n",
    "    \n",
    "    return Command(\n",
    "        goto=\"content_supervisor\",\n",
    "        update={\"messages\": [AIMessage(content=content_raw, name=\"writer\")]}\n",
    "    )\n",
    "\n",
    "def content_supervisor_node(state: MessagesState) -> Command[Literal[\"content_writer_agent\", \"top_supervisor\"]]:\n",
    "    \"\"\"Content Team - Supervisor (ê²€í†  í›„ ì¬ì‘ì„± or ìŠ¹ì¸)\"\"\"\n",
    "    print(\"\\nğŸ‘” [Content > Supervisor] ê²€í†  ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    user_request = messages[0].content\n",
    "    \n",
    "    # Writer ê²°ê³¼ ì°¾ê¸°\n",
    "    writer_result = \"\"\n",
    "    for m in messages:\n",
    "        if hasattr(m, 'name') and m.name == \"writer\":\n",
    "            writer_result = m.content\n",
    "            break\n",
    "    \n",
    "    # ì¬ì‘ì„± íšŸìˆ˜ í™•ì¸\n",
    "    writer_count = sum(1 for m in messages if hasattr(m, 'name') and m.name == \"writer\")\n",
    "    print(f\"   ğŸ“Š ì‘ì„± íšŸìˆ˜: {writer_count}\")\n",
    "    \n",
    "    # LLMì´ íŒë‹¨\n",
    "    prompt = f\"\"\"ì‘ì„±ëœ ì½˜í…ì¸ ë¥¼ ê²€í† í•˜ì„¸ìš”.\n",
    "\n",
    "ì›ë˜ ìš”ì²­: {user_request}\n",
    "ì‘ì„± ê²°ê³¼: {writer_result[:300]}...\n",
    "ì‘ì„± íšŸìˆ˜: {writer_count}\n",
    "\n",
    "ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ:\n",
    "- ì¬ì‘ì„±: í’ˆì§ˆì´ ë¶€ì¡±í•¨ (ìµœëŒ€ 2íšŒê¹Œì§€ë§Œ)\n",
    "- ìŠ¹ì¸: ë§Œì¡±ìŠ¤ëŸ¬ì›€ â†’ Top Supervisorë¡œ ì „ë‹¬\n",
    "\n",
    "í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš” (ì¬ì‘ì„± / ìŠ¹ì¸):\"\"\"\n",
    "    \n",
    "    decision_raw = llm.invoke(prompt)\n",
    "    decision = clean_llm_response_hier(decision_raw).lower()\n",
    "    \n",
    "    if \"ì¬ì‘ì„±\" in decision and writer_count < 2:\n",
    "        print(\"   âŒ ì¬ì‘ì„± í•„ìš” â†’ Writer Agentë¡œ ë³µê·€\")\n",
    "        return Command(goto=\"content_writer_agent\")\n",
    "    else:\n",
    "        print(\"   âœ… ìŠ¹ì¸ â†’ Top Supervisorë¡œ ì „ë‹¬\")\n",
    "        return Command(goto=\"top_supervisor\")\n",
    "\n",
    "# ========== Top Supervisor ==========\n",
    "\n",
    "def top_supervisor_hier(state: MessagesState) -> Command[Literal[\"research_wikipedia_agent\", \"content_writer_agent\", \"__end__\"]]:\n",
    "    \"\"\"Top Supervisor - ì „ì²´ íë¦„ ì œì–´\"\"\"\n",
    "    print(\"\\nğŸ‘‘ [Top Supervisor] íŒë‹¨ ì¤‘...\")\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # 1. ì´ˆê¸° ìš”ì²­? â†’ Research Team ì‹œì‘\n",
    "    if len(messages) == 1:\n",
    "        print(\"   â†’ Research Team ì‹œì‘\")\n",
    "        return Command(goto=\"research_wikipedia_agent\")\n",
    "    \n",
    "    # 2. Research ì™„ë£Œ? â†’ Content Team ì‹œì‘\n",
    "    has_research = any(hasattr(m, 'name') and m.name == \"wikipedia\" for m in messages)\n",
    "    has_content = any(hasattr(m, 'name') and m.name == \"writer\" for m in messages)\n",
    "    \n",
    "    if has_research and not has_content:\n",
    "        print(\"   â†’ Content Team ì‹œì‘\")\n",
    "        return Command(goto=\"content_writer_agent\")\n",
    "    \n",
    "    # 3. ëª¨ë‘ ì™„ë£Œ? â†’ ìµœì¢… ê²€í†  í›„ íŒŒì¼ ì €ì¥\n",
    "    if has_research and has_content:\n",
    "        print(\"   â†’ ìµœì¢… ê²€í†  ë° ì €ì¥\")\n",
    "        \n",
    "        # Writer ê²°ê³¼ ì°¾ê¸°\n",
    "        writer_result = \"\"\n",
    "        for m in messages:\n",
    "            if hasattr(m, 'name') and m.name == \"writer\":\n",
    "                writer_result = m.content\n",
    "                break\n",
    "        \n",
    "        # LLMì´ íŒŒì¼ëª… ìƒì„±\n",
    "        user_request = messages[0].content\n",
    "        prompt = f\"\"\"íŒŒì¼ëª… ìƒì„±:\n",
    "ì¡°ê±´: ì˜ì–´, ì†Œë¬¸ì, ì–¸ë”ìŠ¤ì½”ì–´, .json\n",
    "ì£¼ì œ: {user_request}\n",
    "íŒŒì¼ëª…ë§Œ:\"\"\"\n",
    "        \n",
    "        filename_raw = llm.invoke(prompt)\n",
    "        filename = clean_llm_response_hier(filename_raw)\n",
    "        \n",
    "        # íŒŒì¼ëª… ì •ë¦¬\n",
    "        import re\n",
    "        filename = re.sub(r'[^a-zA-Z0-9_.]', '_', filename)\n",
    "        filename = re.sub(r'_+', '_', filename).strip('_')\n",
    "        if not filename.endswith('.json'):\n",
    "            filename += '.json'\n",
    "        \n",
    "        # LLMì´ ì œëª© ì¶”ì¶œ\n",
    "        prompt = f\"\"\"ë‹¤ìŒ JSONì—ì„œ title ê°’ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.\n",
    "\n",
    "{writer_result[:500]}\n",
    "\n",
    "title ê°’ë§Œ:\"\"\"\n",
    "        \n",
    "        title_raw = llm.invoke(prompt)\n",
    "        title = clean_llm_response_hier(title_raw)\n",
    "        \n",
    "        print(f\"   ğŸ“ íŒŒì¼ëª…: {filename}\")\n",
    "        print(f\"   ğŸ“ ì œëª©: {title}\")\n",
    "        \n",
    "        # íŒŒì¼ ì €ì¥\n",
    "        result = save_project.invoke({\n",
    "            \"filename\": filename,\n",
    "            \"title\": title,\n",
    "            \"content\": writer_result\n",
    "        })\n",
    "        print(\"   âœ… ìµœì¢… ìŠ¹ì¸ ë° ì €ì¥ ì™„ë£Œ â†’ ì¢…ë£Œ\")\n",
    "        \n",
    "        return Command(\n",
    "            goto=\"__end__\",\n",
    "            update={\"messages\": [AIMessage(content=result)]}\n",
    "        )\n",
    "    \n",
    "    # ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ\n",
    "    print(\"   âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ â†’ ì¢…ë£Œ\")\n",
    "    return Command(goto=\"__end__\")\n",
    "\n",
    "# ========== Graph êµ¬ì„± ==========\n",
    "\n",
    "hier_graph = StateGraph(MessagesState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "hier_graph.add_node(\"top_supervisor\", top_supervisor_hier)\n",
    "hier_graph.add_node(\"research_wikipedia_agent\", research_wikipedia_agent)\n",
    "hier_graph.add_node(\"research_supervisor\", research_supervisor_node)\n",
    "hier_graph.add_node(\"content_writer_agent\", content_writer_agent)\n",
    "hier_graph.add_node(\"content_supervisor\", content_supervisor_node)\n",
    "\n",
    "# âœ… STARTë§Œ ì—°ê²°! ë‚˜ë¨¸ì§€ëŠ” ëª¨ë‘ Commandì˜ gotoê°€ ì²˜ë¦¬\n",
    "hier_graph.add_edge(START, \"top_supervisor\")\n",
    "\n",
    "# âš ï¸ add_edge ì—†ìŒ! Commandì˜ gotoë§Œ ì‚¬ìš©!\n",
    "# ì´ìœ : Commandê°€ ë™ì  ë¼ìš°íŒ…ì„ ì²˜ë¦¬í•˜ë¯€ë¡œ ì •ì  ì—£ì§€ ë¶ˆí•„ìš”\n",
    "\n",
    "hier_app = hier_graph.compile()\n",
    "\n",
    "display(Image(hier_app.get_graph().draw_mermaid_png()))\n",
    "\n",
    "print(\"\\nâœ… Hierarchical (ì§„ì§œ 2-Level) ì™„ì„±!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"êµ¬ì¡°:\")\n",
    "print(\"  Top Supervisor (ìµœì¢… ìŠ¹ì¸)\")\n",
    "print(\"    â”œâ”€ Research Team\")\n",
    "print(\"    â”‚   â”œâ”€ Wikipedia Agent (ê²€ìƒ‰)\")\n",
    "print(\"    â”‚   â””â”€ Research Supervisor (ì¬ê²€ìƒ‰ or ìŠ¹ì¸)\")\n",
    "print(\"    â””â”€ Content Team\")\n",
    "print(\"        â”œâ”€ Writer Agent (ì‘ì„±)\")\n",
    "print(\"        â””â”€ Content Supervisor (ì¬ì‘ì„± or ìŠ¹ì¸)\")\n",
    "print()\n",
    "print(\"íë¦„:\")\n",
    "print(\"  1. Top Supervisor â†’ Research Wikipedia Agent\")\n",
    "print(\"  2. Wikipedia Agent â†’ Research Supervisor\")\n",
    "print(\"  3. Research Supervisor â†’ ì¬ê²€ìƒ‰ or Top Supervisor\")\n",
    "print(\"  4. Top Supervisor â†’ Content Writer Agent\")\n",
    "print(\"  5. Writer Agent â†’ Content Supervisor\")\n",
    "print(\"  6. Content Supervisor â†’ ì¬ì‘ì„± or Top Supervisor\")\n",
    "print(\"  7. Top Supervisor â†’ ìµœì¢… ìŠ¹ì¸ ë° ì €ì¥ â†’ END\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical ì‹¤í–‰\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ¢ Hierarchical: ì½˜í…ì¸  ì œì‘ íŒ€\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸: ë¸”ë¡ì²´ì¸ ìë£Œ ì œì‘\n",
    "print(\"\\nğŸ“‹ í…ŒìŠ¤íŠ¸: ë¸”ë¡ì²´ì¸ ê¸°ìˆ  ì†Œê°œ ìë£Œ\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "result = hier_app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"ë¸”ë¡ì²´ì¸ ê¸°ìˆ  ì†Œê°œ ìë£Œ ë§Œë“¤ì–´ì¤˜\")]},\n",
    "    config={\"recursion_limit\": 50}\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ê²°ê³¼:\")\n",
    "print(result['messages'][-1].content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¡ Hierarchical (2-Level) íŠ¹ì§•:\")\n",
    "print(\"   - Level 1: Top Supervisor â†’ íŒ€ ê·¸ë˜í”„ ì„ íƒ\")\n",
    "print(\"   - Level 2-A: Research Team (Supervisor + Wiki Agent + Analyzer Agent)\")\n",
    "print(\"   - Level 2-B: Content Team (Supervisor + Writer Agent + Publisher Agent)\")\n",
    "print(\"   - íŒ€ ë‹¨ìœ„ ë…ë¦½ì„±ê³¼ ê³„ì¸µì  í˜‘ì—… êµ¬ì¡°!\")\n",
    "print(\"   - Subgraphë¡œ íŒ€ êµ¬í˜„ â†’ ì¬ì‚¬ìš© ê°€ëŠ¥\")\n",
    "print(\"=\"*70)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4ï¸âƒ£ Swarm\n",
    "\n",
    "## ğŸ“š ì°¸ê³ ìš©: Swarm íŒ¨í„´\n",
    "\n",
    "```python\n",
    "from langgraph_swarm import create_swarm\n",
    "\n",
    "swarm_app = create_swarm([researcher, writer])\n",
    "```\n",
    "\n",
    "**Agent ììœ¨ í˜‘ì—… íŒ¨í„´ì…ë‹ˆë‹¤.**\n",
    "\n",
    "**â†’ Network íŒ¨í„´ (Cell 8)ê³¼ ìœ ì‚¬í•˜ê²Œ Manual Graphë¡œ êµ¬í˜„ ê°€ëŠ¥í•©ë‹ˆë‹¤!**\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“Š ì „ì²´ ë¹„êµ\n",
    "\n",
    "## Manual Graph vs Prebuilt\n",
    "\n",
    "| í•­ëª© | Manual Graph | Prebuilt (create_react_agent, Supervisor ë“±) |\n",
    "|------|-------------|---------------------------------------------|\n",
    "| **Tool Calling** | ë¶ˆí•„ìš” âœ… | í•„ìˆ˜ âŒ |\n",
    "| **LLM ìš”êµ¬ì‚¬í•­** | ëª¨ë“  ëª¨ë¸ OK | OpenAI, Anthropic, Gemini ë“±ë§Œ |\n",
    "| **ë³µì¡ë„** | ëª…ì‹œì  (ì§ì ‘ ì œì–´) | ì¶”ìƒí™” (ìë™ ì²˜ë¦¬) |\n",
    "| **ì•ˆì •ì„±** | ë§¤ìš° ì•ˆì •ì  | Tool call í’ˆì§ˆì— ì˜ì¡´ |\n",
    "| **í™•ì¥ì„±** | ì‰¬ì›€ (ì§ì ‘ ì¶”ê°€) | ì œí•œì  (API ë²”ìœ„ ë‚´) |\n",
    "| **ë””ë²„ê¹…** | ì‰¬ì›€ (íë¦„ ëª…í™•) | ì–´ë ¤ì›€ (ë¸”ë™ë°•ìŠ¤) |\n",
    "| **ë¹„ìš©** | ë¬´ë£Œ (ë¡œì»¬) | ìœ ë£Œ (API) |\n",
    "\n",
    "## íŒ¨í„´ë³„ ë¹„êµ\n",
    "\n",
    "| íŒ¨í„´ | ìœ ì¦ˆì¼€ì´ìŠ¤ | êµ¬í˜„ ë°©ì‹ | Tool Calling | ì¶”ì²œ |\n",
    "|------|-----------|----------|--------------|------|\n",
    "| **Network** | Wikipedia ë¦¬ì„œì¹˜ | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ ëª¨ë“  ëª¨ë¸ |\n",
    "| **Supervisor Manual** | ê³ ê° ì§€ì› | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ ëª¨ë“  ëª¨ë¸ |\n",
    "| **Hierarchical** | ì½˜í…ì¸  ì œì‘ | Manual Graph | ë¶ˆí•„ìš” | â­â­â­ ëª¨ë“  ëª¨ë¸ |\n",
    "| **create_react_agent** | ë™ì  tool ì„ íƒ | Prebuilt | í•„ìˆ˜ | OpenAI/Anthropicë§Œ |\n",
    "| **LangGraph Supervisor** | ê³„ì¸µì  ì‹œìŠ¤í…œ | Prebuilt (2025.2) | í•„ìˆ˜ | OpenAI/Anthropicë§Œ |\n",
    "| **Swarm** | Agent ììœ¨ í˜‘ì—… | Prebuilt | í•„ìˆ˜ | OpenAI/Anthropicë§Œ |\n",
    "\n",
    "## ì‹¤ë¬´ ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "### ë¡œì»¬ ë¬´ë£Œ ëª¨ë¸ (EXAONE, Llama, Mistral ë“±):\n",
    "âœ… **Manual Graph ë°©ì‹ ì‚¬ìš©**\n",
    "- Network, Supervisor Manual, Hierarchical ëª¨ë‘ êµ¬í˜„ ê°€ëŠ¥\n",
    "- ì•ˆì •ì ì´ê³  í™•ì‹¤í•œ ì‘ë™\n",
    "\n",
    "### ìƒì—…ìš© API (OpenAI, Anthropic):\n",
    "âœ… **Prebuilt ì‚¬ìš© ê¶Œì¥**\n",
    "- create_react_agent\n",
    "- LangGraph Supervisor (ìµœì‹ !)\n",
    "- langgraph-swarm\n",
    "\n",
    "### Hybrid ì ‘ê·¼:\n",
    "âœ… **Manual Graph + Prebuilt ì¡°í•©**\n",
    "- í•µì‹¬ ë¡œì§: Manual Graph\n",
    "- Tool calling: create_react_agent (API ëª¨ë¸ë¡œ)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ’¡ ê²°ë¡ :** \n",
    "- ë¡œì»¬ ë¬´ë£Œ ëª¨ë¸ë¡œ ì¶©ë¶„íˆ ê°•ë ¥í•œ Multi-Agent ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ëŠ¥!\n",
    "- Manual Graphê°€ ë” ëª…ì‹œì ì´ê³  ë””ë²„ê¹…í•˜ê¸° ì‰¬ì›€\n",
    "- PrebuiltëŠ” í¸ë¦¬í•˜ì§€ë§Œ Tool calling í•„ìˆ˜\n",
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}