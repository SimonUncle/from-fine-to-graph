{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 02: LangGraph 고급 통합 패턴\n",
    "\n",
    "## 📚 학습 목표\n",
    "01-langgraph-fundamentals에서 배운 모든 패턴을 조합하여 실무에서 바로 사용할 수 있는 완전한 시스템을 구축합니다.\n",
    "\n",
    "### 🔗 사전 학습 필요\n",
    "이 노트북을 시작하기 전에 `01-langgraph-fundamentals.ipynb`를 먼저 완료하세요:\n",
    "- ✅ Routing 패턴: LLM이 판단하는 지능적 라우팅\n",
    "- ✅ Fan-out/Fan-in 패턴: 병렬 처리로 효율성 극대화  \n",
    "- ✅ Summarization 패턴: 긴 대화를 지능적으로 요약\n",
    "- ✅ Human in the Loop 패턴: AI 처리에 인간 검토 추가\n",
    "\n",
    "## 🏆 실무 통합 예제 - 모든 패턴의 완벽한 조합\n",
    "\n",
    "### 💼 실무 시나리오: 지능형 고객 서비스 시스템\n",
    "1. **고객 질문 분류** (Routing): \"기술 문의\", \"환불 요청\", \"일반 상담\" 등으로 자동 분류\n",
    "2. **병렬 전문 처리** (Fan-out/Fan-in): 각 분야별 전문 팀이 병렬로 조사 후 통합\n",
    "3. **대화 기록 관리** (Summarization): 긴 상담 내역을 자동으로 요약해서 효율적 관리  \n",
    "4. **최종 승인 과정** (Human in the Loop): 중요한 응답은 시니어 직원이 검토 후 승인\n",
    "\n",
    "### 🔄 통합 워크플로우\n",
    "**사용자 질문** → **지능형 분류** → **전문팀 병렬 조사** → **결과 통합** → **인간 검토** → **최종 응답**\n",
    "\n",
    "### 🎯 비즈니스 가치\n",
    "- **효율성**: 자동 분류와 병렬 처리로 처리 시간 단축\n",
    "- **품질**: 각 분야 전문성 + 인간 검토로 높은 품질 보장\n",
    "- **확장성**: 새로운 카테고리나 전문 영역 쉽게 추가\n",
    "- **안전성**: 중요한 결정에는 반드시 인간 승인\n",
    "- **지속가능성**: 대화 요약으로 메모리 효율성 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 필요한 라이브러리 설치 및 EXAONE 모델 로드\n",
    "!pip install -q langgraph langchain langchain-teddynote\n",
    "!pip install -q grandalf matplotlib networkx pyppeteer\n",
    "# 시각화를 위한 추가 패키지들\n",
    "!pip install -q graphviz pygraphviz\n",
    "!pip install -q pydot\n",
    "!pip install -q git+https://github.com/lgai-exaone/transformers@add-exaone4\n",
    "!pip install -q torch accelerate\n",
    "\n",
    "from typing import TypedDict, List, Dict, Any, Annotated\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "import re\n",
    "import uuid\n",
    "import operator\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 관련 라이브러리들\n",
    "try:\n",
    "    from langchain_teddynote.graphs import visualize_graph\n",
    "    print(\"✅ langchain-teddynote 시각화 모듈 로드 성공!\")\n",
    "except ImportError:\n",
    "    print(\"⚠️  langchain-teddynote 시각화 모듈 로드 실패\")\n",
    "\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    print(\"✅ IPython 디스플레이 모듈 로드 성공!\")\n",
    "except ImportError:\n",
    "    print(\"⚠️  IPython 디스플레이 모듈 로드 실패\")\n",
    "\n",
    "try:\n",
    "    import graphviz\n",
    "    print(\"✅ graphviz 모듈 로드 성공!\")\n",
    "except ImportError:\n",
    "    print(\"⚠️  graphviz 모듈 로드 실패 - pip install graphviz 필요\")\n",
    "\n",
    "print(\"✅ 라이브러리 import 완료!\")\n",
    "\n",
    "# 🤖 EXAONE 모델 로드\n",
    "MODEL_NAME = \"LGAI-EXAONE/EXAONE-4.0-1.2B\"\n",
    "\n",
    "print(f\"🚀 EXAONE-4.0-1.2B 모델 로드 시작: {MODEL_NAME}\")\n",
    "\n",
    "# EXAONE-4.0-1.2B 모델 및 토크나이저 로드 (CPU 호환)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float32,  # CPU 호환을 위해 float32 사용\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"✅ EXAONE-4.0-1.2B 모델 로드 성공!\")\n",
    "\n",
    "# GPU 메모리 최적화\n",
    "def clear_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def pure_exaone_inference(messages_or_prompt):\n",
    "    \"\"\"🔥 EXAONE 대화 맥락 지원 함수\"\"\"\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    try:\n",
    "        if isinstance(messages_or_prompt, str):\n",
    "            messages = [{\"role\": \"user\", \"content\": messages_or_prompt}]\n",
    "        else:\n",
    "            messages = messages_or_prompt\n",
    "        \n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids,\n",
    "                max_new_tokens=100,\n",
    "                temperature=0.1,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=tokenizer.pad_token_id or tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        generated_ids = outputs[0][input_ids.shape[-1]:]\n",
    "        ai_response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "        \n",
    "        clear_gpu_memory()\n",
    "        return ai_response if ai_response else \"안녕하세요!\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        clear_gpu_memory()\n",
    "        print(f\"🚨 EXAONE 추론 오류: {e}\")\n",
    "        return \"죄송해요, 다시 말씀해 주시겠어요?\"\n",
    "\n",
    "print(\"✅ EXAONE 모델 설정 완료!\")\n",
    "print(\"🚀 고급 통합 패턴 시스템 준비 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 통합 State 정의\n",
    "\n",
    "모든 패턴의 데이터를 포괄하는 통합 State를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏆 통합 고객 서비스 시스템 State 정의 (모든 패턴 통합)\n",
    "class IntegratedCustomerServiceState(TypedDict):\n",
    "    # 기본 정보\n",
    "    customer_query: str                    # 고객 질문\n",
    "    conversation_history: Annotated[List[str], operator.add]  # 대화 기록\n",
    "    \n",
    "    # Routing 패턴 정보\n",
    "    query_category: str                    # 질문 카테고리 (technical/policy/service)\n",
    "    routing_confidence: float              # 분류 신뢰도\n",
    "    \n",
    "    # Fan-out/Fan-in 패턴 정보  \n",
    "    technical_analysis: str                # 기술팀 분석 결과\n",
    "    policy_guidance: str                   # 정책팀 분석 결과\n",
    "    service_recommendation: str            # 고객서비스팀 분석 결과\n",
    "    integrated_response: str               # 통합된 응답\n",
    "    \n",
    "    # Summarization 패턴 정보\n",
    "    conversation_summary: str              # 대화 요약\n",
    "    needs_summary: bool                    # 요약 필요 여부\n",
    "    \n",
    "    # Human in the Loop 패턴 정보\n",
    "    requires_human_review: bool            # 인간 검토 필요 여부\n",
    "    human_feedback: str                    # 인간 검토자 피드백\n",
    "    approval_status: str                   # 승인 상태\n",
    "    \n",
    "    # 최종 결과\n",
    "    final_customer_response: str           # 최종 고객 응답\n",
    "\n",
    "print(\"🏆 통합 고객 서비스 시스템 State 정의 완료!\")\n",
    "print(\"   📊 모든 LangGraph 패턴의 데이터를 포괄하는 통합 구조\")\n",
    "print(\"   🔄 Routing, Fan-out/Fan-in, Summarization, Human in the Loop 지원\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Routing 패턴 구현\n",
    "\n",
    "고객 질문을 지능적으로 분류하는 라우팅 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Routing 패턴 - 지능형 고객 질문 분류 (수정됨)\n",
    "\n",
    "def classify_customer_query(state: IntegratedCustomerServiceState) -> str:\n",
    "    \"\"\"고객 질문을 지능적으로 분류하여 경로 결정\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    \n",
    "    routing_prompt = f\"\"\"\n",
    "다음 고객 질문을 분석해서 적절한 카테고리로 분류해주세요:\n",
    "\n",
    "고객 질문: {query}\n",
    "\n",
    "카테고리 옵션:\n",
    "1. \"technical\" - 기술적 문제, 오류, 버그, 설정 관련\n",
    "2. \"policy\" - 환불, 취소, 정책, 규정 관련\n",
    "3. \"service\" - 일반 문의, 정보 요청, 고객 서비스 관련\n",
    "\n",
    "가장 적절한 카테고리를 하나만 선택해서 답변해주세요.\n",
    "\"\"\"\n",
    "    \n",
    "    llm_response = pure_exaone_inference(routing_prompt)\n",
    "    \n",
    "    # LLM 응답에서 카테고리 추출\n",
    "    if \"technical\" in llm_response.lower():\n",
    "        category = \"technical\"\n",
    "    elif \"policy\" in llm_response.lower():\n",
    "        category = \"policy\"\n",
    "    else:\n",
    "        category = \"service\"\n",
    "    \n",
    "    print(f\"🧠 라우팅 완료: {query[:30]}... → {category}\")\n",
    "    return category\n",
    "\n",
    "def routing_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"라우팅 결과를 상태에 저장하는 노드\"\"\"\n",
    "    category = classify_customer_query(state)\n",
    "    \n",
    "    return {\n",
    "        \"query_category\": category,\n",
    "        \"routing_confidence\": 0.9,\n",
    "        \"requires_human_review\": category == \"policy\"  # 정책 관련은 인간 검토 필요\n",
    "    }\n",
    "\n",
    "print(\"🧠 Routing 패턴 구현 완료!\")\n",
    "print(\"   🎯 EXAONE 기반 지능형 질문 분류\")\n",
    "print(\"   📋 technical/policy/service 3개 카테고리\")\n",
    "print(\"   🔧 classify_customer_query: 경로 결정 함수\")\n",
    "print(\"   📊 routing_node: 상태 업데이트 노드\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fan-out/Fan-in 패턴 구현\n",
    "\n",
    "여러 전문팀이 병렬로 분석하고 결과를 통합하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Fan-out/Fan-in 패턴 - 전문팀 병렬 분석\n",
    "\n",
    "def technical_team_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"기술팀 전문 분석\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    category = state.get(\"query_category\", \"\")\n",
    "    \n",
    "    if category == \"technical\":\n",
    "        prompt = f\"\"\"\n",
    "기술팀 관점에서 다음 고객 문의를 분석해주세요:\n",
    "\n",
    "고객 질문: {query}\n",
    "\n",
    "기술적 관점에서:\n",
    "- 문제 원인 분석\n",
    "- 해결 방법 제시\n",
    "- 예방 조치 안내\n",
    "\n",
    "전문적이고 정확한 기술 지원을 제공해주세요.\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = f\"기술팀 검토: {query} - 기술적 이슈 없음\"\n",
    "    \n",
    "    technical_analysis = pure_exaone_inference(prompt)\n",
    "    print(f\"🔧 기술팀 분석 완료\")\n",
    "    \n",
    "    return {\"technical_analysis\": technical_analysis}\n",
    "\n",
    "def policy_team_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"정책팀 전문 분석\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    category = state.get(\"query_category\", \"\")\n",
    "    \n",
    "    if category == \"policy\":\n",
    "        prompt = f\"\"\"\n",
    "정책팀 관점에서 다음 요청을 검토해주세요:\n",
    "\n",
    "고객 요청: {query}\n",
    "\n",
    "정책 검토 사항:\n",
    "- 정책 적용 가능성\n",
    "- 필요한 절차와 서류\n",
    "- 예상 처리 시간\n",
    "- 대안 제시\n",
    "\n",
    "회사 정책에 따른 정확한 안내를 제공해주세요.\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = f\"정책팀 검토: {query} - 특별한 정책 이슈 없음\"\n",
    "    \n",
    "    policy_guidance = pure_exaone_inference(prompt)\n",
    "    print(f\"📋 정책팀 분석 완료\")\n",
    "    \n",
    "    return {\"policy_guidance\": policy_guidance}\n",
    "\n",
    "def service_team_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"고객서비스팀 전문 분석\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "고객서비스팀 관점에서 다음 고객 문의에 대한 응답을 준비해주세요:\n",
    "\n",
    "고객 질문: {query}\n",
    "\n",
    "고객 서비스 관점에서:\n",
    "- 고객 감정과 니즈 파악\n",
    "- 친절하고 공감하는 응답\n",
    "- 추가 지원 방안\n",
    "- 고객 만족도 향상 방법\n",
    "\n",
    "고객 중심적이고 따뜻한 서비스를 제공해주세요.\n",
    "\"\"\"\n",
    "    \n",
    "    service_recommendation = pure_exaone_inference(prompt)\n",
    "    print(f\"💝 고객서비스팀 분석 완료\")\n",
    "    \n",
    "    return {\"service_recommendation\": service_recommendation}\n",
    "\n",
    "def fan_in_aggregator_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"3개 팀의 분석 결과를 통합\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    technical = state.get(\"technical_analysis\", \"\")\n",
    "    policy = state.get(\"policy_guidance\", \"\")\n",
    "    service = state.get(\"service_recommendation\", \"\")\n",
    "    \n",
    "    integration_prompt = f\"\"\"\n",
    "다음 고객 질문에 대한 3개 전문팀의 분석 결과를 통합해서 완전한 응답을 만들어주세요:\n",
    "\n",
    "고객 질문: {query}\n",
    "\n",
    "🔧 기술팀 분석:\n",
    "{technical}\n",
    "\n",
    "📋 정책팀 분석:\n",
    "{policy}\n",
    "\n",
    "💝 고객서비스팀 분석:\n",
    "{service}\n",
    "\n",
    "위 3개 팀의 전문 의견을 종합하여:\n",
    "1. 고객 문의에 대한 완전한 해답\n",
    "2. 단계별 해결 방안\n",
    "3. 추가 지원 정보\n",
    "4. 친절하고 전문적인 톤\n",
    "\n",
    "통합된 고품질 고객 응답을 작성해주세요.\n",
    "\"\"\"\n",
    "    \n",
    "    integrated_response = pure_exaone_inference(integration_prompt)\n",
    "    print(f\"🔗 전문팀 분석 통합 완료\")\n",
    "    \n",
    "    return {\"integrated_response\": integrated_response}\n",
    "\n",
    "print(\"🔄 Fan-out/Fan-in 패턴 구현 완료!\")\n",
    "print(\"   🔧 technical_team_node: 기술적 문제 전문 분석\")\n",
    "print(\"   📋 policy_team_node: 정책 및 규정 전문 검토\")\n",
    "print(\"   💝 service_team_node: 고객 서비스 관점 분석\")\n",
    "print(\"   🔗 fan_in_aggregator_node: 모든 분석 결과 통합\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Summarization 패턴 구현\n",
    "\n",
    "긴 대화 기록을 지능적으로 요약하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 Summarization 패턴 - 대화 기록 관리\n",
    "\n",
    "def conversation_summarizer_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"대화 기록을 요약\"\"\"\n",
    "    history = state.get(\"conversation_history\", [])\n",
    "    query = state[\"customer_query\"]\n",
    "    integrated_response = state.get(\"integrated_response\", \"\")\n",
    "    \n",
    "    # 현재 대화를 기록에 추가\n",
    "    current_conversation = f\"고객: {query}\\nAI 응답: {integrated_response}\"\n",
    "    \n",
    "    if len(history) >= 3:  # 3개 이상의 대화가 누적되면 요약\n",
    "        # 기존 대화 + 현재 대화를 모두 요약\n",
    "        all_conversation = \"\\n\\n\".join(history + [current_conversation])\n",
    "        \n",
    "        summary_prompt = f\"\"\"\n",
    "다음 고객 서비스 대화 내용을 핵심만 간단히 요약해주세요:\n",
    "\n",
    "대화 내용:\n",
    "{all_conversation}\n",
    "\n",
    "요약 포함 사항:\n",
    "- 고객의 주요 요청사항\n",
    "- 제공된 해결방안\n",
    "- 현재 진행 상황\n",
    "- 추가 필요한 조치\n",
    "\n",
    "간결하고 명확한 요약을 작성해주세요.\n",
    "\"\"\"\n",
    "        \n",
    "        summary = pure_exaone_inference(summary_prompt)\n",
    "        print(f\"📚 대화 요약 완료\")\n",
    "        \n",
    "        return {\n",
    "            \"conversation_summary\": summary,\n",
    "            \"conversation_history\": [f\"[요약] {summary}\", current_conversation],  # 요약 + 최근 대화만 유지\n",
    "            \"needs_summary\": False\n",
    "        }\n",
    "    else:\n",
    "        print(f\"📚 요약 불필요 (대화 {len(history) + 1}턴)\")\n",
    "        return {\n",
    "            \"conversation_summary\": \"대화 시작 단계\",\n",
    "            \"conversation_history\": [current_conversation],\n",
    "            \"needs_summary\": False\n",
    "        }\n",
    "\n",
    "print(\"📚 Summarization 패턴 구현 완료!\")\n",
    "print(\"   📝 긴 대화 자동 요약으로 메모리 효율성 유지\")\n",
    "print(\"   🎯 핵심 정보 보존하면서 토큰 사용량 최적화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Human in the Loop 패턴 구현\n",
    "\n",
    "중요한 결정에 인간의 검토와 승인을 추가하는 시스템을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👥 Human in the Loop 패턴 - 최종 승인 과정 (동작 명확화)\n",
    "\n",
    "def human_review_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"시니어 직원의 검토 및 승인\"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    category = state.get(\"query_category\", \"\")\n",
    "    integrated_response = state.get(\"integrated_response\", \"\")\n",
    "    requires_review = state.get(\"requires_human_review\", False)\n",
    "    \n",
    "    print(f\"👥 Human in the Loop 단계:\")\n",
    "    print(f\"   📂 카테고리: {category}\")\n",
    "    print(f\"   🔍 검토 필요: {requires_review}\")\n",
    "    \n",
    "    if requires_review:\n",
    "        print(f\"   🛑 정책 관련 문의로 시니어 검토가 필요합니다!\")\n",
    "        print(f\"   📧 AI 통합 응답:\")\n",
    "        print(f\"   {integrated_response[:200]}...\")\n",
    "        \n",
    "        # 🛑 실제 Human in the Loop - 워크플로우 중단!\n",
    "        feedback = interrupt({\n",
    "            \"message\": \"🚨 시니어 직원 검토가 필요합니다\",\n",
    "            \"reason\": f\"{category} 카테고리는 인간 승인이 필수입니다\",\n",
    "            \"customer_query\": query,\n",
    "            \"ai_response\": integrated_response,\n",
    "            \"instructions\": \"응답을 검토하고 승인/수정 피드백을 주세요. '승인' 또는 구체적인 수정 요청을 입력하세요.\"\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"human_feedback\": feedback,\n",
    "            \"approval_status\": \"reviewed\"\n",
    "        }\n",
    "    else:\n",
    "        print(f\"   ⚡ {category} 카테고리는 자동 승인됩니다\")\n",
    "        return {\n",
    "            \"human_feedback\": \"자동 승인\",\n",
    "            \"approval_status\": \"auto_approved\"\n",
    "        }\n",
    "\n",
    "def final_response_node(state: IntegratedCustomerServiceState) -> IntegratedCustomerServiceState:\n",
    "    \"\"\"최종 응답 확정\"\"\"\n",
    "    integrated_response = state.get(\"integrated_response\", \"\")\n",
    "    human_feedback = state.get(\"human_feedback\", \"\")\n",
    "    approval_status = state.get(\"approval_status\", \"auto_approved\")\n",
    "    \n",
    "    print(f\"✅ 최종 응답 생성:\")\n",
    "    print(f\"   📋 승인 상태: {approval_status}\")\n",
    "    \n",
    "    if approval_status == \"reviewed\" and human_feedback:\n",
    "        if \"승인\" in human_feedback:\n",
    "            final_response = integrated_response\n",
    "            print(\"   ✅ 시니어 승인 완료 - 원본 응답 사용\")\n",
    "        else:\n",
    "            # 피드백 반영해서 수정\n",
    "            revision_prompt = f\"\"\"\n",
    "다음 AI 응답을 시니어 직원의 피드백에 따라 수정해주세요:\n",
    "\n",
    "원본 응답: {integrated_response}\n",
    "시니어 피드백: {human_feedback}\n",
    "\n",
    "피드백을 반영한 개선된 최종 응답을 작성해주세요.\n",
    "\"\"\"\n",
    "            final_response = pure_exaone_inference(revision_prompt)\n",
    "            print(\"   🔄 피드백 반영 수정 완료\")\n",
    "    else:\n",
    "        final_response = integrated_response\n",
    "        print(\"   ⚡ 자동 승인 완료 - 원본 응답 사용\")\n",
    "    \n",
    "    return {\"final_customer_response\": final_response}\n",
    "\n",
    "print(\"👥 Human in the Loop 패턴 구현 완료!\")\n",
    "print(\"\")\n",
    "print(\"🎯 Human in the Loop 동작 규칙:\")\n",
    "print(\"   📋 정책(policy) 문의 → 🛑 interrupt() 발생 → 인간 검토 필수\")\n",
    "print(\"   🔧 기술(technical) 문의 → ⚡ 자동 승인 → 빠른 처리\")\n",
    "print(\"   💝 서비스(service) 문의 → ⚡ 자동 승인 → 빠른 처리\")\n",
    "print(\"\")\n",
    "print(\"💡 실제 운영 시나리오:\")\n",
    "print(\"   1. 정책 문의 시 워크플로우가 중단되고 __interrupt__ 키 반환\")\n",
    "print(\"   2. 시니어가 웹 인터페이스에서 검토 후 피드백 입력\")\n",
    "print(\"   3. Command(resume=피드백)으로 워크플로우 재시작\")\n",
    "print(\"   4. 피드백에 따라 응답 수정 또는 원본 응답 사용\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 통합 워크플로우 구성\n",
    "\n",
    "이제 모든 패턴을 하나의 워크플로우로 연결하여 완전한 고객 서비스 시스템을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통합 워크플로우 생성 (수정됨: 진정한 Fan-out/Fan-in 패턴)\n",
    "\n",
    "# StateGraph 생성\n",
    "workflow = StateGraph(IntegratedCustomerServiceState)\n",
    "\n",
    "# 모든 노드 추가\n",
    "workflow.add_node(\"routing\", routing_node)  # 라우팅 노드로 변경\n",
    "workflow.add_node(\"technical_team\", technical_team_node)\n",
    "workflow.add_node(\"policy_team\", policy_team_node)\n",
    "workflow.add_node(\"service_team\", service_team_node)\n",
    "workflow.add_node(\"fan_in_aggregator\", fan_in_aggregator_node)\n",
    "workflow.add_node(\"conversation_summarizer\", conversation_summarizer_node)\n",
    "workflow.add_node(\"human_review\", human_review_node)\n",
    "workflow.add_node(\"final_response\", final_response_node)\n",
    "\n",
    "# 🔄 진정한 Fan-out/Fan-in 워크플로우 구성\n",
    "workflow.add_edge(START, \"routing\")\n",
    "\n",
    "# 🌟 Fan-out: 라우팅 후 모든 팀이 병렬로 분석 수행\n",
    "workflow.add_edge(\"routing\", \"technical_team\")\n",
    "workflow.add_edge(\"routing\", \"policy_team\") \n",
    "workflow.add_edge(\"routing\", \"service_team\")\n",
    "\n",
    "# 🔄 Fan-in: 모든 팀의 분석 결과를 통합\n",
    "workflow.add_edge(\"technical_team\", \"fan_in_aggregator\")\n",
    "workflow.add_edge(\"policy_team\", \"fan_in_aggregator\")\n",
    "workflow.add_edge(\"service_team\", \"fan_in_aggregator\")\n",
    "\n",
    "# 순차 처리: 통합 → 요약 → 휴먼 리뷰 → 최종 응답\n",
    "workflow.add_edge(\"fan_in_aggregator\", \"conversation_summarizer\")\n",
    "workflow.add_edge(\"conversation_summarizer\", \"human_review\")\n",
    "workflow.add_edge(\"human_review\", \"final_response\")\n",
    "workflow.add_edge(\"final_response\", END)\n",
    "\n",
    "# 체크포인터와 함께 컴파일\n",
    "checkpointer = MemorySaver()\n",
    "integrated_app = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"✅ 진정한 Fan-out/Fan-in 통합 워크플로우 완성!\")\n",
    "print(\"🔄 수정된 워크플로우 구조:\")\n",
    "print(\"   START → 라우팅 → [모든팀 병렬분석] → 통합 → 요약 → 휴먼리뷰 → 최종응답 → END\")\n",
    "print(\"\")\n",
    "print(\"🌟 주요 개선사항:\")\n",
    "print(\"   ✅ 라우팅 후 모든 팀이 병렬로 분석 (진정한 Fan-out)\")\n",
    "print(\"   ✅ 각 팀이 카테고리에 관계없이 자신의 관점에서 분석\")\n",
    "print(\"   ✅ Fan-in에서 모든 분석 결과를 종합하여 고품질 응답 생성\")\n",
    "print(\"   ✅ 타입 안전성 확보 및 명확한 역할 분리\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 워크플로우 시각화 (수정됨 - 여러 방법 시도)\n",
    "print(\"📊 통합 워크플로우 시각화\")\n",
    "print(\"=\" * 50)\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "visualize_graph(integrated_app)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 테스트 시나리오 1: 기술 문의 (자동 승인 데모) - 개선됨\nprint(\"=== 테스트 시나리오 1: 기술 문의 ===\")\nprint(\"\")\nprint(\"🎯 이 시나리오의 목적:\")\nprint(\"   ✅ 라우팅 패턴: '크래시' 키워드로 'technical' 카테고리 분류\")\nprint(\"   ✅ Fan-out/Fan-in: 모든 팀이 병렬 분석 후 통합\")\nprint(\"   ✅ 요약 패턴: 대화 기록 관리\")\nprint(\"   ✅ Human in Loop: 기술 문의는 자동 승인 (interrupt 없음)\")\nprint(\"\")\nprint(\"📋 예상 실행 흐름:\")\nprint(\"   1. 라우팅 → 'technical' 분류\")\nprint(\"   2. 모든 팀 병렬 분석 (기술팀 상세, 다른 팀 간략)\")\nprint(\"   3. 결과 통합 → 기술적 해결책 중심의 응답 생성\")\nprint(\"   4. 대화 요약 → 첫 번째 대화로 요약 불필요\")\nprint(\"   5. Human Review → 자동 승인 (requires_human_review=False)\")\nprint(\"   6. 최종 응답 → 고객에게 완성된 기술 지원 제공\")\nprint(\"\")\n\ninitial_state = IntegratedCustomerServiceState(\n    customer_query=\"앱이 자꾸 크래시가 나는데 어떻게 해결하나요?\",\n    conversation_history=[],\n    query_category=\"\",\n    routing_confidence=0.0,\n    technical_analysis=\"\",\n    policy_guidance=\"\", \n    service_recommendation=\"\",\n    integrated_response=\"\",\n    conversation_summary=\"\",\n    needs_summary=False,\n    requires_human_review=False,\n    human_feedback=\"\",\n    approval_status=\"\",\n    final_customer_response=\"\"\n)\n\n# 워크플로우 실행\nconfig = {\"configurable\": {\"thread_id\": \"test_technical_1\"}}\n\nprint(\"🚀 워크플로우 실행 중...\")\ntry:\n    result = integrated_app.invoke(initial_state, config)\n    \n    print(\"\")\n    print(\"📋 실행 결과:\")\n    print(f\"   📂 분류 카테고리: {result['query_category']}\")\n    print(f\"   🔧 기술팀 분석: {result['technical_analysis'][:80]}...\")\n    print(f\"   📋 정책팀 검토: {result['policy_guidance'][:60]}...\")\n    print(f\"   💝 서비스팀 분석: {result['service_recommendation'][:60]}...\")\n    print(f\"   📝 대화 요약: {result['conversation_summary']}\")\n    print(f\"   👥 인간 검토: {result['human_feedback']}\")\n    print(f\"   📋 승인 상태: {result.get('approval_status', 'Unknown')}\")\n    print(f\"   💬 최종 응답: {result['final_customer_response'][:100]}...\")\n    \n    # 안전한 인터럽트 체크\n    if \"__interrupt__\" in result:\n        print(\"\")\n        print(\"❌ 예상과 다름: interrupt가 발생했습니다!\")\n        print(\"🔍 기술 문의인데 인간 검토가 트리거되었습니다\")\n        \n        # 인터럽트 데이터 안전하게 출력\n        try:\n            interrupt_info = result[\"__interrupt__\"]\n            print(f\"🎯 인터럽트 데이터 타입: {type(interrupt_info)}\")\n            print(f\"🎯 인터럽트 내용: {str(interrupt_info)[:100]}...\")\n        except Exception as int_err:\n            print(f\"⚠️ 인터럽트 데이터 처리 오류: {int_err}\")\n    else:\n        print(\"\")\n        print(\"✅ 예상대로 작동: 기술 문의는 자동 승인으로 완료!\")\n        print(\"🎯 Human in the Loop가 올바르게 우회되었습니다\")\n        \n    # 추가 검증\n    print(\"\")\n    print(\"🔍 상세 검증:\")\n    print(f\"   📋 requires_human_review: {result.get('requires_human_review', 'Not Set')}\")\n    if result.get('requires_human_review') == False:\n        print(\"   ✅ 기술 문의는 올바르게 자동 승인 경로로 처리됨\")\n    else:\n        print(\"   ⚠️ 예상과 다른 human_review 설정\")\n        \nexcept Exception as e:\n    print(f\"❌ 워크플로우 실행 오류: {e}\")\n    print(\"🔍 디버깅 정보:\")\n    print(f\"   📋 오류 타입: {type(e).__name__}\")\n    print(f\"   📋 오류 메시지: {str(e)}\")\n    \nprint(\"\\n\" + \"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 테스트 시나리오 2: 정책 문의 (Human in the Loop 활성화 데모) - 수정됨\nprint(\"=== 테스트 시나리오 2: 정책 문의 ===\")\nprint(\"\")\nprint(\"🎯 이 시나리오의 목적:\")\nprint(\"   ✅ 라우팅 패턴: '환불' 키워드로 'policy' 카테고리 분류\")\nprint(\"   ✅ Fan-out/Fan-in: 모든 팀이 병렬 분석 (정책팀 상세)\")\nprint(\"   ✅ 요약 패턴: 기존 대화 기록과 함께 요약\")\nprint(\"   ✅ Human in Loop: 정책 문의는 interrupt() 발생 → 인간 검토 필수!\")\nprint(\"\")\nprint(\"📋 예상 실행 흐름:\")\nprint(\"   1. 라우팅 → 'policy' 분류\")\nprint(\"   2. 모든 팀 병렬 분석 (정책팀 상세, 다른 팀 지원)\")\nprint(\"   3. 결과 통합 → 정책 가이드라인 중심의 응답 생성\")\nprint(\"   4. 대화 요약 → 기존 대화와 통합하여 요약\")\nprint(\"   5. Human Review → interrupt() 발생! (__interrupt__ 키 반환)\")\nprint(\"   6. 워크플로우 중단 → 시니어 검토 대기\")\nprint(\"\")\n\npolicy_state = IntegratedCustomerServiceState(\n    customer_query=\"환불 정책이 어떻게 되나요? 구매한지 15일 됐는데 환불 가능한가요?\",\n    conversation_history=[\"이전에 비슷한 문의가 있었습니다.\"],\n    query_category=\"\",\n    routing_confidence=0.0,\n    technical_analysis=\"\",\n    policy_guidance=\"\", \n    service_recommendation=\"\",\n    integrated_response=\"\",\n    conversation_summary=\"\",\n    needs_summary=False,\n    requires_human_review=False,\n    human_feedback=\"\",\n    approval_status=\"\",\n    final_customer_response=\"\"\n)\n\nconfig2 = {\"configurable\": {\"thread_id\": \"test_policy_1\"}}\n\nprint(\"🚀 워크플로우 실행 중...\")\ntry:\n    result2 = integrated_app.invoke(policy_state, config2)\n    \n    print(\"\")\n    print(\"📋 실행 결과:\")\n    print(f\"   📂 분류 카테고리: {result2['query_category']}\")\n    print(f\"   📋 정책팀 가이던스: {result2['policy_guidance'][:80]}...\")\n    print(f\"   📝 대화 요약: {result2['conversation_summary']}\")\n    \n    if \"__interrupt__\" in result2:\n        print(\"\")\n        print(\"✅ 예상대로 작동: interrupt가 발생했습니다!\")\n        print(\"🛑 정책 관련 문의로 시니어 검토가 필요합니다\")\n        \n        # 🔧 안전한 인터럽트 데이터 처리\n        print(\"📋 인터럽트 상세 정보:\")\n        try:\n            interrupt_data = result2[\"__interrupt__\"]\n            \n            # 데이터 타입별 처리\n            if isinstance(interrupt_data, dict):\n                print(\"   📊 인터럽트 데이터 타입: 딕셔너리\")\n                for key, value in interrupt_data.items():\n                    if key == \"ai_response\":\n                        print(f\"   {key}: {str(value)[:100]}...\")\n                    else:\n                        print(f\"   {key}: {value}\")\n                        \n            elif isinstance(interrupt_data, list):\n                print(\"   📊 인터럽트 데이터 타입: 리스트\")\n                for i, item in enumerate(interrupt_data):\n                    print(f\"   인터럽트 {i+1}: {str(item)[:100]}...\")\n                    \n            else:\n                print(\"   📊 인터럽트 데이터 타입: 기타\")\n                print(f\"   전체 데이터: {str(interrupt_data)[:200]}...\")\n                \n        except Exception as e:\n            print(f\"   ⚠️ 인터럽트 데이터 파싱 오류: {e}\")\n            print(f\"   🔍 원본 데이터 타입: {type(result2.get('__interrupt__', 'Not Found'))}\")\n            print(f\"   🔍 원본 데이터: {str(result2.get('__interrupt__', 'Not Found'))[:100]}...\")\n        \n        print(\"\")\n        print(\"💡 다음 단계 (실제 운영 시):\")\n        print(\"   1. 시니어가 웹 인터페이스에서 AI 응답 검토\")\n        print(\"   2. 승인 또는 수정 요청 입력\")\n        print(\"   3. Command(resume='피드백')으로 워크플로우 재시작\")\n        \n        # 시뮬레이션: 시니어 승인 후 재시작\n        print(\"\")\n        print(\"🎭 시니어 승인 시뮬레이션...\")\n        try:\n            resume_result2 = integrated_app.invoke(\n                Command(resume=\"정책에 따라 15일 이내이므로 환불 승인합니다.\"), \n                config2\n            )\n            print(\"✅ 워크플로우 재시작 완료!\")\n            print(f\"💬 최종 고객 응답: {resume_result2['final_customer_response'][:150]}...\")\n        except Exception as resume_error:\n            print(f\"⚠️ 워크플로우 재시작 오류: {resume_error}\")\n        \n    else:\n        print(\"\")\n        print(\"❌ 예상과 다름: interrupt가 발생하지 않았습니다!\")\n        print(\"🔍 정책 문의인데 자동 승인되었을 가능성이 있습니다\")\n        print(f\"   📋 requires_human_review: {result2.get('requires_human_review', 'Unknown')}\")\n        print(f\"   📋 approval_status: {result2.get('approval_status', 'Unknown')}\")\n        print(f\"💬 최종 응답: {result2['final_customer_response'][:150]}...\")\n        \nexcept Exception as e:\n    print(f\"❌ 워크플로우 실행 오류: {e}\")\n    print(\"🔍 디버깅 정보:\")\n    print(f\"   📋 오류 타입: {type(e).__name__}\")\n    print(f\"   📋 오류 메시지: {str(e)}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"\")\nprint(\"🎓 학습 포인트:\")\nprint(\"   📌 기술 문의 = 자동 승인 = 빠른 처리\")\nprint(\"   📌 정책 문의 = 인간 검토 = 신중한 처리\")\nprint(\"   📌 interrupt()는 실제 워크플로우를 중단시키는 강력한 도구\")\nprint(\"   📌 Command(resume)으로 중단된 워크플로우를 재시작할 수 있음\")\nprint(\"   📌 인터럽트 데이터 구조는 환경에 따라 다를 수 있음\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 결론 및 학습 포인트\n",
    "\n",
    "## 🎯 이번 실습에서 배운 것들\n",
    "\n",
    "### 패턴 통합의 힘\n",
    "- **라우팅 패턴**: 적절한 전문가에게 문의를 자동 분배\n",
    "- **Fan-out/Fan-in 패턴**: 여러 관점에서 동시에 문제를 분석하고 통합\n",
    "- **요약 패턴**: 긴 대화를 효율적으로 관리\n",
    "- **Human in the Loop**: 중요한 결정에서 인간의 판단력 활용\n",
    "\n",
    "### 실제 비즈니스 적용\n",
    "이 통합 시스템은 다음과 같은 실제 시나리오에서 활용할 수 있습니다:\n",
    "- 🎧 **고객 서비스 센터**: 문의를 자동으로 분류하고 전문가 검토 후 응답\n",
    "- 🏥 **의료 상담**: 증상을 분석하고 의사의 최종 검토 후 권고사항 제공\n",
    "- 💼 **법률 자문**: 법적 문제를 분석하고 변호사의 검토 후 조언 제공\n",
    "- 🏭 **제품 지원**: 기술 문제를 자동 분류하고 전문가 승인 후 해결책 제공\n",
    "\n",
    "### 다음 단계\n",
    "- 더 복잡한 조건부 라우팅 구현\n",
    "- 실시간 피드백 루프 추가\n",
    "- 성능 모니터링 및 최적화\n",
    "- 다양한 데이터 소스와의 통합\n",
    "- 멀티모달 입력 (텍스트, 이미지, 음성) 지원\n",
    "\n",
    "## 💡 핵심 인사이트\n",
    "각각의 LangGraph 패턴은 강력하지만, 이들을 조합했을 때 진정한 가치가 나타납니다. 실제 비즈니스 문제는 단일 패턴으로 해결되지 않으며, 이런 통합 접근법이 필요합니다.\n",
    "\n",
    "## 🚀 실무 적용 가이드\n",
    "1. **단계적 접근**: 한 번에 모든 패턴을 구현하지 말고 점진적으로 추가\n",
    "2. **비즈니스 우선순위**: 가장 중요한 비즈니스 문제부터 해결\n",
    "3. **사용자 피드백**: 실제 사용자의 피드백을 통한 지속적 개선\n",
    "4. **성능 모니터링**: 각 패턴의 성능을 모니터링하고 최적화\n",
    "5. **확장성 고려**: 미래의 요구사항 변화에 대비한 유연한 설계\n",
    "\n",
    "🎉 **축하합니다! 이제 LangGraph의 모든 핵심 패턴을 마스터하고 실무급 통합 시스템을 구축할 수 있습니다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}