{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¤ 05: Multi-Agent HandOffs ì‹¤ì „ (LangGraph)\n",
        "\n",
        "ì•ì„  02Â·03Â·04 ë…¸íŠ¸ë¶ì—ì„œ `StateGraph`ì™€ `create_react_agent`ë¡œ **ë£¨í”„Â·ë¼ìš°íŒ…Â·ë„êµ¬ ì‚¬ìš©**ì„ ìµí˜”ì–´ìš”.  \n",
        "ì´ë²ˆì—ëŠ” ê·¸ ê¸°ë°˜ ìœ„ì— \"ì™œ ë©€í‹° ì—ì´ì „íŠ¸ HandOffsê°€ í”„ë¡œë•ì…˜ì—ì„œ í•„ìˆ˜ì¸ì§€\"ë¥¼ ì²´ê°í˜• ì‹¤ìŠµìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§­ ìš©ì–´ ë§¤í•‘ (ë¹ ë¥¸ ì •ë¦¬)\n",
        "- **ReAct ë£¨í”„**: ìƒê°(Reason) â†’ í–‰ë™(Act) â†’ ê´€ì°°(Observe)ë¡œ ìê¸° ìì‹ ì—ê²Œ ë˜ëŒì•„ì˜¤ëŠ” ì—£ì§€\n",
        "- **Swarm HandOffs**: ì—ì´ì „íŠ¸ê°€ ìƒíƒœì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë“¤ê³  ë‹¤ìŒ ë‹´ë‹¹ìì—ê²Œ ìˆœì°¨ ì¸ê³„\n",
        "- **LangGraph StateGraph**: ë…¸ë“œÂ·ì—£ì§€ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„ ì–¸í•´ ê²°ì •ë¡ , ì²´í¬í¬ì¸íŠ¸, ê°€ë“œ, ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•©\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Multi-Agent ì§„í™” íƒ€ì„ë¼ì¸ (LangGraph ê´€ì )\n",
        "1. **Super-Agent (2022)**: ëª¨ë“  ë„êµ¬Â·ì—­í• ì„ ë‹¨ì¼ ì—ì´ì „íŠ¸ì— ëª°ì•„ë„£ìŒ â†’ ì„ íƒ í”¼ë¡œ, ë¹„ìš©â†‘\n",
        "2. **ReAct & Planner-Executor (2022~2023)**: ë£¨í”„Â·ê³„íšìœ¼ë¡œ ì§ˆì„œâ†‘ â†’ ë£¨í”„ ì œì–´Â·ì‹¤íŒ¨ ë³µêµ¬ê°€ ì·¨ì•½\n",
        "3. **ë³‘ë ¬Â·ìœ„ì›íšŒ íŒ¨í„´ (2023 ì¤‘ë°˜)**: í’ˆì§ˆâ†‘ â†’ í†µí•©Â·ì¡°ì • ë¹„ìš©â†‘\n",
        "4. **Swarm HandOffs (2023 í›„ë°˜~2024)**: í•„ìš”í•  ë•Œë§Œ ì í•©í•œ ì—ì´ì „íŠ¸ì—ê²Œ ìƒíƒœ + ì»¨í…ìŠ¤íŠ¸ ì¸ê³„\n",
        "5. **LangGraph StateGraph (2024~)**: ê·¸ë˜í”„/DAG ê¸°ë°˜ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸, HITL, ê°€ë“œë ˆì¼, íŒ¬ì¸Â·íŒ¬ì•„ì›ƒê¹Œì§€ í‘œì¤€í™”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ HandOffsê°€ í•´ê²°í•˜ëŠ” í•µì‹¬ ì´ìŠˆ\n",
        "**Before (Super-Agent / ë³‘ë ¬)**\n",
        "- ë„êµ¬ ì„ íƒ í˜¼ë€, ìˆœì„œ ë¶ˆëª…í™•, í‰ê· ì  ê²°ê³¼\n",
        "\n",
        "**After (HandOffs / StateGraph)**\n",
        "- ë¼ìš°í„° â†’ Research â†’ Calculator â†’ Writer ë‹¨ê³„ë³„ ì¸ê³„\n",
        "- ìƒíƒœì— ì‘ì—… ë§¥ë½ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•˜ë©° í•„ìš”í•œ ì „ë¬¸ ì—ì´ì „íŠ¸ë§Œ í™œì„±í™”\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª ì˜¤ëŠ˜ ì‹¤ìŠµ ë¡œë“œë§µ\n",
        "- **Lab A**: ReAct ë£¨í”„ í•œê³„ë¥¼ ì§ì ‘ ê´€ì°°í•˜ê³  ì œì–´ ì¥ì¹˜ë¥¼ ë¶™ì—¬ë³´ê¸°\n",
        "- **Lab B**: Swarm HandOffs ìŠ¤íƒ€ì¼ ë¯¸ë‹ˆ ë¼ìš°í„° êµ¬í˜„ìœ¼ë¡œ ìƒíƒœ ì¸ê³„ ê°ê° ìµíˆê¸°\n",
        "- **Lab C**: LangGraph StateGraphë¡œ í”„ë¡œë•ì…˜ê¸‰ ë©€í‹° ì—ì´ì „íŠ¸ í•¸ë“œì˜¤í”„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“¦ Colab & ì˜¤í”ˆì†ŒìŠ¤ í™˜ê²½ ì¤€ë¹„\n",
        "Colabì—ì„œ ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ëª¨ë“  ì˜ì¡´ì„±ì„ ì˜¤í”ˆì†ŒìŠ¤ íŒ¨í‚¤ì§€ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤. ì¶œë ¥ì€ `%%capture`ë¡œ ìˆ¨ê²¨ë‘¡ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -q --upgrade \"transformers>=4.44.2\" accelerate bitsandbytes     langgraph langchain langchain-core langchain-community langchain-huggingface langchain-teddynote     sentence-transformers faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import math\n",
        "from typing import Dict, List, TypedDict, Literal, Any, Optional\n",
        "from uuid import uuid4\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.types import Command\n",
        "\n",
        "from langchain_teddynote.messages import stream_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ§  Qwen2.5-7B-Instruct (4bit) ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"âš™ï¸ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
        "\n",
        "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_use_double_quant=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "text_gen = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.9,\n",
        ")\n",
        "\n",
        "llm = ChatHuggingFace(llm=HuggingFacePipeline(pipeline=text_gen))\n",
        "print(\"âœ… Qwen2.5-7B-Instruct 4bit ì¤€ë¹„ ì™„ë£Œ! (í•œêµ­ì–´ + íˆ´ì½œ ì§€ì›)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MARKET_DATA = {\n",
        "    \"size_2022\": 120.0,\n",
        "    \"size_2023\": 150.0,\n",
        "    \"size_2024\": 184.7,\n",
        "    \"major_players\": [\"OpenAI\", \"Google\", \"Microsoft\", \"Amazon\"],\n",
        "    \"trends\": [\"Generative AI\", \"Multimodal AI\", \"Enterprise AI\"],\n",
        "}\n",
        "\n",
        "def format_market_report(summary: str, forecast: str) -> str:\n",
        "    return (\n",
        "        \"ìš”ì•½: {summary}\"\n",
        "        \"ì „ë§: {forecast}\"\n",
        "        \"í•µì‹¬ ê¸°ì—…: {players}\"\n",
        "        \"í•µì‹¬ íŠ¸ë Œë“œ: {trends}\"\n",
        "    ).format(\n",
        "        summary=summary,\n",
        "        forecast=forecast,\n",
        "        players=\", \".join(MARKET_DATA[\"major_players\"]),\n",
        "        trends=\", \".join(MARKET_DATA[\"trends\"]),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def market_research_tool(topic: str) -> str:\n",
        "    \"\"\"ê°„ë‹¨í•œ ì‹œì¥ ì¡°ì‚¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(\"ğŸ”§ market_research_tool í˜¸ì¶œ\")\n",
        "    report = (\n",
        "        f\"AI ì‹œì¥ì€ 2024ë…„ì— {MARKET_DATA['size_2024']}B USD ê·œëª¨ë¡œ ì„±ì¥í–ˆì–´ìš”. \"\n",
        "        f\"ì£¼ìš” ê¸°ì—…ì€ {', '.join(MARKET_DATA['major_players'])}ì…ë‹ˆë‹¤.\"\n",
        "    )\n",
        "    return report\n",
        "\n",
        "@tool\n",
        "def growth_calculator_tool(series: str) -> str:\n",
        "    \"\"\"ë‹¨ìˆœ ì„±ì¥ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤. seriesëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìˆ«ìì…ë‹ˆë‹¤.\"\"\"\n",
        "    print(\"ğŸ”§ growth_calculator_tool í˜¸ì¶œ\")\n",
        "    try:\n",
        "        numbers = [float(x.strip()) for x in series.split(',')]\n",
        "        if len(numbers) < 2:\n",
        "            return \"ë‘ ê°œ ì´ìƒì˜ ìˆ«ìê°€ í•„ìš”í•©ë‹ˆë‹¤.\"\n",
        "        start, end = numbers[0], numbers[-1]\n",
        "        years = len(numbers) - 1\n",
        "        cagr = (end / start) ** (1 / years) - 1\n",
        "        return f\"ì—°í‰ê·  ì„±ì¥ë¥ (CAGR): {cagr * 100:.2f}%\"\n",
        "    except Exception as exc:\n",
        "        return f\"ì„±ì¥ë¥  ê³„ì‚° ì˜¤ë¥˜: {exc}\"\n",
        "\n",
        "TOOLS = [market_research_tool, growth_calculator_tool]\n",
        "MEMORY = MemorySaver()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Lab A â€“ ReAct ë£¨í”„ í•œê³„ ì²´ê°í•˜ê¸°\n",
        "ReAct íŒ¨í„´ì€ ê·¸ ìì²´ë¡œ ê°•ë ¥í•˜ì§€ë§Œ, ë³µí•© ì—…ë¬´ì—ì„œëŠ” **ë£¨í”„ ì œì–´ì™€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬**ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ê¸°ë³¸ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ì–´ë–¤ ì œì•½ì´ ìˆëŠ”ì§€ ì§ì ‘ í™•ì¸í•´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "REACT_POLICY = \"\"\"\n",
        "ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”.\n",
        "\n",
        "Thought: í˜„ì¬ ìƒê°ì„ í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ ì •ë¦¬ (ë„êµ¬ í˜¸ì¶œ ì „ í•„ìš”).\n",
        "Action: ì‚¬ìš©í•  ë„êµ¬ ì´ë¦„ë§Œ ì…ë ¥ (ì˜ˆ: market_research_tool).\n",
        "Action Input: JSON ë¬¸ìì—´ í˜•íƒœë¡œ ë„êµ¬ì— ì „ë‹¬í•  ì¸ìë¥¼ ì‘ì„±. ì˜ˆ: {\"topic\": \"AI market\"}\n",
        "Observation: ë„êµ¬ê°€ ë°˜í™˜í•œ ê²°ê³¼ë¥¼ ìš”ì•½.\n",
        "\n",
        "ë„êµ¬ë¥¼ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šì„ ë•Œë§Œ Final Answerë¥¼ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "Final Answer: í•œêµ­ì–´ ìš”ì•½.\n",
        "\n",
        "ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¶”ì¸¡í•´ì„œ ë‹µë³€í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.\n",
        "\"\"\"\n",
        "\n",
        "react_agent = create_react_agent(\n",
        "    llm,\n",
        "    TOOLS,\n",
        "    checkpointer=MEMORY,\n",
        "    prompt=REACT_POLICY,\n",
        ")\n",
        "\n",
        "print(\"ğŸ§  ReAct Agent êµ¬ì„± ì™„ë£Œ!\")\n",
        "\n",
        "def run_react_demo(task: str, recursion_limit: int = 8) -> None:\n",
        "    \"\"\"ReAct ë£¨í”„ ì‹¤í–‰ + íˆ´ ì‚¬ìš© ìš”ì•½\"\"\"\n",
        "    thread_id = f\"lab-a-demo-{uuid4().hex[:4]}\"\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}, \"recursion_limit\": recursion_limit}\n",
        "\n",
        "    print(\"ğŸ§ª Lab A ë°ëª¨ ì‹¤í–‰\")\n",
        "    print(\"-\" * 60)\n",
        "    stream_graph(\n",
        "        react_agent,\n",
        "        {\"messages\": [HumanMessage(content=task)]},\n",
        "        config=config,\n",
        "    )\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    records = MEMORY.get(config)\n",
        "    if not records:\n",
        "        print(\"âš ï¸ ì €ì¥ëœ ìƒíƒœê°€ ì—†ì–´ íˆ´ ì‚¬ìš© ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "    latest_entry = records[-1]\n",
        "    if isinstance(latest_entry, dict):\n",
        "        latest_state = latest_entry.get(\"state\", latest_entry)\n",
        "    elif isinstance(latest_entry, (list, tuple)) and len(latest_entry) >= 2:\n",
        "        latest_state = latest_entry[1]\n",
        "    else:\n",
        "        latest_state = latest_entry\n",
        "    messages = latest_state.get(\"messages\", [])\n",
        "\n",
        "    tool_msgs = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
        "    final_reply = next((msg.content for msg in reversed(messages) if isinstance(msg, AIMessage)), \"\")\n",
        "\n",
        "    print(\"ğŸ“Š íˆ´ ì‚¬ìš© ìš”ì•½\")\n",
        "    if tool_msgs:\n",
        "        for msg in tool_msgs:\n",
        "            print(f\"- {msg.name}: {msg.content}\")\n",
        "    else:\n",
        "        print(\"- ì‚¬ìš©ëœ íˆ´ì´ ì—†ìŠµë‹ˆë‹¤\")\n",
        "    print(\"\n",
        "ğŸ“ ìµœì¢… ì‘ë‹µ\")\n",
        "    print(final_reply.strip())\n",
        "\n",
        "    if hasattr(MEMORY, \"delete\"):\n",
        "        MEMORY.delete(config)\n",
        "\n",
        "sample_task = (\n",
        "    \"ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œë¥¼ ì§€ì¼œì„œ ë‹µë³€í•˜ì„¸ìš”:\n",
        "\"\n",
        "    \"1. market_research_toolì„ í˜¸ì¶œí•´ ìµœì‹  ì‹œì¥ ìš”ì•½ì„ ì–»ëŠ”ë‹¤.\n",
        "\"\n",
        "    \"2. growth_calculator_toolì„ í˜¸ì¶œí•´ ì„±ì¥ë¥ ì„ ê³„ì‚°í•œë‹¤.\n",
        "\"\n",
        "    \"3. ë‘ ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ìììš© ìš”ì•½ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•œë‹¤.\n",
        "\"\n",
        "    \"ìš”ì²­: AI ì‹œì¥ì„ ì¡°ì‚¬í•˜ê³ , ìµœê·¼ ì„±ì¥ë¥ ì„ ê³„ì‚°í•œ ë’¤, íˆ¬ìììš© ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.\"\n",
        ")\n",
        "\n",
        "run_react_demo(sample_task)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” ì‹¤í–‰ ê²°ê³¼ í•´ì„ ê°€ì´ë“œ\n",
        "- ì¶œë ¥ ìƒë‹¨ì˜ `stream_graph` ì„¹ì…˜ì—ì„œ ReAct ë£¨í”„ê°€ ì–´ë–»ê²Œ ì§„í–‰ëëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n",
        "- `ğŸ“Š íˆ´ ì‚¬ìš© ìš”ì•½`ì— `market_research_tool`, `growth_calculator_tool`ì´ ëª¨ë‘ ë‚˜íƒ€ë‚˜ë©´ ë„êµ¬ í˜¸ì¶œì´ ì •ìƒ ì‹¤í–‰ëœ ê²ƒì…ë‹ˆë‹¤.\n",
        "- `ğŸ“ ìµœì¢… ì‘ë‹µ`ì€ ë„êµ¬ ê²°ê³¼ë¥¼ ë°˜ì˜í•œ ìš”ì•½ì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì„ ê°•ì˜ ìŠ¬ë¼ì´ë“œë‚˜ ì‹¤ìŠµ ì•ˆë‚´ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ReactRunResult:\n",
        "    content: str\n",
        "    stop_reason: str\n",
        "    steps: int\n",
        "    tool_calls: List[str]\n",
        "\n",
        "\n",
        "def run_react_with_controls(task: str, max_steps: int, stop_keyword: Optional[str] = None) -> ReactRunResult:\n",
        "    \"\"\"ReAct ì‹¤í–‰ì„ í†µì œí•˜ê³  ê²°ê³¼ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
        "    thread_id = f\"lab-a-ctrl-{uuid4().hex[:4]}\"\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id}, \"recursion_limit\": max_steps}\n",
        "\n",
        "    list(react_agent.stream({\"messages\": [HumanMessage(content=task)]}, config=config))\n",
        "\n",
        "    records = MEMORY.get(config)\n",
        "    if not records:\n",
        "        return ReactRunResult(content=\"\", stop_reason=\"no_state\", steps=0, tool_calls=[])\n",
        "\n",
        "    latest_entry = records[-1]\n",
        "    if isinstance(latest_entry, dict):\n",
        "        latest_state = latest_entry.get(\"state\", latest_entry)\n",
        "    elif isinstance(latest_entry, (list, tuple)) and len(latest_entry) >= 2:\n",
        "        latest_state = latest_entry[1]\n",
        "    else:\n",
        "        latest_state = latest_entry\n",
        "    messages = latest_state.get(\"messages\", [])\n",
        "\n",
        "    tool_msgs = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
        "    tool_calls = [msg.name for msg in tool_msgs]\n",
        "    final_reply = next((msg.content for msg in reversed(messages) if isinstance(msg, AIMessage)), \"\")\n",
        "\n",
        "    stop_reason = \"finished\"\n",
        "    if stop_keyword and stop_keyword in final_reply:\n",
        "        stop_reason = f\"keyword:{stop_keyword}\"\n",
        "    elif len(tool_calls) >= max_steps:\n",
        "        stop_reason = \"max_steps\"\n",
        "\n",
        "    if hasattr(MEMORY, \"delete\"):\n",
        "        MEMORY.delete(config)\n",
        "\n",
        "    return ReactRunResult(\n",
        "        content=final_reply.strip(),\n",
        "        stop_reason=stop_reason,\n",
        "        steps=len(tool_calls),\n",
        "        tool_calls=tool_calls,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "control_result = run_react_with_controls(\n",
        "    task=sample_task,\n",
        "    max_steps=3,\n",
        "    stop_keyword=\"ë³´ê³ ì„œ\",\n",
        ")\n",
        "\n",
        "print(\"ğŸ›‘ ì¢…ë£Œ ì‚¬ìœ :\", control_result.stop_reason)\n",
        "print(\"ğŸ§® ì‚¬ìš©í•œ íˆ´ ìˆ˜:\", control_result.steps)\n",
        "print(\"ğŸ”§ íˆ´ í˜¸ì¶œ ëª©ë¡:\", control_result.tool_calls)\n",
        "print(\"\n",
        "ğŸ“ ìµœì¢… ì‘ë‹µ\")\n",
        "print(control_result.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ReactRunResult:\n",
        "    content: str\n",
        "    stop_reason: str\n",
        "\n",
        "# TODO: ë¯¸ì…˜ A-1 êµ¬í˜„\n",
        "\n",
        "def run_react_with_controls(task: str, max_steps: int, stop_keyword: str) -> ReactRunResult:\n",
        "    raise NotImplementedError(\"ë¯¸ì…˜ A-1ì„ ì™„ë£Œí•˜ê³  ë³´ê³ ì„œë¥¼ ì œì¶œí•˜ì„¸ìš”!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ğŸ’¡ íŒíŠ¸: `stream_graph`ë¥¼ ë‹¤ì‹œ í™œìš©í•´ ì´ë²¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©´ì„œ í‚¤ì›Œë“œë¥¼ ê°ì§€í•˜ê³ , `recursion_limit`ìœ¼ë¡œ ìµœëŒ€ ìŠ¤í…ì„ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Lab B â€“ Swarm HandOffs ë¯¸ë‹ˆ ë¼ìš°í„° ë§Œë“¤ê¸°\n",
        "Swarm ìŠ¤íƒ€ì¼ì—ì„œëŠ” ê° ì—ì´ì „íŠ¸ê°€ **`next_agent`, `state`**ë¥¼ ë°˜í™˜í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ ë°”í†¤ì„ ë„˜ê¹ë‹ˆë‹¤. ê°„ë‹¨í•œ ìƒíƒœ ì‚¬ì „ì„ ì‚¬ìš©í•´ ì»¨í…ìŠ¤íŠ¸ê°€ ì–´ë–»ê²Œ ì „ë‹¬ë˜ëŠ”ì§€ ì‚´í´ë´…ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HandOffState(TypedDict):\n",
        "    current_agent: str\n",
        "    messages: List[str]\n",
        "    results: Dict[str, Any]\n",
        "    next_action: str\n",
        "\n",
        "def supervisor_agent(state: HandOffState) -> tuple[str, HandOffState]:\n",
        "    state = state.copy()\n",
        "    state[\"current_agent\"] = \"supervisor\"\n",
        "    state[\"next_action\"] = \"ì‹œì¥ ì¡°ì‚¬ ê³„íš ìˆ˜ë¦½\"\n",
        "    state[\"messages\"].append(\"Supervisor: ìš°ì„  ì‹œì¥ ë°ì´í„°ë¥¼ ëª¨ì•„ë³´ì\")\n",
        "    return \"research_agent\", state\n",
        "\n",
        "def research_agent(state: HandOffState) -> tuple[str, HandOffState]:\n",
        "    state = state.copy()\n",
        "    state[\"current_agent\"] = \"research_agent\"\n",
        "    state[\"next_action\"] = \"ì„±ì¥ë¥  ê³„ì‚°\"\n",
        "    state[\"results\"][\"research\"] = market_research_tool.func(\"AI market\")\n",
        "    state[\"messages\"].append(\"Research: ì‹œì¥ ì¡°ì‚¬ ì™„ë£Œ\")\n",
        "    return \"calculator_agent\", state\n",
        "\n",
        "def calculator_agent(state: HandOffState) -> tuple[str, HandOffState]:\n",
        "    state = state.copy()\n",
        "    state[\"current_agent\"] = \"calculator_agent\"\n",
        "    values = \",\".join(str(MARKET_DATA[k]) for k in [\"size_2022\", \"size_2023\", \"size_2024\"])\n",
        "    state[\"results\"][\"growth\"] = growth_calculator_tool.func(values)\n",
        "    state[\"messages\"].append(\"Calculator: ì„±ì¥ë¥  ê³„ì‚° ì™„ë£Œ\")\n",
        "    state[\"next_action\"] = \"ë³´ê³ ì„œ ì‘ì„±\"\n",
        "    return \"writer_agent\", state\n",
        "\n",
        "def writer_agent(state: HandOffState) -> tuple[str, HandOffState]:\n",
        "    state = state.copy()\n",
        "    state[\"current_agent\"] = \"writer_agent\"\n",
        "    summary = state[\"results\"].get(\"research\", \"\")\n",
        "    forecast = state[\"results\"].get(\"growth\", \"\")\n",
        "    state[\"results\"][\"report\"] = format_market_report(summary, forecast)\n",
        "    state[\"messages\"].append(\"Writer: ìµœì¢… ë³´ê³ ì„œ ì‘ì„±\")\n",
        "    state[\"next_action\"] = \"ì™„ë£Œ\"\n",
        "    return \"END\", state\n",
        "\n",
        "HANDOFF_PIPELINE = {\n",
        "    \"supervisor\": supervisor_agent,\n",
        "    \"research_agent\": research_agent,\n",
        "    \"calculator_agent\": calculator_agent,\n",
        "    \"writer_agent\": writer_agent,\n",
        "}\n",
        "\n",
        "def run_swarm_handoff(initial_state: HandOffState) -> HandOffState:\n",
        "    agent = \"supervisor\"\n",
        "    state = initial_state\n",
        "    while agent != \"END\":\n",
        "        agent, state = HANDOFF_PIPELINE[agent](state)\n",
        "    return state\n",
        "\n",
        "initial_state: HandOffState = {\n",
        "    \"current_agent\": \"user\",\n",
        "    \"messages\": [\"User: AI ì‹œì¥ ì¡°ì‚¬í•˜ê³  ì„±ì¥ë¥  ê³„ì‚°í•´ì„œ ë³´ê³ ì„œ ì¨ì¤˜\"],\n",
        "    \"results\": {},\n",
        "    \"next_action\": \"\"\n",
        "}\n",
        "\n",
        "final_state = run_swarm_handoff(initial_state)\n",
        "print(final_state[\"results\"][\"report\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” ë¯¸ì…˜ B-1: ì¡°ê±´ë¶€ HandOff ì¶”ê°€\n",
        "- `research_agent`ì—ì„œ ì‹œì¥ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ `calculator_agent` ëŒ€ì‹  `human_review`ë¡œ ë„˜ê¸°ë„ë¡ ì¡°ê±´ì„ ì¶”ê°€í•´ë³´ì„¸ìš”.\n",
        "- ìƒˆë¡œìš´ `human_review` ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•´ `messages`ì— TODOë¥¼ ë‚¨ê¸°ê³  ë‹¤ì‹œ `writer_agent`ë¡œ ì—°ê²°ë˜ë„ë¡ ì„¤ê³„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: ë¯¸ì…˜ B-1 êµ¬í˜„ ê³µê°„\n",
        "# ì•„ë˜ì— ì¡°ê±´ë¶€ handoff ë¡œì§ê³¼ human_review ì—ì´ì „íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Lab C â€“ LangGraph StateGraphë¡œ í”„ë¡œë•ì…˜ ì›Œí¬í”Œë¡œ êµ¬ì¶•\n",
        "ì´ì œ LangGraphë¥¼ í™œìš©í•´ **ê²°ì •ë¡ ì **ì´ê³  **ë³µêµ¬ ê°€ëŠ¥í•œ** HandOff íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤. `Command` ê°ì²´ë¡œ ì œì–´ê¶Œì„ ëª…í™•íˆ ë„˜ê¸°ê³ , ì²´í¬í¬ì¸íŠ¸ë¥¼ í†µí•´ ì–´ë””ì„œë“  ì¬ì‹œì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WorkflowState(TypedDict):\n",
        "    messages: List[Any]\n",
        "    current_agent: str\n",
        "    results: Dict[str, Any]\n",
        "    audit_log: List[str]\n",
        "\n",
        "workflow_memory = MemorySaver()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def router_node(state: WorkflowState) -> Command:\n",
        "    latest = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
        "    update = {\n",
        "        \"current_agent\": \"research_agent\",\n",
        "        \"audit_log\": [*state[\"audit_log\"], f\"Router â†’ Research ({latest[:30]}...)\"]\n",
        "    }\n",
        "    return Command(goto=\"research_agent\", update=update)\n",
        "\n",
        "\n",
        "def research_node(state: WorkflowState) -> Command:\n",
        "    summary = market_research_tool.func(\"AI market\")\n",
        "    update = {\n",
        "        \"current_agent\": \"research_agent\",\n",
        "        \"results\": {**state[\"results\"], \"research\": summary},\n",
        "        \"audit_log\": [*state[\"audit_log\"], \"Research ì™„ë£Œ\"],\n",
        "    }\n",
        "    return Command(goto=\"calculator_agent\", update=update)\n",
        "\n",
        "\n",
        "def calculator_node(state: WorkflowState) -> Command:\n",
        "    values = \",\".join(str(MARKET_DATA[k]) for k in [\"size_2022\", \"size_2023\", \"size_2024\"])\n",
        "    growth = growth_calculator_tool.func(values)\n",
        "    update = {\n",
        "        \"current_agent\": \"calculator_agent\",\n",
        "        \"results\": {**state[\"results\"], \"growth\": growth},\n",
        "        \"audit_log\": [*state[\"audit_log\"], \"Calculator ì™„ë£Œ\"],\n",
        "    }\n",
        "    return Command(goto=\"writer_agent\", update=update)\n",
        "\n",
        "\n",
        "def writer_node(state: WorkflowState) -> Command:\n",
        "    summary = state[\"results\"].get(\"research\", \"\")\n",
        "    forecast = state[\"results\"].get(\"growth\", \"\")\n",
        "    report = format_market_report(summary, forecast)\n",
        "    update = {\n",
        "        \"current_agent\": \"writer_agent\",\n",
        "        \"results\": {**state[\"results\"], \"report\": report},\n",
        "        \"audit_log\": [*state[\"audit_log\"], \"Writer ì™„ë£Œ\"],\n",
        "    }\n",
        "    return Command(goto=\"quality_guard\", update=update)\n",
        "\n",
        "\n",
        "def quality_guard_node(state: WorkflowState) -> Command:\n",
        "    report = state[\"results\"].get(\"report\", \"\")\n",
        "    if \"ì„±ì¥ë¥ \" not in report:\n",
        "        update = {\n",
        "            \"audit_log\": [*state[\"audit_log\"], \"Guard: ê³„ì‚° ëˆ„ë½ â†’ Calculator ì¬ì‹¤í–‰\"],\n",
        "        }\n",
        "        return Command(goto=\"calculator_agent\", update=update)\n",
        "    update = {\n",
        "        \"audit_log\": [*state[\"audit_log\"], \"Guard í†µê³¼\"],\n",
        "    }\n",
        "    return Command(goto=\"writer_signoff\", update=update)\n",
        "\n",
        "\n",
        "def writer_signoff_node(state: WorkflowState) -> Command:\n",
        "    update = {\n",
        "        \"audit_log\": [*state[\"audit_log\"], \"Writer Sign-off\"],\n",
        "    }\n",
        "    return Command(goto=END, update=update)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow = StateGraph(WorkflowState)\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"research_agent\", research_node)\n",
        "workflow.add_node(\"calculator_agent\", calculator_node)\n",
        "workflow.add_node(\"writer_agent\", writer_node)\n",
        "workflow.add_node(\"quality_guard\", quality_guard_node)\n",
        "workflow.add_node(\"writer_signoff\", writer_signoff_node)\n",
        "\n",
        "workflow.add_edge(START, \"router\")\n",
        "\n",
        "langgraph_app = workflow.compile(checkpointer=workflow_memory)\n",
        "\n",
        "print(\"âœ… LangGraph ì›Œí¬í”Œë¡œ ì»´íŒŒì¼ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "workflow_input = {\n",
        "    \"messages\": [HumanMessage(content=\"AI ì‹œì¥ ì¡°ì‚¬í•˜ê³  ì„±ì¥ë¥  ê³„ì‚°í•´ì„œ ë³´ê³ ì„œ ì¨ì¤˜\")],\n",
        "    \"current_agent\": \"user\",\n",
        "    \"results\": {},\n",
        "    \"audit_log\": [],\n",
        "}\n",
        "\n",
        "print(\"ğŸ§ª LangGraph ì‹¤í–‰\")\n",
        "print(\"-\" * 60)\n",
        "stream_graph(\n",
        "    langgraph_app,\n",
        "    workflow_input,\n",
        "    config={\"configurable\": {\"thread_id\": \"lab-c\"}},\n",
        ")\n",
        "print(\"-\" * 60)\n",
        "result = langgraph_app.invoke(workflow_input, config={\"configurable\": {\"thread_id\": \"lab-c\"}})\n",
        "print(result[\"results\"].get(\"report\", \"ê²°ê³¼ ì—†ìŒ\"))\n",
        "print(\"ê°ì‚¬ ë¡œê·¸:\")\n",
        "for log in result[\"audit_log\"]:\n",
        "    print(f\"- {log}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” ë¯¸ì…˜ C-1: HITL / ì¬ì‹œë„ ì „ëµ ì¶”ê°€\n",
        "- `quality_guard_node`ê°€ ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ëª»í–ˆì„ ë•Œ `human_review` ë…¸ë“œë¡œ ë¶„ê¸°í•˜ë„ë¡ í™•ì¥í•´ë³´ì„¸ìš”.\n",
        "- `workflow.compile`ì— `interrupt_before=[\"human_review\"]` ì˜µì…˜ì„ ì£¼ê³ , ì‚¬ìš©ì ì…ë ¥ìœ¼ë¡œ ìŠ¹ì¸/ìˆ˜ì •ì„ ë°›ëŠ” íë¦„ì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤.\n",
        "- ì¶”ê°€ë¡œ, `calculator_node` ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ì„ `Command`ë¡œ êµ¬í˜„í•´ í’ˆì§ˆì„ ê°•í™”í•´ë³´ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§­ í”„ë ˆì„ì›Œí¬ë³„ êµ¬í˜„ ê´€ì  ìš”ì•½\n",
        "| íŒ¨í„´ | ì¥ì  | í•œê³„ | ì–¸ì œ ì“°ë‚˜ |\n",
        "| --- | --- | --- | --- |\n",
        "| ReAct (Lab A) | ë¹ ë¥¸ PoC, ë„êµ¬ ë£¨í”„ ìë™í™” | ë£¨í”„ ì œì–´Â·ë³µêµ¬Â·ë³‘ë ¬ ì²˜ë¦¬ ì•½í•¨ | ë‹¨ì¼ ì—ì´ì „íŠ¸ + ì†Œê·œëª¨ íƒœìŠ¤í¬ |\n",
        "| Swarm HandOffs (Lab B) | ìƒíƒœ ì¸ê³„ ëª…í™•, ê²½ëŸ‰ ë¼ìš°íŒ… | ê°ì‚¬ ë¡œê·¸Â·ì¬ì‹œë„Â·íŒ¬ì¸ ì„¤ê³„ ì§ì ‘ êµ¬í˜„ í•„ìš” | ì‘ì€ íŒ€/ê°„ë‹¨í•œ ë¶„ê¸° |\n",
        "| LangGraph StateGraph (Lab C) | ê²°ì •ë¡ , ì²´í¬í¬ì¸íŠ¸, ê°€ë“œ, ë³‘ë ¬/ì¬ì‹œë„ ë‚´ì¥ | ì´ˆê¸° ì„¤ê³„ ë¹„ìš©, ê·¸ë˜í”„ ì •ì˜ í•„ìš” | í”„ë¡œë•ì…˜/ê·œëª¨ ìˆëŠ” ìë™í™” |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… ë§ˆë¬´ë¦¬ ì²´í¬í¬ì¸íŠ¸\n",
        "- [ ] ReAct ë£¨í”„ì˜ ìµœëŒ€ ìŠ¤í…Â·ì¢…ë£Œ ì¡°ê±´ì„ ì§ì ‘ ì œì–´í–ˆë‹¤.\n",
        "- [ ] Swarm HandOffsì—ì„œ ìƒíƒœì™€ ì»¨í…ìŠ¤íŠ¸ ì¸ê³„ íë¦„ì„ êµ¬í˜„í–ˆë‹¤.\n",
        "- [ ] LangGraph `Command`ì™€ ì²´í¬í¬ì¸íŠ¸ë¡œ í”„ë¡œë•ì…˜ ì›Œí¬í”Œë¡œë¥¼ ì‹¤í–‰í–ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
        "1. LangGraph ê·¸ë˜í”„ì— ë³‘ë ¬ ì¡°(íŒ¬ì•„ì›ƒ) ë…¸ë“œë¥¼ ì¶”ê°€í•´ ë³´ê³ ì„œë¥¼ ì´ë¯¸ì§€/ìˆ«ì ë²„ì „ìœ¼ë¡œ ë¶„ê¸°í•´ë³´ì„¸ìš”.\n",
        "2. ì‹¤ì‹œê°„ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì—°ê²°í•  MCP ë˜ëŠ” ì™¸ë¶€ API ì—ì´ì „íŠ¸ë¥¼ ë¶™ì—¬ë³´ì„¸ìš”.\n",
        "3. `workflow_memory` ëŒ€ì‹  Redisë‚˜ Postgres ì²´í¬í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•´ ì¥ê¸° ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤í—˜í•´ë³´ì„¸ìš”.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}